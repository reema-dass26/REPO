{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ff24f2a-931c-4543-b179-dc8bf1bfd74d",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "########################################################\n",
    "# EXPERIMENT CODE\n",
    "########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f97a375-387a-4368-a629-556f56f51dcc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "import platform\n",
    "import sys\n",
    "import uuid\n",
    "from datetime import datetime\n",
    "\n",
    "def prompt_if_none(env_key, prompt_text, default_value=\"unknown\"):\n",
    "    val = os.getenv(env_key)\n",
    "    if not val:\n",
    "        try:\n",
    "            val = input(f\"{prompt_text} (default: {default_value}): \").strip() or default_value\n",
    "        except Exception:\n",
    "            val = default_value\n",
    "    return val\n",
    "\n",
    "def collect_session_metadata(\n",
    "    prompt_fields=True,\n",
    "    fixed_role=None,\n",
    "    fixed_project_id=None\n",
    "):\n",
    "    session_id = str(uuid.uuid4())\n",
    "    \n",
    "    session_metadata = {\n",
    "        \"session_id\": session_id,\n",
    "        \"username\": os.getenv(\"JUPYTERHUB_USER\", getpass.getuser()),\n",
    "        \"timestamp_utc\": datetime.utcnow().isoformat(),\n",
    "        \"hostname\": platform.node(),\n",
    "        \"platform\": platform.system(),\n",
    "        \"os_version\": platform.version(),\n",
    "        \"python_version\": sys.version.split()[0],\n",
    "    }\n",
    "\n",
    "    # Prompt or use defaults\n",
    "    session_metadata[\"role\"] = fixed_role or (\n",
    "        prompt_if_none(\"RESEARCHER_ROLE\", \"Enter your role\", \"collaborator\") if prompt_fields \n",
    "        else os.getenv(\"RESEARCHER_ROLE\", \"researcher\")\n",
    "    )\n",
    "    session_metadata[\"project_id\"] = fixed_project_id or (\n",
    "        prompt_if_none(\"PROJECT_ID\", \"Enter project ID\", \"default_project\") if prompt_fields \n",
    "        else os.getenv(\"PROJECT_ID\", \"default_project\")\n",
    "    )\n",
    "\n",
    "    print(\"\\n📌 Session Metadata:\")\n",
    "    for k, v in session_metadata.items():\n",
    "        print(f\"  {k}: {v}\")\n",
    "\n",
    "    return session_metadata\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca4f0ae-39ee-4b22-b013-dfb1fa1b5694",
   "metadata": {},
   "source": [
    "LIBRARY IMPORTS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ca332e5-6501-4310-920b-2b769477b46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# 📦 Standard Library Imports\n",
    "# ============================\n",
    "import os\n",
    "import glob\n",
    "import io\n",
    "import json\n",
    "import time\n",
    "import ast\n",
    "import pickle\n",
    "import platform\n",
    "import subprocess\n",
    "from datetime import datetime, timezone\n",
    "from pprint import pprint\n",
    "from typing import List, Dict, Any\n",
    "import xml.etree.ElementTree as ET\n",
    "import urllib.parse\n",
    "import yaml\n",
    "\n",
    "# ============================\n",
    "# 📊 Data and Visualization\n",
    "# ============================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ============================\n",
    "# 🤖 Machine Learning\n",
    "# ============================\n",
    "import sklearn\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, label_binarize\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    roc_auc_score,\n",
    "    confusion_matrix,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    RocCurveDisplay,\n",
    "    PrecisionRecallDisplay\n",
    ")\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "# ============================\n",
    "# 🔬 Experiment Tracking\n",
    "# ============================\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow import MlflowClient\n",
    "\n",
    "# ============================\n",
    "# 🌐 Web / API / Networking\n",
    "# ============================\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ============================\n",
    "# 🧪 Git & Version Control\n",
    "# ============================\n",
    "import git\n",
    "from git import Repo, GitCommandError\n",
    "import hashlib\n",
    "\n",
    "\n",
    "# ============================\n",
    "# 🧠 SHAP for Explainability\n",
    "# ============================\n",
    "import shap\n",
    "\n",
    "# ============================\n",
    "# 🧬 RDF & Provenance (rdflib)\n",
    "# ============================\n",
    "from rdflib import Graph, URIRef, Literal\n",
    "from rdflib.namespace import PROV, XSD\n",
    "\n",
    "# ============================\n",
    "# ⚙️ System Monitoring\n",
    "# ============================\n",
    "import psutil\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfde18b5-ae9c-442c-a5b3-7dfb06957646",
   "metadata": {},
   "source": [
    "#Dataset metadata!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a394398-cd25-45b5-89ac-6d909b65d417",
   "metadata": {},
   "source": [
    "#Metadata from ZONEDO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceba00ff-139b-4433-ab7d-2170cd137012",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79c3e945-508a-4c1c-8bb1-c1b5d9121615",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def extract_dataset_metadata_from_doi(doi: str) -> dict:\n",
    "    base_url = f\"https://api.datacite.org/dois/{doi.lower()}\"\n",
    "    r = requests.get(base_url)\n",
    "    r.raise_for_status()\n",
    "    meta = r.json().get(\"data\", {}).get(\"attributes\", {})\n",
    "\n",
    "    # Extract fields\n",
    "    title = meta.get(\"titles\", [{}])[0].get(\"title\", \"info not available\")\n",
    "    creators = [c.get(\"name\", \"\") for c in meta.get(\"creators\", [])]\n",
    "    publisher = meta.get(\"publisher\", \"info not available\")\n",
    "    pub_year = meta.get(\"publicationYear\", \"info not available\")\n",
    "    url = meta.get(\"url\", f\"https://doi.org/{doi}\")\n",
    "\n",
    "    dataset_metadata = {\n",
    "        \"dataset_id\": doi,\n",
    "        \"dataset_title\": title,\n",
    "        \"dataset_description\": meta.get(\"descriptions\", \"info not available\"),\n",
    "        \"dataset_creator\": \", \".join(creators) if creators else \"info not available\",\n",
    "        \"dataset_publisher\": publisher,\n",
    "        \"dataset_publication_date\": pub_year,\n",
    "        \"dataset_version\": meta.get(\"version\", \"info not available\"),\n",
    "        \"dataset_license\": meta.get(\"rightsList\", \"info not available\"),\n",
    "        \"dataset_keywords\": \"info not available\",  # not always exposed\n",
    "        \"dataset_access_url\": url,\n",
    "        \"dataset_documentation\": url,\n",
    "        \"metadata_standard\": meta.get(\"types\", {}).get(\"resourceTypeGeneral\", \"info not available\"),\n",
    "        \"related_resources\": url,\n",
    "\n",
    "        # PROV-O traceability fields\n",
    "        \"prov_entity\": title,\n",
    "        \"prov_activity\": \"Ingestion and Publication\",\n",
    "        \"prov_agent_dataset_creator\": \", \".join(creators) if creators else \"info not available\",\n",
    "        \"prov_used\": url,\n",
    "        \"prov_wasDerivedFrom\": doi,\n",
    "        \"prov_wasAttributedTo\": \", \".join(creators) if creators else \"info not available\",\n",
    "        \"prov_startedAtTime\": pub_year,\n",
    "        \"prov_role_dataset_creator\": \"Original Data Author\",\n",
    "        \"prov_role_database_creator\": \"Database Ingestor and Maintainer\"\n",
    "    }\n",
    "\n",
    "    return dataset_metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "529b2898-a4e7-4f5b-a1eb-c44f78620414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract_dataset_metadata_from_doi(\"10.24432/C56C76\") #dataset related metadata logging \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ee5cf89-7c47-4601-b57c-04415d5966c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "DB_API = \"http://localhost/api/database/{db_id}\"\n",
    "HISTORY_API = \"http://localhost/api/database/{db_id}/table/{table_id}/history\"\n",
    "\n",
    "def fetch_db_dataset_metadata(\n",
    "    db_id: str,\n",
    "    table_id: str,\n",
    "    selected_version: str,\n",
    "    target_variable: str,\n",
    "    num_samples: int\n",
    ") -> dict:\n",
    "    try:\n",
    "        # Fetch main DB metadata\n",
    "        db_url = DB_API.format(db_id=db_id)\n",
    "        db_response = requests.get(db_url)\n",
    "        db_response.raise_for_status()\n",
    "        db_data = db_response.json()\n",
    "        print(db_data)\n",
    "\n",
    "        # Fetch table history metadata\n",
    "        history_url = HISTORY_API.format(db_id=db_id, table_id=table_id)\n",
    "        history_response = requests.get(history_url)\n",
    "        timestamp = \"info not available\"\n",
    "        if history_response.status_code == 200:\n",
    "            history_data = history_response.json()\n",
    "            print(history_data)\n",
    "            if isinstance(history_data, list) and len(history_data) > 0:\n",
    "                timestamp = history_data[0].get(\"timestamp\", timestamp)\n",
    "\n",
    "        # Build flat metadata structure for DB storage\n",
    "        dataset_metadata = {\n",
    "            # Basic identity\n",
    "            \"dataset_id\": table_id,\n",
    "            \"dataset_name\": next(\n",
    "                (t.get(\"name\") for t in db_data.get(\"tables\", []) if t.get(\"id\") == table_id),\n",
    "                \"table name not available\"\n",
    "            ),\n",
    "            \"dataset_version\": selected_version,\n",
    "            \"dataset_title\": db_data.get(\"name\", \"info not available\"),\n",
    "            \"dataset_description\": db_data.get(\"description\", \"info not available\"),\n",
    "\n",
    "            # Ownership and access\n",
    "            \"dataset_creator\": \"info not available\",\n",
    "            \"dataset_publisher\": db_data.get(\"owner\", {}).get(\"name\", \"info not available\"),\n",
    "            \"dataset_access_url\": db_url,\n",
    "            \"dataset_publication_date\": timestamp,\n",
    "            \"dataset_license\": \"info not available\",\n",
    "\n",
    "            # Structure\n",
    "            \"columns\": db_data.get(\"columns\", \"info not available\"),\n",
    "            \"dataset_dataset_type\": \"tabular\",\n",
    "            \"target_variable\": target_variable,\n",
    "            \"ml_task\": \"classification\",\n",
    "            \"num_samples\": num_samples,\n",
    "\n",
    "            # FAIR4ML placeholders\n",
    "            \"data_distribution\": \"info not available\",\n",
    "            \"known_issues\": \"info not available\",\n",
    "            \"trainedOn\": \"info not available\",\n",
    "            \"testedOn\": \"info not available\",\n",
    "            \"validatedOn\": \"info not available\",\n",
    "            \"modelRisks\": \"info not available\",\n",
    "            \"usageInstructions\": \"info not available\",\n",
    "            \"ethicalLegalSocial\": \"info not available\",\n",
    "\n",
    "            # PROV-style fields\n",
    "            \"prov_entity\": db_data.get(\"name\", \"info not available\"),\n",
    "            \"prov_activity\": \"Ingestion and Publication\",\n",
    "            \"prov_agent_dataset_creator\": \"info not available\",\n",
    "            \"prov_agent_database_creator\": db_data.get('owner', {}).get('name', 'info not available'),\n",
    "            \"prov_wasGeneratedBy\": db_data.get('owner', {}).get('name', 'info not available'),\n",
    "            \"prov_used\": db_url,\n",
    "            \"prov_wasDerivedFrom\": \"info not available\",\n",
    "            \"prov_wasAttributedTo\": \"info not available\",\n",
    "            \"prov_wasAssociatedWith\": db_data.get('owner', {}).get('name', 'info not available'),\n",
    "            \"prov_startedAtTime\": \"info not available\",\n",
    "            \"prov_endedAtTime\": timestamp,\n",
    "            \"prov_location\": db_url,\n",
    "            \"prov_role_dataset_creator\": \"\",\n",
    "            \"prov_role_database_creator\": \"Database Ingestor and Maintainer\"\n",
    "        }\n",
    "\n",
    "        return dataset_metadata\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"[⚠️ Error] Failed to fetch DB metadata for {db_id}: {e}\")\n",
    "        return {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b61178-0a4a-48d5-8b6f-737104605005",
   "metadata": {},
   "source": [
    "Fetch info needed to fetch metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91e0611d-d579-485a-ac24-094c1890bc2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select dataset version:\n",
      "  v0 - Original\n",
      "  v1 - Duplicated\n",
      "  v2 - First 100\n",
      "  v3 - Shuffled\n",
      "  v4 - Normalized\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter version (v0–v4):  v4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ You selected version 'v4' → Table ID: 3cb219b2-8cc6-4698-b69f-213deacc763c\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Mapping of version tags to table UUIDs\n",
    "version_to_table_id = {\n",
    "    \"v0\": \"519eb3fc-687c-4791-aa13-96d5bee8cbad\",  # Original\n",
    "    \"v1\": \"3fd0f36e-572e-4f99-841b-a8381a052a97\",  # Duplicated\n",
    "    \"v2\": \"2a8083fa-8270-49c1-80ea-86ce6bf39977\",  # First 100\n",
    "    \"v3\": \"14cc6f38-b5c6-4225-83ce-3dc92b7c045a\",  # Shuffled\n",
    "    \"v4\": \"3cb219b2-8cc6-4698-b69f-213deacc763c\"   # Normalized\n",
    "}\n",
    "\n",
    "db_id = \"4bd4ddc7-378c-4ffa-8bdb-0bf8969c80a1\"  # Static DB ID\n",
    "\n",
    "def select_dataset_version():\n",
    "    print(\"Select dataset version:\")\n",
    "    print(\"  v0 - Original\")\n",
    "    print(\"  v1 - Duplicated\")\n",
    "    print(\"  v2 - First 100\")\n",
    "    print(\"  v3 - Shuffled\")\n",
    "    print(\"  v4 - Normalized\")\n",
    "    \n",
    "    selected_version = input(\"Enter version (v0–v4): \").strip().lower()\n",
    "    \n",
    "    if selected_version not in version_to_table_id:\n",
    "        raise ValueError(f\"❌ Invalid version selected: {selected_version}\")\n",
    "    \n",
    "    selected_table_id = version_to_table_id[selected_version]\n",
    "    \n",
    "    print(f\"\\n✅ You selected version '{selected_version}' → Table ID: {selected_table_id}\\n\")\n",
    "    \n",
    "    return selected_version, selected_table_id\n",
    "\n",
    "# Usage: #TODO CALL\n",
    "selected_version, selected_table_id = select_dataset_version()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aab28b04-4db7-43bf-8320-f6382120984a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import mlflow\n",
    "# \n",
    "def log_metadata_dict_to_mlflow(metadata: dict, prefix: str = \"\", snapshot_name: str = \"metadata_snapshot.json\"):\n",
    "    \"\"\"\n",
    "    Logs a flat metadata dictionary to MLflow:\n",
    "    - Adds prefix to each key if provided (e.g., \"session_\")\n",
    "    - Skips empty values\n",
    "    - Logs a full JSON artifact for traceability\n",
    "    \"\"\"\n",
    "    \n",
    "    def safe_tag(key, value):\n",
    "        if not mlflow.active_run():\n",
    "            raise RuntimeError(\"❌ No active MLflow run.\")\n",
    "        \n",
    "        key_clean = key.replace(\":\", \"_\").replace(\"/\", \"_\").replace(\" \", \"_\")\n",
    "        try:\n",
    "            val_str = json.dumps(value) if isinstance(value, (dict, list)) else str(value)\n",
    "            if len(val_str) > 5000:\n",
    "                val_str = val_str[:5000] + \"...[TRUNCATED]\"\n",
    "            if len(key_clean) > 255:\n",
    "                print(f\"⚠️ Skipped tag (key too long): {key_clean}\")\n",
    "                return\n",
    "            mlflow.set_tag(key_clean, val_str)\n",
    "            print(f\"✅ Logged tag: {key_clean}\")\n",
    "        except Exception as e:\n",
    "            print(f\"[⚠️ Error logging tag] {key_clean}: {e}\")\n",
    "\n",
    "    for key, value in metadata.items():\n",
    "        if value not in [None, \"\"]:\n",
    "            full_key = f\"{prefix}{key}\" if prefix else key\n",
    "            safe_tag(full_key, value)\n",
    "\n",
    "    # Save full metadata snapshot as JSON artifact\n",
    "    os.makedirs(\"metadata\", exist_ok=True)\n",
    "    full_path = os.path.join(\"metadata\", snapshot_name)\n",
    "    with open(full_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(metadata, f, indent=2)\n",
    "    \n",
    "    mlflow.log_artifact(full_path, artifact_path=\"metadata\")\n",
    "    print(f\"📁 Full metadata snapshot logged as: {snapshot_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063803f5-8a93-420a-8a98-d2b5371c9574",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "61d4d6b8-34a9-47b5-974d-5927c0ee2256",
   "metadata": {},
   "source": [
    "DBREPO INTEGRETION: API call to fetch the dataset for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e3570e2-9a60-45b4-8653-28060071e728",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': '1', 'sepallengthcm': '0.222222222222222100', 'sepalwidthcm': '0.625000000000000000', 'petallengthcm': '0.067796610169491510', 'petalwidthcm': '0.041666666666666670', 'species': 'Iris-setosa'}, {'id': '2', 'sepallengthcm': '0.166666666666666740', 'sepalwidthcm': '0.416666666666666740', 'petallengthcm': '0.067796610169491510', 'petalwidthcm': '0.041666666666666670', 'species': 'Iris-setosa'}, {'id': '3', 'sepallengthcm': '0.111111111111111160', 'sepalwidthcm': '0.500000000000000000', 'petallengthcm': '0.050847457627118650', 'petalwidthcm': '0.041666666666666670', 'species': 'Iris-setosa'}, {'id': '4', 'sepallengthcm': '0.083333333333333260', 'sepalwidthcm': '0.458333333333333260', 'petallengthcm': '0.084745762711864400', 'petalwidthcm': '0.041666666666666670', 'species': 'Iris-setosa'}, {'id': '5', 'sepallengthcm': '0.194444444444444420', 'sepalwidthcm': '0.666666666666666700', 'petallengthcm': '0.067796610169491510', 'petalwidthcm': '0.041666666666666670', 'species': 'Iris-setosa'}, {'id': '6', 'sepallengthcm': '0.305555555555555600', 'sepalwidthcm': '0.791666666666666500', 'petallengthcm': '0.118644067796610130', 'petalwidthcm': '0.125000000000000000', 'species': 'Iris-setosa'}, {'id': '7', 'sepallengthcm': '0.083333333333333260', 'sepalwidthcm': '0.583333333333333300', 'petallengthcm': '0.067796610169491510', 'petalwidthcm': '0.083333333333333330', 'species': 'Iris-setosa'}, {'id': '8', 'sepallengthcm': '0.194444444444444420', 'sepalwidthcm': '0.583333333333333300', 'petallengthcm': '0.084745762711864400', 'petalwidthcm': '0.041666666666666670', 'species': 'Iris-setosa'}, {'id': '9', 'sepallengthcm': '0.027777777777777900', 'sepalwidthcm': '0.375000000000000000', 'petallengthcm': '0.067796610169491510', 'petalwidthcm': '0.041666666666666670', 'species': 'Iris-setosa'}, {'id': '10', 'sepallengthcm': '0.166666666666666740', 'sepalwidthcm': '0.458333333333333260', 'petallengthcm': '0.084745762711864400', 'petalwidthcm': '0E-18', 'species': 'Iris-setosa'}, {'id': '11', 'sepallengthcm': '0.305555555555555600', 'sepalwidthcm': '0.708333333333333300', 'petallengthcm': '0.084745762711864400', 'petalwidthcm': '0.041666666666666670', 'species': 'Iris-setosa'}, {'id': '12', 'sepallengthcm': '0.138888888888888840', 'sepalwidthcm': '0.583333333333333300', 'petallengthcm': '0.101694915254237300', 'petalwidthcm': '0.041666666666666670', 'species': 'Iris-setosa'}, {'id': '13', 'sepallengthcm': '0.138888888888888840', 'sepalwidthcm': '0.416666666666666740', 'petallengthcm': '0.067796610169491510', 'petalwidthcm': '0E-18', 'species': 'Iris-setosa'}, {'id': '14', 'sepallengthcm': '0E-18', 'sepalwidthcm': '0.416666666666666740', 'petallengthcm': '0.016949152542372890', 'petalwidthcm': '0E-18', 'species': 'Iris-setosa'}, {'id': '15', 'sepallengthcm': '0.416666666666666500', 'sepalwidthcm': '0.833333333333333300', 'petallengthcm': '0.033898305084745756', 'petalwidthcm': '0.041666666666666670', 'species': 'Iris-setosa'}, {'id': '16', 'sepallengthcm': '0.388888888888888840', 'sepalwidthcm': '1.000000000000000000', 'petallengthcm': '0.084745762711864400', 'petalwidthcm': '0.125000000000000000', 'species': 'Iris-setosa'}, {'id': '17', 'sepallengthcm': '0.305555555555555600', 'sepalwidthcm': '0.791666666666666500', 'petallengthcm': '0.050847457627118650', 'petalwidthcm': '0.125000000000000000', 'species': 'Iris-setosa'}, {'id': '18', 'sepallengthcm': '0.222222222222222100', 'sepalwidthcm': '0.625000000000000000', 'petallengthcm': '0.067796610169491510', 'petalwidthcm': '0.083333333333333330', 'species': 'Iris-setosa'}, {'id': '19', 'sepallengthcm': '0.388888888888888840', 'sepalwidthcm': '0.749999999999999800', 'petallengthcm': '0.118644067796610130', 'petalwidthcm': '0.083333333333333330', 'species': 'Iris-setosa'}, {'id': '20', 'sepallengthcm': '0.222222222222222100', 'sepalwidthcm': '0.749999999999999800', 'petallengthcm': '0.084745762711864400', 'petalwidthcm': '0.083333333333333330', 'species': 'Iris-setosa'}, {'id': '21', 'sepallengthcm': '0.305555555555555600', 'sepalwidthcm': '0.583333333333333300', 'petallengthcm': '0.118644067796610130', 'petalwidthcm': '0.041666666666666670', 'species': 'Iris-setosa'}, {'id': '22', 'sepallengthcm': '0.222222222222222100', 'sepalwidthcm': '0.708333333333333300', 'petallengthcm': '0.084745762711864400', 'petalwidthcm': '0.125000000000000000', 'species': 'Iris-setosa'}, {'id': '23', 'sepallengthcm': '0.083333333333333260', 'sepalwidthcm': '0.666666666666666700', 'petallengthcm': '0E-18', 'petalwidthcm': '0.041666666666666670', 'species': 'Iris-setosa'}, {'id': '24', 'sepallengthcm': '0.222222222222222100', 'sepalwidthcm': '0.541666666666666500', 'petallengthcm': '0.118644067796610130', 'petalwidthcm': '0.166666666666666690', 'species': 'Iris-setosa'}, {'id': '25', 'sepallengthcm': '0.138888888888888840', 'sepalwidthcm': '0.583333333333333300', 'petallengthcm': '0.152542372881355910', 'petalwidthcm': '0.041666666666666670', 'species': 'Iris-setosa'}, {'id': '26', 'sepallengthcm': '0.194444444444444420', 'sepalwidthcm': '0.416666666666666740', 'petallengthcm': '0.101694915254237300', 'petalwidthcm': '0.041666666666666670', 'species': 'Iris-setosa'}, {'id': '27', 'sepallengthcm': '0.194444444444444420', 'sepalwidthcm': '0.583333333333333300', 'petallengthcm': '0.101694915254237300', 'petalwidthcm': '0.125000000000000000', 'species': 'Iris-setosa'}, {'id': '28', 'sepallengthcm': '0.250000000000000000', 'sepalwidthcm': '0.625000000000000000', 'petallengthcm': '0.084745762711864400', 'petalwidthcm': '0.041666666666666670', 'species': 'Iris-setosa'}, {'id': '29', 'sepallengthcm': '0.250000000000000000', 'sepalwidthcm': '0.583333333333333300', 'petallengthcm': '0.067796610169491510', 'petalwidthcm': '0.041666666666666670', 'species': 'Iris-setosa'}, {'id': '30', 'sepallengthcm': '0.111111111111111160', 'sepalwidthcm': '0.500000000000000000', 'petallengthcm': '0.101694915254237300', 'petalwidthcm': '0.041666666666666670', 'species': 'Iris-setosa'}, {'id': '31', 'sepallengthcm': '0.138888888888888840', 'sepalwidthcm': '0.458333333333333260', 'petallengthcm': '0.101694915254237300', 'petalwidthcm': '0.041666666666666670', 'species': 'Iris-setosa'}, {'id': '32', 'sepallengthcm': '0.305555555555555600', 'sepalwidthcm': '0.583333333333333300', 'petallengthcm': '0.084745762711864400', 'petalwidthcm': '0.125000000000000000', 'species': 'Iris-setosa'}, {'id': '33', 'sepallengthcm': '0.250000000000000000', 'sepalwidthcm': '0.874999999999999800', 'petallengthcm': '0.084745762711864400', 'petalwidthcm': '0E-18', 'species': 'Iris-setosa'}, {'id': '34', 'sepallengthcm': '0.333333333333333260', 'sepalwidthcm': '0.916666666666666700', 'petallengthcm': '0.067796610169491510', 'petalwidthcm': '0.041666666666666670', 'species': 'Iris-setosa'}, {'id': '35', 'sepallengthcm': '0.166666666666666740', 'sepalwidthcm': '0.458333333333333260', 'petallengthcm': '0.084745762711864400', 'petalwidthcm': '0E-18', 'species': 'Iris-setosa'}, {'id': '36', 'sepallengthcm': '0.194444444444444420', 'sepalwidthcm': '0.500000000000000000', 'petallengthcm': '0.033898305084745756', 'petalwidthcm': '0.041666666666666670', 'species': 'Iris-setosa'}, {'id': '37', 'sepallengthcm': '0.333333333333333260', 'sepalwidthcm': '0.625000000000000000', 'petallengthcm': '0.050847457627118650', 'petalwidthcm': '0.041666666666666670', 'species': 'Iris-setosa'}, {'id': '38', 'sepallengthcm': '0.166666666666666740', 'sepalwidthcm': '0.458333333333333260', 'petallengthcm': '0.084745762711864400', 'petalwidthcm': '0E-18', 'species': 'Iris-setosa'}, {'id': '39', 'sepallengthcm': '0.027777777777777900', 'sepalwidthcm': '0.416666666666666740', 'petallengthcm': '0.050847457627118650', 'petalwidthcm': '0.041666666666666670', 'species': 'Iris-setosa'}, {'id': '40', 'sepallengthcm': '0.222222222222222100', 'sepalwidthcm': '0.583333333333333300', 'petallengthcm': '0.084745762711864400', 'petalwidthcm': '0.041666666666666670', 'species': 'Iris-setosa'}, {'id': '41', 'sepallengthcm': '0.194444444444444420', 'sepalwidthcm': '0.625000000000000000', 'petallengthcm': '0.050847457627118650', 'petalwidthcm': '0.083333333333333330', 'species': 'Iris-setosa'}, {'id': '42', 'sepallengthcm': '0.055555555555555580', 'sepalwidthcm': '0.124999999999999890', 'petallengthcm': '0.050847457627118650', 'petalwidthcm': '0.083333333333333330', 'species': 'Iris-setosa'}, {'id': '43', 'sepallengthcm': '0.027777777777777900', 'sepalwidthcm': '0.500000000000000000', 'petallengthcm': '0.050847457627118650', 'petalwidthcm': '0.041666666666666670', 'species': 'Iris-setosa'}, {'id': '44', 'sepallengthcm': '0.194444444444444420', 'sepalwidthcm': '0.625000000000000000', 'petallengthcm': '0.101694915254237300', 'petalwidthcm': '0.208333333333333310', 'species': 'Iris-setosa'}, {'id': '45', 'sepallengthcm': '0.222222222222222100', 'sepalwidthcm': '0.749999999999999800', 'petallengthcm': '0.152542372881355910', 'petalwidthcm': '0.125000000000000000', 'species': 'Iris-setosa'}, {'id': '46', 'sepallengthcm': '0.138888888888888840', 'sepalwidthcm': '0.416666666666666740', 'petallengthcm': '0.067796610169491510', 'petalwidthcm': '0.083333333333333330', 'species': 'Iris-setosa'}, {'id': '47', 'sepallengthcm': '0.222222222222222100', 'sepalwidthcm': '0.749999999999999800', 'petallengthcm': '0.101694915254237300', 'petalwidthcm': '0.041666666666666670', 'species': 'Iris-setosa'}, {'id': '48', 'sepallengthcm': '0.083333333333333260', 'sepalwidthcm': '0.500000000000000000', 'petallengthcm': '0.067796610169491510', 'petalwidthcm': '0.041666666666666670', 'species': 'Iris-setosa'}, {'id': '49', 'sepallengthcm': '0.277777777777777700', 'sepalwidthcm': '0.708333333333333300', 'petallengthcm': '0.084745762711864400', 'petalwidthcm': '0.041666666666666670', 'species': 'Iris-setosa'}, {'id': '50', 'sepallengthcm': '0.194444444444444420', 'sepalwidthcm': '0.541666666666666500', 'petallengthcm': '0.067796610169491510', 'petalwidthcm': '0.041666666666666670', 'species': 'Iris-setosa'}, {'id': '51', 'sepallengthcm': '0.750000000000000000', 'sepalwidthcm': '0.500000000000000000', 'petallengthcm': '0.627118644067796600', 'petalwidthcm': '0.541666666666666700', 'species': 'Iris-versicolor'}, {'id': '52', 'sepallengthcm': '0.583333333333333500', 'sepalwidthcm': '0.500000000000000000', 'petallengthcm': '0.593220338983050800', 'petalwidthcm': '0.583333333333333400', 'species': 'Iris-versicolor'}, {'id': '53', 'sepallengthcm': '0.722222222222222300', 'sepalwidthcm': '0.458333333333333260', 'petallengthcm': '0.661016949152542400', 'petalwidthcm': '0.583333333333333400', 'species': 'Iris-versicolor'}, {'id': '54', 'sepallengthcm': '0.333333333333333260', 'sepalwidthcm': '0.124999999999999890', 'petallengthcm': '0.508474576271186400', 'petalwidthcm': '0.500000000000000100', 'species': 'Iris-versicolor'}, {'id': '55', 'sepallengthcm': '0.611111111111111200', 'sepalwidthcm': '0.333333333333333260', 'petallengthcm': '0.610169491525423700', 'petalwidthcm': '0.583333333333333400', 'species': 'Iris-versicolor'}, {'id': '56', 'sepallengthcm': '0.388888888888888840', 'sepalwidthcm': '0.333333333333333260', 'petallengthcm': '0.593220338983050800', 'petalwidthcm': '0.500000000000000100', 'species': 'Iris-versicolor'}, {'id': '57', 'sepallengthcm': '0.555555555555555600', 'sepalwidthcm': '0.541666666666666500', 'petallengthcm': '0.627118644067796600', 'petalwidthcm': '0.625000000000000100', 'species': 'Iris-versicolor'}, {'id': '58', 'sepallengthcm': '0.166666666666666740', 'sepalwidthcm': '0.166666666666666630', 'petallengthcm': '0.389830508474576230', 'petalwidthcm': '0.375000000000000000', 'species': 'Iris-versicolor'}, {'id': '59', 'sepallengthcm': '0.638888888888888800', 'sepalwidthcm': '0.375000000000000000', 'petallengthcm': '0.610169491525423700', 'petalwidthcm': '0.500000000000000100', 'species': 'Iris-versicolor'}, {'id': '60', 'sepallengthcm': '0.250000000000000000', 'sepalwidthcm': '0.291666666666666740', 'petallengthcm': '0.491525423728813470', 'petalwidthcm': '0.541666666666666700', 'species': 'Iris-versicolor'}, {'id': '61', 'sepallengthcm': '0.194444444444444420', 'sepalwidthcm': '0E-18', 'petallengthcm': '0.423728813559322000', 'petalwidthcm': '0.375000000000000000', 'species': 'Iris-versicolor'}, {'id': '62', 'sepallengthcm': '0.444444444444444640', 'sepalwidthcm': '0.416666666666666740', 'petallengthcm': '0.542372881355932200', 'petalwidthcm': '0.583333333333333400', 'species': 'Iris-versicolor'}, {'id': '63', 'sepallengthcm': '0.472222222222222300', 'sepalwidthcm': '0.083333333333333370', 'petallengthcm': '0.508474576271186400', 'petalwidthcm': '0.375000000000000000', 'species': 'Iris-versicolor'}, {'id': '64', 'sepallengthcm': '0.499999999999999800', 'sepalwidthcm': '0.375000000000000000', 'petallengthcm': '0.627118644067796600', 'petalwidthcm': '0.541666666666666700', 'species': 'Iris-versicolor'}, {'id': '65', 'sepallengthcm': '0.361111111111110940', 'sepalwidthcm': '0.375000000000000000', 'petallengthcm': '0.440677966101694960', 'petalwidthcm': '0.500000000000000100', 'species': 'Iris-versicolor'}, {'id': '66', 'sepallengthcm': '0.666666666666666700', 'sepalwidthcm': '0.458333333333333260', 'petallengthcm': '0.576271186440678000', 'petalwidthcm': '0.541666666666666700', 'species': 'Iris-versicolor'}, {'id': '67', 'sepallengthcm': '0.361111111111110940', 'sepalwidthcm': '0.416666666666666740', 'petallengthcm': '0.593220338983050800', 'petalwidthcm': '0.583333333333333400', 'species': 'Iris-versicolor'}, {'id': '68', 'sepallengthcm': '0.416666666666666500', 'sepalwidthcm': '0.291666666666666740', 'petallengthcm': '0.525423728813559300', 'petalwidthcm': '0.375000000000000000', 'species': 'Iris-versicolor'}, {'id': '69', 'sepallengthcm': '0.527777777777777900', 'sepalwidthcm': '0.083333333333333370', 'petallengthcm': '0.593220338983050800', 'petalwidthcm': '0.583333333333333400', 'species': 'Iris-versicolor'}, {'id': '70', 'sepallengthcm': '0.361111111111110940', 'sepalwidthcm': '0.208333333333333260', 'petallengthcm': '0.491525423728813470', 'petalwidthcm': '0.416666666666666700', 'species': 'Iris-versicolor'}, {'id': '71', 'sepallengthcm': '0.444444444444444640', 'sepalwidthcm': '0.500000000000000000', 'petallengthcm': '0.644067796610169400', 'petalwidthcm': '0.708333333333333400', 'species': 'Iris-versicolor'}, {'id': '72', 'sepallengthcm': '0.499999999999999800', 'sepalwidthcm': '0.333333333333333260', 'petallengthcm': '0.508474576271186400', 'petalwidthcm': '0.500000000000000100', 'species': 'Iris-versicolor'}, {'id': '73', 'sepallengthcm': '0.555555555555555600', 'sepalwidthcm': '0.208333333333333260', 'petallengthcm': '0.661016949152542400', 'petalwidthcm': '0.583333333333333400', 'species': 'Iris-versicolor'}, {'id': '74', 'sepallengthcm': '0.499999999999999800', 'sepalwidthcm': '0.333333333333333260', 'petallengthcm': '0.627118644067796600', 'petalwidthcm': '0.458333333333333300', 'species': 'Iris-versicolor'}, {'id': '75', 'sepallengthcm': '0.583333333333333500', 'sepalwidthcm': '0.375000000000000000', 'petallengthcm': '0.559322033898305000', 'petalwidthcm': '0.500000000000000100', 'species': 'Iris-versicolor'}, {'id': '76', 'sepallengthcm': '0.638888888888888800', 'sepalwidthcm': '0.416666666666666740', 'petallengthcm': '0.576271186440678000', 'petalwidthcm': '0.541666666666666700', 'species': 'Iris-versicolor'}, {'id': '77', 'sepallengthcm': '0.694444444444444400', 'sepalwidthcm': '0.333333333333333260', 'petallengthcm': '0.644067796610169400', 'petalwidthcm': '0.541666666666666700', 'species': 'Iris-versicolor'}, {'id': '78', 'sepallengthcm': '0.666666666666666700', 'sepalwidthcm': '0.416666666666666740', 'petallengthcm': '0.677966101694915200', 'petalwidthcm': '0.666666666666666700', 'species': 'Iris-versicolor'}, {'id': '79', 'sepallengthcm': '0.472222222222222300', 'sepalwidthcm': '0.375000000000000000', 'petallengthcm': '0.593220338983050800', 'petalwidthcm': '0.583333333333333400', 'species': 'Iris-versicolor'}, {'id': '80', 'sepallengthcm': '0.388888888888888840', 'sepalwidthcm': '0.250000000000000000', 'petallengthcm': '0.423728813559322000', 'petalwidthcm': '0.375000000000000000', 'species': 'Iris-versicolor'}, {'id': '81', 'sepallengthcm': '0.333333333333333260', 'sepalwidthcm': '0.166666666666666630', 'petallengthcm': '0.474576271186440630', 'petalwidthcm': '0.416666666666666700', 'species': 'Iris-versicolor'}, {'id': '82', 'sepallengthcm': '0.333333333333333260', 'sepalwidthcm': '0.166666666666666630', 'petallengthcm': '0.457627118644067800', 'petalwidthcm': '0.375000000000000000', 'species': 'Iris-versicolor'}, {'id': '83', 'sepallengthcm': '0.416666666666666500', 'sepalwidthcm': '0.291666666666666740', 'petallengthcm': '0.491525423728813470', 'petalwidthcm': '0.458333333333333300', 'species': 'Iris-versicolor'}, {'id': '84', 'sepallengthcm': '0.472222222222222300', 'sepalwidthcm': '0.291666666666666740', 'petallengthcm': '0.694915254237288100', 'petalwidthcm': '0.625000000000000100', 'species': 'Iris-versicolor'}, {'id': '85', 'sepallengthcm': '0.305555555555555600', 'sepalwidthcm': '0.416666666666666740', 'petallengthcm': '0.593220338983050800', 'petalwidthcm': '0.583333333333333400', 'species': 'Iris-versicolor'}, {'id': '86', 'sepallengthcm': '0.472222222222222300', 'sepalwidthcm': '0.583333333333333300', 'petallengthcm': '0.593220338983050800', 'petalwidthcm': '0.625000000000000100', 'species': 'Iris-versicolor'}, {'id': '87', 'sepallengthcm': '0.666666666666666700', 'sepalwidthcm': '0.458333333333333260', 'petallengthcm': '0.627118644067796600', 'petalwidthcm': '0.583333333333333400', 'species': 'Iris-versicolor'}, {'id': '88', 'sepallengthcm': '0.555555555555555600', 'sepalwidthcm': '0.124999999999999890', 'petallengthcm': '0.576271186440678000', 'petalwidthcm': '0.500000000000000100', 'species': 'Iris-versicolor'}, {'id': '89', 'sepallengthcm': '0.361111111111110940', 'sepalwidthcm': '0.416666666666666740', 'petallengthcm': '0.525423728813559300', 'petalwidthcm': '0.500000000000000100', 'species': 'Iris-versicolor'}, {'id': '90', 'sepallengthcm': '0.333333333333333260', 'sepalwidthcm': '0.208333333333333260', 'petallengthcm': '0.508474576271186400', 'petalwidthcm': '0.500000000000000100', 'species': 'Iris-versicolor'}, {'id': '91', 'sepallengthcm': '0.333333333333333260', 'sepalwidthcm': '0.250000000000000000', 'petallengthcm': '0.576271186440678000', 'petalwidthcm': '0.458333333333333300', 'species': 'Iris-versicolor'}, {'id': '92', 'sepallengthcm': '0.499999999999999800', 'sepalwidthcm': '0.416666666666666740', 'petallengthcm': '0.610169491525423700', 'petalwidthcm': '0.541666666666666700', 'species': 'Iris-versicolor'}, {'id': '93', 'sepallengthcm': '0.416666666666666500', 'sepalwidthcm': '0.250000000000000000', 'petallengthcm': '0.508474576271186400', 'petalwidthcm': '0.458333333333333300', 'species': 'Iris-versicolor'}, {'id': '94', 'sepallengthcm': '0.194444444444444420', 'sepalwidthcm': '0.124999999999999890', 'petallengthcm': '0.389830508474576230', 'petalwidthcm': '0.375000000000000000', 'species': 'Iris-versicolor'}, {'id': '95', 'sepallengthcm': '0.361111111111110940', 'sepalwidthcm': '0.291666666666666740', 'petallengthcm': '0.542372881355932200', 'petalwidthcm': '0.500000000000000100', 'species': 'Iris-versicolor'}, {'id': '96', 'sepallengthcm': '0.388888888888888840', 'sepalwidthcm': '0.416666666666666740', 'petallengthcm': '0.542372881355932200', 'petalwidthcm': '0.458333333333333300', 'species': 'Iris-versicolor'}, {'id': '97', 'sepallengthcm': '0.388888888888888840', 'sepalwidthcm': '0.375000000000000000', 'petallengthcm': '0.542372881355932200', 'petalwidthcm': '0.500000000000000100', 'species': 'Iris-versicolor'}, {'id': '98', 'sepallengthcm': '0.527777777777777900', 'sepalwidthcm': '0.375000000000000000', 'petallengthcm': '0.559322033898305000', 'petalwidthcm': '0.500000000000000100', 'species': 'Iris-versicolor'}, {'id': '99', 'sepallengthcm': '0.222222222222222100', 'sepalwidthcm': '0.208333333333333260', 'petallengthcm': '0.338983050847457600', 'petalwidthcm': '0.416666666666666700', 'species': 'Iris-versicolor'}, {'id': '100', 'sepallengthcm': '0.388888888888888840', 'sepalwidthcm': '0.333333333333333260', 'petallengthcm': '0.525423728813559300', 'petalwidthcm': '0.500000000000000100', 'species': 'Iris-versicolor'}, {'id': '101', 'sepallengthcm': '0.555555555555555600', 'sepalwidthcm': '0.541666666666666500', 'petallengthcm': '0.847457627118644000', 'petalwidthcm': '1.000000000000000000', 'species': 'Iris-virginica'}, {'id': '102', 'sepallengthcm': '0.416666666666666500', 'sepalwidthcm': '0.291666666666666740', 'petallengthcm': '0.694915254237288100', 'petalwidthcm': '0.750000000000000000', 'species': 'Iris-virginica'}, {'id': '103', 'sepallengthcm': '0.777777777777777700', 'sepalwidthcm': '0.416666666666666740', 'petallengthcm': '0.830508474576271200', 'petalwidthcm': '0.833333333333333500', 'species': 'Iris-virginica'}, {'id': '104', 'sepallengthcm': '0.555555555555555600', 'sepalwidthcm': '0.375000000000000000', 'petallengthcm': '0.779661016949152500', 'petalwidthcm': '0.708333333333333400', 'species': 'Iris-virginica'}, {'id': '105', 'sepallengthcm': '0.611111111111111200', 'sepalwidthcm': '0.416666666666666740', 'petallengthcm': '0.813559322033898200', 'petalwidthcm': '0.875000000000000100', 'species': 'Iris-virginica'}, {'id': '106', 'sepallengthcm': '0.916666666666666500', 'sepalwidthcm': '0.416666666666666740', 'petallengthcm': '0.949152542372881300', 'petalwidthcm': '0.833333333333333500', 'species': 'Iris-virginica'}, {'id': '107', 'sepallengthcm': '0.166666666666666740', 'sepalwidthcm': '0.208333333333333260', 'petallengthcm': '0.593220338983050800', 'petalwidthcm': '0.666666666666666700', 'species': 'Iris-virginica'}, {'id': '108', 'sepallengthcm': '0.833333333333333000', 'sepalwidthcm': '0.375000000000000000', 'petallengthcm': '0.898305084745762500', 'petalwidthcm': '0.708333333333333400', 'species': 'Iris-virginica'}, {'id': '109', 'sepallengthcm': '0.666666666666666700', 'sepalwidthcm': '0.208333333333333260', 'petallengthcm': '0.813559322033898200', 'petalwidthcm': '0.708333333333333400', 'species': 'Iris-virginica'}, {'id': '110', 'sepallengthcm': '0.805555555555555600', 'sepalwidthcm': '0.666666666666666700', 'petallengthcm': '0.864406779661016900', 'petalwidthcm': '1.000000000000000000', 'species': 'Iris-virginica'}, {'id': '111', 'sepallengthcm': '0.611111111111111200', 'sepalwidthcm': '0.500000000000000000', 'petallengthcm': '0.694915254237288100', 'petalwidthcm': '0.791666666666666700', 'species': 'Iris-virginica'}, {'id': '112', 'sepallengthcm': '0.583333333333333500', 'sepalwidthcm': '0.291666666666666740', 'petallengthcm': '0.728813559322033800', 'petalwidthcm': '0.750000000000000000', 'species': 'Iris-virginica'}, {'id': '113', 'sepallengthcm': '0.694444444444444400', 'sepalwidthcm': '0.416666666666666740', 'petallengthcm': '0.762711864406779600', 'petalwidthcm': '0.833333333333333500', 'species': 'Iris-virginica'}, {'id': '114', 'sepallengthcm': '0.388888888888888840', 'sepalwidthcm': '0.208333333333333260', 'petallengthcm': '0.677966101694915200', 'petalwidthcm': '0.791666666666666700', 'species': 'Iris-virginica'}, {'id': '115', 'sepallengthcm': '0.416666666666666500', 'sepalwidthcm': '0.333333333333333260', 'petallengthcm': '0.694915254237288100', 'petalwidthcm': '0.958333333333333400', 'species': 'Iris-virginica'}, {'id': '116', 'sepallengthcm': '0.583333333333333500', 'sepalwidthcm': '0.500000000000000000', 'petallengthcm': '0.728813559322033800', 'petalwidthcm': '0.916666666666666600', 'species': 'Iris-virginica'}, {'id': '117', 'sepallengthcm': '0.611111111111111200', 'sepalwidthcm': '0.416666666666666740', 'petallengthcm': '0.762711864406779600', 'petalwidthcm': '0.708333333333333400', 'species': 'Iris-virginica'}, {'id': '118', 'sepallengthcm': '0.944444444444444200', 'sepalwidthcm': '0.749999999999999800', 'petallengthcm': '0.966101694915254300', 'petalwidthcm': '0.875000000000000100', 'species': 'Iris-virginica'}, {'id': '119', 'sepallengthcm': '0.944444444444444200', 'sepalwidthcm': '0.250000000000000000', 'petallengthcm': '1.000000000000000000', 'petalwidthcm': '0.916666666666666600', 'species': 'Iris-virginica'}, {'id': '120', 'sepallengthcm': '0.472222222222222300', 'sepalwidthcm': '0.083333333333333370', 'petallengthcm': '0.677966101694915200', 'petalwidthcm': '0.583333333333333400', 'species': 'Iris-virginica'}, {'id': '121', 'sepallengthcm': '0.722222222222222300', 'sepalwidthcm': '0.500000000000000000', 'petallengthcm': '0.796610169491525400', 'petalwidthcm': '0.916666666666666600', 'species': 'Iris-virginica'}, {'id': '122', 'sepallengthcm': '0.361111111111110940', 'sepalwidthcm': '0.333333333333333260', 'petallengthcm': '0.661016949152542400', 'petalwidthcm': '0.791666666666666700', 'species': 'Iris-virginica'}, {'id': '123', 'sepallengthcm': '0.944444444444444200', 'sepalwidthcm': '0.333333333333333260', 'petallengthcm': '0.966101694915254300', 'petalwidthcm': '0.791666666666666700', 'species': 'Iris-virginica'}, {'id': '124', 'sepallengthcm': '0.555555555555555600', 'sepalwidthcm': '0.291666666666666740', 'petallengthcm': '0.661016949152542400', 'petalwidthcm': '0.708333333333333400', 'species': 'Iris-virginica'}, {'id': '125', 'sepallengthcm': '0.666666666666666700', 'sepalwidthcm': '0.541666666666666500', 'petallengthcm': '0.796610169491525400', 'petalwidthcm': '0.833333333333333500', 'species': 'Iris-virginica'}, {'id': '126', 'sepallengthcm': '0.805555555555555600', 'sepalwidthcm': '0.500000000000000000', 'petallengthcm': '0.847457627118644000', 'petalwidthcm': '0.708333333333333400', 'species': 'Iris-virginica'}, {'id': '127', 'sepallengthcm': '0.527777777777777900', 'sepalwidthcm': '0.333333333333333260', 'petallengthcm': '0.644067796610169400', 'petalwidthcm': '0.708333333333333400', 'species': 'Iris-virginica'}, {'id': '128', 'sepallengthcm': '0.499999999999999800', 'sepalwidthcm': '0.416666666666666740', 'petallengthcm': '0.661016949152542400', 'petalwidthcm': '0.708333333333333400', 'species': 'Iris-virginica'}, {'id': '129', 'sepallengthcm': '0.583333333333333500', 'sepalwidthcm': '0.333333333333333260', 'petallengthcm': '0.779661016949152500', 'petalwidthcm': '0.833333333333333500', 'species': 'Iris-virginica'}, {'id': '130', 'sepallengthcm': '0.805555555555555600', 'sepalwidthcm': '0.416666666666666740', 'petallengthcm': '0.813559322033898200', 'petalwidthcm': '0.625000000000000100', 'species': 'Iris-virginica'}, {'id': '131', 'sepallengthcm': '0.861111111111111200', 'sepalwidthcm': '0.333333333333333260', 'petallengthcm': '0.864406779661016900', 'petalwidthcm': '0.750000000000000000', 'species': 'Iris-virginica'}, {'id': '132', 'sepallengthcm': '1.000000000000000000', 'sepalwidthcm': '0.749999999999999800', 'petallengthcm': '0.915254237288135600', 'petalwidthcm': '0.791666666666666700', 'species': 'Iris-virginica'}, {'id': '133', 'sepallengthcm': '0.583333333333333500', 'sepalwidthcm': '0.333333333333333260', 'petallengthcm': '0.779661016949152500', 'petalwidthcm': '0.875000000000000100', 'species': 'Iris-virginica'}, {'id': '134', 'sepallengthcm': '0.555555555555555600', 'sepalwidthcm': '0.333333333333333260', 'petallengthcm': '0.694915254237288100', 'petalwidthcm': '0.583333333333333400', 'species': 'Iris-virginica'}, {'id': '135', 'sepallengthcm': '0.499999999999999800', 'sepalwidthcm': '0.250000000000000000', 'petallengthcm': '0.779661016949152500', 'petalwidthcm': '0.541666666666666700', 'species': 'Iris-virginica'}, {'id': '136', 'sepallengthcm': '0.944444444444444200', 'sepalwidthcm': '0.416666666666666740', 'petallengthcm': '0.864406779661016900', 'petalwidthcm': '0.916666666666666600', 'species': 'Iris-virginica'}, {'id': '137', 'sepallengthcm': '0.555555555555555600', 'sepalwidthcm': '0.583333333333333300', 'petallengthcm': '0.779661016949152500', 'petalwidthcm': '0.958333333333333400', 'species': 'Iris-virginica'}, {'id': '138', 'sepallengthcm': '0.583333333333333500', 'sepalwidthcm': '0.458333333333333260', 'petallengthcm': '0.762711864406779600', 'petalwidthcm': '0.708333333333333400', 'species': 'Iris-virginica'}, {'id': '139', 'sepallengthcm': '0.472222222222222300', 'sepalwidthcm': '0.416666666666666740', 'petallengthcm': '0.644067796610169400', 'petalwidthcm': '0.708333333333333400', 'species': 'Iris-virginica'}, {'id': '140', 'sepallengthcm': '0.722222222222222300', 'sepalwidthcm': '0.458333333333333260', 'petallengthcm': '0.745762711864406800', 'petalwidthcm': '0.833333333333333500', 'species': 'Iris-virginica'}, {'id': '141', 'sepallengthcm': '0.666666666666666700', 'sepalwidthcm': '0.458333333333333260', 'petallengthcm': '0.779661016949152500', 'petalwidthcm': '0.958333333333333400', 'species': 'Iris-virginica'}, {'id': '142', 'sepallengthcm': '0.722222222222222300', 'sepalwidthcm': '0.458333333333333260', 'petallengthcm': '0.694915254237288100', 'petalwidthcm': '0.916666666666666600', 'species': 'Iris-virginica'}, {'id': '143', 'sepallengthcm': '0.416666666666666500', 'sepalwidthcm': '0.291666666666666740', 'petallengthcm': '0.694915254237288100', 'petalwidthcm': '0.750000000000000000', 'species': 'Iris-virginica'}, {'id': '144', 'sepallengthcm': '0.694444444444444400', 'sepalwidthcm': '0.500000000000000000', 'petallengthcm': '0.830508474576271200', 'petalwidthcm': '0.916666666666666600', 'species': 'Iris-virginica'}, {'id': '145', 'sepallengthcm': '0.666666666666666700', 'sepalwidthcm': '0.541666666666666500', 'petallengthcm': '0.796610169491525400', 'petalwidthcm': '1.000000000000000000', 'species': 'Iris-virginica'}, {'id': '146', 'sepallengthcm': '0.666666666666666700', 'sepalwidthcm': '0.416666666666666740', 'petallengthcm': '0.711864406779661000', 'petalwidthcm': '0.916666666666666600', 'species': 'Iris-virginica'}, {'id': '147', 'sepallengthcm': '0.555555555555555600', 'sepalwidthcm': '0.208333333333333260', 'petallengthcm': '0.677966101694915200', 'petalwidthcm': '0.750000000000000000', 'species': 'Iris-virginica'}, {'id': '148', 'sepallengthcm': '0.611111111111111200', 'sepalwidthcm': '0.416666666666666740', 'petallengthcm': '0.711864406779661000', 'petalwidthcm': '0.791666666666666700', 'species': 'Iris-virginica'}, {'id': '149', 'sepallengthcm': '0.527777777777777900', 'sepalwidthcm': '0.583333333333333300', 'petallengthcm': '0.745762711864406800', 'petalwidthcm': '0.916666666666666600', 'species': 'Iris-virginica'}, {'id': '150', 'sepallengthcm': '0.444444444444444640', 'sepalwidthcm': '0.416666666666666740', 'petallengthcm': '0.694915254237288100', 'petalwidthcm': '0.708333333333333400', 'species': 'Iris-virginica'}]\n"
     ]
    }
   ],
   "source": [
    "# API endpoint URL\n",
    "API_URL = f\"http://localhost/api/database/{db_id}/table/{selected_table_id}/data?size=100000&page=0\"\n",
    "\n",
    "# Define the headers\n",
    "headers = {\n",
    "    \"Accept\": \"application/json\"  # Specify the expected response format\n",
    "}\n",
    "\n",
    "try:\n",
    "    # Send a GET request to the API with the Accept header\n",
    "    response = requests.get(API_URL, headers=headers)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Parse the JSON response\n",
    "        dataset = response.json()\n",
    "        \n",
    "        \n",
    "        print( dataset)\n",
    "    else:\n",
    "        print(f\"Error: Received status code {response.status_code}\")\n",
    "        print(\"Response content:\", response.text)\n",
    "       \n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"Request failed: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09557f94-325c-4bd6-882a-069a9e3c5ecd",
   "metadata": {},
   "source": [
    "replacing dynamic fetching of data When and if DBREPO isnt running (BACKUP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce6e020d-cb80-49ec-8bcc-687b1e08885c",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'iris_data.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 1. Read the JSON file id the API isnt available this data is saved locally but the data is from the API endpoint\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43miris_data.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      3\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    279\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m     )\n\u001b[1;32m--> 284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'iris_data.json'"
     ]
    }
   ],
   "source": [
    "# # 1. Read the JSON file id the API isnt available this data is saved locally but the data is from the API endpoint\n",
    "# with open(\"iris_data.json\", \"r\") as f:\n",
    "#     dataset = json.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcf2244-14dd-4e3d-b8cf-f7f3ba34f80f",
   "metadata": {},
   "source": [
    "# ============================\n",
    "# 📂 Setup MLflow\n",
    "# ============================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cbe91ec0-6447-4586-b7cc-2c1f74d4218f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter experiment name for MLflow:  efrgtr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/18 16:59:10 INFO mlflow.tracking.fluent: Experiment with name 'efrgtr' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///C:/Users/reema/REPO/notebooks/RQ_notebooks/mlrunlogs/mlflow.db/225271718569336729', creation_time=1747580350310, experiment_id='225271718569336729', last_update_time=1747580350310, lifecycle_stage='active', name='efrgtr', tags={}>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import mlflow\n",
    "\n",
    "# Ensure tracking directory exists\n",
    "project_dir = os.getcwd()\n",
    "mlrunlogs_dir = os.path.join(project_dir, \"mlrunlogs\")\n",
    "os.makedirs(mlrunlogs_dir, exist_ok=True)\n",
    "\n",
    "# Set MLflow tracking URI (local SQLite backend)\n",
    "mlflow_tracking_path = os.path.join(mlrunlogs_dir, \"mlflow.db\")\n",
    "mlflow.set_tracking_uri(\"mlrunlogs/mlflow.db\")\n",
    "\n",
    "# Prompt for experiment name\n",
    "experiment_name = input(\"Enter experiment name for MLflow: \").strip()\n",
    "if not experiment_name:\n",
    "    experiment_name = \"default_experiment\"\n",
    "    print(\"⚠️ No name entered. Using fallback:\", experiment_name)\n",
    "\n",
    "mlflow.set_experiment(experiment_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2c2c5f-cc36-41a3-9643-83ef95b9f55e",
   "metadata": {},
   "source": [
    "# ============================\n",
    "# 🔄 Git Commit Hash for previous commit for metadata\n",
    "# ============================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "838dd233-25dc-4725-974d-4da89c257782",
   "metadata": {},
   "outputs": [],
   "source": [
    "import git\n",
    "import os\n",
    "\n",
    "def get_latest_git_commit(repo_path: str = \"C:/Users/reema/REPO\") -> dict:\n",
    "    \"\"\"\n",
    "    Returns the latest Git commit metadata from the given repo path.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        repo = git.Repo(repo_path)\n",
    "        commit = repo.head.commit\n",
    "        commit_metadata = {\n",
    "            \"git_commit\": commit.hexsha,\n",
    "            \"git_author\": commit.author.name,\n",
    "            \"git_email\": commit.author.email,\n",
    "            \"git_commit_time\": str(commit.committed_datetime),\n",
    "            \"git_message\": commit.message.strip(),\n",
    "            \"git_branch\": repo.active_branch.name if not repo.head.is_detached else \"detached\"\n",
    "        }\n",
    "        return commit_metadata\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[⚠️ Git Error] Could not read Git repo at {repo_path}: {e}\")\n",
    "        return {\n",
    "            \"git_commit\": \"not available\",\n",
    "            \"git_author\": \"not available\",\n",
    "            \"git_email\": \"not available\",\n",
    "            \"git_commit_time\": \"not available\",\n",
    "            \"git_message\": \"not available\",\n",
    "            \"git_branch\": \"not available\"\n",
    "        }\n",
    "\n",
    "# Usage\n",
    "repo_dir = \"C:/Users/reema/REPO\"\n",
    "git_metadata = get_latest_git_commit(repo_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430d15ef-3432-4e45-88fb-b7048a5b10a9",
   "metadata": {},
   "source": [
    "# ============================\n",
    "# Make threadpoolctl safe so MLflow’s autologger won’t crash ───\n",
    "# ============================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9668451f-4352-4bdc-8b6b-bbe49074212a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/18 16:59:17 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
      "2025/05/18 16:59:18 INFO mlflow.tracking.fluent: Autologging successfully enabled for statsmodels.\n"
     ]
    }
   ],
   "source": [
    "# ─── Patch threadpoolctl if needed to avoid autolog crashes ───\n",
    "try:\n",
    "    import threadpoolctl\n",
    "    _original_threadpool_info = threadpoolctl.threadpool_info\n",
    "\n",
    "    def _safe_threadpool_info(*args, **kwargs):\n",
    "        try:\n",
    "            return _original_threadpool_info(*args, **kwargs)\n",
    "        except Exception:\n",
    "            return []\n",
    "\n",
    "    threadpoolctl.threadpool_info = _safe_threadpool_info\n",
    "except ImportError:\n",
    "    pass  # If threadpoolctl isn't installed, we just skip this patch\n",
    "\n",
    "# ─── Enable MLflow autologging (generic, works with sklearn and more) ───\n",
    "import mlflow\n",
    "\n",
    "mlflow.autolog(\n",
    "    log_input_examples=True,\n",
    "    log_model_signatures=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b608670-96a5-42b0-b69b-263ac1e452eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import json\n",
    "import platform\n",
    "import psutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from subprocess import check_output, CalledProcessError\n",
    "\n",
    "def log_standard_metadata(\n",
    "    model_name: str,\n",
    "    model,\n",
    "    hyperparams: dict,\n",
    "    acc: float,\n",
    "    prec: float,\n",
    "    rec: float,\n",
    "    f1: float,\n",
    "    auc: float,\n",
    "    label_map: dict,\n",
    "    run_id: str,\n",
    "    test_size: float,\n",
    "    random_state: int,\n",
    "    id_cols: list,\n",
    "    target_col: str,\n",
    "    X,\n",
    "    y,\n",
    "    run_data=None\n",
    "):\n",
    "    # === Experiment Metadata ===\n",
    "    mlflow.set_tag(\"run_id\", run_id)  # [MLflow / DB anchor]\n",
    "    mlflow.set_tag(\"model_name\", model_name)  # [ML Metadata, FAIR]\n",
    "    mlflow.set_tag(\"model_architecture\", model.__class__.__name__)  # [MLSEA]\n",
    "    mlflow.set_tag(\"test_size\", test_size)  # [MLSEA, Reproducibility]\n",
    "    mlflow.set_tag(\"random_state\", random_state)  # [MLSEA, Reproducibility]\n",
    "\n",
    "    # === Evaluation Metrics ===\n",
    "    mlflow.set_tag(\"accuracy\", acc)\n",
    "    mlflow.set_tag(\"precision_macro\", prec)\n",
    "    mlflow.set_tag(\"recall_macro\", rec)\n",
    "    mlflow.set_tag(\"f1_macro\", f1)\n",
    "    mlflow.set_tag(\"roc_auc\", auc)\n",
    "\n",
    "    # === Hyperparameters and Label Encoding ===\n",
    "    mlflow.set_tag(\"hyperparameters\", json.dumps(hyperparams))  # [FAIR, MLSEA]\n",
    "    mlflow.set_tag(\"label_map\", json.dumps(label_map))  # [ML Preprocessing]\n",
    "\n",
    "    # === Preprocessing Snapshot ===\n",
    "    preprocessing_info = {\n",
    "        \"dropped_columns\": id_cols,\n",
    "        \"numeric_columns\": list(X.columns),\n",
    "        \"target_column\": target_col,\n",
    "        \"stratified\": False,\n",
    "        \"coercion_strategy\": \"Numeric cast (auto)\",\n",
    "        \"feature_engineering\": \"None\",\n",
    "        \"missing_value_strategy\": \"None\",\n",
    "        \"outlier_detection\": \"None\",\n",
    "        \"encoding_strategy\": \"LabelEncoder (target only)\",\n",
    "        \"scaling\": \"None\",\n",
    "        \"sampling\": \"None\",\n",
    "        \"feature_selection\": \"None\",\n",
    "        \"train_test_split\": {\"test_size\": test_size, \"random_state\": random_state},\n",
    "        \"imbalance_ratio\": str(dict(zip(*np.unique(y, return_counts=True)))),\n",
    "        \"preprocessing_timestamp\": datetime.now().isoformat()\n",
    "    }\n",
    "    preprocessing_hash = hashlib.sha256(json.dumps(preprocessing_info).encode()).hexdigest()\n",
    "    mlflow.set_tag(\"preprocessing_info\", json.dumps(preprocessing_info))  # [MLSEA]\n",
    "    mlflow.set_tag(\"preprocessing_hash\", preprocessing_hash)\n",
    "\n",
    "    # === Reproducibility ===\n",
    "    mlflow.set_tag(\"model_serialization\", \"pickle\")  # [FAIR, MLSEA]\n",
    "    mlflow.set_tag(\"model_path\", f\"{model_name}.pkl\")\n",
    "\n",
    "    try:\n",
    "        sha = check_output([\"git\", \"rev-parse\", \"HEAD\"], text=True).strip()\n",
    "    except CalledProcessError:\n",
    "        sha = \"unknown\"\n",
    "    mlflow.set_tag(\"git_commit\", sha)\n",
    "\n",
    "    # === Compute Environment ===\n",
    "    compute_env = {\n",
    "        \"os\": f\"{platform.system()} {platform.release()}\",\n",
    "        \"cpu\": platform.processor(),\n",
    "        \"ram_gb\": round(psutil.virtual_memory().total / (1024 ** 3), 2),\n",
    "        \"python_version\": platform.python_version(),\n",
    "        \"sklearn_version\": sklearn.__version__,\n",
    "        \"pandas_version\": pd.__version__,\n",
    "        \"numpy_version\": np.__version__,\n",
    "    }\n",
    "    mlflow.set_tag(\"compute_environment\", json.dumps(compute_env))  # [Reproducibility]\n",
    "\n",
    "    # === Optional: Tag MLflow Justifications (previously logged manually) ===\n",
    "    if run_data:\n",
    "        for key, val in run_data.tags.items():\n",
    "            if key.startswith(\"justification_\"):\n",
    "                mlflow.set_tag(key, val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69f000f9-d0b6-41f7-92d3-4b605e4ecaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "def generate_reproducibility_txt_log(\n",
    "    model_name: str,\n",
    "    dataset_name: str,\n",
    "    dataset_version: str,\n",
    "    hyperparams: dict,\n",
    "    metrics: dict,\n",
    "    git_commit: str,\n",
    "    run_id: str,\n",
    "    architecture_file_path: str = \"provenance_architecture_description.txt\"\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Generate a reproducibility log (YAML + architecture) and return the saved path.\n",
    "    This log combines:\n",
    "    - Model and dataset details\n",
    "    - Hyperparameters and evaluation metrics\n",
    "    - Git provenance info\n",
    "    - Reproduction steps\n",
    "    - Provenance architecture description\n",
    "    \"\"\"\n",
    "\n",
    "    def clean_values(d):\n",
    "        \"\"\"Convert numpy floats to native floats.\"\"\"\n",
    "        return {k: float(v) if isinstance(v, (np.float32, np.float64)) else v for k, v in d.items()}\n",
    "\n",
    "    timestamp = datetime.utcnow().strftime(\"%Y-%m-%d %H:%M UTC\")\n",
    "\n",
    "    repro_data = {\n",
    "        \"📌 Model Details\": {\n",
    "            \"Model Name\": model_name,\n",
    "            \"Dataset Name\": dataset_name,\n",
    "            \"Dataset Version\": dataset_version,\n",
    "            \"Run ID\": run_id,\n",
    "            \"Timestamp\": timestamp\n",
    "        },\n",
    "        \"🛠️ Hyperparameters\": clean_values(hyperparams),\n",
    "        \"📈 Metrics\": clean_values(metrics),\n",
    "        \"🔗 Git Info\": {\n",
    "            \"Commit Hash\": git_commit,\n",
    "            \"Reproduce With\": f\"git checkout {git_commit}\"\n",
    "        },\n",
    "        \"🚀 Reproduction Guide\": [\n",
    "            \"1. Clone the repo and checkout the commit:\",\n",
    "            f\"   git checkout {git_commit}\",\n",
    "            \"2. Load and preprocess the dataset exactly as during training.\",\n",
    "            \"3. Load the model using MLflow:\",\n",
    "            f\"   mlflow.sklearn.load_model('runs:/{run_id}/model')\",\n",
    "            \"4. Run inference or evaluation using the same pipeline/script.\"\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    # 🔐 Create and write to output file\n",
    "    save_dir = os.path.join(\"MODEL_PROVENANCE\", model_name)\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    txt_path = os.path.join(save_dir, f\"{model_name}_reproducibility.txt\")\n",
    "\n",
    "    with open(txt_path, \"w\", encoding=\"utf-8\") as repro_file:\n",
    "        yaml.dump(repro_data, repro_file, allow_unicode=True, sort_keys=False, width=100)\n",
    "        repro_file.write(\"\\n\\n\")\n",
    "\n",
    "        if os.path.exists(architecture_file_path):\n",
    "            with open(architecture_file_path, \"r\", encoding=\"utf-8\") as arch_file:\n",
    "                architecture_description = arch_file.read()\n",
    "                repro_file.write(architecture_description)\n",
    "        else:\n",
    "            repro_file.write(\"[⚠️ Missing architecture description file]\\n\")\n",
    "\n",
    "    return txt_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2a08a1f1-c3a6-45bd-97b1-92e2fade9ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_with_justification(log_func, key: str, value, context: str = \"\"):\n",
    "    \"\"\"\n",
    "    Log a value using the specified MLflow log function (e.g., mlflow.log_param),\n",
    "    then prompt the user for a justification and log it as a tag.\n",
    "    \"\"\"\n",
    "    log_func(key, value)\n",
    "    print(f\"\\n📝 Justification for `{key}` ({context})\")\n",
    "    user_reason = input(\"→ Why did you choose this value? \")\n",
    "    mlflow.set_tag(f\"justification_{key}\", user_reason or \"No justification provided\")\n",
    "\n",
    "def log_justification(key: str, question: str):\n",
    "    \"\"\"\n",
    "    Prompt for a justification only (without logging a value), and log it as a tag.\n",
    "    \"\"\"\n",
    "    print(f\"\\n📝 Justification for `{key}`\")\n",
    "    user_reason = input(f\"→ {question} \")\n",
    "    mlflow.set_tag(f\"justification_{key}\", user_reason or \"No justification provided\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "00237086-0d9c-41b2-a780-b2322ecd69fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9058319a-adba-4a6b-93e9-d17080c0594d",
   "metadata": {},
   "source": [
    "# ============================\n",
    "# 🚀 Start MLflow Run \n",
    "# ============================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "14c62f08-a116-4060-9689-f69968e9f240",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your role (default: collaborator):  dsf\n",
      "Enter project ID (default: default_project):  fsdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📌 Session Metadata:\n",
      "  session_id: a703d999-0a29-4cfb-8dab-48d1f14d1bff\n",
      "  username: reema\n",
      "  timestamp_utc: 2025-05-18T15:03:47.945054\n",
      "  hostname: Purplish\n",
      "  platform: Windows\n",
      "  os_version: 10.0.26100\n",
      "  python_version: 3.11.5\n",
      "  role: dsf\n",
      "  project_id: fsdf\n",
      "ML_EXP_Shapes: (150, 4) (150,)\n",
      "ML_EXP_Classes: ['Iris-setosa' 'Iris-versicolor' 'Iris-virginica']\n",
      "{'id': 'f6a329d0-0cd6-4308-8c89-ad5763b42324', 'name': 'Iris', 'description': None, 'tables': [{'id': 'e435fe7c-f889-40f5-9660-007597ad4a5b', 'name': 'iris_data_v2', 'alias': None, 'identifiers': [], 'owner': {'id': '55bad3e0-c815-103f-9c9e-43ec87b6b872', 'username': 'reema', 'name': 'reema dass', 'orcid': None, 'qualified_name': 'reema dass — @reema', 'given_name': 'reema', 'family_name': 'dass'}, 'description': 'iris_data_v2', 'columns': [{'id': '9208e04f-b09c-4d43-9ddc-a41cffc55840', 'name': 'Id', 'alias': None, 'size': None, 'd': None, 'mean': 51, 'median': 51, 'concept': None, 'unit': None, 'description': None, 'enums': [], 'sets': [], 'database_id': 'f6a329d0-0cd6-4308-8c89-ad5763b42324', 'table_id': 'e435fe7c-f889-40f5-9660-007597ad4a5b', 'ord': 0, 'internal_name': 'id', 'index_length': None, 'length': None, 'type': 'bigint', 'data_length': None, 'max_data_length': None, 'num_rows': None, 'val_min': None, 'val_max': None, 'std_dev': 29, 'is_null_allowed': False}, {'id': '6285c88a-8cb7-42c3-afcc-d5623f96b0ad', 'name': 'SepalLengthCm', 'alias': None, 'size': 40, 'd': 20, 'mean': 5, 'median': 5, 'concept': None, 'unit': None, 'description': None, 'enums': [], 'sets': [], 'database_id': 'f6a329d0-0cd6-4308-8c89-ad5763b42324', 'table_id': 'e435fe7c-f889-40f5-9660-007597ad4a5b', 'ord': 1, 'internal_name': 'sepallengthcm', 'index_length': None, 'length': None, 'type': 'decimal', 'data_length': None, 'max_data_length': None, 'num_rows': None, 'val_min': None, 'val_max': None, 'std_dev': 1, 'is_null_allowed': False}, {'id': 'dfe7abba-0c31-4bb6-95d8-48467b619dad', 'name': 'SepalWidthCm', 'alias': None, 'size': 40, 'd': 20, 'mean': 3, 'median': 3, 'concept': None, 'unit': None, 'description': None, 'enums': [], 'sets': [], 'database_id': 'f6a329d0-0cd6-4308-8c89-ad5763b42324', 'table_id': 'e435fe7c-f889-40f5-9660-007597ad4a5b', 'ord': 2, 'internal_name': 'sepalwidthcm', 'index_length': None, 'length': None, 'type': 'decimal', 'data_length': None, 'max_data_length': None, 'num_rows': None, 'val_min': None, 'val_max': None, 'std_dev': 0, 'is_null_allowed': False}, {'id': '86f0cd65-72b6-42a4-b710-24e3026cb155', 'name': 'PetalLengthCm', 'alias': None, 'size': 40, 'd': 20, 'mean': 3, 'median': 3, 'concept': None, 'unit': None, 'description': None, 'enums': [], 'sets': [], 'database_id': 'f6a329d0-0cd6-4308-8c89-ad5763b42324', 'table_id': 'e435fe7c-f889-40f5-9660-007597ad4a5b', 'ord': 3, 'internal_name': 'petallengthcm', 'index_length': None, 'length': None, 'type': 'decimal', 'data_length': None, 'max_data_length': None, 'num_rows': None, 'val_min': None, 'val_max': None, 'std_dev': 1, 'is_null_allowed': False}, {'id': 'ee6d4920-2c24-447e-86d7-cae81d85c091', 'name': 'PetalWidthCm', 'alias': None, 'size': 40, 'd': 20, 'mean': 1, 'median': 1, 'concept': None, 'unit': None, 'description': None, 'enums': [], 'sets': [], 'database_id': 'f6a329d0-0cd6-4308-8c89-ad5763b42324', 'table_id': 'e435fe7c-f889-40f5-9660-007597ad4a5b', 'ord': 4, 'internal_name': 'petalwidthcm', 'index_length': None, 'length': None, 'type': 'decimal', 'data_length': None, 'max_data_length': None, 'num_rows': None, 'val_min': None, 'val_max': None, 'std_dev': 1, 'is_null_allowed': False}, {'id': 'fe728517-04fc-4cd2-9d57-d4b036d26db0', 'name': 'Species', 'alias': None, 'size': 255, 'd': None, 'mean': None, 'median': None, 'concept': None, 'unit': None, 'description': None, 'enums': [], 'sets': [], 'database_id': 'f6a329d0-0cd6-4308-8c89-ad5763b42324', 'table_id': 'e435fe7c-f889-40f5-9660-007597ad4a5b', 'ord': 5, 'internal_name': 'species', 'index_length': None, 'length': None, 'type': 'varchar', 'data_length': None, 'max_data_length': None, 'num_rows': None, 'val_min': None, 'val_max': None, 'std_dev': None, 'is_null_allowed': False}], 'constraints': {'uniques': [{'id': 'feb9db84-3974-44df-8456-dfa5021db0cd', 'name': 'uk_iris_data_v2_0', 'table': {'id': 'e435fe7c-f889-40f5-9660-007597ad4a5b', 'name': 'iris_data_v2', 'description': 'iris_data_v2', 'database_id': 'f6a329d0-0cd6-4308-8c89-ad5763b42324', 'internal_name': 'iris_data_v2', 'is_versioned': True, 'is_public': True, 'is_schema_public': True, 'owned_by': '55bad3e0-c815-103f-9c9e-43ec87b6b872'}, 'columns': [{'id': '9208e04f-b09c-4d43-9ddc-a41cffc55840', 'name': 'Id', 'alias': None, 'database_id': 'f6a329d0-0cd6-4308-8c89-ad5763b42324', 'table_id': 'e435fe7c-f889-40f5-9660-007597ad4a5b', 'internal_name': 'id', 'type': 'bigint'}]}], 'checks': [], 'foreign_keys': [], 'primary_key': [{'id': '23a1fd6a-871f-4a00-bde2-1a51a2873b07', 'table': {'id': 'e435fe7c-f889-40f5-9660-007597ad4a5b', 'name': 'iris_data_v2', 'description': 'iris_data_v2', 'database_id': 'f6a329d0-0cd6-4308-8c89-ad5763b42324', 'internal_name': 'iris_data_v2', 'is_versioned': True, 'is_public': True, 'is_schema_public': True, 'owned_by': '55bad3e0-c815-103f-9c9e-43ec87b6b872'}, 'column': {'id': '9208e04f-b09c-4d43-9ddc-a41cffc55840', 'name': 'Id', 'alias': None, 'database_id': 'f6a329d0-0cd6-4308-8c89-ad5763b42324', 'table_id': 'e435fe7c-f889-40f5-9660-007597ad4a5b', 'internal_name': 'id', 'type': 'bigint'}}]}, 'created': '2025-05-18 09:29:15', 'last_retrieved': None, 'database_id': 'f6a329d0-0cd6-4308-8c89-ad5763b42324', 'internal_name': 'iris_data_v2', 'is_versioned': True, 'is_schema_public': True, 'queue_name': 'dbrepo', 'queue_type': 'quorum', 'routing_key': 'dbrepo.f6a329d0-0cd6-4308-8c89-ad5763b42324.e435fe7c-f889-40f5-9660-007597ad4a5b', 'is_public': True, 'num_rows': 100, 'data_length': 16384, 'max_data_length': 0, 'avg_row_length': 163}, {'id': '5aa89543-bd03-4118-bdc6-7c4d09e8ff75', 'name': 'iris_data', 'alias': None, 'identifiers': [], 'owner': {'id': '55bad3e0-c815-103f-9c9e-43ec87b6b872', 'username': 'reema', 'name': 'reema dass', 'orcid': None, 'qualified_name': 'reema dass — @reema', 'given_name': 'reema', 'family_name': 'dass'}, 'description': 'iris data', 'columns': [{'id': '5f1b7208-823d-48f7-b529-10d28c03b95d', 'name': 'Id', 'alias': None, 'size': None, 'd': None, 'mean': 76, 'median': 76, 'concept': None, 'unit': None, 'description': None, 'enums': [], 'sets': [], 'database_id': 'f6a329d0-0cd6-4308-8c89-ad5763b42324', 'table_id': '5aa89543-bd03-4118-bdc6-7c4d09e8ff75', 'ord': 0, 'internal_name': 'id', 'index_length': None, 'length': None, 'type': 'bigint', 'data_length': None, 'max_data_length': None, 'num_rows': None, 'val_min': None, 'val_max': None, 'std_dev': 43, 'is_null_allowed': False}, {'id': 'e8f4b88f-04f8-4270-8dcc-82cf53716963', 'name': 'SepalLengthCm', 'alias': None, 'size': 40, 'd': 20, 'mean': 6, 'median': 6, 'concept': None, 'unit': None, 'description': None, 'enums': [], 'sets': [], 'database_id': 'f6a329d0-0cd6-4308-8c89-ad5763b42324', 'table_id': '5aa89543-bd03-4118-bdc6-7c4d09e8ff75', 'ord': 1, 'internal_name': 'sepallengthcm', 'index_length': None, 'length': None, 'type': 'decimal', 'data_length': None, 'max_data_length': None, 'num_rows': None, 'val_min': None, 'val_max': None, 'std_dev': 1, 'is_null_allowed': False}, {'id': '38b10d14-9275-48e8-bdb3-056882bc0d89', 'name': 'SepalWidthCm', 'alias': None, 'size': 40, 'd': 20, 'mean': 3, 'median': 3, 'concept': None, 'unit': None, 'description': None, 'enums': [], 'sets': [], 'database_id': 'f6a329d0-0cd6-4308-8c89-ad5763b42324', 'table_id': '5aa89543-bd03-4118-bdc6-7c4d09e8ff75', 'ord': 2, 'internal_name': 'sepalwidthcm', 'index_length': None, 'length': None, 'type': 'decimal', 'data_length': None, 'max_data_length': None, 'num_rows': None, 'val_min': None, 'val_max': None, 'std_dev': 0, 'is_null_allowed': False}, {'id': 'bd9e25b2-876f-4eed-8860-30426c3fc7db', 'name': 'PetalLengthCm', 'alias': None, 'size': 40, 'd': 20, 'mean': 4, 'median': 4, 'concept': None, 'unit': None, 'description': None, 'enums': [], 'sets': [], 'database_id': 'f6a329d0-0cd6-4308-8c89-ad5763b42324', 'table_id': '5aa89543-bd03-4118-bdc6-7c4d09e8ff75', 'ord': 3, 'internal_name': 'petallengthcm', 'index_length': None, 'length': None, 'type': 'decimal', 'data_length': None, 'max_data_length': None, 'num_rows': None, 'val_min': None, 'val_max': None, 'std_dev': 2, 'is_null_allowed': False}, {'id': 'a19effb4-94f1-48a2-a2ed-4c306ad40118', 'name': 'PetalWidthCm', 'alias': None, 'size': 40, 'd': 20, 'mean': 1, 'median': 1, 'concept': None, 'unit': None, 'description': None, 'enums': [], 'sets': [], 'database_id': 'f6a329d0-0cd6-4308-8c89-ad5763b42324', 'table_id': '5aa89543-bd03-4118-bdc6-7c4d09e8ff75', 'ord': 4, 'internal_name': 'petalwidthcm', 'index_length': None, 'length': None, 'type': 'decimal', 'data_length': None, 'max_data_length': None, 'num_rows': None, 'val_min': None, 'val_max': None, 'std_dev': 1, 'is_null_allowed': False}, {'id': '5d373e57-3824-4fc2-a09c-8c67180d95c4', 'name': 'Species', 'alias': None, 'size': 255, 'd': None, 'mean': None, 'median': None, 'concept': None, 'unit': None, 'description': None, 'enums': [], 'sets': [], 'database_id': 'f6a329d0-0cd6-4308-8c89-ad5763b42324', 'table_id': '5aa89543-bd03-4118-bdc6-7c4d09e8ff75', 'ord': 5, 'internal_name': 'species', 'index_length': None, 'length': None, 'type': 'varchar', 'data_length': None, 'max_data_length': None, 'num_rows': None, 'val_min': None, 'val_max': None, 'std_dev': None, 'is_null_allowed': False}], 'constraints': {'uniques': [{'id': 'f40db558-06c7-4f0b-ab97-c45ab36127ed', 'name': 'uk_iris_data_0', 'table': {'id': '5aa89543-bd03-4118-bdc6-7c4d09e8ff75', 'name': 'iris_data', 'description': 'iris data', 'database_id': 'f6a329d0-0cd6-4308-8c89-ad5763b42324', 'internal_name': 'iris_data', 'is_versioned': True, 'is_public': True, 'is_schema_public': True, 'owned_by': '55bad3e0-c815-103f-9c9e-43ec87b6b872'}, 'columns': [{'id': '5f1b7208-823d-48f7-b529-10d28c03b95d', 'name': 'Id', 'alias': None, 'database_id': 'f6a329d0-0cd6-4308-8c89-ad5763b42324', 'table_id': '5aa89543-bd03-4118-bdc6-7c4d09e8ff75', 'internal_name': 'id', 'type': 'bigint'}]}], 'checks': [], 'foreign_keys': [], 'primary_key': [{'id': '8c3895fc-262e-46db-8fb4-6f3098d29715', 'table': {'id': '5aa89543-bd03-4118-bdc6-7c4d09e8ff75', 'name': 'iris_data', 'description': 'iris data', 'database_id': 'f6a329d0-0cd6-4308-8c89-ad5763b42324', 'internal_name': 'iris_data', 'is_versioned': True, 'is_public': True, 'is_schema_public': True, 'owned_by': '55bad3e0-c815-103f-9c9e-43ec87b6b872'}, 'column': {'id': '5f1b7208-823d-48f7-b529-10d28c03b95d', 'name': 'Id', 'alias': None, 'database_id': 'f6a329d0-0cd6-4308-8c89-ad5763b42324', 'table_id': '5aa89543-bd03-4118-bdc6-7c4d09e8ff75', 'internal_name': 'id', 'type': 'bigint'}}]}, 'created': '2025-05-18 09:24:19', 'last_retrieved': None, 'database_id': 'f6a329d0-0cd6-4308-8c89-ad5763b42324', 'internal_name': 'iris_data', 'is_versioned': True, 'is_schema_public': True, 'queue_name': 'dbrepo', 'queue_type': 'quorum', 'routing_key': 'dbrepo.f6a329d0-0cd6-4308-8c89-ad5763b42324.5aa89543-bd03-4118-bdc6-7c4d09e8ff75', 'is_public': True, 'num_rows': 150, 'data_length': 16384, 'max_data_length': 0, 'avg_row_length': 109}, {'id': '4f9cfe1e-db91-41cc-ba3e-5a49a8274b42', 'name': 'iris_data_v1', 'alias': None, 'identifiers': [], 'owner': {'id': '55bad3e0-c815-103f-9c9e-43ec87b6b872', 'username': 'reema', 'name': 'reema dass', 'orcid': None, 'qualified_name': 'reema dass — @reema', 'given_name': 'reema', 'family_name': 'dass'}, 'description': 'iris_data_v1', 'columns': [{'id': 'a509056c-9d1b-4054-afba-4c464ee52244', 'name': 'Id', 'alias': None, 'size': None, 'd': None, 'mean': 76, 'median': 76, 'concept': None, 'unit': None, 'description': None, 'enums': [], 'sets': [], 'database_id': 'f6a329d0-0cd6-4308-8c89-ad5763b42324', 'table_id': '4f9cfe1e-db91-41cc-ba3e-5a49a8274b42', 'ord': 0, 'internal_name': 'id', 'index_length': None, 'length': None, 'type': 'bigint', 'data_length': None, 'max_data_length': None, 'num_rows': None, 'val_min': None, 'val_max': None, 'std_dev': 43, 'is_null_allowed': False}, {'id': '3bec13be-a801-4b78-9162-39e89b27e8ae', 'name': 'SepalLengthCm', 'alias': None, 'size': 40, 'd': 20, 'mean': 6, 'median': 6, 'concept': None, 'unit': None, 'description': None, 'enums': [], 'sets': [], 'database_id': 'f6a329d0-0cd6-4308-8c89-ad5763b42324', 'table_id': '4f9cfe1e-db91-41cc-ba3e-5a49a8274b42', 'ord': 1, 'internal_name': 'sepallengthcm', 'index_length': None, 'length': None, 'type': 'decimal', 'data_length': None, 'max_data_length': None, 'num_rows': None, 'val_min': None, 'val_max': None, 'std_dev': 1, 'is_null_allowed': False}, {'id': 'b4073647-4641-4e3b-a453-2c8f042a7fe3', 'name': 'SepalWidthCm', 'alias': None, 'size': 40, 'd': 20, 'mean': 3, 'median': 3, 'concept': None, 'unit': None, 'description': None, 'enums': [], 'sets': [], 'database_id': 'f6a329d0-0cd6-4308-8c89-ad5763b42324', 'table_id': '4f9cfe1e-db91-41cc-ba3e-5a49a8274b42', 'ord': 2, 'internal_name': 'sepalwidthcm', 'index_length': None, 'length': None, 'type': 'decimal', 'data_length': None, 'max_data_length': None, 'num_rows': None, 'val_min': None, 'val_max': None, 'std_dev': 0, 'is_null_allowed': False}, {'id': '5305cc3a-6bb5-4652-afe2-0a765c2c583d', 'name': 'PetalLengthCm', 'alias': None, 'size': 40, 'd': 20, 'mean': 4, 'median': 4, 'concept': None, 'unit': None, 'description': None, 'enums': [], 'sets': [], 'database_id': 'f6a329d0-0cd6-4308-8c89-ad5763b42324', 'table_id': '4f9cfe1e-db91-41cc-ba3e-5a49a8274b42', 'ord': 3, 'internal_name': 'petallengthcm', 'index_length': None, 'length': None, 'type': 'decimal', 'data_length': None, 'max_data_length': None, 'num_rows': None, 'val_min': None, 'val_max': None, 'std_dev': 2, 'is_null_allowed': False}, {'id': '5dfb58b5-51aa-44b8-99dd-4bed7860557b', 'name': 'PetalWidthCm', 'alias': None, 'size': 40, 'd': 20, 'mean': 1, 'median': 1, 'concept': None, 'unit': None, 'description': None, 'enums': [], 'sets': [], 'database_id': 'f6a329d0-0cd6-4308-8c89-ad5763b42324', 'table_id': '4f9cfe1e-db91-41cc-ba3e-5a49a8274b42', 'ord': 4, 'internal_name': 'petalwidthcm', 'index_length': None, 'length': None, 'type': 'decimal', 'data_length': None, 'max_data_length': None, 'num_rows': None, 'val_min': None, 'val_max': None, 'std_dev': 1, 'is_null_allowed': False}, {'id': '2f7c5230-36e7-402d-b9fc-14d37e032d8d', 'name': 'Species', 'alias': None, 'size': 255, 'd': None, 'mean': None, 'median': None, 'concept': None, 'unit': None, 'description': None, 'enums': [], 'sets': [], 'database_id': 'f6a329d0-0cd6-4308-8c89-ad5763b42324', 'table_id': '4f9cfe1e-db91-41cc-ba3e-5a49a8274b42', 'ord': 5, 'internal_name': 'species', 'index_length': None, 'length': None, 'type': 'varchar', 'data_length': None, 'max_data_length': None, 'num_rows': None, 'val_min': None, 'val_max': None, 'std_dev': None, 'is_null_allowed': False}], 'constraints': {'uniques': [{'id': 'ee22b7f6-cc74-4bed-8460-b262abaa1840', 'name': 'uk_iris_data_v1_0', 'table': {'id': '4f9cfe1e-db91-41cc-ba3e-5a49a8274b42', 'name': 'iris_data_v1', 'description': 'iris_data_v1', 'database_id': 'f6a329d0-0cd6-4308-8c89-ad5763b42324', 'internal_name': 'iris_data_v1', 'is_versioned': True, 'is_public': True, 'is_schema_public': True, 'owned_by': '55bad3e0-c815-103f-9c9e-43ec87b6b872'}, 'columns': [{'id': 'a509056c-9d1b-4054-afba-4c464ee52244', 'name': 'Id', 'alias': None, 'database_id': 'f6a329d0-0cd6-4308-8c89-ad5763b42324', 'table_id': '4f9cfe1e-db91-41cc-ba3e-5a49a8274b42', 'internal_name': 'id', 'type': 'bigint'}]}], 'checks': [], 'foreign_keys': [], 'primary_key': [{'id': '9926ca7a-740d-466e-bbf7-8b2bbdf64f3a', 'table': {'id': '4f9cfe1e-db91-41cc-ba3e-5a49a8274b42', 'name': 'iris_data_v1', 'description': 'iris_data_v1', 'database_id': 'f6a329d0-0cd6-4308-8c89-ad5763b42324', 'internal_name': 'iris_data_v1', 'is_versioned': True, 'is_public': True, 'is_schema_public': True, 'owned_by': '55bad3e0-c815-103f-9c9e-43ec87b6b872'}, 'column': {'id': 'a509056c-9d1b-4054-afba-4c464ee52244', 'name': 'Id', 'alias': None, 'database_id': 'f6a329d0-0cd6-4308-8c89-ad5763b42324', 'table_id': '4f9cfe1e-db91-41cc-ba3e-5a49a8274b42', 'internal_name': 'id', 'type': 'bigint'}}]}, 'created': '2025-05-18 09:28:39', 'last_retrieved': None, 'database_id': 'f6a329d0-0cd6-4308-8c89-ad5763b42324', 'internal_name': 'iris_data_v1', 'is_versioned': True, 'is_schema_public': True, 'queue_name': 'dbrepo', 'queue_type': 'quorum', 'routing_key': 'dbrepo.f6a329d0-0cd6-4308-8c89-ad5763b42324.4f9cfe1e-db91-41cc-ba3e-5a49a8274b42', 'is_public': True, 'num_rows': 150, 'data_length': 16384, 'max_data_length': 0, 'avg_row_length': 109}, {'id': '1a4073f0-49ce-4ce6-8e6c-ad176e8fa871', 'name': 'iris_data_v4', 'alias': None, 'identifiers': [], 'owner': {'id': '55bad3e0-c815-103f-9c9e-43ec87b6b872', 'username': 'reema', 'name': 'reema dass', 'orcid': None, 'qualified_name': 'reema dass — @reema', 'given_name': 'reema', 'family_name': 'dass'}, 'description': 'iris_data_v4', 'columns': [{'id': '7aedba01-fb5f-4794-93d7-2e624fa43762', 'name': 'Id', 'alias': None, 'size': None, 'd': None, 'mean': 76, 'median': 76, 'concept': None, 'unit': None, 'description': None, 'enums': [], 'sets': [], 'database_id': 'f6a329d0-0cd6-4308-8c89-ad5763b42324', 'table_id': '1a4073f0-49ce-4ce6-8e6c-ad176e8fa871', 'ord': 0, 'internal_name': 'id', 'index_length': None, 'length': None, 'type': 'bigint', 'data_length': None, 'max_data_length': None, 'num_rows': None, 'val_min': None, 'val_max': None, 'std_dev': 43, 'is_null_allowed': False}, {'id': '282bfebb-8d39-41f0-b620-2a85bc623ff7', 'name': 'SepalLengthCm', 'alias': None, 'size': 40, 'd': 20, 'mean': 0, 'median': 0, 'concept': None, 'unit': None, 'description': None, 'enums': [], 'sets': [], 'database_id': 'f6a329d0-0cd6-4308-8c89-ad5763b42324', 'table_id': '1a4073f0-49ce-4ce6-8e6c-ad176e8fa871', 'ord': 1, 'internal_name': 'sepallengthcm', 'index_length': None, 'length': None, 'type': 'decimal', 'data_length': None, 'max_data_length': None, 'num_rows': None, 'val_min': None, 'val_max': None, 'std_dev': 0, 'is_null_allowed': False}, {'id': 'aad43499-3531-45f2-9389-7f65c388e087', 'name': 'SepalWidthCm', 'alias': None, 'size': 40, 'd': 20, 'mean': 0, 'median': 0, 'concept': None, 'unit': None, 'description': None, 'enums': [], 'sets': [], 'database_id': 'f6a329d0-0cd6-4308-8c89-ad5763b42324', 'table_id': '1a4073f0-49ce-4ce6-8e6c-ad176e8fa871', 'ord': 2, 'internal_name': 'sepalwidthcm', 'index_length': None, 'length': None, 'type': 'decimal', 'data_length': None, 'max_data_length': None, 'num_rows': None, 'val_min': None, 'val_max': None, 'std_dev': 0, 'is_null_allowed': False}, {'id': 'ef16c745-a43a-4008-ba96-92dcfd5d3878', 'name': 'PetalLengthCm', 'alias': None, 'size': 40, 'd': 20, 'mean': 0, 'median': 0, 'concept': None, 'unit': None, 'description': None, 'enums': [], 'sets': [], 'database_id': 'f6a329d0-0cd6-4308-8c89-ad5763b42324', 'table_id': '1a4073f0-49ce-4ce6-8e6c-ad176e8fa871', 'ord': 3, 'internal_name': 'petallengthcm', 'index_length': None, 'length': None, 'type': 'decimal', 'data_length': None, 'max_data_length': None, 'num_rows': None, 'val_min': None, 'val_max': None, 'std_dev': 0, 'is_null_allowed': False}, {'id': '5cbd27c4-3521-4f8e-b968-c6f6efa6fe34', 'name': 'PetalWidthCm', 'alias': None, 'size': 40, 'd': 20, 'mean': 0, 'median': 0, 'concept': None, 'unit': None, 'description': None, 'enums': [], 'sets': [], 'database_id': 'f6a329d0-0cd6-4308-8c89-ad5763b42324', 'table_id': '1a4073f0-49ce-4ce6-8e6c-ad176e8fa871', 'ord': 4, 'internal_name': 'petalwidthcm', 'index_length': None, 'length': None, 'type': 'decimal', 'data_length': None, 'max_data_length': None, 'num_rows': None, 'val_min': None, 'val_max': None, 'std_dev': 0, 'is_null_allowed': False}, {'id': 'a37ba198-a44c-413e-b888-da5836b44e66', 'name': 'Species', 'alias': None, 'size': 255, 'd': None, 'mean': None, 'median': None, 'concept': None, 'unit': None, 'description': None, 'enums': [], 'sets': [], 'database_id': 'f6a329d0-0cd6-4308-8c89-ad5763b42324', 'table_id': '1a4073f0-49ce-4ce6-8e6c-ad176e8fa871', 'ord': 5, 'internal_name': 'species', 'index_length': None, 'length': None, 'type': 'varchar', 'data_length': None, 'max_data_length': None, 'num_rows': None, 'val_min': None, 'val_max': None, 'std_dev': None, 'is_null_allowed': False}], 'constraints': {'uniques': [{'id': 'c0bd3d9a-b925-4230-8cc7-cfcbd17cb390', 'name': 'uk_iris_data_v4_0', 'table': {'id': '1a4073f0-49ce-4ce6-8e6c-ad176e8fa871', 'name': 'iris_data_v4', 'description': 'iris_data_v4', 'database_id': 'f6a329d0-0cd6-4308-8c89-ad5763b42324', 'internal_name': 'iris_data_v4', 'is_versioned': True, 'is_public': True, 'is_schema_public': True, 'owned_by': '55bad3e0-c815-103f-9c9e-43ec87b6b872'}, 'columns': [{'id': '7aedba01-fb5f-4794-93d7-2e624fa43762', 'name': 'Id', 'alias': None, 'database_id': 'f6a329d0-0cd6-4308-8c89-ad5763b42324', 'table_id': '1a4073f0-49ce-4ce6-8e6c-ad176e8fa871', 'internal_name': 'id', 'type': 'bigint'}]}], 'checks': [], 'foreign_keys': [], 'primary_key': [{'id': '4550fad1-269f-4977-8cd9-ae1eb9bf394e', 'table': {'id': '1a4073f0-49ce-4ce6-8e6c-ad176e8fa871', 'name': 'iris_data_v4', 'description': 'iris_data_v4', 'database_id': 'f6a329d0-0cd6-4308-8c89-ad5763b42324', 'internal_name': 'iris_data_v4', 'is_versioned': True, 'is_public': True, 'is_schema_public': True, 'owned_by': '55bad3e0-c815-103f-9c9e-43ec87b6b872'}, 'column': {'id': '7aedba01-fb5f-4794-93d7-2e624fa43762', 'name': 'Id', 'alias': None, 'database_id': 'f6a329d0-0cd6-4308-8c89-ad5763b42324', 'table_id': '1a4073f0-49ce-4ce6-8e6c-ad176e8fa871', 'internal_name': 'id', 'type': 'bigint'}}]}, 'created': '2025-05-18 09:30:26', 'last_retrieved': None, 'database_id': 'f6a329d0-0cd6-4308-8c89-ad5763b42324', 'internal_name': 'iris_data_v4', 'is_versioned': True, 'is_schema_public': True, 'queue_name': 'dbrepo', 'queue_type': 'quorum', 'routing_key': 'dbrepo.f6a329d0-0cd6-4308-8c89-ad5763b42324.1a4073f0-49ce-4ce6-8e6c-ad176e8fa871', 'is_public': True, 'num_rows': 150, 'data_length': 16384, 'max_data_length': 0, 'avg_row_length': 109}, {'id': '0c672781-25c3-438e-8fba-18c2c7f16886', 'name': 'iris_data_v3', 'alias': None, 'identifiers': [], 'owner': {'id': '55bad3e0-c815-103f-9c9e-43ec87b6b872', 'username': 'reema', 'name': 'reema dass', 'orcid': None, 'qualified_name': 'reema dass — @reema', 'given_name': 'reema', 'family_name': 'dass'}, 'description': 'iris_data_v3', 'columns': [{'id': 'd9b9e855-5899-4b7a-8d23-09c40a10f0e3', 'name': 'Id', 'alias': None, 'size': None, 'd': None, 'mean': 76, 'median': 76, 'concept': None, 'unit': None, 'description': None, 'enums': [], 'sets': [], 'database_id': 'f6a329d0-0cd6-4308-8c89-ad5763b42324', 'table_id': '0c672781-25c3-438e-8fba-18c2c7f16886', 'ord': 0, 'internal_name': 'id', 'index_length': None, 'length': None, 'type': 'bigint', 'data_length': None, 'max_data_length': None, 'num_rows': None, 'val_min': None, 'val_max': None, 'std_dev': 43, 'is_null_allowed': False}, {'id': 'd1f55ce2-1ed1-44e2-9839-8b5228b54a16', 'name': 'SepalLengthCm', 'alias': None, 'size': 40, 'd': 20, 'mean': 6, 'median': 6, 'concept': None, 'unit': None, 'description': None, 'enums': [], 'sets': [], 'database_id': 'f6a329d0-0cd6-4308-8c89-ad5763b42324', 'table_id': '0c672781-25c3-438e-8fba-18c2c7f16886', 'ord': 1, 'internal_name': 'sepallengthcm', 'index_length': None, 'length': None, 'type': 'decimal', 'data_length': None, 'max_data_length': None, 'num_rows': None, 'val_min': None, 'val_max': None, 'std_dev': 1, 'is_null_allowed': False}, {'id': 'bfd4a89d-1112-409d-b206-eca792b9d8f9', 'name': 'SepalWidthCm', 'alias': None, 'size': 40, 'd': 20, 'mean': 3, 'median': 3, 'concept': None, 'unit': None, 'description': None, 'enums': [], 'sets': [], 'database_id': 'f6a329d0-0cd6-4308-8c89-ad5763b42324', 'table_id': '0c672781-25c3-438e-8fba-18c2c7f16886', 'ord': 2, 'internal_name': 'sepalwidthcm', 'index_length': None, 'length': None, 'type': 'decimal', 'data_length': None, 'max_data_length': None, 'num_rows': None, 'val_min': None, 'val_max': None, 'std_dev': 0, 'is_null_allowed': False}, {'id': '9fe0bbb9-0461-4562-b8be-c4c99e083905', 'name': 'PetalLengthCm', 'alias': None, 'size': 40, 'd': 20, 'mean': 4, 'median': 4, 'concept': None, 'unit': None, 'description': None, 'enums': [], 'sets': [], 'database_id': 'f6a329d0-0cd6-4308-8c89-ad5763b42324', 'table_id': '0c672781-25c3-438e-8fba-18c2c7f16886', 'ord': 3, 'internal_name': 'petallengthcm', 'index_length': None, 'length': None, 'type': 'decimal', 'data_length': None, 'max_data_length': None, 'num_rows': None, 'val_min': None, 'val_max': None, 'std_dev': 2, 'is_null_allowed': False}, {'id': 'c54e7746-4179-4b31-9bd6-a0d17809c7ac', 'name': 'PetalWidthCm', 'alias': None, 'size': 40, 'd': 20, 'mean': 1, 'median': 1, 'concept': None, 'unit': None, 'description': None, 'enums': [], 'sets': [], 'database_id': 'f6a329d0-0cd6-4308-8c89-ad5763b42324', 'table_id': '0c672781-25c3-438e-8fba-18c2c7f16886', 'ord': 4, 'internal_name': 'petalwidthcm', 'index_length': None, 'length': None, 'type': 'decimal', 'data_length': None, 'max_data_length': None, 'num_rows': None, 'val_min': None, 'val_max': None, 'std_dev': 1, 'is_null_allowed': False}, {'id': '71249099-7722-4bec-b2bb-10a1e67861cd', 'name': 'Species', 'alias': None, 'size': 255, 'd': None, 'mean': None, 'median': None, 'concept': None, 'unit': None, 'description': None, 'enums': [], 'sets': [], 'database_id': 'f6a329d0-0cd6-4308-8c89-ad5763b42324', 'table_id': '0c672781-25c3-438e-8fba-18c2c7f16886', 'ord': 5, 'internal_name': 'species', 'index_length': None, 'length': None, 'type': 'varchar', 'data_length': None, 'max_data_length': None, 'num_rows': None, 'val_min': None, 'val_max': None, 'std_dev': None, 'is_null_allowed': False}], 'constraints': {'uniques': [{'id': 'dfb10fdc-00e0-496e-b80f-bdd2089d2e58', 'name': 'uk_iris_data_v3_0', 'table': {'id': '0c672781-25c3-438e-8fba-18c2c7f16886', 'name': 'iris_data_v3', 'description': 'iris_data_v3', 'database_id': 'f6a329d0-0cd6-4308-8c89-ad5763b42324', 'internal_name': 'iris_data_v3', 'is_versioned': True, 'is_public': True, 'is_schema_public': True, 'owned_by': '55bad3e0-c815-103f-9c9e-43ec87b6b872'}, 'columns': [{'id': 'd9b9e855-5899-4b7a-8d23-09c40a10f0e3', 'name': 'Id', 'alias': None, 'database_id': 'f6a329d0-0cd6-4308-8c89-ad5763b42324', 'table_id': '0c672781-25c3-438e-8fba-18c2c7f16886', 'internal_name': 'id', 'type': 'bigint'}]}], 'checks': [], 'foreign_keys': [], 'primary_key': [{'id': '9b74d026-7cfb-4144-9b74-780215371112', 'table': {'id': '0c672781-25c3-438e-8fba-18c2c7f16886', 'name': 'iris_data_v3', 'description': 'iris_data_v3', 'database_id': 'f6a329d0-0cd6-4308-8c89-ad5763b42324', 'internal_name': 'iris_data_v3', 'is_versioned': True, 'is_public': True, 'is_schema_public': True, 'owned_by': '55bad3e0-c815-103f-9c9e-43ec87b6b872'}, 'column': {'id': 'd9b9e855-5899-4b7a-8d23-09c40a10f0e3', 'name': 'Id', 'alias': None, 'database_id': 'f6a329d0-0cd6-4308-8c89-ad5763b42324', 'table_id': '0c672781-25c3-438e-8fba-18c2c7f16886', 'internal_name': 'id', 'type': 'bigint'}}]}, 'created': '2025-05-18 09:29:51', 'last_retrieved': None, 'database_id': 'f6a329d0-0cd6-4308-8c89-ad5763b42324', 'internal_name': 'iris_data_v3', 'is_versioned': True, 'is_schema_public': True, 'queue_name': 'dbrepo', 'queue_type': 'quorum', 'routing_key': 'dbrepo.f6a329d0-0cd6-4308-8c89-ad5763b42324.0c672781-25c3-438e-8fba-18c2c7f16886', 'is_public': True, 'num_rows': 150, 'data_length': 16384, 'max_data_length': 0, 'avg_row_length': 109}], 'views': [], 'container': {'id': '6cfb3b8e-1792-4e46-871a-f3d103527203', 'name': 'mariadb:11.3.2', 'image': {'id': 'd79cb089-363c-488b-9717-649e44d8fcc5', 'name': 'mariadb', 'version': '11.1.3', 'operators': [{'id': '2d24ddd7-33c9-11f0-bcbb-e2d84432ea81', 'value': '!=', 'documentation': 'https://mariadb.com/kb/en/not-equal/', 'display_name': 'Not equal operator'}, {'id': '2d24daab-33c9-11f0-bcbb-e2d84432ea81', 'value': '<', 'documentation': 'https://mariadb.com/kb/en/less-than/', 'display_name': 'Less-than operator'}, {'id': '2d24db68-33c9-11f0-bcbb-e2d84432ea81', 'value': '<=', 'documentation': 'https://mariadb.com/kb/en/less-than-or-equal/', 'display_name': 'Less than or equal operator'}, {'id': '2d24d8a3-33c9-11f0-bcbb-e2d84432ea81', 'value': '<=>', 'documentation': 'https://mariadb.com/kb/en/null-safe-equal/', 'display_name': 'NULL-safe equal operator'}, {'id': '2d24d4ff-33c9-11f0-bcbb-e2d84432ea81', 'value': '=', 'documentation': 'https://mariadb.com/kb/en/assignment-operators-assignment-operator/', 'display_name': 'Equal operator'}, {'id': '2d24dcca-33c9-11f0-bcbb-e2d84432ea81', 'value': '>', 'documentation': 'https://mariadb.com/kb/en/greater-than/', 'display_name': 'Greater-than operator'}, {'id': '2d24dd51-33c9-11f0-bcbb-e2d84432ea81', 'value': '>=', 'documentation': 'https://mariadb.com/kb/en/greater-than-or-equal/', 'display_name': 'Greater than or equal operator'}, {'id': '2d24df85-33c9-11f0-bcbb-e2d84432ea81', 'value': 'IN', 'documentation': 'https://mariadb.com/kb/en/in/', 'display_name': 'IN'}, {'id': '2d24e07f-33c9-11f0-bcbb-e2d84432ea81', 'value': 'IS NOT NULL', 'documentation': 'https://mariadb.com/kb/en/is-not-null/', 'display_name': 'IS NOT NULL'}, {'id': '2d24e0f7-33c9-11f0-bcbb-e2d84432ea81', 'value': 'IS NULL', 'documentation': 'https://mariadb.com/kb/en/is-null/', 'display_name': 'IS NULL'}, {'id': '2d24de7c-33c9-11f0-bcbb-e2d84432ea81', 'value': 'LIKE', 'documentation': 'https://mariadb.com/kb/en/like/', 'display_name': 'LIKE'}, {'id': '2d24dfff-33c9-11f0-bcbb-e2d84432ea81', 'value': 'NOT IN', 'documentation': 'https://mariadb.com/kb/en/not-in/', 'display_name': 'NOT IN'}, {'id': '2d24df05-33c9-11f0-bcbb-e2d84432ea81', 'value': 'NOT LIKE', 'documentation': 'https://mariadb.com/kb/en/not-like/', 'display_name': 'NOT LIKE'}, {'id': '2d24e1e5-33c9-11f0-bcbb-e2d84432ea81', 'value': 'NOT REGEXP', 'documentation': 'https://mariadb.com/kb/en/not-regexp/', 'display_name': 'NOT REGEXP'}, {'id': '2d24e16a-33c9-11f0-bcbb-e2d84432ea81', 'value': 'REGEXP', 'documentation': 'https://mariadb.com/kb/en/regexp/', 'display_name': 'REGEXP'}], 'default': False, 'data_types': [{'id': '2d23cc31-33c9-11f0-bcbb-e2d84432ea81', 'value': 'bigint', 'documentation': 'https://mariadb.com/kb/en/bigint/', 'display_name': 'BIGINT(size)', 'size_min': 0, 'size_max': None, 'size_default': None, 'size_required': False, 'd_min': None, 'd_max': None, 'd_default': None, 'd_required': None, 'data_hint': None, 'type_hint': None, 'is_quoted': False, 'is_buildable': True}, {'id': '2d23cf57-33c9-11f0-bcbb-e2d84432ea81', 'value': 'binary', 'documentation': 'https://mariadb.com/kb/en/binary/', 'display_name': 'BINARY(size)', 'size_min': 0, 'size_max': 255, 'size_default': 255, 'size_required': True, 'd_min': None, 'd_max': None, 'd_default': None, 'd_required': None, 'data_hint': None, 'type_hint': 'size in Bytes', 'is_quoted': False, 'is_buildable': True}, {'id': '2d23d188-33c9-11f0-bcbb-e2d84432ea81', 'value': 'bit', 'documentation': 'https://mariadb.com/kb/en/bit/', 'display_name': 'BIT(size)', 'size_min': 0, 'size_max': 64, 'size_default': None, 'size_required': False, 'd_min': None, 'd_max': None, 'd_default': None, 'd_required': None, 'data_hint': None, 'type_hint': None, 'is_quoted': False, 'is_buildable': True}, {'id': '2d23d262-33c9-11f0-bcbb-e2d84432ea81', 'value': 'blob', 'documentation': 'https://mariadb.com/kb/en/blob/', 'display_name': 'BLOB(size)', 'size_min': 0, 'size_max': 65535, 'size_default': None, 'size_required': False, 'd_min': None, 'd_max': None, 'd_default': None, 'd_required': None, 'data_hint': None, 'type_hint': 'size in Bytes', 'is_quoted': False, 'is_buildable': False}, {'id': '2d23d301-33c9-11f0-bcbb-e2d84432ea81', 'value': 'bool', 'documentation': 'https://mariadb.com/kb/en/bool/', 'display_name': 'BOOL', 'size_min': None, 'size_max': None, 'size_default': None, 'size_required': None, 'd_min': None, 'd_max': None, 'd_default': None, 'd_required': None, 'data_hint': None, 'type_hint': None, 'is_quoted': False, 'is_buildable': True}, {'id': '2d23d38a-33c9-11f0-bcbb-e2d84432ea81', 'value': 'char', 'documentation': 'https://mariadb.com/kb/en/char/', 'display_name': 'CHAR(size)', 'size_min': 0, 'size_max': 255, 'size_default': 255, 'size_required': False, 'd_min': None, 'd_max': None, 'd_default': None, 'd_required': None, 'data_hint': None, 'type_hint': None, 'is_quoted': False, 'is_buildable': True}, {'id': '2d23d3f0-33c9-11f0-bcbb-e2d84432ea81', 'value': 'date', 'documentation': 'https://mariadb.com/kb/en/date/', 'display_name': 'DATE', 'size_min': None, 'size_max': None, 'size_default': None, 'size_required': None, 'd_min': None, 'd_max': None, 'd_default': None, 'd_required': None, 'data_hint': 'e.g. YYYY-MM-DD, YY-MM-DD, YYMMDD, YYYY/MM/DD', 'type_hint': 'min. 1000-01-01, max. 9999-12-31', 'is_quoted': True, 'is_buildable': True}, {'id': '2d23d4bf-33c9-11f0-bcbb-e2d84432ea81', 'value': 'datetime', 'documentation': 'https://mariadb.com/kb/en/datetime/', 'display_name': 'DATETIME(fsp)', 'size_min': 0, 'size_max': 6, 'size_default': None, 'size_required': None, 'd_min': None, 'd_max': None, 'd_default': None, 'd_required': None, 'data_hint': 'e.g. YYYY-MM-DD HH:MM:SS, YY-MM-DD HH:MM:SS, YYYYMMDDHHMMSS, YYMMDDHHMMSS, YYYYMMDD, YYMMDD', 'type_hint': 'fsp=microsecond precision, min. 1000-01-01 00:00:00.0, max. 9999-12-31 23:59:59.9', 'is_quoted': True, 'is_buildable': True}, {'id': '2d23d569-33c9-11f0-bcbb-e2d84432ea81', 'value': 'decimal', 'documentation': 'https://mariadb.com/kb/en/decimal/', 'display_name': 'DECIMAL(size, d)', 'size_min': 0, 'size_max': 65, 'size_default': None, 'size_required': False, 'd_min': 0, 'd_max': 38, 'd_default': None, 'd_required': False, 'data_hint': None, 'type_hint': None, 'is_quoted': False, 'is_buildable': True}, {'id': '2d23d5f9-33c9-11f0-bcbb-e2d84432ea81', 'value': 'double', 'documentation': 'https://mariadb.com/kb/en/double/', 'display_name': 'DOUBLE(size, d)', 'size_min': None, 'size_max': None, 'size_default': None, 'size_required': False, 'd_min': None, 'd_max': None, 'd_default': None, 'd_required': False, 'data_hint': None, 'type_hint': None, 'is_quoted': False, 'is_buildable': True}, {'id': '2d23d67a-33c9-11f0-bcbb-e2d84432ea81', 'value': 'enum', 'documentation': 'https://mariadb.com/kb/en/enum/', 'display_name': 'ENUM(v1,v2,...)', 'size_min': None, 'size_max': None, 'size_default': None, 'size_required': None, 'd_min': None, 'd_max': None, 'd_default': None, 'd_required': None, 'data_hint': 'e.g. value1, value2, ...', 'type_hint': None, 'is_quoted': True, 'is_buildable': True}, {'id': '2d23d6ec-33c9-11f0-bcbb-e2d84432ea81', 'value': 'float', 'documentation': 'https://mariadb.com/kb/en/float/', 'display_name': 'FLOAT(size)', 'size_min': None, 'size_max': None, 'size_default': None, 'size_required': False, 'd_min': None, 'd_max': None, 'd_default': None, 'd_required': None, 'data_hint': None, 'type_hint': None, 'is_quoted': False, 'is_buildable': True}, {'id': '2d23d79c-33c9-11f0-bcbb-e2d84432ea81', 'value': 'int', 'documentation': 'https://mariadb.com/kb/en/int/', 'display_name': 'INT(size)', 'size_min': None, 'size_max': None, 'size_default': None, 'size_required': False, 'd_min': None, 'd_max': None, 'd_default': None, 'd_required': None, 'data_hint': None, 'type_hint': 'size in Bytes', 'is_quoted': False, 'is_buildable': True}, {'id': '2d23d81f-33c9-11f0-bcbb-e2d84432ea81', 'value': 'longblob', 'documentation': 'https://mariadb.com/kb/en/longblob/', 'display_name': 'LONGBLOB', 'size_min': None, 'size_max': None, 'size_default': None, 'size_required': None, 'd_min': None, 'd_max': None, 'd_default': None, 'd_required': None, 'data_hint': None, 'type_hint': 'max. 3.999 GiB', 'is_quoted': False, 'is_buildable': True}, {'id': '2d23d8a4-33c9-11f0-bcbb-e2d84432ea81', 'value': 'longtext', 'documentation': 'https://mariadb.com/kb/en/longtext/', 'display_name': 'LONGTEXT', 'size_min': None, 'size_max': None, 'size_default': None, 'size_required': None, 'd_min': None, 'd_max': None, 'd_default': None, 'd_required': None, 'data_hint': None, 'type_hint': 'max. 3.999 GiB', 'is_quoted': True, 'is_buildable': True}, {'id': '2d23d937-33c9-11f0-bcbb-e2d84432ea81', 'value': 'mediumblob', 'documentation': 'https://mariadb.com/kb/en/mediumblob/', 'display_name': 'MEDIUMBLOB', 'size_min': None, 'size_max': None, 'size_default': None, 'size_required': None, 'd_min': None, 'd_max': None, 'd_default': None, 'd_required': None, 'data_hint': None, 'type_hint': 'max. 15.999 MiB', 'is_quoted': False, 'is_buildable': True}, {'id': '2d23d993-33c9-11f0-bcbb-e2d84432ea81', 'value': 'mediumint', 'documentation': 'https://mariadb.com/kb/en/mediumint/', 'display_name': 'MEDIUMINT', 'size_min': None, 'size_max': None, 'size_default': None, 'size_required': None, 'd_min': None, 'd_max': None, 'd_default': None, 'd_required': None, 'data_hint': None, 'type_hint': 'size in Bytes', 'is_quoted': False, 'is_buildable': True}, {'id': '2d23d9df-33c9-11f0-bcbb-e2d84432ea81', 'value': 'mediumtext', 'documentation': 'https://mariadb.com/kb/en/mediumtext/', 'display_name': 'MEDIUMTEXT', 'size_min': None, 'size_max': None, 'size_default': None, 'size_required': None, 'd_min': None, 'd_max': None, 'd_default': None, 'd_required': None, 'data_hint': None, 'type_hint': 'size in Bytes', 'is_quoted': True, 'is_buildable': True}, {'id': '2d23da2d-33c9-11f0-bcbb-e2d84432ea81', 'value': 'serial', 'documentation': 'https://mariadb.com/kb/en/bigint/', 'display_name': 'SERIAL', 'size_min': None, 'size_max': None, 'size_default': None, 'size_required': None, 'd_min': None, 'd_max': None, 'd_default': None, 'd_required': None, 'data_hint': None, 'type_hint': None, 'is_quoted': True, 'is_buildable': True}, {'id': '2d23da7a-33c9-11f0-bcbb-e2d84432ea81', 'value': 'set', 'documentation': 'https://mariadb.com/kb/en/set/', 'display_name': 'SET(v1,v2,...)', 'size_min': None, 'size_max': None, 'size_default': None, 'size_required': None, 'd_min': None, 'd_max': None, 'd_default': None, 'd_required': None, 'data_hint': 'e.g. value1, value2, ...', 'type_hint': None, 'is_quoted': True, 'is_buildable': True}, {'id': '2d23dae0-33c9-11f0-bcbb-e2d84432ea81', 'value': 'smallint', 'documentation': 'https://mariadb.com/kb/en/smallint/', 'display_name': 'SMALLINT(size)', 'size_min': 0, 'size_max': None, 'size_default': None, 'size_required': False, 'd_min': None, 'd_max': None, 'd_default': None, 'd_required': None, 'data_hint': None, 'type_hint': 'size in Bytes', 'is_quoted': False, 'is_buildable': True}, {'id': '2d23db2d-33c9-11f0-bcbb-e2d84432ea81', 'value': 'text', 'documentation': 'https://mariadb.com/kb/en/text/', 'display_name': 'TEXT(size)', 'size_min': 0, 'size_max': None, 'size_default': None, 'size_required': False, 'd_min': None, 'd_max': None, 'd_default': None, 'd_required': None, 'data_hint': None, 'type_hint': 'size in Bytes', 'is_quoted': True, 'is_buildable': True}, {'id': '2d23db78-33c9-11f0-bcbb-e2d84432ea81', 'value': 'time', 'documentation': 'https://mariadb.com/kb/en/time/', 'display_name': 'TIME(fsp)', 'size_min': 0, 'size_max': 6, 'size_default': 0, 'size_required': False, 'd_min': None, 'd_max': None, 'd_default': None, 'd_required': None, 'data_hint': 'e.g. HH:MM:SS, HH:MM, HHMMSS, H:M:S', 'type_hint': 'fsp=microsecond precision, min. 0, max. 6', 'is_quoted': True, 'is_buildable': True}, {'id': '2d23dbc9-33c9-11f0-bcbb-e2d84432ea81', 'value': 'timestamp', 'documentation': 'https://mariadb.com/kb/en/timestamp/', 'display_name': 'TIMESTAMP(fsp)', 'size_min': 0, 'size_max': 6, 'size_default': 0, 'size_required': False, 'd_min': None, 'd_max': None, 'd_default': None, 'd_required': None, 'data_hint': 'e.g. YYYY-MM-DD HH:MM:SS, YY-MM-DD HH:MM:SS, YYYYMMDDHHMMSS, YYMMDDHHMMSS, YYYYMMDD, YYMMDD', 'type_hint': 'fsp=microsecond precision, min. 0, max. 6', 'is_quoted': True, 'is_buildable': True}, {'id': '2d23dc24-33c9-11f0-bcbb-e2d84432ea81', 'value': 'tinyblob', 'documentation': 'https://mariadb.com/kb/en/timestamp/', 'display_name': 'TINYBLOB', 'size_min': None, 'size_max': None, 'size_default': None, 'size_required': None, 'd_min': None, 'd_max': None, 'd_default': None, 'd_required': None, 'data_hint': 'fsp=microsecond precision, min. 0, max. 6', 'type_hint': None, 'is_quoted': False, 'is_buildable': True}, {'id': '2d23dc74-33c9-11f0-bcbb-e2d84432ea81', 'value': 'tinyint', 'documentation': 'https://mariadb.com/kb/en/tinyint/', 'display_name': 'TINYINT(size)', 'size_min': 0, 'size_max': None, 'size_default': None, 'size_required': False, 'd_min': None, 'd_max': None, 'd_default': None, 'd_required': None, 'data_hint': 'size in Bytes', 'type_hint': None, 'is_quoted': False, 'is_buildable': True}, {'id': '2d23dcc0-33c9-11f0-bcbb-e2d84432ea81', 'value': 'tinytext', 'documentation': 'https://mariadb.com/kb/en/tinytext/', 'display_name': 'TINYTEXT', 'size_min': None, 'size_max': None, 'size_default': None, 'size_required': None, 'd_min': None, 'd_max': None, 'd_default': None, 'd_required': None, 'data_hint': 'max. 255 characters', 'type_hint': None, 'is_quoted': True, 'is_buildable': True}, {'id': '2d23dd19-33c9-11f0-bcbb-e2d84432ea81', 'value': 'year', 'documentation': 'https://mariadb.com/kb/en/year/', 'display_name': 'YEAR', 'size_min': 2, 'size_max': 4, 'size_default': None, 'size_required': False, 'd_min': None, 'd_max': None, 'd_default': None, 'd_required': None, 'data_hint': 'e.g. YYYY, YY', 'type_hint': 'min. 1901, max. 2155', 'is_quoted': False, 'is_buildable': True}, {'id': '2d23dd71-33c9-11f0-bcbb-e2d84432ea81', 'value': 'varbinary', 'documentation': 'https://mariadb.com/kb/en/varbinary/', 'display_name': 'VARBINARY(size)', 'size_min': 0, 'size_max': None, 'size_default': None, 'size_required': True, 'd_min': None, 'd_max': None, 'd_default': None, 'd_required': None, 'data_hint': None, 'type_hint': None, 'is_quoted': False, 'is_buildable': True}, {'id': '2d23ddc3-33c9-11f0-bcbb-e2d84432ea81', 'value': 'varchar', 'documentation': 'https://mariadb.com/kb/en/varchar/', 'display_name': 'VARCHAR(size)', 'size_min': 0, 'size_max': 65532, 'size_default': 255, 'size_required': True, 'd_min': None, 'd_max': None, 'd_default': None, 'd_required': None, 'data_hint': None, 'type_hint': None, 'is_quoted': False, 'is_buildable': True}]}, 'quota': None, 'count': None, 'username': None, 'password': None, 'last_retrieved': None, 'internal_name': 'mariadb_11_3_2'}, 'accesses': [], 'identifiers': [], 'subsets': [], 'contact': {'id': '55bad3e0-c815-103f-9c9e-43ec87b6b872', 'username': 'reema', 'name': 'reema dass', 'orcid': None, 'qualified_name': 'reema dass — @reema', 'given_name': 'reema', 'family_name': 'dass'}, 'owner': {'id': '55bad3e0-c815-103f-9c9e-43ec87b6b872', 'username': 'reema', 'name': 'reema dass', 'orcid': None, 'qualified_name': 'reema dass — @reema', 'given_name': 'reema', 'family_name': 'dass'}, 'created': '2025-05-18 09:22:32', 'last_retrieved': None, 'dashboard_uid': 'bem8sq0qnka9sf', 'exchange_name': 'dbrepo', 'exchange_type': None, 'internal_name': 'iris_wmeb', 'is_public': True, 'is_schema_public': True, 'is_dashboard_enabled': True, 'preview_image': None}\n",
      "[{'timestamp': '2025-05-18T09:29:55.721Z', 'event': 'insert', 'total': 150}]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter test size (e.g., 0.2 for 20% test set):  fssf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid input. Defaulting to 0.2\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter random seed (e.g., 42):  fsvd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid input. Defaulting to 42\n",
      "Choose a model to train:\n",
      "1. random_forest\n",
      "2. decision_tree\n",
      "3. logistic_regression\n",
      "4. knn\n",
      "5. svm\n",
      "6. gradient_boosting\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter model number (default 1 for random_forest):  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📝 Justification for `n_estimators` (Hyperparameter configuration)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "→ Why did you choose this value?  bd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📝 Justification for `criterion` (Hyperparameter configuration)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "→ Why did you choose this value?  fbd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📝 Justification for `max_depth` (Hyperparameter configuration)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "→ Why did you choose this value?  sffffffffffff\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📝 Justification for `min_samples_split` (Hyperparameter configuration)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "→ Why did you choose this value?  fvdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📝 Justification for `min_samples_leaf` (Hyperparameter configuration)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "→ Why did you choose this value?  dbfd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📝 Justification for `max_features` (Hyperparameter configuration)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "→ Why did you choose this value?  vcxbs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📝 Justification for `bootstrap` (Hyperparameter configuration)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "→ Why did you choose this value?  dssf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📝 Justification for `oob_score` (Hyperparameter configuration)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "→ Why did you choose this value?  fddfb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📝 Justification for `class_weight` (Hyperparameter configuration)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "→ Why did you choose this value?  fbdbd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📝 Justification for `verbose` (Hyperparameter configuration)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "→ Why did you choose this value?  fbbbd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📝 Justification for `n_jobs` (Hyperparameter configuration)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "→ Why did you choose this value?  dfbd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4df1394dd45b43f781e6cf633990acd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📝 Justification for `model_choice`\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "→ Why did you choose this model (e.g., RandomForestClassifier) for this task?  fdd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📝 Justification for `target_variable`\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "→ Why did you choose this column as the prediction target?  gdbvd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📝 Justification for `test_split`\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "→ Why this train/test ratio (e.g., 80/20)?  dfvdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📝 Justification for `metric_choice`\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "→ Why did you use accuracy/f1/ROC-AUC as your evaluation metric?  dfbd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📝 Justification for `threshold_accuracy`\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "→ Was there a threshold for accuracy? Why?  dbdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📝 Justification for `dataset_version`\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "→ Why did you use this specific dataset version?  dbdb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📝 Justification for `drop_column_X`\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "→ Why did you drop any specific columns from the dataset?  dbdb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📝 Justification for `experiment_name`\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "→ Any context behind this experiment name or setup?  ddb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📝 Justification for `model_limitations`\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "→ Any known model limitations?  dbdb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📝 Justification for `ethical_considerations`\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "→ Any known model ethical considerations?  dbdbd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📝 Justification for `intended_use`\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "→ Known model intended use?  dbdb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📝 Justification for `not_intended_for`\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "→ Model not_intended_for?  db\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\reema\\anaconda3\\Lib\\site-packages\\shap\\plots\\_beeswarm.py:1153: UserWarning: The figure layout has changed to tight\n",
      "  pl.tight_layout()\n",
      "C:\\Users\\reema\\anaconda3\\Lib\\site-packages\\shap\\plots\\_beeswarm.py:761: UserWarning: The figure layout has changed to tight\n",
      "  pl.tight_layout(pad=0, w_pad=0, h_pad=0.0)\n",
      "C:\\Users\\reema\\AppData\\Local\\Temp\\ipykernel_27980\\1830696726.py:327: UserWarning: The figure layout has changed to tight\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Commit successful.\n",
      "🚀 Push successful.\n",
      "⚠️ Commit c53df165 is not tagged with a version.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "🔖 Enter version tag for this commit (or press Enter to skip):  v99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Logged tag: DOI_dataset_id\n",
      "✅ Logged tag: DOI_dataset_title\n",
      "✅ Logged tag: DOI_dataset_description\n",
      "✅ Logged tag: DOI_dataset_creator\n",
      "✅ Logged tag: DOI_dataset_publisher\n",
      "✅ Logged tag: DOI_dataset_publication_date\n",
      "✅ Logged tag: DOI_dataset_license\n",
      "✅ Logged tag: DOI_dataset_keywords\n",
      "✅ Logged tag: DOI_dataset_access_url\n",
      "✅ Logged tag: DOI_dataset_documentation\n",
      "✅ Logged tag: DOI_metadata_standard\n",
      "✅ Logged tag: DOI_related_resources\n",
      "✅ Logged tag: DOI_prov_entity\n",
      "✅ Logged tag: DOI_prov_activity\n",
      "✅ Logged tag: DOI_prov_agent_dataset_creator\n",
      "✅ Logged tag: DOI_prov_used\n",
      "✅ Logged tag: DOI_prov_wasDerivedFrom\n",
      "✅ Logged tag: DOI_prov_wasAttributedTo\n",
      "✅ Logged tag: DOI_prov_startedAtTime\n",
      "✅ Logged tag: DOI_prov_role_dataset_creator\n",
      "✅ Logged tag: DOI_prov_role_database_creator\n",
      "📁 Full metadata snapshot logged as: doi_metadata_snapshot.json\n",
      "📁 Run summary JSON logged at: C:\\Users\\reema\\REPO\\notebooks\\RQ_notebooks\\MODEL_PROVENANCE\\RandomForest_Iris_v20250518_170352\\RandomForest_Iris_v20250518_170352_run_summary.json\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "from datetime import datetime\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "    client = MlflowClient()\n",
    "    run_data = client.get_run(run.info.run_id).data\n",
    "    # ─────────────── Session Metadata ─────────────────────────────────────\n",
    "    session_metadata = collect_session_metadata(prompt_fields=True)\n",
    "    mlflow.log_params(session_metadata)  # [PROV, Internal] Session and environment context\n",
    "\n",
    "    # ─────────────── Dataset Metadata ─────────────────────────────────────\n",
    "    doi_metadata = extract_dataset_metadata_from_doi(\"10.24432/C56C76\")  # [FAIR, PROV, FAIR4ML]\n",
    "\n",
    "    # ─────────────── Experiment Start Time ────────────────────────────────\n",
    "    start_time = datetime.now().isoformat()\n",
    "    mlflow.set_tag(\"startedAtTime\", start_time)  # [PROV] Activity start time\n",
    "\n",
    "    #######################################################################\n",
    "    ### Preprocessing #####################################################\n",
    "\n",
    "    # ── Load into a DataFrame ────────────────────────────────────────────\n",
    "    df = pd.DataFrame(dataset)\n",
    "    original_row_count = df.shape[0]\n",
    "    mlflow.log_param(\"input_row_count\", original_row_count)  # [MLSEA] Input data size\n",
    "\n",
    "    # Log column names before transformation\n",
    "    mlflow.set_tag(\"raw_columns\", ','.join(df.columns))  # [FAIR4ML, Internal]\n",
    "\n",
    "    # ── Generate row hashes ───────────────────────────────────────────────\n",
    "    before_hashes = set(df.astype(str).apply(lambda row: hash(tuple(row)), axis=1))\n",
    "    mlflow.set_tag(\"row_hash_tracking\", \"enabled\")  # [Internal] Used for provenance/repeatability\n",
    "\n",
    "    # ── Extract target variable ───────────────────────────────────────────\n",
    "    target_col = df.columns[-1]\n",
    "    mlflow.set_tag(\"target_variable\", target_col)  # [FAIR4ML, MLSEA]\n",
    "\n",
    "    # ── Separate features and labels ──────────────────────────────────────\n",
    "    y = df[target_col]\n",
    "    X = df.drop(columns=[target_col])\n",
    "    mlflow.set_tag(\"feature_columns\", ','.join(X.columns))  # [FAIR4ML, MLSEA]\n",
    "\n",
    "    # ── Drop ID columns (case-insensitive) ────────────────────────────────\n",
    "    id_cols = [c for c in X.columns if c.lower() == \"id\"]\n",
    "    if id_cols:\n",
    "        X = X.drop(columns=id_cols)\n",
    "        mlflow.set_tag(\"dropped_id_columns\", ','.join(id_cols))  # [Internal]\n",
    "\n",
    "    # ── Convert columns to numeric where possible ─────────────────────────\n",
    "    numeric_conversion_count = 0\n",
    "    for c in X.columns:\n",
    "        try:\n",
    "            X[c] = pd.to_numeric(X[c])\n",
    "            numeric_conversion_count += 1\n",
    "        except Exception:\n",
    "            continue\n",
    "    mlflow.log_param(\"numeric_columns_converted\", numeric_conversion_count)  # [Internal, FAIR4ML]\n",
    "\n",
    "    # ── Print diagnostic info ─────────────────────────────────────────────\n",
    "    print(\"ML_EXP_Shapes:\", X.shape, y.shape)\n",
    "    mlflow.log_param(\"feature_matrix_shape\", str(X.shape))  # [MLSEA]\n",
    "    mlflow.log_param(\"label_vector_shape\", str(y.shape))    # [MLSEA]\n",
    "#######################################################################################################\n",
    "### 8) Label Encoding and Metadata Logging ############################################################\n",
    "\n",
    "# ── Encode class labels numerically ────────────────────────────────────────────────────────\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(y)\n",
    "    print(\"ML_EXP_Classes:\", le.classes_)\n",
    "    \n",
    "    mlflow.set_tag(\"class_names\", ','.join(le.classes_))  # [FAIR4ML, MLSEA]\n",
    "    \n",
    "    # ── Count rows and hash comparison before vs after preprocessing ────────────────────────────\n",
    "    count_end = df.shape[0]\n",
    "    after_hashes = set(df.astype(str).apply(lambda row: hash(tuple(row)), axis=1))\n",
    "    \n",
    "    n_insert = len(after_hashes - before_hashes)\n",
    "    n_delete = len(before_hashes - after_hashes)\n",
    "    \n",
    "    #######################################################################################################\n",
    "    ### Metadata Logging (Standardized Format) ############################################################\n",
    "    \n",
    "    # ── Extended DB Metadata ────────────────────────────────────────────────────────────────────\n",
    "    db_meta = fetch_db_dataset_metadata(db_id, selected_table_id, selected_version, target_col, df.shape[0])  # [Internal]\n",
    "    \n",
    "    mlflow.set_tag(\"Internal_DBRepo_table_last_modified\", db_meta.get(\"dataset_publication_date\", \"unknown\"))\n",
    "  # [PROV]\n",
    "    \n",
    "    # ── Row Count Metrics ────────────────────────────────────────────────────────────────────────\n",
    "    mlflow.log_metric(\"row_count_start\", original_row_count)              # [MLSEA, FAIR4ML]\n",
    "    mlflow.log_metric(\"row_count_end\", count_end)                  # [MLSEA, FAIR4ML]\n",
    "    mlflow.log_metric(\"num_inserted_rows\", n_insert)               # [PROV]\n",
    "    mlflow.log_metric(\"num_deleted_rows\", n_delete)                # [PROV]\n",
    "    \n",
    "    # ── Raw Data Source Metadata ─────────────────────────────────────────────────────────────────\n",
    "    mlflow.set_tag(\"data_source\", API_URL)                         # [FAIR]\n",
    "    mlflow.log_param(\"retrieval_time_utc\", datetime.utcnow().isoformat())  # [PROV]\n",
    "    mlflow.log_param(\"raw_row_count\", len(df))                     # [MLSEA]\n",
    "    mlflow.log_param(\"raw_columns\", df.columns.tolist())           # [FAIR4ML]\n",
    "    mlflow.log_param(\"dropped_columns\", id_cols)                   # [Internal]\n",
    "    \n",
    "    # ── Post-Processing Metadata ─────────────────────────────────────────────────────────────────\n",
    "    mlflow.log_param(\"final_num_features\", X.shape[1])             # [MLSEA]\n",
    "    mlflow.log_param(\"final_feature_names\", X.columns.tolist())    # [FAIR4ML]\n",
    "    mlflow.set_tag(\"target_variable_encoded\", target_col)          # [FAIR4ML]\n",
    "    \n",
    "    # ── Label Mapping as Artifact ───────────────────────────────────────────────────────────────\n",
    "    label_map = {int(idx): cls for idx, cls in enumerate(le.classes_)}\n",
    "    buffer = io.StringIO()\n",
    "    json.dump(label_map, buffer, indent=2)\n",
    "    buffer.seek(0)\n",
    "    mlflow.log_text(buffer.getvalue(), artifact_file=\"label_mapping.json\")  # [FAIR4ML]\n",
    "    \n",
    "    # ── Training Metadata ────────────────────────────────────────────────────────────────────────\n",
    "    ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    model_name = f\"RandomForest_Iris_v{ts}\"\n",
    "    mlflow.set_tag(\"model_name\", model_name)                       # [MLSEA]\n",
    "    \n",
    "    train_start_ts = datetime.now().isoformat()\n",
    "    mlflow.set_tag(\"training_start_time\", train_start_ts)          # [PROV]\n",
    "########################################################################################################\n",
    "### Model Parameters & Split Metadata ##################################################################\n",
    "\n",
    "# ── Prompt test size and seed ─────────────────────────────────────────────────────────────────────────\n",
    "    try:\n",
    "        test_size = float(input(\"Enter test size (e.g., 0.2 for 20% test set): \"))\n",
    "    except ValueError:\n",
    "        print(\"Invalid input. Defaulting to 0.2\")\n",
    "        test_size = 0.2\n",
    "    \n",
    "    try:\n",
    "        random_state = int(input(\"Enter random seed (e.g., 42): \"))\n",
    "    except ValueError:\n",
    "        print(\"Invalid input. Defaulting to 42\")\n",
    "        random_state = 42\n",
    "    \n",
    "    # ── Train/test split ────────────────────────────────────────────────────────────────────────────────\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "    \n",
    "    # ── Log split config ────────────────────────────────────────────────────────────────────────────────\n",
    "    mlflow.log_param(\"test_size\", test_size)                     # [MLSEA]\n",
    "    mlflow.log_param(\"random_seed\", random_state)               # [PROV]\n",
    "    mlflow.log_param(\"n_train_samples\", X_train.shape[0])       # [FAIR4ML]\n",
    "    mlflow.log_param(\"n_test_samples\",  X_test.shape[0])        # [FAIR4ML]\n",
    "    mlflow.log_param(\"n_features\",      X_train.shape[1])       # [MLSEA]\n",
    "    \n",
    "    ########################################################################################################\n",
    "    ### Model Selection & Hyperparameters ##################################################################\n",
    "    \n",
    "    # ── Define hyperparameters ───────────────────────────────────────────────────────────────────────────\n",
    "    ML_EXP_hyperparams = {\n",
    "        \"n_estimators\":       100,\n",
    "        \"criterion\":          \"entropy\",\n",
    "        \"max_depth\":          10,\n",
    "        \"min_samples_split\":  3,\n",
    "        \"min_samples_leaf\":   1,\n",
    "        \"max_features\":       \"sqrt\",\n",
    "        \"bootstrap\":          True,\n",
    "        \"oob_score\":          True,\n",
    "        \"class_weight\":       None,\n",
    "        \"verbose\":            1,\n",
    "        \"n_jobs\":             -1\n",
    "    }\n",
    "    \n",
    "    # ── Model selection ───────────────────────────────────────────────────────────────────────────────────\n",
    "    available_models = {\n",
    "        \"random_forest\": RandomForestClassifier,\n",
    "        \"decision_tree\": DecisionTreeClassifier,\n",
    "        \"logistic_regression\": LogisticRegression,\n",
    "        \"knn\": KNeighborsClassifier,\n",
    "        \"svm\": SVC,\n",
    "        \"gradient_boosting\": GradientBoostingClassifier\n",
    "    }\n",
    "    \n",
    "    # User prompt\n",
    "    print(\"Choose a model to train:\")\n",
    "    for i, name in enumerate(available_models.keys()):\n",
    "        print(f\"{i + 1}. {name}\")\n",
    "    \n",
    "    choice = input(\"Enter model number (default 1 for random_forest): \").strip()\n",
    "    choice = int(choice) if choice else 1\n",
    "    selected_key = list(available_models.keys())[choice - 1]\n",
    "    selected_model_class = available_models[selected_key]\n",
    "    mlflow.set_tag(\"selected_model\", selected_key)  # [FAIR4ML, MLSEA]\n",
    "    \n",
    "    # ── Initialize model ────────────────────────────────────────────────────────────────────────────────\n",
    "    model = selected_model_class(**ML_EXP_hyperparams)\n",
    "    \n",
    "    # ── Log hyperparameters with justification ───────────────────────────────────────────────────────────\n",
    "    for key, val in ML_EXP_hyperparams.items():\n",
    "        log_with_justification(mlflow.log_param, key, val, context=\"Hyperparameter configuration\")  # [FAIR4ML, MLSEA]\n",
    "    \n",
    "    ########################################################################################################\n",
    "    ### Model Training & Evaluation ########################################################################\n",
    "    \n",
    "    # ── Fit the model ────────────────────────────────────────────────────────────────────────────────────\n",
    "    model.fit(X_train, y_train)\n",
    "    train_end_ts = datetime.now().isoformat()\n",
    "    mlflow.set_tag(\"training_end_time\", train_end_ts)  # [PROV]\n",
    "    \n",
    "    # ── Predictions ──────────────────────────────────────────────────────────────────────────────────────\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)\n",
    "    \n",
    "    # ── Compute and log metrics ─────────────────────────────────────────────────────────────────────────\n",
    "    acc  = accuracy_score(y_test, y_pred)\n",
    "    auc  = roc_auc_score(y_test, y_proba, multi_class=\"ovr\")\n",
    "    prec = precision_score(y_test, y_pred, average=\"macro\")\n",
    "    rec  = recall_score(y_test,  y_pred, average=\"macro\")\n",
    "    f1   = f1_score(y_test,      y_pred, average=\"macro\")\n",
    "    \n",
    "    mlflow.log_metric(\"accuracy\", acc)              # [MLSEA]\n",
    "    mlflow.log_metric(\"roc_auc\", auc)               # [MLSEA]\n",
    "    mlflow.log_metric(\"precision_macro\", prec)      # [MLSEA]\n",
    "    mlflow.log_metric(\"recall_macro\", rec)          # [MLSEA]\n",
    "    mlflow.log_metric(\"f1_macro\", f1)               # [MLSEA]\n",
    "\n",
    "\n",
    "########################################################################################################\n",
    "### Final Logging: Justifications, Metrics, Environment, Dataset Metadata #############################\n",
    "\n",
    "# ── Prompt for and log justifications ────────────────────────────────────────────────────────────────\n",
    "    log_justification(\"model_choice\", \"Why did you choose this model (e.g., RandomForestClassifier) for this task?\")\n",
    "    log_justification(\"target_variable\", \"Why did you choose this column as the prediction target?\")\n",
    "    log_justification(\"test_split\", \"Why this train/test ratio (e.g., 80/20)?\")\n",
    "    log_justification(\"metric_choice\", \"Why did you use accuracy/f1/ROC-AUC as your evaluation metric?\")\n",
    "    log_justification(\"threshold_accuracy\", \"Was there a threshold for accuracy? Why?\")\n",
    "    log_justification(\"dataset_version\", \"Why did you use this specific dataset version?\")\n",
    "    log_justification(\"drop_column_X\", \"Why did you drop any specific columns from the dataset?\")\n",
    "    log_justification(\"experiment_name\", \"Any context behind this experiment name or setup?\")\n",
    "    log_justification(\"model_limitations\", \"Any known model limitations?\")\n",
    "    log_justification(\"ethical_considerations\", \"Any known model ethical considerations?\")\n",
    "    log_justification(\"intended_use\", \"Known model intended use?\")\n",
    "    log_justification(\"not_intended_for\", \"Model not_intended_for?\")\n",
    "\n",
    "\n",
    "    # ── Log model evaluation metrics ────────────────────────────────────────────────────────────────────\n",
    "    mlflow.log_metric(\"precision_macro\", prec)    # [MLSEA]\n",
    "    mlflow.log_metric(\"recall_macro\", rec)        # [MLSEA]\n",
    "    mlflow.log_metric(\"f1_macro\", f1)             # [MLSEA]\n",
    "    mlflow.log_metric(\"accuracy\", acc)            # [MLSEA]\n",
    "    mlflow.log_metric(\"roc_auc\", auc)             # [MLSEA]\n",
    "    \n",
    "    # ── Log environment info ─────────────────────────────────────────────────────────────────────────────\n",
    "    mlflow.log_params({\n",
    "        \"python_version\":       platform.python_version(),\n",
    "        \"os_platform\":          f\"{platform.system()} {platform.release()}\",\n",
    "        \"sklearn_version\":      sklearn.__version__,\n",
    "        \"pandas_version\":       pd.__version__,\n",
    "        \"numpy_version\":        np.__version__,\n",
    "        \"matplotlib_version\":   matplotlib.__version__,\n",
    "        \"seaborn_version\":      sns.__version__,\n",
    "        \"shap_version\":         shap.__version__,\n",
    "    })  # [PROV, Internal]\n",
    "    \n",
    "    # ── Tag notebook name ────────────────────────────────────────────────────────────────────────────────\n",
    "    mlflow.set_tag(\"notebook_name\", \"RQ1_2.ipynb\")  # [Internal]\n",
    "    \n",
    "    # ── Dataset metadata tags ────────────────────────────────────────────────────────────────────────────\n",
    "    mlflow.set_tag(\"dataset_name\",    db_meta.get(\"dataset_name\", \"unknown\") )    # [FAIR4ML, PROV]\n",
    "    mlflow.set_tag(\"dataset_version\", selected_version)                                           # [FAIR4ML, Internal]\n",
    "    mlflow.set_tag(\"dataset_id\",      selected_table_id)  # [FAIR4ML, Internal]\n",
    "\n",
    "########################################################################################################\n",
    "### Plots: Feature Importance, ROC, PR, Confusion Matrix, SHAP #########################################\n",
    "\n",
    "# ── Create plot output directory ─────────────────────────────────────────────────────────────────────\n",
    "    plot_dir = os.path.join(\"ML_EXP_plots\", run.info.run_id) ##TODO test this path change\n",
    "    os.makedirs(plot_dir, exist_ok=True)\n",
    "    \n",
    "    # ── 1) Feature Importance Bar Chart ──────────────────────────────────────────────────────────────────\n",
    "    if hasattr(model, \"feature_importances_\"):\n",
    "        importances = model.feature_importances_\n",
    "        feature_names = getattr(X_train, \"columns\", [f\"f{i}\" for i in range(X_train.shape[1])])\n",
    "        \n",
    "        fi_path = os.path.join(plot_dir, \"feature_importances.png\")\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.barplot(x=importances, y=feature_names)\n",
    "        plt.title(\"Feature Importances\")\n",
    "        plt.xlabel(\"Importance\")\n",
    "        plt.ylabel(\"Feature\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(fi_path)\n",
    "        mlflow.log_artifact(fi_path)  # [MLSEA]\n",
    "        plt.close()\n",
    "    \n",
    "    # ── 2) Multi-class ROC Curves ───────────────────────────────────────────────────────────────────────\n",
    "    classes = np.unique(y_test)\n",
    "    y_test_bin = label_binarize(y_test, classes=classes)\n",
    "    \n",
    "    for idx, cls in enumerate(classes):\n",
    "        disp = RocCurveDisplay.from_predictions(y_test_bin[:, idx], y_proba[:, idx], name=f\"ROC for class {cls}\")\n",
    "        roc_path = os.path.join(plot_dir, f\"roc_curve_cls_{cls}.png\")\n",
    "        disp.figure_.savefig(roc_path)\n",
    "        mlflow.log_artifact(roc_path)  # [MLSEA]\n",
    "        plt.close(disp.figure_)\n",
    "    \n",
    "    # ── 3) Multi-class Precision-Recall Curves ───────────────────────────────────────────────────────────\n",
    "    for idx, cls in enumerate(classes):\n",
    "        disp = PrecisionRecallDisplay.from_predictions(y_test_bin[:, idx], y_proba[:, idx], name=f\"PR curve for class {cls}\")\n",
    "        pr_path = os.path.join(plot_dir, f\"pr_curve_cls_{cls}.png\")\n",
    "        disp.figure_.savefig(pr_path)\n",
    "        mlflow.log_artifact(pr_path)  # [MLSEA]\n",
    "        plt.close(disp.figure_)\n",
    "    \n",
    "    # ── 4) Confusion Matrix Plot ─────────────────────────────────────────────────────────────────────────\n",
    "    cm_path = os.path.join(plot_dir, \"confusion_matrix.png\")\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    plt.figure(figsize=(6, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(cm_path)\n",
    "    mlflow.log_artifact(cm_path)  # [MLSEA]\n",
    "    plt.close()\n",
    "    \n",
    "    # ── 5) SHAP Summary Plot ─────────────────────────────────────────────────────────────────────────────\n",
    "    shap_path = os.path.join(plot_dir, \"shap_summary.png\")\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer.shap_values(X_test)\n",
    "    \n",
    "    shap.summary_plot(shap_values, X_test, show=False)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(shap_path)\n",
    "    mlflow.log_artifact(shap_path)  # [FAIR4ML, MLSEA]\n",
    "    plt.close()\n",
    "    \n",
    "    ########################################################################################################\n",
    "    ### Final: Metadata Summary Logging ####################################################################\n",
    "    \n",
    "    \n",
    "    \n",
    "    # log_standard_metadata(\n",
    "    #     model_name=model_name,\n",
    "    #     model=model,\n",
    "    #     hyperparams=ML_EXP_hyperparams,\n",
    "    #     acc=acc,\n",
    "    #     prec=prec,\n",
    "    #     rec=rec,\n",
    "    #     f1=f1,\n",
    "    #     auc=auc,\n",
    "    #     label_map=label_map,\n",
    "    #     run_id=run.info.run_id,\n",
    "    #     test_size=test_size,\n",
    "    #     random_state=random_state,\n",
    "    #     run_data=run_data\n",
    "    # )\n",
    "    log_standard_metadata(\n",
    "    model_name=model_name,\n",
    "    model=model,\n",
    "    hyperparams=ML_EXP_hyperparams,\n",
    "    acc=acc,\n",
    "    prec=prec,\n",
    "    rec=rec,\n",
    "    f1=f1,\n",
    "    auc=auc,\n",
    "    label_map=label_map,\n",
    "    run_id=run.info.run_id,\n",
    "    test_size=test_size,\n",
    "    random_state=random_state,\n",
    "    id_cols=id_cols,         # ✅ list of dropped ID columns\n",
    "    target_col=target_col,   # ✅ your target column, likely defined as df.columns[-1]\n",
    "    X=X,                     # ✅ your features DataFrame\n",
    "    y=y,                     # ✅ your labels array or Series\n",
    "    run_data=run_data        # optional but useful\n",
    "    )\n",
    "\n",
    "########################################################################################################\n",
    "### Export Model (.pkl) and Log as Artifact ############################################################\n",
    "\n",
    "# ── Define output path ───────────────────────────────────────────────────────────────────────────────\n",
    "    pkl_path = f\"Trained_models/{model_name}.pkl\"\n",
    "    os.makedirs(\"Trained_models\", exist_ok=True)  # Ensure the folder exists\n",
    "    \n",
    "    # ── Serialize the trained model to disk ──────────────────────────────────────────────────────────────\n",
    "    with open(pkl_path, \"wb\") as f:\n",
    "        pickle.dump(model, f)\n",
    "    \n",
    "    # ── Log the serialized model to MLflow as an artifact ────────────────────────────────────────────────\n",
    "    mlflow.log_artifact(pkl_path, artifact_path=model_name)  # [FAIR4ML, MLSEA]\n",
    "\n",
    "########################################################################################################\n",
    "### COMMIT: Git Integration + Provenance Logging #######################################################\n",
    "\n",
    "    def get_latest_commit_hash(repo_path=\".\"):\n",
    "        res = subprocess.run(\n",
    "            [\"git\", \"-C\", repo_path, \"rev-parse\", \"HEAD\"],\n",
    "            capture_output=True, text=True, check=True\n",
    "        )\n",
    "        return res.stdout.strip()\n",
    "    \n",
    "    def get_remote_url(repo_path=\".\", remote=\"origin\"):\n",
    "        res = subprocess.run(\n",
    "            [\"git\", \"-C\", repo_path, \"config\", \"--get\", f\"remote.{remote}.url\"],\n",
    "            capture_output=True, text=True, check=True\n",
    "        )\n",
    "        return res.stdout.strip()\n",
    "    \n",
    "    def make_commit_link(remote_url, commit_hash):\n",
    "        base = remote_url.rstrip(\".git\")\n",
    "        if base.startswith(\"git@\"):\n",
    "            base = base.replace(\":\", \"/\").replace(\"git@\", \"https://\")\n",
    "        return f\"{base}/commit/{commit_hash}\"\n",
    "    \n",
    "    def simple_commit_and_push_and_log(repo_path=\".\", message=\"Auto commit\", remote=\"origin\", branch=\"main\"):\n",
    "        status = subprocess.run([\"git\", \"-C\", repo_path, \"status\", \"--porcelain\"], capture_output=True, text=True)\n",
    "        if not status.stdout.strip():\n",
    "            print(\"🟡 No changes to commit.\")\n",
    "            return None, None\n",
    "    \n",
    "        subprocess.run([\"git\", \"-C\", repo_path, \"add\", \"--all\"], capture_output=True, text=True)\n",
    "        commit = subprocess.run([\"git\", \"-C\", repo_path, \"commit\", \"-m\", message], capture_output=True, text=True)\n",
    "        if commit.returncode:\n",
    "            print(\"❌ git commit failed:\\n\", commit.stderr)\n",
    "            return None, None\n",
    "        print(\"✅ Commit successful.\")\n",
    "    \n",
    "        push = subprocess.run([\"git\", \"-C\", repo_path, \"push\", \"-u\", remote, branch], capture_output=True, text=True)\n",
    "        if push.returncode:\n",
    "            print(\"❌ git push failed:\\n\", push.stderr)\n",
    "        else:\n",
    "            print(\"🚀 Push successful.\")\n",
    "    \n",
    "        sha = get_latest_commit_hash(repo_path)\n",
    "        url = get_remote_url(repo_path, remote)\n",
    "        link = make_commit_link(url, sha)\n",
    "        return sha, link\n",
    "    \n",
    "    # ── Perform commit and get commit SHA and link ───────────────────────────────────────────────────────\n",
    "    sha, link = simple_commit_and_push_and_log(\n",
    "        repo_path=\".\",\n",
    "        message=\"Auto commit after successful training\"\n",
    "    )\n",
    "    \n",
    "    # ── Ask for version tag and log it ───────────────────────────────────────────────────────────────────\n",
    "    def get_version_tag_for_commit(commit_hash, known_tags=None):\n",
    "        known_tags = known_tags or {}\n",
    "        version_tag = known_tags.get(commit_hash, \"untagged\")\n",
    "        if version_tag == \"untagged\":\n",
    "            print(f\"⚠️ Commit {commit_hash[:8]} is not tagged with a version.\")\n",
    "            user_input = input(\"🔖 Enter version tag for this commit (or press Enter to skip): \").strip()\n",
    "            version_tag = user_input if user_input else \"untagged\"\n",
    "        return commit_hash, version_tag\n",
    "    \n",
    "    commit, version_tag = get_version_tag_for_commit(sha)\n",
    "    mlflow.set_tag(\"GIT_code_version\", version_tag)  # [PROV]\n",
    "    mlflow.set_tag(\"model_version\", version_tag)  # [PROV]\n",
    "\n",
    "    \n",
    "    \n",
    "    # ── Log author info ──────────────────────────────────────────────────────────────────────────────────\n",
    "    def get_git_author():\n",
    "        name = subprocess.check_output([\"git\", \"config\", \"user.name\"]).decode().strip()\n",
    "        email = subprocess.check_output([\"git\", \"config\", \"user.email\"]).decode().strip()\n",
    "        return name, email\n",
    "    \n",
    "    name, email = get_git_author()\n",
    "    mlflow.set_tag(\"GIT_user\", name)               # [PROV]\n",
    "    mlflow.set_tag(\"GIT_user_email\", email)        # [PROV]\n",
    "    \n",
    "    # ── Log Git diff between this and previous commit ────────────────────────────────────────────────────\n",
    "    if sha and link:\n",
    "        previous_commit_hash = db_meta.get(\"code_commit_hash\", \"\")  # Fallback for comparison\n",
    "        if previous_commit_hash:\n",
    "            diff_text = subprocess.check_output(\n",
    "                [\"git\", \"-C\", \".\", \"diff\", previous_commit_hash, sha],\n",
    "                encoding=\"utf-8\", errors=\"ignore\"\n",
    "            )\n",
    "    \n",
    "            remote_url = get_remote_url(\".\")\n",
    "            remote_url = remote_url.rstrip(\".git\")\n",
    "            if remote_url.startswith(\"git@\"):\n",
    "                remote_url = remote_url.replace(\":\", \"/\").replace(\"git@\", \"https://\")\n",
    "    \n",
    "            previous_commit_url = f\"{remote_url}/commit/{previous_commit_hash}\"\n",
    "            current_commit_url  = f\"{remote_url}/commit/{sha}\"\n",
    "    \n",
    "            diff_data = {\n",
    "                \"GIT_previous_commit\":        previous_commit_hash,\n",
    "                \"GIT_previous_commit_url\":    previous_commit_url,\n",
    "                \"GIT_current_commit\":         sha,\n",
    "                \"GIT_current_commit_url\":     current_commit_url,\n",
    "                \"GIT_diff\":                   diff_text\n",
    "            }\n",
    "    \n",
    "            mlflow.log_dict(diff_data, artifact_file=\"GIT_commit_diff.json\")  # [PROV]\n",
    "            mlflow.set_tag(\"GIT_previous_commit_hash\", previous_commit_hash)\n",
    "            mlflow.set_tag(\"GIT_current_commit_hash\", sha)\n",
    "            mlflow.set_tag(\"GIT_current_commit_url\", link)\n",
    "########################################################################################################\n",
    "### Reproducibility Metadata Extraction + Text Log #####################################################\n",
    "\n",
    "# ── Log all categorized metadata (FAIR, PROV, DBRepo, etc.) ───────────────────────────────────────────\n",
    "    # log_metadata_dict_to_mlflow(categorized_fields)  # [FAIR4ML, PROV, Internal]\n",
    "\n",
    "    log_metadata_dict_to_mlflow(\n",
    "        metadata=doi_metadata,\n",
    "        prefix=\"DOI_\",\n",
    "        snapshot_name=\"doi_metadata_snapshot.json\"\n",
    "    )\n",
    "    # ── Retrieve full run metadata ───────────────────────────────────────────────────────────────────────\n",
    "    run_id    = run.info.run_id\n",
    "    run_info  = client.get_run(run_id).info\n",
    "    run_data  = client.get_run(run_id).data\n",
    "    \n",
    "    params  = dict(run_data.params)\n",
    "    metrics = dict(run_data.metrics)\n",
    "    tags    = dict(run_data.tags)\n",
    "    \n",
    "    # ── List all artifacts in the run ────────────────────────────────────────────────────────────────────\n",
    "    artifact_uri  = run_info.artifact_uri\n",
    "    artifact_meta = []\n",
    "    \n",
    "    def _gather(path=\"\"):\n",
    "        for af in client.list_artifacts(run_id, path):\n",
    "            if af.is_dir:\n",
    "                _gather(af.path)\n",
    "            else:\n",
    "                rel_path = af.path.lower()\n",
    "                if rel_path.endswith((\".json\", \".txt\", \".patch\")):\n",
    "                    artifact_meta.append({\"path\": af.path, \"type\": \"text\"})\n",
    "                elif rel_path.endswith((\".png\", \".jpg\", \".jpeg\", \".svg\")):\n",
    "                    artifact_meta.append({\"path\": af.path, \"type\": \"image\"})\n",
    "                else:\n",
    "                    artifact_meta.append({\"path\": af.path, \"type\": \"other\"})\n",
    "    \n",
    "    _gather()\n",
    "    \n",
    "    # ── (Optional) Store artifact meta if needed ─────────────────────────────────────────────────────────\n",
    "    mlflow.log_dict({\"artifacts\": artifact_meta}, artifact_file=\"artifact_summary.json\")  # [Internal]\n",
    "    \n",
    "    # ── Notebook directory (for trace/log location reference) ────────────────────────────────────────────\n",
    "    notebook_dir = os.getcwd()\n",
    "    \n",
    "    ########################################################################################################\n",
    "    ### Generate Reproducibility Instructions ##############################################################\n",
    "    \n",
    "    # ── Generate reproducibility .txt log with key details ───────────────────────────────────────────────\n",
    "    repro_txt_path = generate_reproducibility_txt_log(\n",
    "        model_name=model_name,\n",
    "        dataset_name=db_meta.get(\"dataset_name\", \"unknown\"),\n",
    "        dataset_version=selected_version,\n",
    "        hyperparams=ML_EXP_hyperparams,\n",
    "        metrics={\n",
    "            \"accuracy\": acc,\n",
    "            \"f1_macro\": f1,\n",
    "            \"precision_macro\": prec,\n",
    "            \"recall_macro\": rec,\n",
    "            \"roc_auc\": auc\n",
    "        },\n",
    "        git_commit=sha,\n",
    "        run_id=run_id\n",
    "    )\n",
    "    \n",
    "    # ── Log the .txt path to MLflow for traceability ─────────────────────────────────────────────────────\n",
    "    mlflow.log_param(\"reproducibility_log_path\", repro_txt_path)  # [Internal, FAIR4ML]\n",
    "########################################################################################################\n",
    "### COMBINE: Export Full Run Summary as JSON ###########################################################\n",
    "\n",
    "# ── Create output directory ──────────────────────────────────────────────────────────────────────────\n",
    "    summary_dir = os.path.join(os.getcwd(), \"MODEL_PROVENANCE\", model_name)\n",
    "    os.makedirs(summary_dir, exist_ok=True)\n",
    "    \n",
    "    # ── Prepare run summary dict ─────────────────────────────────────────────────────────────────────────\n",
    "    summary = {\n",
    "        \"run_id\":         run_id,\n",
    "        \"run_name\":       run_info.run_name,\n",
    "        \"experiment_id\":  run_info.experiment_id,\n",
    "        \"start_time\":     run_info.start_time,\n",
    "        \"end_time\":       run_info.end_time,\n",
    "        \"params\":         params,\n",
    "        \"metrics\":        metrics,\n",
    "        \"tags\":           tags,\n",
    "        \"artifacts\":      artifact_meta\n",
    "    }\n",
    "    \n",
    "    # ── Write summary to JSON file ───────────────────────────────────────────────────────────────────────\n",
    "    summary_filename    = f\"{model_name}_run_summary.json\"\n",
    "    summary_local_path  = os.path.join(summary_dir, summary_filename)\n",
    "    \n",
    "    with open(summary_local_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "    \n",
    "    # ── Log summary JSON to MLflow ───────────────────────────────────────────────────────────────────────\n",
    "    mlflow.log_artifact(summary_local_path, artifact_path=\"run_summaries\")  # [FAIR4ML, Internal]\n",
    "    print(\"📁 Run summary JSON logged at:\", summary_local_path)\n",
    "    \n",
    "    # ── End MLflow run with PROV-O end timestamp ─────────────────────────────────────────────────────────\n",
    "    end_time = datetime.now().isoformat()\n",
    "    mlflow.set_tag(\"endedAtTime\", end_time)  # [PROV]\n",
    "    mlflow.end_run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e468bd63-075d-4d2b-899f-659468c9e0e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\reema\\\\REPO\\\\notebooks\\\\RQ_notebooks\\\\MODEL_PROVENANCE\\\\RandomForest_Iris_v20250518_170352\\\\RandomForest_Iris_v20250518_170352_run_summary.json'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_local_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cee2f35d-1cb5-481a-aa26-3212cabca3f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'requirements.txt'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "required_keywords = [\n",
    "    \"mlflow\", \"scikit-learn\", \"pandas\", \"numpy\", \"pyyaml\", \"seaborn\",\n",
    "    \"matplotlib\", \"shap\", \"rdflib\", \"requests\", \"python-dotenv\", \"gitpython\", \"psutil\", \"pyld\"\n",
    "]\n",
    "\n",
    "# Run pip freeze\n",
    "result = subprocess.run([\"pip\", \"freeze\"], stdout=subprocess.PIPE, text=True)\n",
    "all_packages = result.stdout.splitlines()\n",
    "\n",
    "# Filter based on matching names\n",
    "filtered = [pkg for pkg in all_packages if any(kw.lower() in pkg.lower() for kw in required_keywords)]\n",
    "\n",
    "# Save filtered requirements to file\n",
    "filtered_requirements_path = \"requirements.txt\"\n",
    "with open(filtered_requirements_path, \"w\") as f:\n",
    "    f.write(\"\\n\".join(filtered))\n",
    "\n",
    "filtered_requirements_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ca333c-1c4f-4b79-8385-5de253b16511",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #WORKS!!\n",
    "# database = client.create_database(\n",
    "#     name=\"Provenance_MetaData\",\n",
    "#     container_id=\"6cfb3b8e-1792-4e46-871a-f3d103527203\",\n",
    "#     is_public=True\n",
    "# )\n",
    "# print(f\"✅ Database created: {database.id}\")\n",
    "# # resp = requests.get(\"http://localhost/api/container\", auth=(\"reema\", \"Toothless!26\"))\n",
    "# # print(resp.json())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe2dadb-3154-434d-8513-11f02017b936",
   "metadata": {},
   "source": [
    "Table creations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c2cec661-0b1d-47ac-84a8-baa5bb2bed15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<ColumnType.CHAR: 'char'>, <ColumnType.VARCHAR: 'varchar'>, <ColumnType.BINARY: 'binary'>, <ColumnType.VARBINARY: 'varbinary'>, <ColumnType.TINYBLOB: 'tinyblob'>, <ColumnType.TINYTEXT: 'tinytext'>, <ColumnType.TEXT: 'text'>, <ColumnType.BLOB: 'blob'>, <ColumnType.MEDIUMTEXT: 'mediumtext'>, <ColumnType.MEDIUMBLOB: 'mediumblob'>, <ColumnType.LONGTEXT: 'longtext'>, <ColumnType.LONGBLOB: 'longblob'>, <ColumnType.ENUM: 'enum'>, <ColumnType.SERIAL: 'serial'>, <ColumnType.SET: 'set'>, <ColumnType.BIT: 'bit'>, <ColumnType.TINYINT: 'tinyint'>, <ColumnType.BOOL: 'bool'>, <ColumnType.SMALLINT: 'smallint'>, <ColumnType.MEDIUMINT: 'mediumint'>, <ColumnType.INT: 'int'>, <ColumnType.BIGINT: 'bigint'>, <ColumnType.FLOAT: 'float'>, <ColumnType.DOUBLE: 'double'>, <ColumnType.DECIMAL: 'decimal'>, <ColumnType.DATE: 'date'>, <ColumnType.DATETIME: 'datetime'>, <ColumnType.TIMESTAMP: 'timestamp'>, <ColumnType.TIME: 'time'>, <ColumnType.YEAR: 'year'>]\n"
     ]
    }
   ],
   "source": [
    "# from dbrepo.api.dto import ColumnType\n",
    "\n",
    "# print(list(ColumnType))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6823feb-5a8a-4d0f-9959-db4becf9c13c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cf769532-4ab7-4202-bf34-93b31557bb3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Failed\n",
      "400\n",
      "{\"type\":\"about:blank\",\"title\":\"Bad Request\",\"status\":400,\"detail\":\"Failed to read request\",\"instance\":\"/api/database/ce4550bd-0fad-4a6b-894b-455a1decae5d/table/fbd07137-cc8f-42dc-b587-6be1ecad1001/data\",\"properties\":null}\n"
     ]
    }
   ],
   "source": [
    "# import requests\n",
    "# import json\n",
    "\n",
    "# url = \"http://localhost/api/database/ce4550bd-0fad-4a6b-894b-455a1decae5d/table/fbd07137-cc8f-42dc-b587-6be1ecad1001/data\"\n",
    "# auth = (\"reema\", \"Toothless!26\")\n",
    "# headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "# rows = [\n",
    "#     {\n",
    "#         \"runID\": \"run006\",\n",
    "#         \"sessionID\": \"sess006\",\n",
    "#         \"modelId\": \"model006\",\n",
    "#         \"datasetID\": \"data006\",\n",
    "#         \"git_commit\": \"abc123\",\n",
    "#         \"invenioID\": \"inv006\",\n",
    "#         \"timestamp\": \"2025-05-18T17:00:00Z\"\n",
    "#     }\n",
    "# ]\n",
    "\n",
    "# response = requests.post(url, auth=auth, headers=headers, json=rows)\n",
    "\n",
    "# if response.status_code == 200:\n",
    "#     print(\"✅ Insert successful\")\n",
    "# else:\n",
    "#     print(\"❌ Failed\")\n",
    "#     print(response.status_code)\n",
    "#     print(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5469841d-d44c-45e4-a53c-e32554595e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'runid': 'run001', 'sessionid': 'sess001', 'modelid': 'model001', 'datasetid': 'data001', 'git_commit': 'abc1234', 'invenioid': 'inv001', 'timestamp': '2025-05-18 14:30:00.0'}, {'runid': 'run002', 'sessionid': 'sess002', 'modelid': 'model002', 'datasetid': 'data002', 'git_commit': 'def5678', 'invenioid': 'inv002', 'timestamp': '2025-05-18 15:00:00.0'}, {'runid': 'run003', 'sessionid': 'sess003', 'modelid': 'model003', 'datasetid': 'data003', 'git_commit': 'ghi9012', 'invenioid': 'inv003', 'timestamp': '2025-05-18 15:30:00.0'}, {'runid': 'run004', 'sessionid': 'sess004', 'modelid': 'model004', 'datasetid': 'data004', 'git_commit': 'jkl3456', 'invenioid': 'inv004', 'timestamp': '2025-05-18 16:00:00.0'}, {'runid': 'run005', 'sessionid': 'sess005', 'modelid': 'model005', 'datasetid': 'data005', 'git_commit': 'mno7890', 'invenioid': 'inv005', 'timestamp': '2025-05-18 16:30:00.0'}]\n"
     ]
    }
   ],
   "source": [
    "# # API endpoint URL\n",
    "# db_id=\"ce4550bd-0fad-4a6b-894b-455a1decae5d\"\n",
    "# selected_table_id=\"fbd07137-cc8f-42dc-b587-6be1ecad1001\"\n",
    "# API_URL = f\"http://localhost/api/database/{db_id}/table/{selected_table_id}/data?size=100000&page=0\"\n",
    "\n",
    "# # Define the headers\n",
    "# headers = {\n",
    "#     \"Accept\": \"application/json\"  # Specify the expected response format\n",
    "# }\n",
    "\n",
    "# try:\n",
    "#     # Send a GET request to the API with the Accept header\n",
    "#     response = requests.get(API_URL, headers=headers)\n",
    "\n",
    "#     # Check if the request was successful\n",
    "#     if response.status_code == 200:\n",
    "#         # Parse the JSON response\n",
    "#         dataset = response.json()\n",
    "        \n",
    "        \n",
    "#         print( dataset)\n",
    "#     else:\n",
    "#         print(f\"Error: Received status code {response.status_code}\")\n",
    "#         print(\"Response content:\", response.text)\n",
    "       \n",
    "\n",
    "# except requests.exceptions.RequestException as e:\n",
    "#     print(f\"Request failed: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f2231f52-11d9-4a6f-bbc0-25efc6ab5f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Row inserted successfully!\n"
     ]
    }
   ],
   "source": [
    "# import requests\n",
    "# import json\n",
    "\n",
    "# url = \"http://localhost/api/database/ce4550bd-0fad-4a6b-894b-455a1decae5d/table/53ffac33-9391-4cba-bd7b-5759a1c98201/data\"\n",
    "\n",
    "# headers = {\n",
    "#     \"Content-Type\": \"application/json\"\n",
    "# }\n",
    "\n",
    "# auth = (\"reema\", \"Toothless!26\")  # Replace with your actual credentials\n",
    "\n",
    "# # Payload matching the JSON format that worked in Postman\n",
    "# payload = {\n",
    "#     \"data\": {\n",
    "#         \"runid\": \"run0010000\",\n",
    "#         \"sessionid\": \"sess009\",\n",
    "#         \"modelid\": \"model009\",\n",
    "#         \"datasetid\": \"data009\",\n",
    "#         \"git_commit\": \"xyz999\",\n",
    "#         \"invenioid\": \"inv009\",\n",
    "#         \"timestamp\": \"2025-05-18T11:31:31.914+00:00\"\n",
    "#     }\n",
    "# }\n",
    "\n",
    "# response = requests.post(url, headers=headers, auth=auth, json=payload)\n",
    "\n",
    "# if response.status_code == 201:\n",
    "#     print(\"✅ Row inserted successfully!\")\n",
    "# else:\n",
    "#     print(\"❌ Failed to insert\")\n",
    "#     print(\"Status:\", response.status_code)\n",
    "#     print(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7f46eb8f-4ab6-471b-99fe-c6678607b5ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2025-05-18T11:32:27.292+00:00'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2987b94d-deec-4a0b-b71c-62c4da98061c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [201]>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import requests\n",
    "# from datetime import datetime\n",
    "\n",
    "# # Auth & headers\n",
    "# headers = {\"Content-Type\": \"application/json\"}\n",
    "# auth = (\"reema\", \"Toothless!26\")  # ⚠️ Never hardcode this in prod\n",
    "\n",
    "# # Timestamp conversion\n",
    "# def to_mysql_datetime(ts):\n",
    "#     return datetime.strptime(ts, \"%Y-%m-%d %H:%M:%S\").isoformat() + \"+00:00\"\n",
    "\n",
    "# # Define base URL (adjust table IDs per table)\n",
    "# BASE = \"http://localhost/api/database/ce4550bd-0fad-4a6b-894b-455a1decae5d/table\"\n",
    "\n",
    "# # Define table-specific endpoints\n",
    "# TABLES = {\n",
    "#     \"session_metadata\": \"3af934ed-a467-46e5-bb0a-495b2ff0efbf\",\n",
    "#     \"experiment_metadata\": \"53ffac33-9391-4cba-bd7b-5759a1c98201\",\n",
    "#     \"git_metadata\": \"ad546581-467e-4570-94eb-45eeb4f3019b\",\n",
    "#     \"dataset_metadata\": \"9119bded-19af-42b6-b27e-c9d229a9a7c2\",\n",
    "#     \"model_metadata\": \"26294b1f-4f4d-4a7a-917e-141fa048fb39\",\n",
    "# }\n",
    "\n",
    "# # 1. Session Metadata\n",
    "# requests.post(\n",
    "#     f\"{BASE}/{TABLES['session_metadata']}/data\",\n",
    "#     headers=headers,\n",
    "#     auth=auth,\n",
    "#     json={\n",
    "#         \"data\": {\n",
    "#             \"session_id\": \"sess_001pppp\",\n",
    "#             \"username\": \"user123\",\n",
    "#             \"timestamp\": to_mysql_datetime(\"2025-05-18 09:30:00\"),\n",
    "#             \"hostname\": \"host001\",\n",
    "#             \"platform\": \"Linux\"\n",
    "#         }\n",
    "#     }\n",
    "# )\n",
    "\n",
    "# # 2. Experiment Metadata\n",
    "# requests.post(\n",
    "#     f\"{BASE}/{TABLES['experiment_metadata']}/data\",\n",
    "#     headers=headers,\n",
    "#     auth=auth,\n",
    "#     json={\n",
    "#         \"data\": {\n",
    "#             \"runid\": \"run_001xppppp\",\n",
    "#             \"sessionid\": \"sess_001\",\n",
    "#             \"modelid\": \"model_001\",\n",
    "#             \"datasetid\": \"ds_001\",\n",
    "#             \"git_commit\": \"abc1234\",\n",
    "#             \"invenioid\": \"inv_001\",\n",
    "#             \"timestamp\": to_mysql_datetime(\"2025-05-18 09:45:00\")\n",
    "#         }\n",
    "#     }\n",
    "# )\n",
    "\n",
    "# # 3. Git Metadata\n",
    "# requests.post(\n",
    "#     f\"{BASE}/{TABLES['git_metadata']}/data\",\n",
    "#     headers=headers,\n",
    "#     auth=auth,\n",
    "#     json={\n",
    "#         \"data\": {\n",
    "#             \"commit_hash\": \"abc1234xppppp\",\n",
    "#             \"repo_url\": \"https://github.com/example/repo\",\n",
    "#             \"branch\": \"main\",\n",
    "#             \"author\": \"dev_user\",\n",
    "#             \"timestamp\": to_mysql_datetime(\"2025-05-18 09:20:00\"),\n",
    "#             \"version\": \"v2.3.1\"\n",
    "#         }\n",
    "#     }\n",
    "# )\n",
    "\n",
    "# # 4. Dataset Metadata\n",
    "# requests.post(\n",
    "#     f\"{BASE}/{TABLES['dataset_metadata']}/data\",\n",
    "#     headers=headers,\n",
    "#     auth=auth,\n",
    "#     json={\n",
    "#         \"data\": {\n",
    "#             \"dataset_id\": \"ds_001xpppppp\",\n",
    "#             \"table_name\": \"table_xyz\",\n",
    "#             \"detailed_type\": \"CSV\",\n",
    "#             \"classes\": 3,\n",
    "#             \"features\": 5,\n",
    "#             \"output_type\": \"categorical\",\n",
    "#             \"version\": \"v1.0\"\n",
    "#         }\n",
    "#     }\n",
    "# )\n",
    "\n",
    "# # 5. Model Metadata\n",
    "# requests.post(\n",
    "#     f\"{BASE}/{TABLES['model_metadata']}/data\",\n",
    "#     headers=headers,\n",
    "#     auth=auth,\n",
    "#     json={\n",
    "#         \"data\": {\n",
    "#             \"model_id\": \"model_001xppppppppp\",\n",
    "#             \"name\": \"RandomForest\",\n",
    "#             \"algo\": \"RandomForestClassifier\",\n",
    "#             \"features\": '[\"age\", \"income\", \"education\", \"gender\", \"marital_status\"]',\n",
    "#             \"label_snap\": \"income_group\",\n",
    "#             \"train_split\": 0.8,\n",
    "#             \"test_split\": 0.2,\n",
    "#             \"target_var\": \"income_group\",\n",
    "#             \"label_map\": '{\"0\":\"Low\",\"1\":\"Medium\",\"2\":\"High\"}',\n",
    "#             \"feature_select\": '[\"age\", \"income\", \"education\"]',\n",
    "#             \"imbalance_ratio\": 1.5\n",
    "#         }\n",
    "#     }\n",
    "# )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f587f002-e685-46f4-8626-cee0d485a2dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "378d771a-aa32-458a-b5bf-3bf75363010f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__annotations__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_upload', '_wrapper', 'analyse_datatypes', 'analyse_keys', 'analyse_table_statistics', 'create_container', 'create_database', 'create_database_access', 'create_identifier', 'create_subset', 'create_table', 'create_table_data', 'create_view', 'delete_container', 'delete_database_access', 'delete_table', 'delete_table_data', 'delete_view', 'endpoint', 'get_concepts', 'get_container', 'get_containers', 'get_database', 'get_database_access', 'get_databases', 'get_databases_count', 'get_identifier', 'get_identifier_data', 'get_identifiers', 'get_image', 'get_images', 'get_licenses', 'get_messages', 'get_ontologies', 'get_queries', 'get_subset', 'get_subset_data', 'get_subset_data_count', 'get_table', 'get_table_data', 'get_table_data_count', 'get_table_history', 'get_tables', 'get_units', 'get_user', 'get_users', 'get_view', 'get_view_data', 'get_view_data_count', 'get_views', 'import_table_data', 'password', 'publish_identifier', 'secure', 'update_database_access', 'update_database_owner', 'update_database_schema', 'update_database_visibility', 'update_identifier', 'update_subset', 'update_table_column', 'update_table_data', 'update_user', 'update_view', 'username', 'whoami']\n"
     ]
    }
   ],
   "source": [
    "from dbrepo.RestClient import RestClient\n",
    "client = RestClient(endpoint=\"http://localhost\", username=\"reema\", password=\"Toothless!26\")\n",
    "print(dir(client))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297ff6e9-af91-490b-a280-24450a3b4082",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d13600-db42-4010-93cd-ef77787a1565",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "82fe4cc5-396c-48ae-8561-df4e0a44fbe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Git Metadata POST\n",
      "➡️ URL: http://localhost/api/database/ce4550bd-0fad-4a6b-894b-455a1decae5d/table/ad546581-467e-4570-94eb-45eeb4f3019b/data\n",
      "📦 Payload:\n",
      "{\n",
      "  \"commit_hash\": \"edb72cb2613a3001b07b1ae6e0d18d4a1023fd1e\",\n",
      "  \"repo_url\": \"https://archive.ics.uci.edu/dataset/53\",\n",
      "  \"branch\": \"main\",\n",
      "  \"author\": \"Reema George\",\n",
      "  \"timestamp\": \"2025-05-18T15:03:47+00:00\",\n",
      "  \"version\": \"v99\"\n",
      "}\n",
      "📤 Status Code: 201\n",
      "📝 Response Text: \n",
      "\n",
      "🔍 Dataset Metadata POST\n",
      "➡️ URL: http://localhost/api/database/ce4550bd-0fad-4a6b-894b-455a1decae5d/table/9119bded-19af-42b6-b27e-c9d229a9a7c2/data\n",
      "📦 Payload:\n",
      "{\n",
      "  \"dataset_id\": \"0c672781-25c3-438e-8fba-18c2c7f16886\",\n",
      "  \"table_name\": \"iris_data_v3\",\n",
      "  \"detailed_type\": \"CSV\",\n",
      "  \"classes\": 3,\n",
      "  \"features\": 4,\n",
      "  \"output_type\": \"categorical\",\n",
      "  \"version\": \"v3\"\n",
      "}\n",
      "📤 Status Code: 201\n",
      "📝 Response Text: \n",
      "\n",
      "🔍 MODEL METADATA POST\n",
      "➡️ URL: http://localhost/api/database/ce4550bd-0fad-4a6b-894b-455a1decae5d/table/26294b1f-4f4d-4a7a-917e-141fa048fb39/data\n",
      "📦 Payload:\n",
      "{\n",
      "  \"model_id\": \"model_iris\",\n",
      "  \"name\": \"RandomForest_Iris_v20250518_170352\",\n",
      "  \"algo\": \"RandomForestClassifier\",\n",
      "  \"features\": \"['sepallengthcm', 'sepalwidthcm', 'petallengthcm', 'petalwidthcm']\",\n",
      "  \"label_snap\": \"species\",\n",
      "  \"train_split\": 0.8,\n",
      "  \"test_split\": 0.2,\n",
      "  \"target_var\": \"species\",\n",
      "  \"label_map\": \"{\\\"0\\\": \\\"Iris-setosa\\\", \\\"1\\\": \\\"Iris-versicolor\\\", \\\"2\\\": \\\"Iris-virginica\\\"}\",\n",
      "  \"feature_select\": \"id,sepallengthcm,sepalwidthcm,petallengthcm,petalwidthcm\",\n",
      "  \"imbalance_ratio\": 1.0\n",
      "}\n",
      "📤 Status Code: 201\n",
      "📝 Response Text: \n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "from datetime import datetime\n",
    "\n",
    "# --- Configuration ---\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "auth = (\"reema\", \"Toothless!26\")\n",
    "BASE = \"http://localhost/api/database/633f5987-d116-42e8-97fc-36b9c25ade24/table\"\n",
    "TABLES = {\n",
    "    \"session_metadata\": \"a4b15637-b98c-41f1-910d-cedfe80ca53b\",\n",
    "    \"experiment_metadata\": \"0bf9cd0c-f0c0-4236-a412-30265f5ee1a6\",\n",
    "    \"git_metadata\": \"e3bb40a4-484c-4148-99a9-8189d02afacd\",\n",
    "    \"dataset_metadata\": \"78bce105-fe1b-4d02-a7af-68885030a15d\",\n",
    "    \"model_metadata\": \"99391154-5d55-4d28-9843-194508cd0c7e\"\n",
    "}\n",
    "\n",
    "# --- Load metadata file ---\n",
    "# with open(\"MODEL_PROVENANCE/b788db5d12174c28bc175589898f7f95/RandomForest_Iris_v20250516_193049_run_summary.json\", \"r\") as f:\n",
    "with open(summary_local_path, \"r\") as f:\n",
    "\n",
    "    meta = json.load(f)\n",
    "\n",
    "# --- Helper ---\n",
    "def to_mysql_datetime(ts):\n",
    "    return datetime.strptime(ts.split(\".\")[0], \"%Y-%m-%dT%H:%M:%S\").isoformat() + \"+00:00\"\n",
    "\n",
    "# --- Extract shared values ---\n",
    "run_id = meta[\"run_id\"]\n",
    "session_id = meta[\"params\"][\"session_id\"]\n",
    "dataset_id = meta[\"tags\"][\"dataset_id\"]\n",
    "model_id = \"model_\" + meta[\"tags\"][\"model_name\"].split(\"_\")[1].lower()\n",
    "git_commit = meta[\"tags\"][\"git_commit\"]\n",
    "git_version = meta[\"tags\"][\"GIT_code_version\"]\n",
    "timestamp_utc = meta[\"params\"][\"timestamp_utc\"]\n",
    "username = meta[\"params\"][\"username\"]\n",
    "platform = meta[\"params\"][\"platform\"]\n",
    "hostname = meta[\"params\"][\"hostname\"]\n",
    "target_var = meta[\"tags\"][\"target_variable\"]\n",
    "label_map = meta[\"tags\"][\"label_map\"]\n",
    "feature_list = meta[\"params\"][\"final_feature_names\"]\n",
    "dataset_name = meta[\"tags\"][\"dataset_name\"]\n",
    "dataset_version = meta[\"tags\"][\"dataset_version\"]\n",
    "estimator = meta[\"tags\"][\"estimator_name\"]\n",
    "feature_select = meta[\"tags\"][\"feature_columns\"]\n",
    "label_snap = meta[\"tags\"][\"target_variable_encoded\"]\n",
    "model_name = meta[\"tags\"][\"model_name\"]\n",
    "imbalance_ratio = 1.0 if \"imbalance_ratio\" not in meta[\"tags\"] else meta[\"tags\"][\"imbalance_ratio\"]\n",
    "\n",
    "# # --- 1. Session Metadata ---\n",
    "# session_payload = {\n",
    "#     \"session_id\": session_id,\n",
    "#     \"username\": username,\n",
    "#     \"timestamp\": to_mysql_datetime(timestamp_utc),\n",
    "#     \"hostname\": hostname,\n",
    "#     \"platform\": platform\n",
    "# }\n",
    "\n",
    "# session_url = f\"{BASE}/{TABLES['session_metadata']}/data\"\n",
    "\n",
    "# response = requests.post(\n",
    "#     session_url,\n",
    "#     headers=headers,\n",
    "#     auth=auth,\n",
    "#     json={\"data\": session_payload}\n",
    "# )\n",
    "\n",
    "# # --- Logging ---\n",
    "# print(\"\\n🔍 Session Metadata POST\")\n",
    "# print(\"➡️ URL:\", session_url)\n",
    "# print(\"📦 Payload:\")\n",
    "# print(json.dumps(session_payload, indent=2))\n",
    "# print(\"📤 Status Code:\", response.status_code)\n",
    "# print(\"📝 Response Text:\", response.text)\n",
    "\n",
    "# # # --- 2. Experiment Metadata ---\n",
    "# exp_payload = {\n",
    "#     \"runid\": run_id,\n",
    "#     \"sessionid\": session_id,\n",
    "#     \"modelid\": model_id,\n",
    "#     \"datasetid\": dataset_id,\n",
    "#     \"git_commit\": git_commit,\n",
    "#     \"invenioid\": meta[\"tags\"].get(\"DOI_dataset_id\"),\n",
    "#     \"timestamp\": to_mysql_datetime(timestamp_utc)\n",
    "# }\n",
    "\n",
    "# exp_url = f\"{BASE}/{TABLES['experiment_metadata']}/data\"\n",
    "\n",
    "# response = requests.post(\n",
    "#     exp_url,\n",
    "#     headers=headers,\n",
    "#     auth=auth,\n",
    "#     json={\"data\": exp_payload}\n",
    "# )\n",
    "\n",
    "# # --- Logging ---\n",
    "# print(\"\\n🔍 Experiment Metadata POST\")\n",
    "# print(\"➡️ URL:\", exp_url)\n",
    "# print(\"📦 Payload:\")\n",
    "# print(json.dumps(exp_payload, indent=2))\n",
    "# print(\"📤 Status Code:\", response.status_code)\n",
    "# print(\"📝 Response Text:\", response.text)\n",
    "\n",
    "\n",
    "# --- 3. Git Metadata ---\n",
    "git_payload = {\n",
    "    \"commit_hash\": git_commit,\n",
    "    \"repo_url\": meta[\"tags\"][\"DOI_prov_used\"],\n",
    "    \"branch\": \"main\",  # assumed\n",
    "    \"author\": meta[\"tags\"][\"GIT_user\"],\n",
    "    \"timestamp\": to_mysql_datetime(timestamp_utc),\n",
    "    \"version\": git_version\n",
    "}\n",
    "\n",
    "git_url = f\"{BASE}/{TABLES['git_metadata']}/data\"\n",
    "\n",
    "response = requests.post(\n",
    "    git_url,\n",
    "    headers=headers,\n",
    "    auth=auth,\n",
    "    json={\"data\": git_payload}\n",
    ")\n",
    "\n",
    "# --- Logging ---\n",
    "print(\"\\n🔍 Git Metadata POST\")\n",
    "print(\"➡️ URL:\", git_url)\n",
    "print(\"📦 Payload:\")\n",
    "print(json.dumps(git_payload, indent=2))\n",
    "print(\"📤 Status Code:\", response.status_code)\n",
    "print(\"📝 Response Text:\", response.text)\n",
    "\n",
    "# --- Build payload dynamically ---\n",
    "dataset_payload = {\n",
    "    \"dataset_id\": dataset_id,\n",
    "    \"table_name\": dataset_name,\n",
    "    \"detailed_type\": \"CSV\",\n",
    "    \"classes\": 3,\n",
    "    \"features\": int(meta[\"params\"][\"final_num_features\"]),\n",
    "    \"output_type\": \"categorical\",\n",
    "    \"version\": dataset_version\n",
    "}\n",
    "\n",
    "# --- Build URL ---\n",
    "dataset_url = f\"{BASE}/{TABLES['dataset_metadata']}/data\"\n",
    "\n",
    "# --- Send POST request ---\n",
    "response = requests.post(\n",
    "    dataset_url,\n",
    "    headers=headers,\n",
    "    auth=auth,\n",
    "    json={\"data\": dataset_payload}\n",
    ")\n",
    "\n",
    "# --- Log request/response ---\n",
    "print(\"\\n🔍 Dataset Metadata POST\")\n",
    "print(\"➡️ URL:\", dataset_url)\n",
    "print(\"📦 Payload:\")\n",
    "print(json.dumps(dataset_payload, indent=2))\n",
    "print(\"📤 Status Code:\", response.status_code)\n",
    "print(\"📝 Response Text:\", response.text)\n",
    "\n",
    "\n",
    "# -- Log POST request for model metadata --\n",
    "model_payload = {\n",
    "    \"model_id\": model_id,\n",
    "    \"name\": model_name,\n",
    "    \"algo\": estimator,\n",
    "    \"features\": feature_list,\n",
    "    \"label_snap\": label_snap,\n",
    "    \"train_split\": float(meta[\"params\"][\"n_train_samples\"]) / int(meta[\"params\"][\"input_row_count\"]),\n",
    "    \"test_split\": float(meta[\"params\"][\"n_test_samples\"]) / int(meta[\"params\"][\"input_row_count\"]),\n",
    "    \"target_var\": target_var,\n",
    "    \"label_map\": label_map,\n",
    "    \"feature_select\": feature_select,\n",
    "    \"imbalance_ratio\": imbalance_ratio\n",
    "}\n",
    "\n",
    "model_url = f\"{BASE}/{TABLES['model_metadata']}/data\"\n",
    "response = requests.post(\n",
    "    model_url,\n",
    "    headers=headers,\n",
    "    auth=auth,\n",
    "    json={\"data\": model_payload}\n",
    ")\n",
    "\n",
    "# --- Logging ---\n",
    "print(\"\\n🔍 MODEL METADATA POST\")\n",
    "print(\"➡️ URL:\", model_url)\n",
    "print(\"📦 Payload:\")\n",
    "print(json.dumps(model_payload, indent=2))\n",
    "print(\"📤 Status Code:\", response.status_code)\n",
    "print(\"📝 Response Text:\", response.text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29f3d37-d830-40b8-a147-dcdc1c491fab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26a8bcc-5a5c-47dd-92c8-5e4ddd1fbcc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af02016-3e12-4745-a612-de0ac1bc4411",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802d0218-dac9-4fac-a473-46b15cac3cb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33849487-1ea4-4f68-8760-7c9c57842243",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f67cdcc-6b6a-404c-8253-2598bc885cde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8056340b-3c7f-4625-bd09-8bcba40e1bd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54718d49-b55a-407d-a158-a9c60768453f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd04063-9e56-43e2-9bdd-2a5e4ed09ec0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2041c098-a708-4bd3-a69a-c800e1de10f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88ff418-8279-4992-9b32-56b713bb182e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75a080f-9910-4c67-a285-544c5bee3604",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca9fc11-4c3f-4db0-9ea4-17dc81b33493",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0d96de-3d46-43f9-bb67-8a3e3851237c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7a5e3bbb-0288-47d0-9dc4-2855d7e4801a",
   "metadata": {},
   "source": [
    "1. Standards-compliant export (JSON-LD + Turtle)\n",
    "I already have your plain run_summary.json , wrap it in a JSON-LD context that maps your fields into PROV-O terms, then use rdflib to emit Turtle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ed1cfb-930a-4f17-a48f-30e4cffb7f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Load the JSON file\n",
    "json_path = \"/mnt/data/REPO/notebooks/RQ_notebooks/MODEL_PROVENANCE/RandomForest_Iris_v20250425_125653/RandomForest_Iris_v20250425_125653_run_summary.json\"\n",
    "with open(json_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Extract justification tags\n",
    "justifications = {\n",
    "    k: v for k, v in data.get(\"tags\", {}).items()\n",
    "    if k.startswith(\"justification_\")\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "justification_df = pd.DataFrame([\n",
    "    {\"Decision\": k.replace(\"justification_\", \"\"), \"Justification\": v}\n",
    "    for k, v in justifications.items()\n",
    "])\n",
    "\n",
    "import ace_tools as tools; tools.display_dataframe_to_user(name=\"Researcher Justifications\", dataframe=justification_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf88da4-69f8-4982-a594-28cf25e4f79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def iso8601(ms):\n",
    "    \"\"\"Convert milliseconds since epoch to ISO8601 UTC.\"\"\"\n",
    "    return datetime.fromtimestamp(ms / 1000, tz=timezone.utc).isoformat()\n",
    "\n",
    "for json_path in glob.glob(\"MODEL_PROVENANCE/*/*_run_summary.json\"):\n",
    "    basename   = os.path.basename(json_path)\n",
    "    model_name = basename.rsplit(\"_run_summary.json\", 1)[0]\n",
    "\n",
    "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        summary = json.load(f)\n",
    "\n",
    "    #–– Minimal override context: keep all your flat fields as-is,\n",
    "    #–– and only map the actual PROV terms to their IRIs.\n",
    "    ctx = {\n",
    "        # keep these flat\n",
    "        \"run_id\":       { \"@id\": \"run_id\" },\n",
    "        \"run_name\":     { \"@id\": \"run_name\" },\n",
    "        \"experiment_id\":{ \"@id\": \"experiment_id\" },\n",
    "        \"params\":       { \"@id\": \"params\" },\n",
    "        \"metrics\":      { \"@id\": \"metrics\" },\n",
    "        \"artifacts\":    { \"@id\": \"artifacts\" },\n",
    "        \"tags\":         { \"@id\": \"tags\" },\n",
    "\n",
    "        # provenance namespace\n",
    "        \"prov\": \"http://www.w3.org/ns/prov#\",\n",
    "        \"xsd\":  \"http://www.w3.org/2001/XMLSchema#\",\n",
    "\n",
    "        # map your timestamp fields into PROV\n",
    "        \"start_time\": { \"@id\": \"prov:startedAtTime\", \"@type\": \"xsd:dateTime\" },\n",
    "        \"end_time\":   { \"@id\": \"prov:endedAtTime\",   \"@type\": \"xsd:dateTime\" },\n",
    "\n",
    "        # PROV-used/generated\n",
    "        \"used\":      { \"@id\": \"prov:used\",      \"@type\": \"@id\" },\n",
    "        \"generated\": { \"@id\": \"prov:generated\", \"@type\": \"@id\" },\n",
    "\n",
    "        # JSON-LD boilerplate\n",
    "        \"@id\":   \"@id\",\n",
    "        \"@type\": \"@type\"\n",
    "    }\n",
    "\n",
    "    #–– Build JSON-LD document, re-using your original keys verbatim\n",
    "    doc = {\n",
    "        \"@context\":      ctx,\n",
    "        \"run_id\":        summary[\"run_id\"],\n",
    "        \"run_name\":      summary.get(\"run_name\"),\n",
    "        \"experiment_id\": summary.get(\"experiment_id\"),\n",
    "        \"params\":        summary.get(\"params\", {}),\n",
    "        \"metrics\":       summary.get(\"metrics\", {}),\n",
    "        \"artifacts\":     summary.get(\"artifacts\", []),\n",
    "        \"tags\":          summary.get(\"tags\", {}),\n",
    "\n",
    "        # PROV fields:\n",
    "        \"start_time\": iso8601(summary[\"start_time\"])\n",
    "    }\n",
    "\n",
    "    if summary.get(\"end_time\") is not None:\n",
    "        doc[\"end_time\"] = iso8601(summary[\"end_time\"])\n",
    "\n",
    "    # for used/generated, just point at your dataset/model URIs\n",
    "    # (or blank-node them if you prefer richer structure)\n",
    "    doc[\"used\"] = summary.get(\"tags\", {}).get(\"dataset_uri\") or []\n",
    "    doc[\"generated\"] = [\n",
    "        art.get(\"uri\") or art.get(\"path\")\n",
    "        for art in summary.get(\"artifacts\", [])\n",
    "    ]\n",
    "\n",
    "    #–– write JSON-LD\n",
    "    out_jsonld = os.path.join(\"MODEL_PROVENANCE\", model_name, f\"{model_name}.jsonld\")\n",
    "    with open(out_jsonld, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(doc, f, indent=2)\n",
    "\n",
    "    #–– parse & serialize to Turtle\n",
    "    g = Graph().parse(data=json.dumps(doc), format=\"json-ld\")\n",
    "    out_ttl = os.path.join(\"MODEL_PROVENANCE\", model_name, f\"{model_name}.ttl\")\n",
    "    g.serialize(destination=out_ttl, format=\"turtle\")\n",
    "\n",
    "    print(f\"Converted {basename} → {os.path.basename(out_jsonld)}, {os.path.basename(out_ttl)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d6d524-01da-4f20-8131-0d4a3ac005e2",
   "metadata": {},
   "source": [
    "This code programatically, finds diff between generated Json file and created JsonLD and .TTL file to make it easier to understand if there is any discrepency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a420c0-230d-41c0-9b63-f3dbbca1e670",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def load_as_dict(path):\n",
    "    if path.endswith((\".ttl\", \".turtle\")):\n",
    "        g = Graph()\n",
    "        g.parse(path, format=\"turtle\")\n",
    "        # normalize to JSON-LD dict\n",
    "        return json.loads(g.serialize(format=\"json-ld\", indent=2))\n",
    "    else:\n",
    "        with open(path, encoding=\"utf-8\") as f:\n",
    "            return json.load(f)\n",
    "\n",
    "def compare_json(a, b, path=\"\"):\n",
    "    diffs = []\n",
    "    if isinstance(a, dict) and isinstance(b, dict):\n",
    "        all_keys = set(a) | set(b)\n",
    "        for k in all_keys:\n",
    "            new_path = f\"{path}/{k}\" if path else k\n",
    "            if k not in a:\n",
    "                diffs.append({\"path\": new_path, \"type\": \"added\",   \"a\": None,    \"b\": b[k]})\n",
    "            elif k not in b:\n",
    "                diffs.append({\"path\": new_path, \"type\": \"removed\", \"a\": a[k],   \"b\": None})\n",
    "            else:\n",
    "                diffs.extend(compare_json(a[k], b[k], new_path))\n",
    "    elif isinstance(a, list) and isinstance(b, list):\n",
    "        for i, (ia, ib) in enumerate(zip(a, b)):\n",
    "            diffs.extend(compare_json(ia, ib, f\"{path}[{i}]\"))\n",
    "        # handle length mismatches\n",
    "        if len(a) < len(b):\n",
    "            for i in range(len(a), len(b)):\n",
    "                diffs.append({\"path\": f\"{path}[{i}]\", \"type\": \"added\",   \"a\": None,  \"b\": b[i]})\n",
    "        elif len(a) > len(b):\n",
    "            for i in range(len(b), len(a)):\n",
    "                diffs.append({\"path\": f\"{path}[{i}]\", \"type\": \"removed\", \"a\": a[i],  \"b\": None})\n",
    "    else:\n",
    "        if a != b:\n",
    "            diffs.append({\"path\": path, \"type\": \"changed\", \"a\": a, \"b\": b})\n",
    "    return diffs\n",
    "\n",
    "\n",
    "# Define base directory\n",
    "base_dir = os.path.join(\"MODEL_PROVENANCE\", model_name)\n",
    "\n",
    "# Build full paths for the files to compare\n",
    "summary_json    = os.path.join(base_dir, f\"{model_name}_run_summary.json\")\n",
    "turtle_file     = os.path.join(base_dir, f\"{model_name}.ttl\")\n",
    "jsonld_file     = os.path.join(base_dir, f\"{model_name}.jsonld\")\n",
    "\n",
    "# Load files\n",
    "a = load_as_dict(summary_json)\n",
    "b = load_as_dict(turtle_file)\n",
    "c = load_as_dict(summary_json)\n",
    "d = load_as_dict(jsonld_file)\n",
    "\n",
    "# Perform comparisons\n",
    "diffs_jsonld_vs_ttl = compare_json(a, b)\n",
    "diffs_json_vs_jsonld = compare_json(c, d)\n",
    "\n",
    "# Build DataFrames for interactive inspection\n",
    "df1 = pd.DataFrame(diffs_jsonld_vs_ttl)\n",
    "df2 = pd.DataFrame(diffs_json_vs_jsonld)\n",
    "\n",
    "# --- Summaries & Filtering ---------------------------------------\n",
    "\n",
    "def summarize_and_preview(df, preview_n=10):\n",
    "    print(\"Change summary:\")\n",
    "    print(df['type'].value_counts().to_string(), \"\\n\")\n",
    "    \n",
    "    print(f\"First {preview_n} ‘changed’ entries:\")\n",
    "    # print(df[df['type']==\"changed\"].head(preview_n).to_string(index=False), \"\\n\")\n",
    "    \n",
    "    # Top‐level (one slash) adds/removes\n",
    "    top = df[df['path'].str.count(\"/\") == 1]\n",
    "    print(\"Top-level adds/removes:\")\n",
    "    print(top[top['type'].isin(['added','removed'])].to_string(index=False))\n",
    "\n",
    "print(\"== JSON-LD vs TTL ==\")\n",
    "summarize_and_preview(df1)\n",
    "\n",
    "print(\"\\n== JSON vs JSON-LD ==\")\n",
    "summarize_and_preview(df2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41af9d6e-c683-45f9-bac1-296611b4d0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show all the removed paths (in JSON but not in JSON-LD)\n",
    "print(\"Removed in JSON-LD comparison:\")\n",
    "print(df2[df2['type']==\"removed\"][['path']].to_string(index=False))\n",
    "\n",
    "# show all the added paths (in JSON-LD but not in JSON)\n",
    "print(\"\\nAdded in JSON-LD comparison:\")\n",
    "print(df2[df2['type']==\"added\"][['path']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d6f92a-5cd9-4c78-9c2a-0cd3247137c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show all the removed paths (in JSON but not in JSON-LD)\n",
    "print(\"Removed in .ttl comparison:\")\n",
    "print(df1[df1['type']==\"removed\"][['path']].to_string(index=False))\n",
    "\n",
    "# show all the added paths (in JSON-LD but not in JSON)\n",
    "print(\"\\nAdded in .ttl comparison:\")\n",
    "print(df1[df1['type']==\"added\"][['path']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69efd0d0-9277-4efa-88cf-d2fd1b90d74c",
   "metadata": {},
   "source": [
    "Checks for completeness and mapping and time taken, needs work #TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165a13eb-7679-4f4c-b346-24f25da72cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ── User configuration ─────────────────────────────────────────────────────────\n",
    "\n",
    "# Which keys must appear in every run_summary.json?\n",
    "REQUIRED_TOPLEVEL = {\n",
    "    \"run_id\", \"start_time\", \"end_time\",\n",
    "    \"params\", \"metrics\", \"tags\", \"artifacts\"\n",
    "}\n",
    "\n",
    "# A couple of sub-fields we also want to spot-check:\n",
    "REQUIRED_PARAMS  = {\"random_state\"}\n",
    "REQUIRED_METRICS = {\"accuracy\"}\n",
    "\n",
    "JSON_SUMMARIES = glob.glob(\"MODEL_PROVENANCE/*_run_summary.json\")\n",
    "\n",
    "\n",
    "# ── Helpers ────────────────────────────────────────────────────────────────────\n",
    "\n",
    "def iso8601(ms):\n",
    "    return datetime.fromtimestamp(ms/1000, tz=timezone.utc).isoformat()\n",
    "\n",
    "\n",
    "def load_json(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "\n",
    "def write_json(path, obj):\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(obj, f, indent=2)\n",
    "\n",
    "\n",
    "def convert_to_jsonld_and_ttl(summary, basename):\n",
    "    # build @context\n",
    "    ctx = {\n",
    "        \"prov\":    \"http://www.w3.org/ns/prov#\",\n",
    "        \"xsd\":     \"http://www.w3.org/2001/XMLSchema#\",\n",
    "        \"run\":     \"prov:Activity\",\n",
    "        \"start\":   \"prov:startedAtTime\",\n",
    "        \"end\":     \"prov:endedAtTime\",\n",
    "        \"used\":    \"prov:used\",\n",
    "        \"gen\":     \"prov:generated\",\n",
    "        \"param\":   \"prov:hadParameter\",\n",
    "        \"metric\":  \"prov:hadQuality\",\n",
    "        \"entity\":  \"prov:Entity\",\n",
    "        \"label\":   \"prov:label\",\n",
    "        \"value\":   \"prov:value\",\n",
    "        \"version\": \"prov:hadRevision\",\n",
    "        \"id\":      \"@id\",\n",
    "        \"type\":    \"@type\"\n",
    "    }\n",
    "\n",
    "    jsonld = {\n",
    "        \"@context\": ctx,\n",
    "        \"@id\":      f\"urn:run:{summary['run_id']}\",\n",
    "        \"@type\":    \"run\",\n",
    "        \"start\": {\n",
    "            \"@type\":  \"xsd:dateTime\",\n",
    "            \"@value\": iso8601(summary[\"start_time\"])\n",
    "        }\n",
    "    }\n",
    "    if summary.get(\"end_time\") is not None:\n",
    "        jsonld[\"end\"] = {\n",
    "            \"@type\":  \"xsd:dateTime\",\n",
    "            \"@value\": iso8601(summary[\"end_time\"])\n",
    "        }\n",
    "\n",
    "    # params\n",
    "    jsonld[\"param\"] = [\n",
    "        {\"@type\":\"entity\",\"label\":k,\"value\":str(v)}\n",
    "        for k,v in summary.get(\"params\",{}).items()\n",
    "    ]\n",
    "    # metrics\n",
    "    jsonld[\"metric\"] = [\n",
    "        {\"@type\":\"entity\",\"label\":k,\n",
    "         \"value\":{\"@type\":\"xsd:decimal\",\"@value\":v}}\n",
    "        for k,v in summary.get(\"metrics\",{}).items()\n",
    "    ]\n",
    "    # artifacts\n",
    "    jsonld[\"gen\"] = [\n",
    "        {\n",
    "            \"@type\":\"entity\",\n",
    "            \"label\": art.get(\"path\") or art.get(\"label\"),\n",
    "            \"prov:location\": (\n",
    "                art.get(\"uri\")\n",
    "                or (art.get(\"content\",\"\")[:30]+\"…\")\n",
    "                if isinstance(art.get(\"content\"),str)\n",
    "                else \"\"\n",
    "            )\n",
    "        }\n",
    "        for art in summary.get(\"artifacts\",[])\n",
    "    ]\n",
    "    # dataset used\n",
    "    jsonld[\"used\"] = {\n",
    "        \"@type\":\"entity\",\n",
    "        \"label\": summary[\"tags\"].get(\"dataset_name\"),\n",
    "        \"version\": summary[\"tags\"].get(\"dataset_version\")\n",
    "    }\n",
    "\n",
    "    # write JSON-LD\n",
    "    out_jsonld = f\"MODEL_PROVENANCE/{basename}.jsonld\"\n",
    "    write_json(out_jsonld, jsonld)\n",
    "\n",
    "    # serialize TTL\n",
    "    g = Graph().parse(data=json.dumps(jsonld), format=\"json-ld\")\n",
    "    out_ttl = f\"MODEL_PROVENANCE/{basename}.ttl\"\n",
    "    g.serialize(destination=out_ttl, format=\"turtle\")\n",
    "\n",
    "    return out_jsonld, out_ttl\n",
    "\n",
    "\n",
    "def normalize_jsonld(js):\n",
    "    \"\"\"Simple deep-sort so compare_json doesn’t trip over ordering.\"\"\"\n",
    "    if isinstance(js, dict):\n",
    "        return {k: normalize_jsonld(js[k]) for k in sorted(js)}\n",
    "    if isinstance(js, list):\n",
    "        return sorted((normalize_jsonld(el) for el in js),\n",
    "                      key=lambda x: json.dumps(x, sort_keys=True))\n",
    "    return js\n",
    "\n",
    "\n",
    "def diff_roundtrip(orig_json, jsonld_path, ttl_path):\n",
    "    orig = load_json(orig_json)\n",
    "    ld   = load_json(jsonld_path)\n",
    "\n",
    "    # parse TTL back to JSON-LD\n",
    "    g = Graph().parse(ttl_path, format=\"turtle\")\n",
    "    ttl_as_ld = json.loads(g.serialize(format=\"json-ld\"))\n",
    "\n",
    "    # normalize\n",
    "    nl = normalize_jsonld(ld)\n",
    "    nt = normalize_jsonld(ttl_as_ld)\n",
    "\n",
    "    return {\n",
    "        \"orig_vs_jsonld\":   compare_json(orig, ld),\n",
    "        \"jsonld_vs_ttl_ld\": compare_json(nl, nt)\n",
    "    }\n",
    "\n",
    "\n",
    "# ── Main flow ─────────────────────────────────────────────────────────────────\n",
    "\n",
    "def main():\n",
    "    ok = 0\n",
    "    total = len(JSON_SUMMARIES)\n",
    "    missing_reports = []\n",
    "    cases = {}  # store diff results per run\n",
    "\n",
    "    for js_path in JSON_SUMMARIES:\n",
    "        summary = load_json(js_path)\n",
    "        base    = os.path.basename(js_path).split(\"_run_summary.json\")[0]\n",
    "\n",
    "        # 1) completeness check\n",
    "        if not REQUIRED_TOPLEVEL.issubset(summary):\n",
    "            missing = REQUIRED_TOPLEVEL - set(summary)\n",
    "            missing_reports.append((js_path, f\"missing fields {missing}\"))\n",
    "            continue\n",
    "\n",
    "        if not (REQUIRED_PARAMS <= summary[\"params\"].keys()):\n",
    "            missing_reports.append((js_path, f\"params missing {REQUIRED_PARAMS - summary['params'].keys()}\"))\n",
    "            continue\n",
    "\n",
    "        if not (REQUIRED_METRICS <= summary[\"metrics\"].keys()):\n",
    "            missing_reports.append((js_path, f\"metrics missing {REQUIRED_METRICS - summary['metrics'].keys()}\"))\n",
    "            continue\n",
    "\n",
    "        ok += 1\n",
    "\n",
    "        # 2) convert\n",
    "        jsonld_path, ttl_path = convert_to_jsonld_and_ttl(summary, base)\n",
    "\n",
    "        # 3) diff\n",
    "        diffs = diff_roundtrip(js_path, jsonld_path, ttl_path)\n",
    "        cases[base] = diffs\n",
    "        print(f\"\\n── {base} diffs ──\")\n",
    "        print(\"  • JSON → JSON-LD:\", len(diffs[\"orig_vs_jsonld\"]), \"differences\")\n",
    "        print(\"  • JSON-LD → TTL → JSON-LD:\", len(diffs[\"jsonld_vs_ttl_ld\"]), \"differences\")\n",
    "\n",
    "    # 4) completeness summary\n",
    "    completeness_pct = (100 * ok / total) if total else 0\n",
    "    print(f\"\\n{ok}/{total} runs passed completeness checks ({completeness_pct:.1f}%).\")\n",
    "    if missing_reports:\n",
    "        print(\"\\nFailures:\")\n",
    "        for path, reason in missing_reports:\n",
    "            print(f\" • {path}: {reason}\")\n",
    "\n",
    "    # 5) integrity check\n",
    "    total_runs = len(cases)\n",
    "    zero_diff_runs = sum(\n",
    "        1\n",
    "        for diffs in cases.values()\n",
    "        if not diffs[\"orig_vs_jsonld\"] and not diffs[\"jsonld_vs_ttl_ld\"]\n",
    "    )\n",
    "    integrity_pct = (100 * zero_diff_runs / total_runs) if total_runs else 0\n",
    "    print(f\"\\nMapping integrity: {zero_diff_runs}/{total_runs} runs have zero diffs — {integrity_pct:.1f}%\")\n",
    "\n",
    "    # 6) overall quality score\n",
    "    overall_score = (completeness_pct + integrity_pct) / 2\n",
    "    print(f\"Overall quality score: {overall_score:.1f}%\")\n",
    "\n",
    "    # 7) Benchmark your training fn\n",
    "    print(\"\\nBenchmarking train_and_log() overhead:\")\n",
    "    def train_and_log(use_mlflow=False):\n",
    "        # ← your real instrumentation + fit logic here\n",
    "        time.sleep(0.5 + (0.1 if use_mlflow else 0))  # stub\n",
    "        return\n",
    "\n",
    "    for flag in (False, True):\n",
    "        start = time.time()\n",
    "        train_and_log(use_mlflow=flag)\n",
    "        elapsed = time.time() - start\n",
    "        label = \"With MLflow\" if flag else \"No MLflow\"\n",
    "        print(f\"  • {label:10s}: {elapsed:.3f}s\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5883f673-371e-415e-a73e-5c9c88b56fb1",
   "metadata": {},
   "source": [
    "RQ2  implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d07ac1c-ea80-4787-bcb9-da047d12167d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Load all run summary JSON files\n",
    "files = glob.glob(\"MODEL_PROVENANCE/*/*_run_summary.json\")\n",
    "rows = []\n",
    "for f in files:\n",
    "    with open(f) as fh:\n",
    "        summary = json.load(fh)\n",
    "    # Flatten parameters and metrics\n",
    "    row = {\"run_id\": summary[\"run_id\"]}\n",
    "    row.update({f\"param_{k}\": v for k, v in summary.get(\"params\", {}).items()})\n",
    "    row.update({f\"metric_{k}\": v for k, v in summary.get(\"metrics\", {}).items()})\n",
    "    row.update({f\"tag_{k}\": v for k, v in summary.get(\"tags\", {}).items()})\n",
    "    rows.append(row)\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "# Display the DataFrame\n",
    "df.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba148da6-6ce5-45cf-a985-f164a53c969b",
   "metadata": {},
   "source": [
    "1) Tracing preprocessing steps\n",
    ":\n",
    "Here are the top 4 Iris‐focused preprocessing‐tracing use cases I’d tackle first:\n",
    "\n",
    "Reconstruct a run’s exact preprocessing\n",
    "Fetch a run’s run_id, columns_raw, dropped_columns, feature_names and test_size so you can replay the exact data pull & split.\n",
    "\n",
    "Feature‐drop impact analysis\n",
    "Identify runs where one or more measurements (e.g. petalwidthcm) were dropped and compare their test accuracies.\n",
    "\n",
    "Best feature subset discovery\n",
    "Group runs by which features they used (sepals only vs petals only vs both) and rank them by test F1 or accuracy.\n",
    "\n",
    "Common steps in high-accuracy runs\n",
    "Filter for runs with accuracy_score_X_test ≥ 0.95 and list the shared preprocessing settings (dropped columns, test_size, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e147555-afbf-4bba-b6da-7e90ff391920",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # Helper to get the “official” feature_names from your summary DF\n",
    "# def _get_all_features(df):\n",
    "#     # assumes every row has the same param_feature_names\n",
    "#     raw = df.loc[0, 'param_feature_names']\n",
    "#     return ast.literal_eval(raw)\n",
    "\n",
    "# # Train & eval RF on just these columns of Iris\n",
    "# def evaluate_subset(features, test_size=0.2, random_state=42, n_estimators=200):\n",
    "#     iris = load_iris()\n",
    "#     X = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "#     # map sklearn’s names to your param names, e.g. \"sepal length (cm)\" → \"sepallengthcm\"\n",
    "#     canon = _get_all_features(df)\n",
    "#     mapping = dict(zip(iris.feature_names, canon))\n",
    "#     X = X.rename(columns=mapping)\n",
    "#     X_sub = X[features]\n",
    "#     y = iris.target\n",
    "#     Xtr, Xte, ytr, yte = train_test_split(X_sub, y, test_size=test_size, random_state=random_state)\n",
    "#     m = RandomForestClassifier(n_estimators=n_estimators, random_state=random_state)\n",
    "#     m.fit(Xtr, ytr)\n",
    "#     return accuracy_score(yte, m.predict(Xte))\n",
    "# def trace_preprocessing(df, run_id=None):\n",
    "#     cols = ['run_id',\n",
    "#             'param_dataset.title',\n",
    "#             'param_columns_raw',\n",
    "#             'param_dropped_columns',\n",
    "#             'param_feature_names',\n",
    "#             'param_dataset.authors', 'param_dataset.doi', 'param_dataset.published',\n",
    "#             'param_test_size',\n",
    "#             'param_criterion',\n",
    "#             'param_max_depth','param_max_leaf_nodes', 'param_max_samples',\n",
    "#            'metric_accuracy','metric_f1_macro','metric_roc_auc']\n",
    "#     if run_id is None:\n",
    "#         subset = df.loc[:, cols]\n",
    "#     else:\n",
    "#         subset = df.loc[df['run_id'] == run_id, cols]\n",
    "#     return subset.to_dict(orient='records')\n",
    "\n",
    "\n",
    "# def drop_impact(df, feature, **_):\n",
    "#     all_feats = _get_all_features(df)\n",
    "#     baseline = evaluate_subset(all_feats)\n",
    "#     without = [f for f in all_feats if f!=feature]\n",
    "#     dropped = evaluate_subset(without)\n",
    "#     return {\n",
    "#       'dropped_feature': feature,\n",
    "#       'baseline_acc': baseline,\n",
    "#       'dropped_acc': dropped,\n",
    "#       'impact': baseline - dropped\n",
    "#     }\n",
    "\n",
    "# def drop_impact_all(df: pd.DataFrame) -> List[Dict[str, Any]]:\n",
    "#     \"\"\"\n",
    "#     Compute drop-impact for every feature in the dataset.\n",
    "#     Returns list of dicts with dropped_feature, baseline_acc, dropped_acc, impact.\n",
    "#     \"\"\"\n",
    "#     feats = _get_all_features(df)\n",
    "#     baseline = evaluate_subset(feats)\n",
    "#     summary = []\n",
    "#     for feat in feats:\n",
    "#         without = [f for f in feats if f != feat]\n",
    "#         acc = evaluate_subset(without)\n",
    "#         summary.append({\n",
    "#             'dropped_feature': feat,\n",
    "#             'baseline_acc': baseline,\n",
    "#             'dropped_acc': acc,\n",
    "#             'impact': round(baseline - acc, 4)\n",
    "#         })\n",
    "#     return summary\n",
    "\n",
    "# def best_feature_subset(df, features, **_):\n",
    "#     acc = evaluate_subset(features)\n",
    "#     return {'features': features, 'accuracy': acc}\n",
    "\n",
    "# def common_high_accuracy(df: pd.DataFrame, threshold: float = 0.95) -> List[Dict[str, Any]]:\n",
    "#     \"\"\"\n",
    "#     Filter runs with test accuracy >= threshold and list unique shared preprocessing settings.\n",
    "#     \"\"\"\n",
    "#     high = df[df['metric_accuracy_score_X_test'] >= threshold]\n",
    "#     cols = ['param_dropped_columns', 'param_test_size', 'param_feature_names']\n",
    "#     return high[cols].drop_duplicates().to_dict(orient='records')\n",
    "\n",
    "\n",
    "# # --------------------------------------------\n",
    "# # Use Case Registry with parameter order for minimal input\n",
    "# # --------------------------------------------\n",
    "# USE_CASES = {\n",
    "#     'trace_preprocessing': {\n",
    "#         'func': trace_preprocessing,\n",
    "#         'required_params': [],            # none strictly required\n",
    "#         'optional_params': ['run_id'],    # run_id can be supplied or not\n",
    "#     },\n",
    "#     'drop_impact': {\n",
    "#         'func': drop_impact,\n",
    "#         'required_params': ['feature'],\n",
    "#         'optional_params': [],\n",
    "#     },\n",
    "#      'drop_impact_all': {\n",
    "#         'func': drop_impact_all,\n",
    "#         'required_params': [],\n",
    "#         'optional_params': [],\n",
    "#     },\n",
    "#     'best_feature_subset': {\n",
    "#         'func': best_feature_subset,\n",
    "#         'required_params': ['features'],\n",
    "#         'optional_params': [],\n",
    "#     },\n",
    "#     'common_high_accuracy': {\n",
    "#         'func': common_high_accuracy,\n",
    "#         'required_params': ['threshold'],\n",
    "#         'optional_params': [],\n",
    "#     },\n",
    "# }\n",
    "\n",
    "\n",
    "# def call_use_case(df, use_case_name, **kwargs):\n",
    "#     if use_case_name not in USE_CASES:\n",
    "#         raise ValueError(f\"Unknown use case: {use_case_name}\")\n",
    "#     case = USE_CASES[use_case_name]\n",
    "#     func = case['func']\n",
    "#     # check required\n",
    "#     missing = [p for p in case['required_params'] if p not in kwargs]\n",
    "#     if missing:\n",
    "#         raise ValueError(f\"{use_case_name} missing required params: {missing}\")\n",
    "#     # build args\n",
    "#     args = {p: kwargs[p] for p in case['required_params']}\n",
    "#     for p in case['optional_params']:\n",
    "#         args[p] = kwargs.get(p)\n",
    "#     return func(df, **args)\n",
    "\n",
    "# # --------------------------------------------\n",
    "# # Example Usage\n",
    "# # --------------------------------------------\n",
    "# if __name__ == '__main__':\n",
    "#    # # 1) trace_preprocessing for all runs\n",
    "#     print(call_use_case(df, 'trace_preprocessing'))\n",
    "    \n",
    "#     # 2) trace_preprocessing for a single run_id\n",
    "#     print(call_use_case(df, 'trace_preprocessing', run_id='361daa12f99f4129a06cd20b78dd6fa7'))\n",
    "\n",
    "#     # 5) common_high_accuracy\n",
    "#     print(call_use_case(df, 'common_high_accuracy', threshold=0.99))\n",
    "\n",
    "#     # 4) Best‐subset on just sepals:\n",
    "#     print(call_use_case(df, 'best_feature_subset', features=['sepallengthcm','sepalwidthcm']))\n",
    "\n",
    "#     # 3) Drop‐impact for “petallengthcm”:\n",
    "#     print(call_use_case(df, 'drop_impact', feature='petallengthcm'))\n",
    "\n",
    "#     print(call_use_case(df, 'drop_impact_all'))  # summary for all features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f912d6-0e84-4155-858a-9668bef63f6e",
   "metadata": {},
   "source": [
    " • Detecting models trained with deprecated code versions\n",
    " • Mapping models to specific datasets used during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a02c9a-5459-478f-a3c5-7f7a58ff22b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def detect_deprecated_code(df: pd.DataFrame, deprecated_commits: List[str], **_) -> List[Dict[str, Any]]:\n",
    "    # we know the column is called tag_git_current_commit_hash\n",
    "    commit_col = 'tag_git_current_commit_hash'\n",
    "    if commit_col not in df.columns:\n",
    "        raise KeyError(f\"Missing {commit_col} in DataFrame\")\n",
    "    out = df[df[commit_col].isin(deprecated_commits)]\n",
    "    # include run_id and notebook/runName for context\n",
    "    cols = ['run_id', commit_col, 'tag_notebook_name', 'tag_mlflow.runName']\n",
    "    # drop any that don’t exist\n",
    "    cols = [c for c in cols if c in df.columns]\n",
    "    return out[cols].to_dict(orient='records')\n",
    "\n",
    "\n",
    "def map_model_dataset(df: pd.DataFrame, **_) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    For each run, return its model name (or run_id) alongside the dataset\n",
    "    title, DOI, published date and publisher.\n",
    "    \"\"\"\n",
    "    # pick whichever model-name column you have\n",
    "    model_col = 'tag_model_name' if 'tag_model_name' in df.columns else 'param_model_name'\n",
    "    cols = [\n",
    "        'run_id',\n",
    "        model_col,\n",
    "        'param_dataset.title',\n",
    "        'param_dataset.doi',\n",
    "        'param_dataset.published',\n",
    "        'param_dataset.publisher'\n",
    "    ]\n",
    "    # filter out any columns that don’t actually exist\n",
    "    cols = [c for c in cols if c in df.columns]\n",
    "    return df[cols].to_dict(orient='records')\n",
    "\n",
    "# --------------------------------------------\n",
    "# Extend Use-Case Registry\n",
    "# --------------------------------------------\n",
    "USE_CASES.update({\n",
    "    'detect_deprecated_code': {\n",
    "        'func': detect_deprecated_code,\n",
    "        'required_params': ['deprecated_commits'],\n",
    "        'optional_params': []\n",
    "    },\n",
    "    'map_model_dataset': {\n",
    "        'func': map_model_dataset,\n",
    "        'required_params': [],\n",
    "        'optional_params': []\n",
    "    },\n",
    "})\n",
    "# 1) Detect runs on deprecated commits:\n",
    "deprecated = [\n",
    "    \"a07434af4f547af2daab044d6873eb7081162293\",\n",
    "    \"d329c92495e196ec0f39fbb19dfdd367131a77d9\"\n",
    "]\n",
    "# print(call_use_case(df, \"detect_deprecated_code\", deprecated_commits=deprecated))\n",
    "pprint(call_use_case(df, 'map_model_dataset'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52607ad-5849-4a2d-97ef-e8fc1ca16dc7",
   "metadata": {},
   "source": [
    "Goal: Notify collaborators who have forked the GitHub repo if their fork is outdated (i.e., behind the current commit used to train a model)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29c8ad9-00bb-4c1e-ac3b-ee6861991acd",
   "metadata": {},
   "source": [
    "🧠 What We Need\n",
    "Current training run’s Git commit hash\n",
    "\n",
    "GitHub API to fetch all forks of your repo\n",
    "\n",
    "Compare each fork’s main or master branch head commit\n",
    "\n",
    "Create an issue on their fork or on your repo tagging them if they’re behind"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72bed50-fb56-442d-a21e-bb7991892d07",
   "metadata": {},
   "source": [
    ": Notify via issues on your own repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852f147c-9d0a-4d7f-a4ab-545d1e2375fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def notify_outdated_forks():\n",
    "    load_dotenv()\n",
    "    token     = os.getenv(\"THESIS_TOKEN\")\n",
    "    owner     = \"reema-dass26\"\n",
    "    repo      = \"REPO\"\n",
    "\n",
    "    if not token:\n",
    "        print(\"⚠️ GITHUB_TOKEN not set.\")\n",
    "        return\n",
    "\n",
    "    headers = {\n",
    "        \"Authorization\": f\"token {token}\",\n",
    "        \"Accept\":        \"application/vnd.github.v3+json\"\n",
    "    }\n",
    "\n",
    "    # 1) Get latest upstream commit\n",
    "    main_commits = requests.get(\n",
    "        f\"https://api.github.com/repos/{owner}/{repo}/commits\",\n",
    "        headers=headers,\n",
    "        params={\"per_page\": 1}\n",
    "    )\n",
    "    main_commits.raise_for_status()\n",
    "    new_commit_hash = main_commits.json()[0][\"sha\"]\n",
    "    print(f\"Latest upstream commit: {new_commit_hash}\")\n",
    "\n",
    "    # 2) List forks\n",
    "    forks_resp = requests.get(f\"https://api.github.com/repos/{owner}/{repo}/forks\", headers=headers)\n",
    "    forks_resp.raise_for_status()\n",
    "    forks = forks_resp.json()\n",
    "\n",
    "    # 3) Compare each fork\n",
    "    outdated = []\n",
    "    for fork in forks:\n",
    "        fork_owner = fork[\"owner\"][\"login\"]\n",
    "        fork_comm = requests.get(\n",
    "            fork[\"url\"] + \"/commits\",\n",
    "            headers=headers,\n",
    "            params={\"per_page\": 1}\n",
    "        )\n",
    "        if fork_comm.status_code != 200:\n",
    "            print(f\"  – could not fetch commits for {fork_owner}, skipping.\")\n",
    "            continue\n",
    "\n",
    "        fork_sha = fork_comm.json()[0][\"sha\"]\n",
    "        if fork_sha != new_commit_hash:\n",
    "            outdated.append(f\"@{fork_owner}\")\n",
    "\n",
    "    # 4) Open an issue if any are behind\n",
    "    if outdated:\n",
    "        title = \"🔔 Notification: Your fork is behind the latest commit\"\n",
    "        body  = (\n",
    "            f\"Hi {' '.join(outdated)},\\n\\n\"\n",
    "            f\"The main repository has been updated to commit `{new_commit_hash}`.\\n\"\n",
    "            \"Please consider pulling the latest changes to stay in sync.\\n\\n\"\n",
    "            \"Thanks!\"\n",
    "        )\n",
    "        issues_url = f\"https://api.github.com/repos/{owner}/{repo}/issues\"\n",
    "        resp = requests.post(\n",
    "        issues_url,\n",
    "        headers=headers,\n",
    "        json={\"title\": title, \"body\": body}\n",
    "    )\n",
    "\n",
    "    # DEBUGGING OUTPUT\n",
    "    print(f\"→ POST {issues_url}\")\n",
    "    print(\"→ Status code:\", resp.status_code)\n",
    "    print(\"→ Response headers:\", resp.headers)\n",
    "    try:\n",
    "        data = resp.json()\n",
    "        print(\"→ Response JSON:\", data)\n",
    "        print(\"→ html_url field:\", data.get(\"html_url\"))\n",
    "    except ValueError:\n",
    "        print(\"→ No JSON response body; raw text:\", resp.text)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    answer = input(\"Do you want to notify collaborators whose forks are behind? (y/N): \").strip().lower()\n",
    "    if answer in (\"y\", \"yes\"):\n",
    "        notify_outdated_forks()\n",
    "    else:\n",
    "        print(\"No action taken.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda31f16-fbe9-40ce-ac1b-9ebc898c8820",
   "metadata": {},
   "source": [
    "INVENIO INTEGRETION to upload the necessary files and publish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e5a7fc-3b03-45c8-bc90-817ea5ba7352",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################\n",
    "# TEST CODE FOR INVENIO INTEGRETION\n",
    "#############################################################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# API_BASE = \"https://127.0.0.1:5000\"\n",
    "# TOKEN    = \"8LnqJuz3TsBHffnDJ3isPLHYHtRbWrC0M667Nb5haEbnXpWqGbFRyfDApymr\"\n",
    "\n",
    "# # 1) Test read‐scope by listing records (no size param or size=1)\n",
    "# resp = requests.get(\n",
    "#     f\"{API_BASE}/api/records\",\n",
    "#     headers={\"Authorization\": f\"Bearer {TOKEN}\"},\n",
    "#     verify=False\n",
    "# )\n",
    "# print(resp.status_code)\n",
    "# # should be 200 and a JSON page of records\n",
    "\n",
    "# # or explicitly:\n",
    "# resp = requests.get(\n",
    "#     f\"{API_BASE}/api/records?size=1\",\n",
    "#     headers={\"Authorization\": f\"Bearer {TOKEN}\"},\n",
    "#     verify=False\n",
    "# )\n",
    "# print(resp.status_code, resp.json())\n",
    "# #################################################################################################\n",
    "# API_BASE = \"https://127.0.0.1:5000\"\n",
    "# TOKEN    = \"8LnqJuz3TsBHffnDJ3isPLHYHtRbWrC0M667Nb5haEbnXpWqGbFRyfDApymr\"\n",
    "\n",
    "# resp = requests.options(\n",
    "#     f\"{API_BASE}/api/records\",\n",
    "#     headers={\"Authorization\": f\"Bearer {TOKEN}\"},\n",
    "#     verify=False\n",
    "# )\n",
    "# print(\"Allowed methods:\", resp.headers.get(\"Allow\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745dc1c9-ed88-45dc-bd8c-1065c9c17aa3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Configuration\n",
    "# -----------------------------------------------------------------------------\n",
    "API_BASE   = \"https://127.0.0.1:5000\"\n",
    "TOKEN      = \"8LnqJuz3TsBHffnDJ3isPLHYHtRbWrC0M667Nb5haEbnXpWqGbFRyfDApymr\"\n",
    "VERIFY_SSL = False  # only for self‐signed dev\n",
    "\n",
    "HEADERS_JSON = {\n",
    "    \"Accept\":        \"application/json\",\n",
    "    \"Content-Type\":  \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {TOKEN}\",\n",
    "}\n",
    "\n",
    "HEADERS_OCTET = {\n",
    "    \"Content-Type\":  \"application/octet-stream\",\n",
    "    \"Authorization\": f\"Bearer {TOKEN}\",\n",
    "}\n",
    "\n",
    "# The folders you want to walk & upload:\n",
    "TO_UPLOAD = [\"Trained_models\", \"plots\", \"MODEL_PROVENANCE\"]\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 1) Create draft with ALL required metadata\n",
    "# -----------------------------------------------------------------------------\n",
    "def create_draft():\n",
    "    payload = {\n",
    "  \"metadata\": {\n",
    "    \"title\":            \"RandomForest Iris Model Artifacts\",\n",
    "    \"creators\": [ {\n",
    "      \"person_or_org\": {\n",
    "        \"type\":        \"personal\",\n",
    "        \"given_name\":  \"Reema\",\n",
    "        \"family_name\": \"Dass\"\n",
    "      }\n",
    "    } ],\n",
    "    \"publication_date\": \"2025-04-24\",\n",
    "    \"resource_type\":    { \"id\": \"software\" },\n",
    "    \"access\": {\n",
    "      \"record\": \"public\",\n",
    "      \"files\":  \"public\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "    r = requests.post(f\"{API_BASE}/api/records\",\n",
    "                      headers=HEADERS_JSON,\n",
    "                      json=payload,\n",
    "                      verify=VERIFY_SSL)\n",
    "    r.raise_for_status()\n",
    "    draft = r.json()\n",
    "    print(\"✅ Draft created:\", draft[\"id\"])\n",
    "    return draft[\"id\"], draft[\"links\"]\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 2) Register, upload and commit a single file\n",
    "# -----------------------------------------------------------------------------\n",
    "def upload_and_commit(links, key, path):\n",
    "    # 2a) register the filename in the draft\n",
    "    r1 = requests.post(links[\"files\"],\n",
    "                       headers=HEADERS_JSON,\n",
    "                       json=[{\"key\": key}],\n",
    "                       verify=VERIFY_SSL)\n",
    "    r1.raise_for_status()\n",
    "    entry = next(e for e in r1.json()[\"entries\"] if e[\"key\"] == key)\n",
    "    file_links = entry[\"links\"]\n",
    "\n",
    "    # 2b) upload the bytes\n",
    "    with open(path, \"rb\") as fp:\n",
    "        r2 = requests.put(file_links[\"content\"],\n",
    "                          headers=HEADERS_OCTET,\n",
    "                          data=fp,\n",
    "                          verify=VERIFY_SSL)\n",
    "    r2.raise_for_status()\n",
    "\n",
    "    # 2c) commit the upload\n",
    "    r3 = requests.post(file_links[\"commit\"],\n",
    "                       headers=HEADERS_JSON,\n",
    "                       verify=VERIFY_SSL)\n",
    "    r3.raise_for_status()\n",
    "    print(f\"  • Uploaded {key}\")\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 3) Walk each folder and upload every file\n",
    "# -----------------------------------------------------------------------------\n",
    "def upload_folder(links):\n",
    "    for folder in TO_UPLOAD:\n",
    "        if not os.path.isdir(folder):\n",
    "            print(f\"⚠️ Skipping missing folder {folder}\")\n",
    "            continue\n",
    "        base = os.path.dirname(folder) or folder\n",
    "        for root, _, files in os.walk(folder):\n",
    "            for fn in files:\n",
    "                local = os.path.join(root, fn)\n",
    "                # create a POSIX‐style key preserving subfolders\n",
    "                key = os.path.relpath(local, start=base).replace(os.sep, \"/\")\n",
    "                upload_and_commit(links, key, local)\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 4) Publish the draft\n",
    "# -----------------------------------------------------------------------------\n",
    "def publish(links):\n",
    "    r = requests.post(links[\"publish\"],\n",
    "                      headers=HEADERS_JSON,\n",
    "                      verify=VERIFY_SSL)\n",
    "    if not r.ok:\n",
    "        print(\"❌ Publish failed:\", r.status_code, r.text)\n",
    "        try: print(r.json())\n",
    "        except: pass\n",
    "        r.raise_for_status()\n",
    "    print(\"✅ Published:\", r.json()[\"id\"])\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Main\n",
    "# -----------------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    recid, links = create_draft()\n",
    "    upload_folder(links)\n",
    "    publish(links)\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b463223e-5425-465c-ae63-815cbb053301",
   "metadata": {},
   "source": [
    "########################################################################\n",
    "# FETCH metadata from INVENIO\n",
    "########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee538759-38b9-4ea8-bdc6-41cc65ede642",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_metadata(record_id, model_name, api_base, headers, verify_ssl=True):\n",
    "    \"\"\"\n",
    "    Fetch Invenio metadata and save to a file named after the model inside 'Invenio_metadata' folder.\n",
    "    \"\"\"\n",
    "    response = requests.get(f\"{API_BASE}/api/records/{record_id}\",\n",
    "                            headers=headers,\n",
    "                            verify=VERIFY_SSL)\n",
    "    response.raise_for_status()\n",
    "    metadata = response.json()\n",
    "\n",
    "    print(\"✅ Metadata fetched successfully\")\n",
    "\n",
    "    # Create the folder if it doesn't exist\n",
    "    os.makedirs(\"Invenio_metadata\", exist_ok=True)\n",
    "\n",
    "    # Construct path and save\n",
    "    file_path = os.path.join(\"Invenio_metadata\", f\"{model_name}_invenio.json\")\n",
    "    with open(file_path, \"w\") as f:\n",
    "        json.dump(metadata, f, indent=4)\n",
    "\n",
    "    print(f\"✅ Metadata saved at {file_path}\")\n",
    "    return file_path\n",
    "path = fetch_metadata(recid, model_name, api_base=API_BASE, headers=HEADERS_JSON)\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7423f2-0ff3-4104-913e-50eeb32d9d0f",
   "metadata": {},
   "source": [
    "METADATA EXTRACTION FROM INVENIO and ADD it to main Provenence FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d5968b-997e-4458-bf6b-a14dcc883698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Function: Extract metadata\n",
    "# ----------------------------\n",
    "def extract_metadata(metadata):\n",
    "    print(\"✅ Metadata loaded successfully\")\n",
    "    print(\"ℹ️ ID:\", metadata.get(\"id\", \"N/A\"))\n",
    "    print(\"🔍 Extracting required fields...\")\n",
    "\n",
    "    extracted_data = {\n",
    "        \"invenio_metadata\": {\n",
    "            \"id\": metadata.get(\"id\", \"\"),\n",
    "            \"title\": metadata.get(\"metadata\", {}).get(\"title\", \"\"),\n",
    "            \"creator\": \", \".join([\n",
    "                creator[\"person_or_org\"].get(\"name\", \"\")\n",
    "                for creator in metadata.get(\"metadata\", {}).get(\"creators\", [])\n",
    "            ]),\n",
    "            \"publication_date\": metadata.get(\"metadata\", {}).get(\"publication_date\", \"\"),\n",
    "            \"files\": [],\n",
    "            \"pids\": metadata.get(\"pids\", {}),\n",
    "            \"version_info\": metadata.get(\"versions\", {}),\n",
    "            \"status\": metadata.get(\"status\", \"\"),\n",
    "            \"views\": metadata.get(\"stats\", {}).get(\"this_version\", {}).get(\"views\", 0),\n",
    "            \"downloads\": metadata.get(\"stats\", {}).get(\"this_version\", {}).get(\"downloads\", 0),\n",
    "        }\n",
    "    }\n",
    "\n",
    "    for key, file_info in metadata.get(\"files\", {}).get(\"entries\", {}).items():\n",
    "        file_detail = {\n",
    "            \"key\": key,\n",
    "            \"url\": file_info[\"links\"].get(\"content\", \"\"),\n",
    "            \"size\": file_info.get(\"size\", 0),\n",
    "            \"mimetype\": file_info.get(\"mimetype\", \"\"),\n",
    "            \"checksum\": file_info.get(\"checksum\", \"\"),\n",
    "            \"metadata\": file_info.get(\"metadata\", {}),\n",
    "        }\n",
    "        extracted_data[\"invenio_metadata\"][\"files\"].append(file_detail)\n",
    "\n",
    "    return extracted_data\n",
    "\n",
    "\n",
    "invenio_path = f\"Invenio_metadata/{model_name}_invenio.json\"\n",
    "run_summary_path = f\"MODEL_PROVENANCE/{model_name}/{model_name}_run_summary.json\"\n",
    "\n",
    "# ----------------------------\n",
    "# Step 1: Load Invenio metadata\n",
    "# ----------------------------\n",
    "with open(invenio_path, \"r\") as f:\n",
    "    original_metadata = json.load(f)\n",
    "\n",
    "# ----------------------------\n",
    "# Step 2: Extract metadata\n",
    "# ----------------------------\n",
    "extracted_metadata = extract_metadata(original_metadata)\n",
    "print(\"📤 Extracted Metadata Preview:\")\n",
    "print(json.dumps(extracted_metadata, indent=4)[:1000])  # Preview\n",
    "\n",
    "# ----------------------------\n",
    "# Step 3: Load run summary\n",
    "# ----------------------------\n",
    "with open(run_summary_path, \"r\") as f:\n",
    "    existing_metadata = json.load(f)\n",
    "\n",
    "# ----------------------------\n",
    "# Step 4: Merge metadata\n",
    "# ----------------------------\n",
    "existing_metadata.update(extracted_metadata)\n",
    "\n",
    "# ----------------------------\n",
    "# Step 5: Save updated summary\n",
    "# ----------------------------\n",
    "with open(run_summary_path, \"w\") as f:\n",
    "    json.dump(existing_metadata, f, indent=4)\n",
    "\n",
    "print(f\"✅ Invenio metadata embedded successfully into: {run_summary_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa460d3-f443-46b1-ba5e-4f1339ba4eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "def get_git_version_info():\n",
    "    try:\n",
    "        commit = subprocess.check_output([\"git\", \"rev-parse\", \"HEAD\"]).decode().strip()\n",
    "        tag = subprocess.check_output([\"git\", \"describe\", \"--tags\", \"--exact-match\"], stderr=subprocess.DEVNULL).decode().strip()\n",
    "    except subprocess.CalledProcessError:\n",
    "        tag = \"untagged\"\n",
    "    return commit, tag\n",
    "\n",
    "commit_hash, version_tag = get_git_version_info()\n",
    "print(\"Commit:\", commit_hash)\n",
    "print(\"Version Tag:\", version_tag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87e6109-de5e-4ba4-baae-7de79c1fb131",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
