{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ff24f2a-931c-4543-b179-dc8bf1bfd74d",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "########################################################\n",
    "# EXPERIMENT CODE\n",
    "########################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb7ee73-aa97-48ef-b1c8-f00cc2af0b0f",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Collects metadata about a user session for logging or reproducibility purposes.\n",
    "This includes system details, user information, and optional project metadata.\n",
    "It supports:\n",
    "- Automatic population via environment variables.\n",
    "- Interactive prompting if fields are missing (when `prompt_fields=True`).\n",
    "- Fixed overrides for role and project ID if provided.\n",
    "Useful in collaborative research, ML experiment tracking, or Jupyter environments.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f97a375-387a-4368-a629-556f56f51dcc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "import platform\n",
    "import sys\n",
    "import uuid\n",
    "from datetime import datetime\n",
    "\n",
    "def prompt_if_none(env_key, prompt_text, default_value=\"unknown\"):\n",
    "    val = os.getenv(env_key)\n",
    "    if not val:\n",
    "        try:\n",
    "            val = input(f\"{prompt_text} (default: {default_value}): \").strip() or default_value\n",
    "        except Exception:\n",
    "            val = default_value\n",
    "    return val\n",
    "\n",
    "def collect_session_metadata(\n",
    "    prompt_fields=True,\n",
    "    fixed_role=None,\n",
    "    fixed_project_id=None\n",
    "):\n",
    "    session_id = str(uuid.uuid4())\n",
    "    \n",
    "    session_metadata = {\n",
    "        \"session_id\": session_id,\n",
    "        \"username\": os.getenv(\"JUPYTERHUB_USER\", getpass.getuser()),\n",
    "        \"timestamp_utc\": datetime.utcnow().isoformat(),\n",
    "        \"hostname\": platform.node(),\n",
    "        \"platform\": platform.system(),\n",
    "        \"os_version\": platform.version(),\n",
    "        \"python_version\": sys.version.split()[0],\n",
    "    }\n",
    "\n",
    "    # Prompt or use defaults\n",
    "    session_metadata[\"role\"] = fixed_role or (\n",
    "        prompt_if_none(\"RESEARCHER_ROLE\", \"Enter your role\", \"collaborator\") if prompt_fields \n",
    "        else os.getenv(\"RESEARCHER_ROLE\", \"researcher\")\n",
    "    )\n",
    "    session_metadata[\"project_id\"] = fixed_project_id or (\n",
    "        prompt_if_none(\"PROJECT_ID\", \"Enter project ID\", \"default_project\") if prompt_fields \n",
    "        else os.getenv(\"PROJECT_ID\", \"default_project\")\n",
    "    )\n",
    "\n",
    "    print(\"\\nüìå Session Metadata:\")\n",
    "    for k, v in session_metadata.items():\n",
    "        print(f\"  {k}: {v}\")\n",
    "\n",
    "    return session_metadata\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca4f0ae-39ee-4b22-b013-dfb1fa1b5694",
   "metadata": {},
   "source": [
    "LIBRARY IMPORTS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ca332e5-6501-4310-920b-2b769477b46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# üì¶ Standard Library Imports\n",
    "# ============================\n",
    "import os\n",
    "import glob\n",
    "import io\n",
    "import json\n",
    "import time\n",
    "import ast\n",
    "import pickle\n",
    "import platform\n",
    "import subprocess\n",
    "from datetime import datetime, timezone\n",
    "from pprint import pprint\n",
    "from typing import List, Dict, Any\n",
    "import xml.etree.ElementTree as ET\n",
    "import urllib.parse\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "\n",
    "# ============================\n",
    "# üìä Data and Visualization\n",
    "# ============================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ============================\n",
    "# ü§ñ Machine Learning\n",
    "# ============================\n",
    "import sklearn\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, label_binarize\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    roc_auc_score,\n",
    "    confusion_matrix,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    RocCurveDisplay,\n",
    "    PrecisionRecallDisplay\n",
    ")\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "# ============================\n",
    "# üî¨ Experiment Tracking\n",
    "# ============================\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow import MlflowClient\n",
    "\n",
    "# ============================\n",
    "# üåê Web / API / Networking\n",
    "# ============================\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ============================\n",
    "# üß™ Git & Version Control\n",
    "# ============================\n",
    "import git\n",
    "from git import Repo, GitCommandError\n",
    "import hashlib\n",
    "\n",
    "\n",
    "# ============================\n",
    "# üß† SHAP for Explainability\n",
    "# ============================\n",
    "import shap\n",
    "\n",
    "# ============================\n",
    "# üß¨ RDF & Provenance (rdflib)\n",
    "# ============================\n",
    "from rdflib import Graph, URIRef, Literal\n",
    "from rdflib.namespace import PROV, XSD\n",
    "\n",
    "# ============================\n",
    "# ‚öôÔ∏è System Monitoring\n",
    "# ============================\n",
    "import psutil\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfde18b5-ae9c-442c-a5b3-7dfb06957646",
   "metadata": {},
   "source": [
    "#Dataset metadata!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a394398-cd25-45b5-89ac-6d909b65d417",
   "metadata": {},
   "source": [
    "#Metadata from ZONEDO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de603b35-9534-477d-a851-8b6e5efb910c",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Fetches and structures dataset metadata from a given DOI using the DataCite API.\n",
    "\n",
    "This function:\n",
    "- Sends a GET request to the DataCite API to retrieve metadata about a dataset.\n",
    "- Extracts important fields (e.g., title, creator, publisher, version, license).\n",
    "- Fills in placeholders like \"info not available\" when data is missing.\n",
    "- Adds additional fields based on the PROV-O provenance model for traceability.\n",
    "\n",
    "Returns a dictionary that can be used for logging, tracking, or enriching metadata\n",
    "in data catalogs, ML pipelines, or reproducibility systems.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79c3e945-508a-4c1c-8bb1-c1b5d9121615",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from datetime import datetime\n",
    "import pprint\n",
    "\n",
    "def extract_dataset_metadata_from_doi(doi: str) -> dict:\n",
    "    base_url = f\"https://api.datacite.org/dois/{doi.lower()}\"\n",
    "    r = requests.get(base_url)\n",
    "    r.raise_for_status()\n",
    "    meta = r.json().get(\"data\", {}).get(\"attributes\", {})\n",
    "\n",
    "    # Print all available raw metadata (for debugging/exploration)\n",
    "    pprint.pprint(meta)\n",
    "\n",
    "    # --- Standard metadata fields ---\n",
    "    title = meta.get(\"titles\", [{}])[0].get(\"title\", \"info not available\")\n",
    "    creators = [c.get(\"name\", \"\") for c in meta.get(\"creators\", [])]\n",
    "    publisher = meta.get(\"publisher\", \"info not available\")\n",
    "    pub_year = meta.get(\"publicationYear\", \"info not available\")\n",
    "    url = meta.get(\"url\", f\"https://doi.org/{doi}\")\n",
    "    created = meta.get(\"created\")\n",
    "    updated = meta.get(\"updated\")\n",
    "    description = meta.get(\"descriptions\", [])\n",
    "    license_info = meta.get(\"rightsList\", [])\n",
    "    language = meta.get(\"language\", \"info not available\")\n",
    "    subjects = meta.get(\"subjects\", [])\n",
    "    related_ids = meta.get(\"relatedIdentifiers\", [])\n",
    "    citation_count = meta.get(\"citationCount\", 0)\n",
    "    registered = meta.get(\"registered\", \"\")\n",
    "    schema_version = meta.get(\"schemaVersion\", \"\")\n",
    "    citation_trend = meta.get(\"citationsOverTime\", [])\n",
    "\n",
    "    # --- Convert useful extras into strings ---\n",
    "    dataset_description = description[0][\"description\"] if description else \"info not available\"\n",
    "    dataset_license = license_info[0][\"rights\"] if license_info else \"info not available\"\n",
    "    dataset_subjects = \", \".join(s.get(\"subject\", \"\") for s in subjects) if subjects else \"info not available\"\n",
    "    related_resources = [r.get(\"relatedIdentifier\", \"\") for r in related_ids]\n",
    "\n",
    "    # --- Structured output ---\n",
    "    dataset_metadata = {\n",
    "        \"dataset_id\": doi,\n",
    "        \"dataset_title\": title,\n",
    "        \"dataset_creator\": \", \".join(creators) if creators else \"info not available\",\n",
    "        \"dataset_publisher\": publisher,\n",
    "        \"dataset_publication_date\": pub_year,\n",
    "        \"dataset_description\": dataset_description,\n",
    "        \"dataset_version\": meta.get(\"version\", \"info not available\"),\n",
    "        \"dataset_license\": dataset_license,\n",
    "        \"dataset_subjects\": dataset_subjects,\n",
    "        \"dataset_language\": language,\n",
    "        \"dataset_access_url\": url,\n",
    "        \"dataset_documentation\": url,\n",
    "        \"metadata_standard\": meta.get(\"types\", {}).get(\"resourceTypeGeneral\", \"info not available\"),\n",
    "        \"related_resources\": related_resources,\n",
    "        \"citation_count\": citation_count,\n",
    "        \"citations_over_time\": citation_trend,\n",
    "        \"schema_version\": schema_version,\n",
    "        \"registered_date\": registered,\n",
    "        \"created\": created,\n",
    "        \"updated\": updated,\n",
    "\n",
    "        # PROV-O traceability fields\n",
    "        \"prov_entity\": title,\n",
    "        \"prov_activity\": \"Ingestion and Publication\",\n",
    "        \"prov_agent_dataset_creator\": \", \".join(creators) if creators else \"info not available\",\n",
    "        \"prov_used\": url,\n",
    "        \"prov_wasDerivedFrom\": doi,\n",
    "        \"prov_wasAttributedTo\": \", \".join(creators) if creators else \"info not available\",\n",
    "        \"prov_startedAtTime\": pub_year,\n",
    "        \"prov_role_dataset_creator\": \"Original Data Author\",\n",
    "        \"prov_role_database_creator\": \"Database Ingestor and Maintainer\"\n",
    "    }\n",
    "\n",
    "    return dataset_metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5384df92-5841-472c-872d-370452f6f902",
   "metadata": {},
   "outputs": [],
   "source": [
    " # doi_metadata = extract_dataset_metadata_from_doi(\"10.24432/C56C76\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef6b25a-51ae-4afa-87ee-64a855c0aaa2",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Fetches and compiles structured metadata about a database table from a local API.\n",
    "\n",
    "This function:\n",
    "- Retrieves database-level metadata (e.g., name, owner, description).\n",
    "- Retrieves versioned history for the specific table.\n",
    "- Constructs a flat metadata dictionary with standardized and FAIR4ML/PROV-O‚Äìstyle fields.\n",
    "- Can be used in ML pipelines, reproducibility tracking, or data cataloging systems.\n",
    "\n",
    "Arguments:\n",
    "- db_id (str): The database identifier.\n",
    "- table_id (str): The table identifier within the database.\n",
    "- selected_version (str): Version string for the dataset.\n",
    "- target_variable (str): Name of the ML target column.\n",
    "- num_samples (int): Number of data samples.\n",
    "\n",
    "Returns:\n",
    "- dict: A metadata dictionary or an empty dict if request fails.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ee5cf89-7c47-4601-b57c-04415d5966c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "DB_API = \"http://localhost/api/database/{db_id}\"\n",
    "HISTORY_API = \"http://localhost/api/database/{db_id}/table/{table_id}/history\"\n",
    "\n",
    "def fetch_db_dataset_metadata(\n",
    "    db_id: str,\n",
    "    table_id: str,\n",
    "    selected_version: str,\n",
    "    target_variable: str,\n",
    "    num_samples: int\n",
    ") -> dict:\n",
    "    try:\n",
    "        # Fetch main DB metadata\n",
    "        db_url = DB_API.format(db_id=db_id)\n",
    "        db_response = requests.get(db_url)\n",
    "        db_response.raise_for_status()\n",
    "        db_data = db_response.json()\n",
    "        print(db_data)\n",
    "\n",
    "        # Fetch table history metadata\n",
    "        history_url = HISTORY_API.format(db_id=db_id, table_id=table_id)\n",
    "        history_response = requests.get(history_url)\n",
    "        timestamp = \"info not available\"\n",
    "        if history_response.status_code == 200:\n",
    "            history_data = history_response.json()\n",
    "            print(history_data)\n",
    "            if isinstance(history_data, list) and len(history_data) > 0:\n",
    "                timestamp = history_data[0].get(\"timestamp\", timestamp)\n",
    "\n",
    "        # Build flat metadata structure for DB storage\n",
    "        dataset_metadata = {\n",
    "            # Basic identity\n",
    "            \"dataset_id\": table_id,\n",
    "            \"dataset_name\": next(\n",
    "                (t.get(\"name\") for t in db_data.get(\"tables\", []) if t.get(\"id\") == table_id),\n",
    "                \"table name not available\"\n",
    "            ),\n",
    "            \"dataset_version\": selected_version,\n",
    "            \"dataset_title\": db_data.get(\"name\", \"info not available\"),\n",
    "            \"dataset_description\": db_data.get(\"description\", \"info not available\"),\n",
    "\n",
    "            # Ownership and access\n",
    "            \"dataset_creator\": \"info not available\",\n",
    "            \"dataset_publisher\": db_data.get(\"owner\", {}).get(\"name\", \"info not available\"),\n",
    "            \"dataset_access_url\": db_url,\n",
    "            \"dataset_publication_date\": timestamp,\n",
    "            \"dataset_license\": \"info not available\",\n",
    "\n",
    "            # Structure\n",
    "            \"columns\": db_data.get(\"columns\", \"info not available\"),\n",
    "            \"dataset_dataset_type\": \"tabular\",\n",
    "            \"target_variable\": target_variable,\n",
    "            \"ml_task\": \"classification\",\n",
    "            \"num_samples\": num_samples,\n",
    "\n",
    "            # FAIR4ML placeholders\n",
    "            \"data_distribution\": \"info not available\",\n",
    "            \"known_issues\": \"info not available\",\n",
    "            \"trainedOn\": \"info not available\",\n",
    "            \"testedOn\": \"info not available\",\n",
    "            \"validatedOn\": \"info not available\",\n",
    "            \"modelRisks\": \"info not available\",\n",
    "            \"usageInstructions\": \"info not available\",\n",
    "            \"ethicalLegalSocial\": \"info not available\",\n",
    "\n",
    "            # PROV-style fields\n",
    "            \"prov_entity\": db_data.get(\"name\", \"info not available\"),\n",
    "            \"prov_activity\": \"Ingestion and Publication\",\n",
    "            \"prov_agent_dataset_creator\": \"info not available\",\n",
    "            \"prov_agent_database_creator\": db_data.get('owner', {}).get('name', 'info not available'),\n",
    "            \"prov_wasGeneratedBy\": db_data.get('owner', {}).get('name', 'info not available'),\n",
    "            \"prov_used\": db_url,\n",
    "            \"prov_wasDerivedFrom\": \"info not available\",\n",
    "            \"prov_wasAttributedTo\": \"info not available\",\n",
    "            \"prov_wasAssociatedWith\": db_data.get('owner', {}).get('name', 'info not available'),\n",
    "            \"prov_startedAtTime\": \"info not available\",\n",
    "            \"prov_endedAtTime\": timestamp,\n",
    "            \"prov_location\": db_url,\n",
    "            \"prov_role_dataset_creator\": \"\",\n",
    "            \"prov_role_database_creator\": \"Database Ingestor and Maintainer\"\n",
    "        }\n",
    "\n",
    "        return dataset_metadata\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"[‚ö†Ô∏è Error] Failed to fetch DB metadata for {db_id}: {e}\")\n",
    "        return {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b61178-0a4a-48d5-8b6f-737104605005",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Interactive version selector for datasets stored in a version-controlled database.\n",
    "\n",
    "This script:\n",
    "- Maintains a mapping between dataset version tags (e.g., \"v0\", \"v1\") and actual table UUIDs.\n",
    "- Prompts the user to select a version from a list of labeled options.\n",
    "- Validates the input and returns the selected version along with the corresponding table UUID.\n",
    "- Useful for ML or data analysis workflows where multiple versions of the same dataset exist.\n",
    "\n",
    "Returns:\n",
    "- selected_version (str): Version tag (e.g., \"v2\")\n",
    "- selected_table_id (str): UUID of the selected table version\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91e0611d-d579-485a-ac24-094c1890bc2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select dataset version:\n",
      "  v0 - Original\n",
      "  v1 - Duplicated\n",
      "  v2 - First 100\n",
      "  v3 - Shuffled\n",
      "  v4 - Normalized\n",
      "  v5 - Random\n",
      "  v6 - test\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter version (v0‚Äìv5):  v1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ You selected version 'v1' ‚Üí Table ID: 2adcf367-baec-43eb-8a7c-8340578beb79\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Mapping of version tags to table UUIDs\n",
    "version_to_table_id = {\n",
    "    \"v0\": \"0a16d4fd-8567-46b8-8f0c-223bfe29f4a1\",  # Original\n",
    "    \"v1\": \"2adcf367-baec-43eb-8a7c-8340578beb79\",  # Duplicated\n",
    "    \"v2\": \"e241e1ad-cd2d-4550-903b-4af424b196f9\",  # First 100\n",
    "    \"v3\": \"dfe800b3-c959-4943-8643-f3d5b9c8ae10\",  # Shuffled\n",
    "    \"v4\": \"7149decf-e01b-4c96-8569-6d2527a1487a\" ,  # Normalized\n",
    "    \"v5\": \"fb2957a5-e083-4faa-b7c6-85ec0978440c\",   # Random\n",
    "    # \"v6\": \"d5981cc3-7518-4f38-9144-003fcdb28ec7\"  #possible replace for v2 dint work\n",
    "\n",
    "}\n",
    "\n",
    "db_id = \"c94c9774-8407-49fd-b21f-9e6e4af57d3b\"  # Static DB ID\n",
    "\n",
    "def select_dataset_version():\n",
    "    print(\"Select dataset version:\")\n",
    "    print(\"  v0 - Original\")\n",
    "    print(\"  v1 - Duplicated\")\n",
    "    print(\"  v2 - First 100\")\n",
    "    print(\"  v3 - Shuffled\")\n",
    "    print(\"  v4 - Normalized\")\n",
    "    print(\"  v5 - Random\")\n",
    "    print(\"  v6 - test\")\n",
    "\n",
    "    \n",
    "    \n",
    "    selected_version = input(\"Enter version (v0‚Äìv5): \").strip().lower()\n",
    "    \n",
    "    if selected_version not in version_to_table_id:\n",
    "        raise ValueError(f\"‚ùå Invalid version selected: {selected_version}\")\n",
    "    \n",
    "    selected_table_id = version_to_table_id[selected_version]\n",
    "    \n",
    "    print(f\"\\n‚úÖ You selected version '{selected_version}' ‚Üí Table ID: {selected_table_id}\\n\")\n",
    "    \n",
    "    return selected_version, selected_table_id\n",
    "\n",
    "# Usage: #TODO CALL\n",
    "selected_version, selected_table_id = select_dataset_version()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78280d38-b041-4c22-8adf-5fd9c5934960",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Logs structured metadata to an active MLflow run.\n",
    "\n",
    "This utility function:\n",
    "- Logs each key-value pair in a flat metadata dictionary as MLflow tags.\n",
    "- Optionally prefixes each key (e.g., \"session_\", \"prov_\").\n",
    "- Skips empty or None values.\n",
    "- Truncates long values and handles dicts/lists by serializing to JSON.\n",
    "- Also saves the entire metadata dictionary as a JSON file and logs it as an MLflow artifact.\n",
    "\n",
    "This function is useful for reproducibility, audit trails, experiment documentation, \n",
    "and standard-compliant ML metadata logging.\n",
    "\n",
    "Args:\n",
    "    metadata (dict): Flat dictionary of metadata fields.\n",
    "    prefix (str): Optional prefix to prepend to each tag key.\n",
    "    snapshot_name (str): Filename for saved full JSON snapshot artifact.\n",
    "\n",
    "Raises:\n",
    "    RuntimeError: If no MLflow run is active.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aab28b04-4db7-43bf-8320-f6382120984a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import mlflow\n",
    "# \n",
    "def log_metadata_dict_to_mlflow(metadata: dict, prefix: str = \"\", snapshot_name: str = \"metadata_snapshot.json\"):\n",
    "    \"\"\"\n",
    "    Logs a flat metadata dictionary to MLflow:\n",
    "    - Adds prefix to each key if provided (e.g., \"session_\")\n",
    "    - Skips empty values\n",
    "    - Logs a full JSON artifact for traceability\n",
    "    \"\"\"\n",
    "    \n",
    "    def safe_tag(key, value):\n",
    "        if not mlflow.active_run():\n",
    "            raise RuntimeError(\"‚ùå No active MLflow run.\")\n",
    "        \n",
    "        key_clean = key.replace(\":\", \"_\").replace(\"/\", \"_\").replace(\" \", \"_\")\n",
    "        try:\n",
    "            val_str = json.dumps(value) if isinstance(value, (dict, list)) else str(value)\n",
    "            if len(val_str) > 5000:\n",
    "                val_str = val_str[:5000] + \"...[TRUNCATED]\"\n",
    "            if len(key_clean) > 255:\n",
    "                print(f\"‚ö†Ô∏è Skipped tag (key too long): {key_clean}\")\n",
    "                return\n",
    "            mlflow.set_tag(key_clean, val_str)\n",
    "            print(f\"‚úÖ Logged tag: {key_clean}\")\n",
    "        except Exception as e:\n",
    "            print(f\"[‚ö†Ô∏è Error logging tag] {key_clean}: {e}\")\n",
    "\n",
    "    for key, value in metadata.items():\n",
    "        if value not in [None, \"\"]:\n",
    "            full_key = f\"{prefix}{key}\" if prefix else key\n",
    "            safe_tag(full_key, value)\n",
    "\n",
    "    # Save full metadata snapshot as JSON artifact\n",
    "    os.makedirs(\"metadata\", exist_ok=True)\n",
    "    full_path = os.path.join(\"metadata\", snapshot_name)\n",
    "    with open(full_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(metadata, f, indent=2)\n",
    "    \n",
    "    mlflow.log_artifact(full_path, artifact_path=\"metadata\")\n",
    "    print(f\"üìÅ Full metadata snapshot logged as: {snapshot_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d4d6b8-34a9-47b5-974d-5927c0ee2256",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Fetches dataset content from a specific versioned table using the local API.\n",
    "\n",
    "This script:\n",
    "- Constructs a GET request to retrieve data from a specified database table.\n",
    "- Sends the request with appropriate headers.\n",
    "- Parses and prints the response JSON if successful.\n",
    "- Handles and reports errors gracefully.\n",
    "\n",
    "Useful for loading versioned datasets (e.g., for analysis or ML training)\n",
    "from a metadata-aware data management backend.\n",
    "\n",
    "Assumes:\n",
    "- `db_id` and `selected_table_id` are already defined.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e3570e2-9a60-45b4-8653-28060071e728",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost/api/database/c94c9774-8407-49fd-b21f-9e6e4af57d3b/table/2adcf367-baec-43eb-8a7c-8340578beb79/data?size=100000&page=0\n",
      "[{'id': '1', 'sepallengthcm': '5.100000000000000000', 'sepalwidthcm': '3.500000000000000000', 'petallengthcm': '1.400000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '2', 'sepallengthcm': '4.900000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '1.400000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '3', 'sepallengthcm': '4.700000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '1.300000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '4', 'sepallengthcm': '4.600000000000000000', 'sepalwidthcm': '3.100000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '5', 'sepallengthcm': '5.000000000000000000', 'sepalwidthcm': '3.600000000000000000', 'petallengthcm': '1.400000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '6', 'sepallengthcm': '5.400000000000000000', 'sepalwidthcm': '3.900000000000000000', 'petallengthcm': '1.700000000000000000', 'petalwidthcm': '0.400000000000000000', 'species': 'Iris-setosa'}, {'id': '7', 'sepallengthcm': '4.600000000000000000', 'sepalwidthcm': '3.400000000000000000', 'petallengthcm': '1.400000000000000000', 'petalwidthcm': '0.300000000000000000', 'species': 'Iris-setosa'}, {'id': '8', 'sepallengthcm': '5.000000000000000000', 'sepalwidthcm': '3.400000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '9', 'sepallengthcm': '4.400000000000000000', 'sepalwidthcm': '2.900000000000000000', 'petallengthcm': '1.400000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '10', 'sepallengthcm': '4.900000000000000000', 'sepalwidthcm': '3.100000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.100000000000000000', 'species': 'Iris-setosa'}, {'id': '11', 'sepallengthcm': '5.400000000000000000', 'sepalwidthcm': '3.700000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '12', 'sepallengthcm': '4.800000000000000000', 'sepalwidthcm': '3.400000000000000000', 'petallengthcm': '1.600000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '13', 'sepallengthcm': '4.800000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '1.400000000000000000', 'petalwidthcm': '0.100000000000000000', 'species': 'Iris-setosa'}, {'id': '14', 'sepallengthcm': '4.300000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '1.100000000000000000', 'petalwidthcm': '0.100000000000000000', 'species': 'Iris-setosa'}, {'id': '15', 'sepallengthcm': '5.800000000000000000', 'sepalwidthcm': '4.000000000000000000', 'petallengthcm': '1.200000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '16', 'sepallengthcm': '5.700000000000000000', 'sepalwidthcm': '4.400000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.400000000000000000', 'species': 'Iris-setosa'}, {'id': '17', 'sepallengthcm': '5.400000000000000000', 'sepalwidthcm': '3.900000000000000000', 'petallengthcm': '1.300000000000000000', 'petalwidthcm': '0.400000000000000000', 'species': 'Iris-setosa'}, {'id': '18', 'sepallengthcm': '5.100000000000000000', 'sepalwidthcm': '3.500000000000000000', 'petallengthcm': '1.400000000000000000', 'petalwidthcm': '0.300000000000000000', 'species': 'Iris-setosa'}, {'id': '19', 'sepallengthcm': '5.700000000000000000', 'sepalwidthcm': '3.800000000000000000', 'petallengthcm': '1.700000000000000000', 'petalwidthcm': '0.300000000000000000', 'species': 'Iris-setosa'}, {'id': '20', 'sepallengthcm': '5.100000000000000000', 'sepalwidthcm': '3.800000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.300000000000000000', 'species': 'Iris-setosa'}, {'id': '21', 'sepallengthcm': '5.400000000000000000', 'sepalwidthcm': '3.400000000000000000', 'petallengthcm': '1.700000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '22', 'sepallengthcm': '5.100000000000000000', 'sepalwidthcm': '3.700000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.400000000000000000', 'species': 'Iris-setosa'}, {'id': '23', 'sepallengthcm': '4.600000000000000000', 'sepalwidthcm': '3.600000000000000000', 'petallengthcm': '1.000000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '24', 'sepallengthcm': '5.100000000000000000', 'sepalwidthcm': '3.300000000000000000', 'petallengthcm': '1.700000000000000000', 'petalwidthcm': '0.500000000000000000', 'species': 'Iris-setosa'}, {'id': '25', 'sepallengthcm': '4.800000000000000000', 'sepalwidthcm': '3.400000000000000000', 'petallengthcm': '1.900000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '26', 'sepallengthcm': '5.000000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '1.600000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '27', 'sepallengthcm': '5.000000000000000000', 'sepalwidthcm': '3.400000000000000000', 'petallengthcm': '1.600000000000000000', 'petalwidthcm': '0.400000000000000000', 'species': 'Iris-setosa'}, {'id': '28', 'sepallengthcm': '5.200000000000000000', 'sepalwidthcm': '3.500000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '29', 'sepallengthcm': '5.200000000000000000', 'sepalwidthcm': '3.400000000000000000', 'petallengthcm': '1.400000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '30', 'sepallengthcm': '4.700000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '1.600000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '31', 'sepallengthcm': '4.800000000000000000', 'sepalwidthcm': '3.100000000000000000', 'petallengthcm': '1.600000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '32', 'sepallengthcm': '5.400000000000000000', 'sepalwidthcm': '3.400000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.400000000000000000', 'species': 'Iris-setosa'}, {'id': '33', 'sepallengthcm': '5.200000000000000000', 'sepalwidthcm': '4.100000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.100000000000000000', 'species': 'Iris-setosa'}, {'id': '34', 'sepallengthcm': '5.500000000000000000', 'sepalwidthcm': '4.200000000000000000', 'petallengthcm': '1.400000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '35', 'sepallengthcm': '4.900000000000000000', 'sepalwidthcm': '3.100000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.100000000000000000', 'species': 'Iris-setosa'}, {'id': '36', 'sepallengthcm': '5.000000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '1.200000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '37', 'sepallengthcm': '5.500000000000000000', 'sepalwidthcm': '3.500000000000000000', 'petallengthcm': '1.300000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '38', 'sepallengthcm': '4.900000000000000000', 'sepalwidthcm': '3.100000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.100000000000000000', 'species': 'Iris-setosa'}, {'id': '39', 'sepallengthcm': '4.400000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '1.300000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '40', 'sepallengthcm': '5.100000000000000000', 'sepalwidthcm': '3.400000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '41', 'sepallengthcm': '5.000000000000000000', 'sepalwidthcm': '3.500000000000000000', 'petallengthcm': '1.300000000000000000', 'petalwidthcm': '0.300000000000000000', 'species': 'Iris-setosa'}, {'id': '42', 'sepallengthcm': '4.500000000000000000', 'sepalwidthcm': '2.300000000000000000', 'petallengthcm': '1.300000000000000000', 'petalwidthcm': '0.300000000000000000', 'species': 'Iris-setosa'}, {'id': '43', 'sepallengthcm': '4.400000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '1.300000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '44', 'sepallengthcm': '5.000000000000000000', 'sepalwidthcm': '3.500000000000000000', 'petallengthcm': '1.600000000000000000', 'petalwidthcm': '0.600000000000000000', 'species': 'Iris-setosa'}, {'id': '45', 'sepallengthcm': '5.100000000000000000', 'sepalwidthcm': '3.800000000000000000', 'petallengthcm': '1.900000000000000000', 'petalwidthcm': '0.400000000000000000', 'species': 'Iris-setosa'}, {'id': '46', 'sepallengthcm': '4.800000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '1.400000000000000000', 'petalwidthcm': '0.300000000000000000', 'species': 'Iris-setosa'}, {'id': '47', 'sepallengthcm': '5.100000000000000000', 'sepalwidthcm': '3.800000000000000000', 'petallengthcm': '1.600000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '48', 'sepallengthcm': '4.600000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '1.400000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '49', 'sepallengthcm': '5.300000000000000000', 'sepalwidthcm': '3.700000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '50', 'sepallengthcm': '5.000000000000000000', 'sepalwidthcm': '3.300000000000000000', 'petallengthcm': '1.400000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '51', 'sepallengthcm': '7.000000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '4.700000000000000000', 'petalwidthcm': '1.400000000000000000', 'species': 'Iris-versicolor'}, {'id': '52', 'sepallengthcm': '6.400000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '4.500000000000000000', 'petalwidthcm': '1.500000000000000000', 'species': 'Iris-versicolor'}, {'id': '53', 'sepallengthcm': '6.900000000000000000', 'sepalwidthcm': '3.100000000000000000', 'petallengthcm': '4.900000000000000000', 'petalwidthcm': '1.500000000000000000', 'species': 'Iris-versicolor'}, {'id': '54', 'sepallengthcm': '5.500000000000000000', 'sepalwidthcm': '2.300000000000000000', 'petallengthcm': '4.000000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '55', 'sepallengthcm': '6.500000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '4.600000000000000000', 'petalwidthcm': '1.500000000000000000', 'species': 'Iris-versicolor'}, {'id': '56', 'sepallengthcm': '5.700000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '4.500000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '57', 'sepallengthcm': '6.300000000000000000', 'sepalwidthcm': '3.300000000000000000', 'petallengthcm': '4.700000000000000000', 'petalwidthcm': '1.600000000000000000', 'species': 'Iris-versicolor'}, {'id': '58', 'sepallengthcm': '4.900000000000000000', 'sepalwidthcm': '2.400000000000000000', 'petallengthcm': '3.300000000000000000', 'petalwidthcm': '1.000000000000000000', 'species': 'Iris-versicolor'}, {'id': '59', 'sepallengthcm': '6.600000000000000000', 'sepalwidthcm': '2.900000000000000000', 'petallengthcm': '4.600000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '60', 'sepallengthcm': '5.200000000000000000', 'sepalwidthcm': '2.700000000000000000', 'petallengthcm': '3.900000000000000000', 'petalwidthcm': '1.400000000000000000', 'species': 'Iris-versicolor'}, {'id': '61', 'sepallengthcm': '5.000000000000000000', 'sepalwidthcm': '2.000000000000000000', 'petallengthcm': '3.500000000000000000', 'petalwidthcm': '1.000000000000000000', 'species': 'Iris-versicolor'}, {'id': '62', 'sepallengthcm': '5.900000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '4.200000000000000000', 'petalwidthcm': '1.500000000000000000', 'species': 'Iris-versicolor'}, {'id': '63', 'sepallengthcm': '6.000000000000000000', 'sepalwidthcm': '2.200000000000000000', 'petallengthcm': '4.000000000000000000', 'petalwidthcm': '1.000000000000000000', 'species': 'Iris-versicolor'}, {'id': '64', 'sepallengthcm': '6.100000000000000000', 'sepalwidthcm': '2.900000000000000000', 'petallengthcm': '4.700000000000000000', 'petalwidthcm': '1.400000000000000000', 'species': 'Iris-versicolor'}, {'id': '65', 'sepallengthcm': '5.600000000000000000', 'sepalwidthcm': '2.900000000000000000', 'petallengthcm': '3.600000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '66', 'sepallengthcm': '6.700000000000000000', 'sepalwidthcm': '3.100000000000000000', 'petallengthcm': '4.400000000000000000', 'petalwidthcm': '1.400000000000000000', 'species': 'Iris-versicolor'}, {'id': '67', 'sepallengthcm': '5.600000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '4.500000000000000000', 'petalwidthcm': '1.500000000000000000', 'species': 'Iris-versicolor'}, {'id': '68', 'sepallengthcm': '5.800000000000000000', 'sepalwidthcm': '2.700000000000000000', 'petallengthcm': '4.100000000000000000', 'petalwidthcm': '1.000000000000000000', 'species': 'Iris-versicolor'}, {'id': '69', 'sepallengthcm': '6.200000000000000000', 'sepalwidthcm': '2.200000000000000000', 'petallengthcm': '4.500000000000000000', 'petalwidthcm': '1.500000000000000000', 'species': 'Iris-versicolor'}, {'id': '70', 'sepallengthcm': '5.600000000000000000', 'sepalwidthcm': '2.500000000000000000', 'petallengthcm': '3.900000000000000000', 'petalwidthcm': '1.100000000000000000', 'species': 'Iris-versicolor'}, {'id': '71', 'sepallengthcm': '5.900000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '4.800000000000000000', 'petalwidthcm': '1.800000000000000000', 'species': 'Iris-versicolor'}, {'id': '72', 'sepallengthcm': '6.100000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '4.000000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '73', 'sepallengthcm': '6.300000000000000000', 'sepalwidthcm': '2.500000000000000000', 'petallengthcm': '4.900000000000000000', 'petalwidthcm': '1.500000000000000000', 'species': 'Iris-versicolor'}, {'id': '74', 'sepallengthcm': '6.100000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '4.700000000000000000', 'petalwidthcm': '1.200000000000000000', 'species': 'Iris-versicolor'}, {'id': '75', 'sepallengthcm': '6.400000000000000000', 'sepalwidthcm': '2.900000000000000000', 'petallengthcm': '4.300000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '76', 'sepallengthcm': '6.600000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '4.400000000000000000', 'petalwidthcm': '1.400000000000000000', 'species': 'Iris-versicolor'}, {'id': '77', 'sepallengthcm': '6.800000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '4.800000000000000000', 'petalwidthcm': '1.400000000000000000', 'species': 'Iris-versicolor'}, {'id': '78', 'sepallengthcm': '6.700000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '5.000000000000000000', 'petalwidthcm': '1.700000000000000000', 'species': 'Iris-versicolor'}, {'id': '79', 'sepallengthcm': '6.000000000000000000', 'sepalwidthcm': '2.900000000000000000', 'petallengthcm': '4.500000000000000000', 'petalwidthcm': '1.500000000000000000', 'species': 'Iris-versicolor'}, {'id': '80', 'sepallengthcm': '5.700000000000000000', 'sepalwidthcm': '2.600000000000000000', 'petallengthcm': '3.500000000000000000', 'petalwidthcm': '1.000000000000000000', 'species': 'Iris-versicolor'}, {'id': '81', 'sepallengthcm': '5.500000000000000000', 'sepalwidthcm': '2.400000000000000000', 'petallengthcm': '3.800000000000000000', 'petalwidthcm': '1.100000000000000000', 'species': 'Iris-versicolor'}, {'id': '82', 'sepallengthcm': '5.500000000000000000', 'sepalwidthcm': '2.400000000000000000', 'petallengthcm': '3.700000000000000000', 'petalwidthcm': '1.000000000000000000', 'species': 'Iris-versicolor'}, {'id': '83', 'sepallengthcm': '5.800000000000000000', 'sepalwidthcm': '2.700000000000000000', 'petallengthcm': '3.900000000000000000', 'petalwidthcm': '1.200000000000000000', 'species': 'Iris-versicolor'}, {'id': '84', 'sepallengthcm': '6.000000000000000000', 'sepalwidthcm': '2.700000000000000000', 'petallengthcm': '5.100000000000000000', 'petalwidthcm': '1.600000000000000000', 'species': 'Iris-versicolor'}, {'id': '85', 'sepallengthcm': '5.400000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '4.500000000000000000', 'petalwidthcm': '1.500000000000000000', 'species': 'Iris-versicolor'}, {'id': '86', 'sepallengthcm': '6.000000000000000000', 'sepalwidthcm': '3.400000000000000000', 'petallengthcm': '4.500000000000000000', 'petalwidthcm': '1.600000000000000000', 'species': 'Iris-versicolor'}, {'id': '87', 'sepallengthcm': '6.700000000000000000', 'sepalwidthcm': '3.100000000000000000', 'petallengthcm': '4.700000000000000000', 'petalwidthcm': '1.500000000000000000', 'species': 'Iris-versicolor'}, {'id': '88', 'sepallengthcm': '6.300000000000000000', 'sepalwidthcm': '2.300000000000000000', 'petallengthcm': '4.400000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '89', 'sepallengthcm': '5.600000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '4.100000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '90', 'sepallengthcm': '5.500000000000000000', 'sepalwidthcm': '2.500000000000000000', 'petallengthcm': '4.000000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '91', 'sepallengthcm': '5.500000000000000000', 'sepalwidthcm': '2.600000000000000000', 'petallengthcm': '4.400000000000000000', 'petalwidthcm': '1.200000000000000000', 'species': 'Iris-versicolor'}, {'id': '92', 'sepallengthcm': '6.100000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '4.600000000000000000', 'petalwidthcm': '1.400000000000000000', 'species': 'Iris-versicolor'}, {'id': '93', 'sepallengthcm': '5.800000000000000000', 'sepalwidthcm': '2.600000000000000000', 'petallengthcm': '4.000000000000000000', 'petalwidthcm': '1.200000000000000000', 'species': 'Iris-versicolor'}, {'id': '94', 'sepallengthcm': '5.000000000000000000', 'sepalwidthcm': '2.300000000000000000', 'petallengthcm': '3.300000000000000000', 'petalwidthcm': '1.000000000000000000', 'species': 'Iris-versicolor'}, {'id': '95', 'sepallengthcm': '5.600000000000000000', 'sepalwidthcm': '2.700000000000000000', 'petallengthcm': '4.200000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '96', 'sepallengthcm': '5.700000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '4.200000000000000000', 'petalwidthcm': '1.200000000000000000', 'species': 'Iris-versicolor'}, {'id': '97', 'sepallengthcm': '5.700000000000000000', 'sepalwidthcm': '2.900000000000000000', 'petallengthcm': '4.200000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '98', 'sepallengthcm': '6.200000000000000000', 'sepalwidthcm': '2.900000000000000000', 'petallengthcm': '4.300000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '99', 'sepallengthcm': '5.100000000000000000', 'sepalwidthcm': '2.500000000000000000', 'petallengthcm': '3.000000000000000000', 'petalwidthcm': '1.100000000000000000', 'species': 'Iris-versicolor'}, {'id': '100', 'sepallengthcm': '5.700000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '4.100000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '101', 'sepallengthcm': '6.300000000000000000', 'sepalwidthcm': '3.300000000000000000', 'petallengthcm': '6.000000000000000000', 'petalwidthcm': '2.500000000000000000', 'species': 'Iris-virginica'}, {'id': '102', 'sepallengthcm': '5.800000000000000000', 'sepalwidthcm': '2.700000000000000000', 'petallengthcm': '5.100000000000000000', 'petalwidthcm': '1.900000000000000000', 'species': 'Iris-virginica'}, {'id': '103', 'sepallengthcm': '7.100000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '5.900000000000000000', 'petalwidthcm': '2.100000000000000000', 'species': 'Iris-virginica'}, {'id': '104', 'sepallengthcm': '6.300000000000000000', 'sepalwidthcm': '2.900000000000000000', 'petallengthcm': '5.600000000000000000', 'petalwidthcm': '1.800000000000000000', 'species': 'Iris-virginica'}, {'id': '105', 'sepallengthcm': '6.500000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '5.800000000000000000', 'petalwidthcm': '2.200000000000000000', 'species': 'Iris-virginica'}, {'id': '106', 'sepallengthcm': '7.600000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '6.600000000000000000', 'petalwidthcm': '2.100000000000000000', 'species': 'Iris-virginica'}, {'id': '107', 'sepallengthcm': '4.900000000000000000', 'sepalwidthcm': '2.500000000000000000', 'petallengthcm': '4.500000000000000000', 'petalwidthcm': '1.700000000000000000', 'species': 'Iris-virginica'}, {'id': '108', 'sepallengthcm': '7.300000000000000000', 'sepalwidthcm': '2.900000000000000000', 'petallengthcm': '6.300000000000000000', 'petalwidthcm': '1.800000000000000000', 'species': 'Iris-virginica'}, {'id': '109', 'sepallengthcm': '6.700000000000000000', 'sepalwidthcm': '2.500000000000000000', 'petallengthcm': '5.800000000000000000', 'petalwidthcm': '1.800000000000000000', 'species': 'Iris-virginica'}, {'id': '110', 'sepallengthcm': '7.200000000000000000', 'sepalwidthcm': '3.600000000000000000', 'petallengthcm': '6.100000000000000000', 'petalwidthcm': '2.500000000000000000', 'species': 'Iris-virginica'}, {'id': '111', 'sepallengthcm': '6.500000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '5.100000000000000000', 'petalwidthcm': '2.000000000000000000', 'species': 'Iris-virginica'}, {'id': '112', 'sepallengthcm': '6.400000000000000000', 'sepalwidthcm': '2.700000000000000000', 'petallengthcm': '5.300000000000000000', 'petalwidthcm': '1.900000000000000000', 'species': 'Iris-virginica'}, {'id': '113', 'sepallengthcm': '6.800000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '5.500000000000000000', 'petalwidthcm': '2.100000000000000000', 'species': 'Iris-virginica'}, {'id': '114', 'sepallengthcm': '5.700000000000000000', 'sepalwidthcm': '2.500000000000000000', 'petallengthcm': '5.000000000000000000', 'petalwidthcm': '2.000000000000000000', 'species': 'Iris-virginica'}, {'id': '115', 'sepallengthcm': '5.800000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '5.100000000000000000', 'petalwidthcm': '2.400000000000000000', 'species': 'Iris-virginica'}, {'id': '116', 'sepallengthcm': '6.400000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '5.300000000000000000', 'petalwidthcm': '2.300000000000000000', 'species': 'Iris-virginica'}, {'id': '117', 'sepallengthcm': '6.500000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '5.500000000000000000', 'petalwidthcm': '1.800000000000000000', 'species': 'Iris-virginica'}, {'id': '118', 'sepallengthcm': '7.700000000000000000', 'sepalwidthcm': '3.800000000000000000', 'petallengthcm': '6.700000000000000000', 'petalwidthcm': '2.200000000000000000', 'species': 'Iris-virginica'}, {'id': '119', 'sepallengthcm': '7.700000000000000000', 'sepalwidthcm': '2.600000000000000000', 'petallengthcm': '6.900000000000000000', 'petalwidthcm': '2.300000000000000000', 'species': 'Iris-virginica'}, {'id': '120', 'sepallengthcm': '6.000000000000000000', 'sepalwidthcm': '2.200000000000000000', 'petallengthcm': '5.000000000000000000', 'petalwidthcm': '1.500000000000000000', 'species': 'Iris-virginica'}, {'id': '121', 'sepallengthcm': '6.900000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '5.700000000000000000', 'petalwidthcm': '2.300000000000000000', 'species': 'Iris-virginica'}, {'id': '122', 'sepallengthcm': '5.600000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '4.900000000000000000', 'petalwidthcm': '2.000000000000000000', 'species': 'Iris-virginica'}, {'id': '123', 'sepallengthcm': '7.700000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '6.700000000000000000', 'petalwidthcm': '2.000000000000000000', 'species': 'Iris-virginica'}, {'id': '124', 'sepallengthcm': '6.300000000000000000', 'sepalwidthcm': '2.700000000000000000', 'petallengthcm': '4.900000000000000000', 'petalwidthcm': '1.800000000000000000', 'species': 'Iris-virginica'}, {'id': '125', 'sepallengthcm': '6.700000000000000000', 'sepalwidthcm': '3.300000000000000000', 'petallengthcm': '5.700000000000000000', 'petalwidthcm': '2.100000000000000000', 'species': 'Iris-virginica'}, {'id': '126', 'sepallengthcm': '7.200000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '6.000000000000000000', 'petalwidthcm': '1.800000000000000000', 'species': 'Iris-virginica'}, {'id': '127', 'sepallengthcm': '6.200000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '4.800000000000000000', 'petalwidthcm': '1.800000000000000000', 'species': 'Iris-virginica'}, {'id': '128', 'sepallengthcm': '6.100000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '4.900000000000000000', 'petalwidthcm': '1.800000000000000000', 'species': 'Iris-virginica'}, {'id': '129', 'sepallengthcm': '6.400000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '5.600000000000000000', 'petalwidthcm': '2.100000000000000000', 'species': 'Iris-virginica'}, {'id': '130', 'sepallengthcm': '7.200000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '5.800000000000000000', 'petalwidthcm': '1.600000000000000000', 'species': 'Iris-virginica'}, {'id': '131', 'sepallengthcm': '7.400000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '6.100000000000000000', 'petalwidthcm': '1.900000000000000000', 'species': 'Iris-virginica'}, {'id': '132', 'sepallengthcm': '7.900000000000000000', 'sepalwidthcm': '3.800000000000000000', 'petallengthcm': '6.400000000000000000', 'petalwidthcm': '2.000000000000000000', 'species': 'Iris-virginica'}, {'id': '133', 'sepallengthcm': '6.400000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '5.600000000000000000', 'petalwidthcm': '2.200000000000000000', 'species': 'Iris-virginica'}, {'id': '134', 'sepallengthcm': '6.300000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '5.100000000000000000', 'petalwidthcm': '1.500000000000000000', 'species': 'Iris-virginica'}, {'id': '135', 'sepallengthcm': '6.100000000000000000', 'sepalwidthcm': '2.600000000000000000', 'petallengthcm': '5.600000000000000000', 'petalwidthcm': '1.400000000000000000', 'species': 'Iris-virginica'}, {'id': '136', 'sepallengthcm': '7.700000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '6.100000000000000000', 'petalwidthcm': '2.300000000000000000', 'species': 'Iris-virginica'}, {'id': '137', 'sepallengthcm': '6.300000000000000000', 'sepalwidthcm': '3.400000000000000000', 'petallengthcm': '5.600000000000000000', 'petalwidthcm': '2.400000000000000000', 'species': 'Iris-virginica'}, {'id': '138', 'sepallengthcm': '6.400000000000000000', 'sepalwidthcm': '3.100000000000000000', 'petallengthcm': '5.500000000000000000', 'petalwidthcm': '1.800000000000000000', 'species': 'Iris-virginica'}, {'id': '139', 'sepallengthcm': '6.000000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '4.800000000000000000', 'petalwidthcm': '1.800000000000000000', 'species': 'Iris-virginica'}, {'id': '140', 'sepallengthcm': '6.900000000000000000', 'sepalwidthcm': '3.100000000000000000', 'petallengthcm': '5.400000000000000000', 'petalwidthcm': '2.100000000000000000', 'species': 'Iris-virginica'}, {'id': '141', 'sepallengthcm': '6.700000000000000000', 'sepalwidthcm': '3.100000000000000000', 'petallengthcm': '5.600000000000000000', 'petalwidthcm': '2.400000000000000000', 'species': 'Iris-virginica'}, {'id': '142', 'sepallengthcm': '6.900000000000000000', 'sepalwidthcm': '3.100000000000000000', 'petallengthcm': '5.100000000000000000', 'petalwidthcm': '2.300000000000000000', 'species': 'Iris-virginica'}, {'id': '143', 'sepallengthcm': '5.800000000000000000', 'sepalwidthcm': '2.700000000000000000', 'petallengthcm': '5.100000000000000000', 'petalwidthcm': '1.900000000000000000', 'species': 'Iris-virginica'}, {'id': '144', 'sepallengthcm': '6.800000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '5.900000000000000000', 'petalwidthcm': '2.300000000000000000', 'species': 'Iris-virginica'}, {'id': '145', 'sepallengthcm': '6.700000000000000000', 'sepalwidthcm': '3.300000000000000000', 'petallengthcm': '5.700000000000000000', 'petalwidthcm': '2.500000000000000000', 'species': 'Iris-virginica'}, {'id': '146', 'sepallengthcm': '6.700000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '5.200000000000000000', 'petalwidthcm': '2.300000000000000000', 'species': 'Iris-virginica'}, {'id': '147', 'sepallengthcm': '6.300000000000000000', 'sepalwidthcm': '2.500000000000000000', 'petallengthcm': '5.000000000000000000', 'petalwidthcm': '1.900000000000000000', 'species': 'Iris-virginica'}, {'id': '148', 'sepallengthcm': '6.500000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '5.200000000000000000', 'petalwidthcm': '2.000000000000000000', 'species': 'Iris-virginica'}, {'id': '149', 'sepallengthcm': '6.200000000000000000', 'sepalwidthcm': '3.400000000000000000', 'petallengthcm': '5.400000000000000000', 'petalwidthcm': '2.300000000000000000', 'species': 'Iris-virginica'}, {'id': '150', 'sepallengthcm': '5.900000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '5.100000000000000000', 'petalwidthcm': '1.800000000000000000', 'species': 'Iris-virginica'}]\n"
     ]
    }
   ],
   "source": [
    "# API endpoint URL\n",
    "API_URL = f\"http://localhost/api/database/{db_id}/table/{selected_table_id}/data?size=100000&page=0\"\n",
    "print(API_URL)\n",
    "auth = (\"reema260995\", \"Toothless!26\")\n",
    "\n",
    "# Define the headers\n",
    "headers = {\n",
    "    \"Accept\": \"application/json\"  # Specify the expected response format\n",
    "}\n",
    "\n",
    "try:\n",
    "    # Send a GET request to the API with the Accept header\n",
    "    response = requests.get(API_URL, headers=headers,auth=auth)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Parse the JSON response\n",
    "        dataset = response.json()\n",
    "        \n",
    "        \n",
    "        print( dataset)\n",
    "    else:\n",
    "        print(f\"Error: Received status code {response.status_code}\")\n",
    "        print(\"Response content:\", response.text)\n",
    "       \n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"Request failed: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09557f94-325c-4bd6-882a-069a9e3c5ecd",
   "metadata": {},
   "source": [
    "replacing dynamic fetching of data When and if DBREPO isnt running (BACKUP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce6e020d-cb80-49ec-8bcc-687b1e08885c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 1. Read the JSON file id the API isnt available this data is saved locally but the data is from the API endpoint\n",
    "# with open(\"iris_data.json\", \"r\") as f:\n",
    "#     dataset = json.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcf2244-14dd-4e3d-b8cf-f7f3ba34f80f",
   "metadata": {},
   "source": [
    "# ============================\n",
    "# üìÇ Setup MLflow\n",
    "# ============================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae32d719-31fc-4ac4-856d-4430a51cd957",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Initializes MLflow tracking with a local SQLite backend.\n",
    "\n",
    "This script:\n",
    "- Ensures a local directory (`mlrunlogs/`) exists for MLflow logs and database.\n",
    "- Sets MLflow's tracking URI to a local SQLite database (`mlflow.db`).\n",
    "- Prompts the user to enter an experiment name; falls back to 'default_experiment' if none is given.\n",
    "- Registers or activates the specified experiment.\n",
    "\n",
    "Useful for local ML experimentation, reproducibility, and metadata tracking\n",
    "without needing a remote MLflow server.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cbe91ec0-6447-4586-b7cc-2c1f74d4218f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter experiment name for MLflow:  eweret\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/29 14:22:42 INFO mlflow.tracking.fluent: Experiment with name 'eweret' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///C:/Users/reema/REPO/notebooks/RQ_notebooks/mlrunlogs/mlflow.db/796588468381089466', creation_time=1751199762799, experiment_id='796588468381089466', last_update_time=1751199762799, lifecycle_stage='active', name='eweret', tags={}>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import mlflow\n",
    "\n",
    "# Ensure tracking directory exists\n",
    "project_dir = os.getcwd()\n",
    "mlrunlogs_dir = os.path.join(project_dir, \"mlrunlogs\")\n",
    "os.makedirs(mlrunlogs_dir, exist_ok=True)\n",
    "\n",
    "# Set MLflow tracking URI (local SQLite backend)\n",
    "mlflow_tracking_path = os.path.join(mlrunlogs_dir, \"mlflow.db\")\n",
    "mlflow.set_tracking_uri(\"mlrunlogs/mlflow.db\")\n",
    "\n",
    "# Prompt for experiment name\n",
    "experiment_name = input(\"Enter experiment name for MLflow: \").strip()\n",
    "if not experiment_name:\n",
    "    experiment_name = \"default_experiment\"\n",
    "    print(\"‚ö†Ô∏è No name entered. Using fallback:\", experiment_name)\n",
    "\n",
    "mlflow.set_experiment(experiment_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2c2c5f-cc36-41a3-9643-83ef95b9f55e",
   "metadata": {},
   "source": [
    "# ============================\n",
    "# üîÑ Git Commit Hash for previous commit for metadata\n",
    "# ============================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6e125f-3104-476a-8157-af335c8d7d84",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Extracts metadata from the latest Git commit in a specified local repository.\n",
    "\n",
    "This function:\n",
    "- Connects to a Git repository at the provided path.\n",
    "- Retrieves metadata from the latest commit, including commit hash, author, time, message, and branch.\n",
    "- Handles detached HEAD states (e.g., in CI/CD or temp checkouts).\n",
    "- Returns placeholder values if the repository is inaccessible or invalid.\n",
    "\n",
    "Useful for:\n",
    "- Logging code version info into ML experiment tracking (e.g., MLflow).\n",
    "- Reproducibility audits.\n",
    "- Attaching Git context to research or development metadata.\n",
    "\n",
    "Returns:\n",
    "    dict: Git metadata fields, or 'not available' if any error occurs.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "838dd233-25dc-4725-974d-4da89c257782",
   "metadata": {},
   "outputs": [],
   "source": [
    "import git\n",
    "import os\n",
    "\n",
    "def get_latest_git_commit(repo_path: str = \"C:/Users/reema/REPO\") -> dict:\n",
    "    \"\"\"\n",
    "    Returns the latest Git commit metadata from the given repo path.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        repo = git.Repo(repo_path)\n",
    "        commit = repo.head.commit\n",
    "        commit_metadata = {\n",
    "            \"git_commit\": commit.hexsha,\n",
    "            \"git_author\": commit.author.name,\n",
    "            \"git_email\": commit.author.email,\n",
    "            \"git_commit_time\": str(commit.committed_datetime),\n",
    "            \"git_message\": commit.message.strip(),\n",
    "            \"git_branch\": repo.active_branch.name if not repo.head.is_detached else \"detached\"\n",
    "        }\n",
    "        return commit_metadata\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[‚ö†Ô∏è Git Error] Could not read Git repo at {repo_path}: {e}\")\n",
    "        return {\n",
    "            \"git_commit\": \"not available\",\n",
    "            \"git_author\": \"not available\",\n",
    "            \"git_email\": \"not available\",\n",
    "            \"git_commit_time\": \"not available\",\n",
    "            \"git_message\": \"not available\",\n",
    "            \"git_branch\": \"not available\"\n",
    "        }\n",
    "\n",
    "# Usage\n",
    "repo_dir = \"C:/Users/reema/REPO\"\n",
    "git_metadata = get_latest_git_commit(repo_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430d15ef-3432-4e45-88fb-b7048a5b10a9",
   "metadata": {},
   "source": [
    "# ============================\n",
    "# Make threadpoolctl safe so MLflow‚Äôs autologger won‚Äôt crash ‚îÄ‚îÄ‚îÄ\n",
    "# ============================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd08ac85-e5a2-4f8b-b4de-cf893d6c2a3e",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Patches `threadpoolctl` to avoid crashes with MLflow autologging,\n",
    "then enables MLflow's automatic logging for supported ML libraries \n",
    "(e.g., scikit-learn, XGBoost, LightGBM, TensorFlow, etc.).\n",
    "\n",
    "This is particularly useful in environments where `threadpoolctl.threadpool_info()` \n",
    "may raise runtime errors (e.g., inside Docker or limited-thread environments).\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9668451f-4352-4bdc-8b6b-bbe49074212a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/29 14:22:43 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
      "2025/06/29 14:22:44 INFO mlflow.tracking.fluent: Autologging successfully enabled for statsmodels.\n"
     ]
    }
   ],
   "source": [
    "# ‚îÄ‚îÄ‚îÄ Patch threadpoolctl if needed to avoid autolog crashes ‚îÄ‚îÄ‚îÄ\n",
    "try:\n",
    "    import threadpoolctl\n",
    "    _original_threadpool_info = threadpoolctl.threadpool_info\n",
    "\n",
    "    def _safe_threadpool_info(*args, **kwargs):\n",
    "        try:\n",
    "            return _original_threadpool_info(*args, **kwargs)\n",
    "        except Exception:\n",
    "            return []\n",
    "\n",
    "    threadpoolctl.threadpool_info = _safe_threadpool_info\n",
    "except ImportError:\n",
    "    pass  # If threadpoolctl isn't installed, we just skip this patch\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Enable MLflow autologging (generic, works with sklearn and more) ‚îÄ‚îÄ‚îÄ\n",
    "import mlflow\n",
    "\n",
    "mlflow.autolog(\n",
    "    log_input_examples=True,\n",
    "    log_model_signatures=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e532d5f6-003c-4897-be80-d668e85ff4e6",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Logs a comprehensive set of metadata to MLflow for an ML experiment run.\n",
    "\n",
    "This function:\n",
    "- Captures model metadata, evaluation metrics, hyperparameters, label encodings.\n",
    "- Logs preprocessing configuration and creates a unique hash for reproducibility.\n",
    "- Tracks the compute environment and Git commit for traceability.\n",
    "- Includes support for FAIR and MLSEA-aligned metadata standards.\n",
    "- Optionally adds previously logged justification tags (e.g., from interactive inputs).\n",
    "\n",
    "Useful for:\n",
    "- ML provenance tracking\n",
    "- Reproducibility and auditability of experiments\n",
    "- Visualizing metadata-rich runs in MLflow dashboards\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b608670-96a5-42b0-b69b-263ac1e452eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import json\n",
    "import platform\n",
    "import psutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from subprocess import check_output, CalledProcessError\n",
    "\n",
    "def log_standard_metadata(\n",
    "    model_name: str,\n",
    "    model,\n",
    "    hyperparams: dict,\n",
    "    acc: float,\n",
    "    prec: float,\n",
    "    rec: float,\n",
    "    f1: float,\n",
    "    auc: float,\n",
    "    label_map: dict,\n",
    "    run_id: str,\n",
    "    test_size: float,\n",
    "    random_state: int,\n",
    "    id_cols: list,\n",
    "    target_col: str,\n",
    "    X,\n",
    "    y,\n",
    "    run_data=None\n",
    "):\n",
    "    # === Experiment Metadata ===\n",
    "    mlflow.set_tag(\"run_id\", run_id)  # [MLflow / DB anchor]\n",
    "    mlflow.set_tag(\"model_name\", model_name)  # [ML Metadata, FAIR]\n",
    "    mlflow.set_tag(\"model_architecture\", model.__class__.__name__)  # [MLSEA]\n",
    "    mlflow.set_tag(\"test_size\", test_size)  # [MLSEA, Reproducibility]\n",
    "    mlflow.set_tag(\"random_state\", random_state)  # [MLSEA, Reproducibility]\n",
    "\n",
    "    # === Evaluation Metrics ===\n",
    "    mlflow.set_tag(\"accuracy\", acc)\n",
    "    mlflow.set_tag(\"precision_macro\", prec)\n",
    "    mlflow.set_tag(\"recall_macro\", rec)\n",
    "    mlflow.set_tag(\"f1_macro\", f1)\n",
    "    mlflow.set_tag(\"roc_auc\", auc)\n",
    "\n",
    "    # === Hyperparameters and Label Encoding ===\n",
    "    mlflow.set_tag(\"hyperparameters\", json.dumps(hyperparams))  # [FAIR, MLSEA]\n",
    "    mlflow.set_tag(\"label_map\", json.dumps(label_map))  # [ML Preprocessing]\n",
    "\n",
    "    # === Preprocessing Snapshot ===\n",
    "    preprocessing_info = {\n",
    "        \"dropped_columns\": id_cols,\n",
    "        \"numeric_columns\": list(X.columns),\n",
    "        \"target_column\": target_col,\n",
    "        \"stratified\": False,\n",
    "        \"coercion_strategy\": \"Numeric cast (auto)\",\n",
    "        \"feature_engineering\": \"None\",\n",
    "        \"missing_value_strategy\": \"None\",\n",
    "        \"outlier_detection\": \"None\",\n",
    "        \"encoding_strategy\": \"LabelEncoder (target only)\",\n",
    "        \"scaling\": \"None\",\n",
    "        \"sampling\": \"None\",\n",
    "        \"feature_selection\": \"None\",\n",
    "        \"train_test_split\": {\"test_size\": test_size, \"random_state\": random_state},\n",
    "        \"imbalance_ratio\": str(dict(zip(*np.unique(y, return_counts=True)))),\n",
    "        \"preprocessing_timestamp\": datetime.now().isoformat()\n",
    "    }\n",
    "    preprocessing_hash = hashlib.sha256(json.dumps(preprocessing_info).encode()).hexdigest()\n",
    "    mlflow.set_tag(\"preprocessing_info\", json.dumps(preprocessing_info))  # [MLSEA]\n",
    "    mlflow.set_tag(\"preprocessing_hash\", preprocessing_hash)\n",
    "\n",
    "    # === Reproducibility ===\n",
    "    mlflow.set_tag(\"model_serialization\", \"pickle\")  # [FAIR, MLSEA]\n",
    "    mlflow.set_tag(\"model_path\", f\"{model_name}.pkl\")\n",
    "\n",
    "    try:\n",
    "        sha = check_output([\"git\", \"rev-parse\", \"HEAD\"], text=True).strip()\n",
    "    except CalledProcessError:\n",
    "        sha = \"unknown\"\n",
    "    mlflow.set_tag(\"git_commit\", sha)\n",
    "\n",
    "    # === Compute Environment ===\n",
    "    compute_env = {\n",
    "        \"os\": f\"{platform.system()} {platform.release()}\",\n",
    "        \"cpu\": platform.processor(),\n",
    "        \"ram_gb\": round(psutil.virtual_memory().total / (1024 ** 3), 2),\n",
    "        \"python_version\": platform.python_version(),\n",
    "        \"sklearn_version\": sklearn.__version__,\n",
    "        \"pandas_version\": pd.__version__,\n",
    "        \"numpy_version\": np.__version__,\n",
    "    }\n",
    "    mlflow.set_tag(\"compute_environment\", json.dumps(compute_env))  # [Reproducibility]\n",
    "\n",
    "    # === Optional: Tag MLflow Justifications (previously logged manually) ===\n",
    "    if run_data:\n",
    "        for key, val in run_data.tags.items():\n",
    "            if key.startswith(\"justification_\"):\n",
    "                mlflow.set_tag(key, val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcddf313-6f86-443a-be51-f8512b943c9e",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Generates a comprehensive reproducibility text log for a machine learning model run.\n",
    "\n",
    "This function:\n",
    "- Compiles metadata including model/dataset identifiers, hyperparameters, evaluation metrics, \n",
    "  Git commit hash, and a structured reproduction guide.\n",
    "- Optionally appends a system architecture description if the file is available.\n",
    "- Saves the log in a YAML-formatted `.txt` file under the `MODEL_PROVENANCE/` directory,\n",
    "  nested by model name.\n",
    "\n",
    "Intended use:\n",
    "- Auditable experiment tracking\n",
    "- Research paper supplementary material\n",
    "- Automated logging in ML pipelines\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "69f000f9-d0b6-41f7-92d3-4b605e4ecaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "def generate_reproducibility_txt_log(\n",
    "    model_name: str,\n",
    "    dataset_name: str,\n",
    "    dataset_version: str,\n",
    "    hyperparams: dict,\n",
    "    metrics: dict,\n",
    "    git_commit: str,\n",
    "    run_id: str,\n",
    "    architecture_file_path: str = \"provenance_architecture_description.txt\"\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Generate a reproducibility log (YAML + architecture) and return the saved path.\n",
    "    This log combines:\n",
    "    - Model and dataset details\n",
    "    - Hyperparameters and evaluation metrics\n",
    "    - Git provenance info\n",
    "    - Reproduction steps\n",
    "    - Provenance architecture description\n",
    "    \"\"\"\n",
    "\n",
    "    def clean_values(d):\n",
    "        \"\"\"Convert numpy floats to native floats.\"\"\"\n",
    "        return {k: float(v) if isinstance(v, (np.float32, np.float64)) else v for k, v in d.items()}\n",
    "\n",
    "    timestamp = datetime.utcnow().strftime(\"%Y-%m-%d %H:%M UTC\")\n",
    "\n",
    "    repro_data = {\n",
    "        \"üìå Model Details\": {\n",
    "            \"Model Name\": model_name,\n",
    "            \"Dataset Name\": dataset_name,\n",
    "            \"Dataset Version\": dataset_version,\n",
    "            \"Run ID\": run_id,\n",
    "            \"Timestamp\": timestamp\n",
    "        },\n",
    "        \"üõ†Ô∏è Hyperparameters\": clean_values(hyperparams),\n",
    "        \"üìà Metrics\": clean_values(metrics),\n",
    "        \"üîó Git Info\": {\n",
    "            \"Commit Hash\": git_commit,\n",
    "            \"Reproduce With\": f\"git checkout {git_commit}\"\n",
    "        },\n",
    "        \"üöÄ Reproduction Guide\": [\n",
    "            \"1. Clone the repo and checkout the commit:\",\n",
    "            f\"   git checkout {git_commit}\",\n",
    "            \"2. Load and preprocess the dataset exactly as during training.\",\n",
    "            \"3. Load the model using MLflow:\",\n",
    "            f\"   mlflow.sklearn.load_model('runs:/{run_id}/model')\",\n",
    "            \"4. Run inference or evaluation using the same pipeline/script.\"\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    # üîê Create and write to output file\n",
    "    save_dir = os.path.join(\"MODEL_PROVENANCE\", model_name)\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    txt_path = os.path.join(save_dir, f\"{model_name}_reproducibility.txt\")\n",
    "\n",
    "    with open(txt_path, \"w\", encoding=\"utf-8\") as repro_file:\n",
    "        yaml.dump(repro_data, repro_file, allow_unicode=True, sort_keys=False, width=100)\n",
    "        repro_file.write(\"\\n\\n\")\n",
    "\n",
    "        if os.path.exists(architecture_file_path):\n",
    "            with open(architecture_file_path, \"r\", encoding=\"utf-8\") as arch_file:\n",
    "                architecture_description = arch_file.read()\n",
    "                repro_file.write(architecture_description)\n",
    "        else:\n",
    "            repro_file.write(\"[‚ö†Ô∏è Missing architecture description file]\\n\")\n",
    "\n",
    "    return txt_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2667134f-e84d-425d-97cf-936344f8a115",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Utility functions for collecting human-in-the-loop justifications during ML experimentation.\n",
    "\n",
    "These functions:\n",
    "- Allow logging of parameter values or decisions via MLflow.\n",
    "- Prompt the user to provide justifications for those values interactively.\n",
    "- Store justifications as MLflow tags prefixed with `justification_`.\n",
    "\n",
    "This supports transparency, documentation, and accountability in model development,\n",
    "especially in research or regulated environments.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a08a1f1-c3a6-45bd-97b1-92e2fade9ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_with_justification(log_func, key: str, value, context: str = \"\"):\n",
    "    \"\"\"\n",
    "    Log a value using the specified MLflow log function (e.g., mlflow.log_param),\n",
    "    then prompt the user for a justification and log it as a tag.\n",
    "    \"\"\"\n",
    "    log_func(key, value)\n",
    "    print(f\"\\nüìù Justification for `{key}` ({context})\")\n",
    "    user_reason = input(\"‚Üí Why did you choose this value? \")\n",
    "    mlflow.set_tag(f\"justification_{key}\", user_reason or \"No justification provided\")\n",
    "\n",
    "def log_justification(key: str, question: str):\n",
    "    \"\"\"\n",
    "    Prompt for a justification only (without logging a value), and log it as a tag.\n",
    "    \"\"\"\n",
    "    print(f\"\\nüìù Justification for `{key}`\")\n",
    "    user_reason = input(f\"‚Üí {question} \")\n",
    "    mlflow.set_tag(f\"justification_{key}\", user_reason or \"No justification provided\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00237086-0d9c-41b2-a780-b2322ecd69fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9058319a-adba-4a6b-93e9-d17080c0594d",
   "metadata": {},
   "source": [
    "# ============================\n",
    "# üöÄ Start MLflow Run \n",
    "# ============================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ef8cdd-ca7f-4c97-8ee7-8cdfb3dd67c3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14c62f08-a116-4060-9689-f69968e9f240",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your role (default: collaborator):  \n",
      "Enter project ID (default: default_project):  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìå Session Metadata:\n",
      "  session_id: 8bcc7998-eab4-4389-92f2-da58da349ff1\n",
      "  username: reema\n",
      "  timestamp_utc: 2025-06-29T12:22:44.560333\n",
      "  hostname: Purplish\n",
      "  platform: Windows\n",
      "  os_version: 10.0.26100\n",
      "  python_version: 3.11.5\n",
      "  role: collaborator\n",
      "  project_id: default_project\n",
      "{'alternateIdentifiers': [],\n",
      " 'citationCount': 23,\n",
      " 'citationsOverTime': [{'total': 5, 'year': '2023'},\n",
      "                       {'total': 11, 'year': '2024'},\n",
      "                       {'total': 7, 'year': '2025'}],\n",
      " 'container': {},\n",
      " 'contentUrl': None,\n",
      " 'contributors': [],\n",
      " 'created': '2023-03-16T12:57:44.000Z',\n",
      " 'creators': [{'affiliation': [],\n",
      "               'name': 'R. A. Fisher',\n",
      "               'nameIdentifiers': []}],\n",
      " 'dates': [{'date': '1936', 'dateType': 'Issued'}],\n",
      " 'descriptions': [],\n",
      " 'doi': '10.24432/c56c76',\n",
      " 'downloadCount': 0,\n",
      " 'downloadsOverTime': [],\n",
      " 'formats': [],\n",
      " 'fundingReferences': [],\n",
      " 'geoLocations': [],\n",
      " 'identifiers': [],\n",
      " 'isActive': True,\n",
      " 'language': None,\n",
      " 'metadataVersion': 1,\n",
      " 'partCount': 0,\n",
      " 'partOfCount': 0,\n",
      " 'prefix': '10.24432',\n",
      " 'publicationYear': 1936,\n",
      " 'published': '1936',\n",
      " 'publisher': 'UCI Machine Learning Repository',\n",
      " 'reason': None,\n",
      " 'referenceCount': 0,\n",
      " 'registered': '2023-03-16T12:57:45.000Z',\n",
      " 'relatedIdentifiers': [],\n",
      " 'relatedItems': [],\n",
      " 'rightsList': [],\n",
      " 'schemaVersion': 'http://datacite.org/schema/kernel-4',\n",
      " 'sizes': [],\n",
      " 'source': 'mds',\n",
      " 'state': 'findable',\n",
      " 'subjects': [],\n",
      " 'suffix': 'c56c76',\n",
      " 'titles': [{'title': 'Iris'}],\n",
      " 'types': {'bibtex': 'misc',\n",
      "           'citeproc': 'dataset',\n",
      "           'resourceTypeGeneral': 'Dataset',\n",
      "           'ris': 'DATA',\n",
      "           'schemaOrg': 'Dataset'},\n",
      " 'updated': '2025-04-18T08:55:20.000Z',\n",
      " 'url': 'https://archive.ics.uci.edu/dataset/53',\n",
      " 'version': None,\n",
      " 'versionCount': 0,\n",
      " 'versionOfCount': 0,\n",
      " 'viewCount': 0,\n",
      " 'viewsOverTime': [],\n",
      " 'xml': 'PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0iVVRGLTgiPz4KPHJlc291cmNlIHhtbG5zPSJodHRwOi8vZGF0YWNpdGUub3JnL3NjaGVtYS9rZXJuZWwtNCIgeG1sbnM6eHNpPSJodHRwOi8vd3d3LnczLm9yZy8yMDAxL1hNTFNjaGVtYS1pbnN0YW5jZSIgeHNpOnNjaGVtYUxvY2F0aW9uPSJodHRwOi8vZGF0YWNpdGUub3JnL3NjaGVtYS9rZXJuZWwtNCAgICAgaHR0cDovL3NjaGVtYS5kYXRhY2l0ZS5vcmcvbWV0YS9rZXJuZWwtNC9tZXRhZGF0YS54c2QiPgogIDxpZGVudGlmaWVyIGlkZW50aWZpZXJUeXBlPSJET0kiPjEwLjI0NDMyL0M1NkM3NjwvaWRlbnRpZmllcj4KICA8Y3JlYXRvcnM+CiAgICA8Y3JlYXRvcj4KICAgICAgPGNyZWF0b3JOYW1lPlIuIEEuIEZpc2hlcjwvY3JlYXRvck5hbWU+CiAgICA8L2NyZWF0b3I+CiAgPC9jcmVhdG9ycz4KICA8dGl0bGVzPgogICAgPHRpdGxlPklyaXM8L3RpdGxlPgogIDwvdGl0bGVzPgogIDxwdWJsaXNoZXI+VUNJIE1hY2hpbmUgTGVhcm5pbmcgUmVwb3NpdG9yeTwvcHVibGlzaGVyPgogIDxwdWJsaWNhdGlvblllYXI+MTkzNjwvcHVibGljYXRpb25ZZWFyPgogIDxyZXNvdXJjZVR5cGUgcmVzb3VyY2VUeXBlR2VuZXJhbD0iRGF0YXNldCIvPgo8L3Jlc291cmNlPg=='}\n",
      "ML_EXP_Shapes: (150, 4) (150,)\n",
      "ML_EXP_Classes: ['Iris-setosa' 'Iris-versicolor' 'Iris-virginica']\n",
      "{'id': 'c94c9774-8407-49fd-b21f-9e6e4af57d3b', 'name': 'Iris_Database', 'description': None, 'tables': [{'id': 'fb2957a5-e083-4faa-b7c6-85ec0978440c', 'name': 'iris_v5', 'alias': None, 'identifiers': [], 'owner': {'id': 'a3359ac4-e205-103f-845c-fd40f2df9b0e', 'username': 'reema260995', 'name': 'Reema  Dass', 'orcid': None, 'qualified_name': 'Reema  Dass ‚Äî @reema260995', 'given_name': 'Reema ', 'family_name': 'Dass'}, 'description': 'iris_v5', 'columns': [{'id': '46fb02e1-bd42-4d83-9b3e-be7914f652fd', 'name': 'Id', 'alias': None, 'size': None, 'd': None, 'mean': 76, 'median': 76, 'concept': None, 'unit': None, 'description': None, 'enums': [], 'sets': [], 'database_id': 'c94c9774-8407-49fd-b21f-9e6e4af57d3b', 'table_id': 'fb2957a5-e083-4faa-b7c6-85ec0978440c', 'ord': 0, 'internal_name': 'id', 'index_length': None, 'length': None, 'type': 'bigint', 'data_length': None, 'max_data_length': None, 'num_rows': None, 'val_min': None, 'val_max': None, 'std_dev': 43, 'is_null_allowed': False}, {'id': '6ffccb90-90cd-4a71-b02b-fc6f33a4ef4b', 'name': 'SepalLengthCm', 'alias': None, 'size': 40, 'd': 20, 'mean': 6, 'median': 6, 'concept': None, 'unit': None, 'description': None, 'enums': [], 'sets': [], 'database_id': 'c94c9774-8407-49fd-b21f-9e6e4af57d3b', 'table_id': 'fb2957a5-e083-4faa-b7c6-85ec0978440c', 'ord': 1, 'internal_name': 'sepallengthcm', 'index_length': None, 'length': None, 'type': 'decimal', 'data_length': None, 'max_data_length': None, 'num_rows': None, 'val_min': None, 'val_max': None, 'std_dev': 1, 'is_null_allowed': False}, {'id': 'cbf2a214-bbcc-4d4e-826b-1a57922b17ed', 'name': 'SepalWidthCm', 'alias': None, 'size': 40, 'd': 20, 'mean': 3, 'median': 3, 'concept': None, 'unit': None, 'description': None, 'enums': [], 'sets': [], 'database_id': 'c94c9774-8407-49fd-b21f-9e6e4af57d3b', 'table_id': 'fb2957a5-e083-4faa-b7c6-85ec0978440c', 'ord': 2, 'internal_name': 'sepalwidthcm', 'index_length': None, 'length': None, 'type': 'decimal', 'data_length': None, 'max_data_length': None, 'num_rows': None, 'val_min': None, 'val_max': None, 'std_dev': 0, 'is_null_allowed': False}, {'id': '7b57f449-510a-45c8-8788-c917b1b4f8c8', 'name': 'PetalLengthCm', 'alias': None, 'size': 40, 'd': 20, 'mean': 4, 'median': 4, 'concept': None, 'unit': None, 'description': None, 'enums': [], 'sets': [], 'database_id': 'c94c9774-8407-49fd-b21f-9e6e4af57d3b', 'table_id': 'fb2957a5-e083-4faa-b7c6-85ec0978440c', 'ord': 3, 'internal_name': 'petallengthcm', 'index_length': None, 'length': None, 'type': 'decimal', 'data_length': None, 'max_data_length': None, 'num_rows': None, 'val_min': None, 'val_max': None, 'std_dev': 2, 'is_null_allowed': False}, {'id': '7fb96208-099f-45f3-a91f-47dcf4716ef1', 'name': 'PetalWidthCm', 'alias': None, 'size': 40, 'd': 20, 'mean': 1, 'median': 1, 'concept': None, 'unit': None, 'description': None, 'enums': [], 'sets': [], 'database_id': 'c94c9774-8407-49fd-b21f-9e6e4af57d3b', 'table_id': 'fb2957a5-e083-4faa-b7c6-85ec0978440c', 'ord': 4, 'internal_name': 'petalwidthcm', 'index_length': None, 'length': None, 'type': 'decimal', 'data_length': None, 'max_data_length': None, 'num_rows': None, 'val_min': None, 'val_max': None, 'std_dev': 1, 'is_null_allowed': False}, {'id': '2fbb30c8-9bf9-4ec4-9fb3-3852568be624', 'name': 'Species', 'alias': None, 'size': 255, 'd': None, 'mean': None, 'median': None, 'concept': None, 'unit': None, 'description': None, 'enums': [], 'sets': [], 'database_id': 'c94c9774-8407-49fd-b21f-9e6e4af57d3b', 'table_id': 'fb2957a5-e083-4faa-b7c6-85ec0978440c', 'ord': 5, 'internal_name': 'species', 'index_length': None, 'length': None, 'type': 'varchar', 'data_length': None, 'max_data_length': None, 'num_rows': None, 'val_min': None, 'val_max': None, 'std_dev': None, 'is_null_allowed': False}], 'constraints': {'uniques': [{'id': 'a237425e-af63-4e0c-9db5-a109e262c441', 'name': 'uk_iris_v5_0', 'table': {'id': 'fb2957a5-e083-4faa-b7c6-85ec0978440c', 'name': 'iris_v5', 'description': 'iris_v5', 'database_id': 'c94c9774-8407-49fd-b21f-9e6e4af57d3b', 'internal_name': 'iris_v5', 'is_versioned': True, 'is_public': True, 'is_schema_public': True, 'owned_by': 'a3359ac4-e205-103f-845c-fd40f2df9b0e'}, 'columns': [{'id': '46fb02e1-bd42-4d83-9b3e-be7914f652fd', 'name': 'Id', 'alias': None, 'database_id': 'c94c9774-8407-49fd-b21f-9e6e4af57d3b', 'table_id': 'fb2957a5-e083-4faa-b7c6-85ec0978440c', 'internal_name': 'id', 'type': 'bigint'}]}], 'checks': [], 'foreign_keys': [], 'primary_key': [{'id': 'db3d7483-5e99-44a1-a7b9-ffa69272b08d', 'table': {'id': 'fb2957a5-e083-4faa-b7c6-85ec0978440c', 'name': 'iris_v5', 'description': 'iris_v5', 'database_id': 'c94c9774-8407-49fd-b21f-9e6e4af57d3b', 'internal_name': 'iris_v5', 'is_versioned': True, 'is_public': True, 'is_schema_public': True, 'owned_by': 'a3359ac4-e205-103f-845c-fd40f2df9b0e'}, 'column': {'id': '46fb02e1-bd42-4d83-9b3e-be7914f652fd', 'name': 'Id', 'alias': None, 'database_id': 'c94c9774-8407-49fd-b21f-9e6e4af57d3b', 'table_id': 'fb2957a5-e083-4faa-b7c6-85ec0978440c', 'internal_name': 'id', 'type': 'bigint'}}]}, 'created': '2025-06-20 09:39:22', 'last_retrieved': None, 'database_id': 'c94c9774-8407-49fd-b21f-9e6e4af57d3b', 'internal_name': 'iris_v5', 'is_versioned': True, 'is_schema_public': True, 'queue_name': 'dbrepo', 'queue_type': 'quorum', 'routing_key': 'dbrepo.c94c9774-8407-49fd-b21f-9e6e4af57d3b.fb2957a5-e083-4faa-b7c6-85ec0978440c', 'is_public': True, 'num_rows': 150, 'data_length': 16384, 'max_data_length': 0, 'avg_row_length': 109}, {'id': 'e241e1ad-cd2d-4550-903b-4af424b196f9', 'name': 'iris_v2', 'alias': None, 'identifiers': [], 'owner': {'id': 'a3359ac4-e205-103f-845c-fd40f2df9b0e', 'username': 'reema260995', 'name': 'Reema  Dass', 'orcid': None, 'qualified_name': 'Reema  Dass ‚Äî @reema260995', 'given_name': 'Reema ', 'family_name': 'Dass'}, 'description': 'iris_v2', 'columns': [{'id': 'cfaae18b-3bfe-41fa-886a-fac0a23db8c5', 'name': 'Id', 'alias': None, 'size': None, 'd': None, 'mean': 51, 'median': 51, 'concept': None, 'unit': None, 'description': None, 'enums': [], 'sets': [], 'database_id': 'c94c9774-8407-49fd-b21f-9e6e4af57d3b', 'table_id': 'e241e1ad-cd2d-4550-903b-4af424b196f9', 'ord': 0, 'internal_name': 'id', 'index_length': None, 'length': None, 'type': 'bigint', 'data_length': None, 'max_data_length': None, 'num_rows': None, 'val_min': None, 'val_max': None, 'std_dev': 29, 'is_null_allowed': False}, {'id': 'eddd7f5a-8ad4-49a7-900e-8eecc592d4d2', 'name': 'SepalLengthCm', 'alias': None, 'size': 40, 'd': 20, 'mean': 5, 'median': 5, 'concept': None, 'unit': None, 'description': None, 'enums': [], 'sets': [], 'database_id': 'c94c9774-8407-49fd-b21f-9e6e4af57d3b', 'table_id': 'e241e1ad-cd2d-4550-903b-4af424b196f9', 'ord': 1, 'internal_name': 'sepallengthcm', 'index_length': None, 'length': None, 'type': 'decimal', 'data_length': None, 'max_data_length': None, 'num_rows': None, 'val_min': None, 'val_max': None, 'std_dev': 1, 'is_null_allowed': False}, {'id': 'ce8a380f-1770-449a-afd2-3564756a0ec3', 'name': 'SepalWidthCm', 'alias': None, 'size': 40, 'd': 20, 'mean': 3, 'median': 3, 'concept': None, 'unit': None, 'description': None, 'enums': [], 'sets': [], 'database_id': 'c94c9774-8407-49fd-b21f-9e6e4af57d3b', 'table_id': 'e241e1ad-cd2d-4550-903b-4af424b196f9', 'ord': 2, 'internal_name': 'sepalwidthcm', 'index_length': None, 'length': None, 'type': 'decimal', 'data_length': None, 'max_data_length': None, 'num_rows': None, 'val_min': None, 'val_max': None, 'std_dev': 0, 'is_null_allowed': False}, {'id': '74f1c6b4-d44f-4648-b649-4257caa0cc02', 'name': 'PetalLengthCm', 'alias': None, 'size': 40, 'd': 20, 'mean': 3, 'median': 3, 'concept': None, 'unit': None, 'description': None, 'enums': [], 'sets': [], 'database_id': 'c94c9774-8407-49fd-b21f-9e6e4af57d3b', 'table_id': 'e241e1ad-cd2d-4550-903b-4af424b196f9', 'ord': 3, 'internal_name': 'petallengthcm', 'index_length': None, 'length': None, 'type': 'decimal', 'data_length': None, 'max_data_length': None, 'num_rows': None, 'val_min': None, 'val_max': None, 'std_dev': 1, 'is_null_allowed': False}, {'id': 'a0a1ed6d-6a34-4880-a13b-d3703f44f9b6', 'name': 'PetalWidthCm', 'alias': None, 'size': 40, 'd': 20, 'mean': 1, 'median': 1, 'concept': None, 'unit': None, 'description': None, 'enums': [], 'sets': [], 'database_id': 'c94c9774-8407-49fd-b21f-9e6e4af57d3b', 'table_id': 'e241e1ad-cd2d-4550-903b-4af424b196f9', 'ord': 4, 'internal_name': 'petalwidthcm', 'index_length': None, 'length': None, 'type': 'decimal', 'data_length': None, 'max_data_length': None, 'num_rows': None, 'val_min': None, 'val_max': None, 'std_dev': 1, 'is_null_allowed': False}, {'id': '3ff2bfe0-85a4-4f3e-a541-cecdb3adf188', 'name': 'Species', 'alias': None, 'size': 255, 'd': None, 'mean': None, 'median': None, 'concept': None, 'unit': None, 'description': None, 'enums': [], 'sets': [], 'database_id': 'c94c9774-8407-49fd-b21f-9e6e4af57d3b', 'table_id': 'e241e1ad-cd2d-4550-903b-4af424b196f9', 'ord': 5, 'internal_name': 'species', 'index_length': None, 'length': None, 'type': 'varchar', 'data_length': None, 'max_data_length': None, 'num_rows': None, 'val_min': None, 'val_max': None, 'std_dev': None, 'is_null_allowed': False}], 'constraints': {'uniques': [{'id': '15fb6214-b616-431f-877c-b9463b573427', 'name': 'uk_iris_v2_0', 'table': {'id': 'e241e1ad-cd2d-4550-903b-4af424b196f9', 'name': 'iris_v2', 'description': 'iris_v2', 'database_id': 'c94c9774-8407-49fd-b21f-9e6e4af57d3b', 'internal_name': 'iris_v2', 'is_versioned': True, 'is_public': True, 'is_schema_public': True, 'owned_by': 'a3359ac4-e205-103f-845c-fd40f2df9b0e'}, 'columns': [{'id': 'cfaae18b-3bfe-41fa-886a-fac0a23db8c5', 'name': 'Id', 'alias': None, 'database_id': 'c94c9774-8407-49fd-b21f-9e6e4af57d3b', 'table_id': 'e241e1ad-cd2d-4550-903b-4af424b196f9', 'internal_name': 'id', 'type': 'bigint'}]}], 'checks': [], 'foreign_keys': [], 'primary_key': [{'id': 'e5d5cb4e-853e-457a-8c45-0cc1b92fcb90', 'table': {'id': 'e241e1ad-cd2d-4550-903b-4af424b196f9', 'name': 'iris_v2', 'description': 'iris_v2', 'database_id': 'c94c9774-8407-49fd-b21f-9e6e4af57d3b', 'internal_name': 'iris_v2', 'is_versioned': True, 'is_public': True, 'is_schema_public': True, 'owned_by': 'a3359ac4-e205-103f-845c-fd40f2df9b0e'}, 'column': {'id': 'cfaae18b-3bfe-41fa-886a-fac0a23db8c5', 'name': 'Id', 'alias': None, 'database_id': 'c94c9774-8407-49fd-b21f-9e6e4af57d3b', 'table_id': 'e241e1ad-cd2d-4550-903b-4af424b196f9', 'internal_name': 'id', 'type': 'bigint'}}]}, 'created': '2025-06-20 09:37:52', 'last_retrieved': None, 'database_id': 'c94c9774-8407-49fd-b21f-9e6e4af57d3b', 'internal_name': 'iris_v2', 'is_versioned': True, 'is_schema_public': True, 'queue_name': 'dbrepo', 'queue_type': 'quorum', 'routing_key': 'dbrepo.c94c9774-8407-49fd-b21f-9e6e4af57d3b.e241e1ad-cd2d-4550-903b-4af424b196f9', 'is_public': True, 'num_rows': 100, 'data_length': 16384, 'max_data_length': 0, 'avg_row_length': 163}, {'id': 'dfe800b3-c959-4943-8643-f3d5b9c8ae10', 'name': 'iris_v3', 'alias': None, 'identifiers': [], 'owner': {'id': 'a3359ac4-e205-103f-845c-fd40f2df9b0e', 'username': 'reema260995', 'name': 'Reema  Dass', 'orcid': None, 'qualified_name': 'Reema  Dass ‚Äî @reema260995', 'given_name': 'Reema ', 'family_name': 'Dass'}, 'description': 'iris_v3', 'columns': [{'id': '0af9c833-be4d-4eb4-9ab7-0a8dfc26085e', 'name': 'Id', 'alias': None, 'size': None, 'd': None, 'mean': 76, 'median': 76, 'concept': None, 'unit': None, 'description': None, 'enums': [], 'sets': [], 'database_id': 'c94c9774-8407-49fd-b21f-9e6e4af57d3b', 'table_id': 'dfe800b3-c959-4943-8643-f3d5b9c8ae10', 'ord': 0, 'internal_name': 'id', 'index_length': None, 'length': None, 'type': 'bigint', 'data_length': None, 'max_data_length': None, 'num_rows': None, 'val_min': None, 'val_max': None, 'std_dev': 43, 'is_null_allowed': False}, {'id': '6c2f6f02-8f36-4274-8b62-cde2b9c5562a', 'name': 'SepalLengthCm', 'alias': None, 'size': 40, 'd': 20, 'mean': 6, 'median': 6, 'concept': None, 'unit': None, 'description': None, 'enums': [], 'sets': [], 'database_id': 'c94c9774-8407-49fd-b21f-9e6e4af57d3b', 'table_id': 'dfe800b3-c959-4943-8643-f3d5b9c8ae10', 'ord': 1, 'internal_name': 'sepallengthcm', 'index_length': None, 'length': None, 'type': 'decimal', 'data_length': None, 'max_data_length': None, 'num_rows': None, 'val_min': None, 'val_max': None, 'std_dev': 1, 'is_null_allowed': False}, {'id': 'c3b64fef-60c5-4057-be43-aa00a6a97efc', 'name': 'SepalWidthCm', 'alias': None, 'size': 40, 'd': 20, 'mean': 3, 'median': 3, 'concept': None, 'unit': None, 'description': None, 'enums': [], 'sets': [], 'database_id': 'c94c9774-8407-49fd-b21f-9e6e4af57d3b', 'table_id': 'dfe800b3-c959-4943-8643-f3d5b9c8ae10', 'ord': 2, 'internal_name': 'sepalwidthcm', 'index_length': None, 'length': None, 'type': 'decimal', 'data_length': None, 'max_data_length': None, 'num_rows': None, 'val_min': None, 'val_max': None, 'std_dev': 0, 'is_null_allowed': False}, {'id': 'c037e324-0d7c-43e9-a089-15a1da093e93', 'name': 'PetalLengthCm', 'alias': None, 'size': 40, 'd': 20, 'mean': 4, 'median': 4, 'concept': None, 'unit': None, 'description': None, 'enums': [], 'sets': [], 'database_id': 'c94c9774-8407-49fd-b21f-9e6e4af57d3b', 'table_id': 'dfe800b3-c959-4943-8643-f3d5b9c8ae10', 'ord': 3, 'internal_name': 'petallengthcm', 'index_length': None, 'length': None, 'type': 'decimal', 'data_length': None, 'max_data_length': None, 'num_rows': None, 'val_min': None, 'val_max': None, 'std_dev': 2, 'is_null_allowed': False}, {'id': '6787eea3-b359-41f7-a02b-8f59b102392f', 'name': 'PetalWidthCm', 'alias': None, 'size': 40, 'd': 20, 'mean': 1, 'median': 1, 'concept': None, 'unit': None, 'description': None, 'enums': [], 'sets': [], 'database_id': 'c94c9774-8407-49fd-b21f-9e6e4af57d3b', 'table_id': 'dfe800b3-c959-4943-8643-f3d5b9c8ae10', 'ord': 4, 'internal_name': 'petalwidthcm', 'index_length': None, 'length': None, 'type': 'decimal', 'data_length': None, 'max_data_length': None, 'num_rows': None, 'val_min': None, 'val_max': None, 'std_dev': 1, 'is_null_allowed': False}, {'id': '327f4be6-609c-4b4c-8b69-17c6d2701f3f', 'name': 'Species', 'alias': None, 'size': 255, 'd': None, 'mean': None, 'median': None, 'concept': None, 'unit': None, 'description': None, 'enums': [], 'sets': [], 'database_id': 'c94c9774-8407-49fd-b21f-9e6e4af57d3b', 'table_id': 'dfe800b3-c959-4943-8643-f3d5b9c8ae10', 'ord': 5, 'internal_name': 'species', 'index_length': None, 'length': None, 'type': 'varchar', 'data_length': None, 'max_data_length': None, 'num_rows': None, 'val_min': None, 'val_max': None, 'std_dev': None, 'is_null_allowed': False}], 'constraints': {'uniques': [{'id': 'ee1e258a-68cd-4941-94e4-d5ee015253b2', 'name': 'uk_iris_v3_0', 'table': {'id': 'dfe800b3-c959-4943-8643-f3d5b9c8ae10', 'name': 'iris_v3', 'description': 'iris_v3', 'database_id': 'c94c9774-8407-49fd-b21f-9e6e4af57d3b', 'internal_name': 'iris_v3', 'is_versioned': True, 'is_public': True, 'is_schema_public': True, 'owned_by': 'a3359ac4-e205-103f-845c-fd40f2df9b0e'}, 'columns': [{'id': '0af9c833-be4d-4eb4-9ab7-0a8dfc26085e', 'name': 'Id', 'alias': None, 'database_id': 'c94c9774-8407-49fd-b21f-9e6e4af57d3b', 'table_id': 'dfe800b3-c959-4943-8643-f3d5b9c8ae10', 'internal_name': 'id', 'type': 'bigint'}]}], 'checks': [], 'foreign_keys': [], 'primary_key': [{'id': '213018d6-da74-45e7-8aad-d2bceed833c6', 'table': {'id': 'dfe800b3-c959-4943-8643-f3d5b9c8ae10', 'name': 'iris_v3', 'description': 'iris_v3', 'database_id': 'c94c9774-8407-49fd-b21f-9e6e4af57d3b', 'internal_name': 'iris_v3', 'is_versioned': True, 'is_public': True, 'is_schema_public': True, 'owned_by': 'a3359ac4-e205-103f-845c-fd40f2df9b0e'}, 'column': {'id': '0af9c833-be4d-4eb4-9ab7-0a8dfc26085e', 'name': 'Id', 'alias': None, 'database_id': 'c94c9774-8407-49fd-b21f-9e6e4af57d3b', 'table_id': 'dfe800b3-c959-4943-8643-f3d5b9c8ae10', 'internal_name': 'id', 'type': 'bigint'}}]}, 'created': '2025-06-20 09:38:18', 'last_retrieved': None, 'database_id': 'c94c9774-8407-49fd-b21f-9e6e4af57d3b', 'internal_name': 'iris_v3', 'is_versioned': True, 'is_schema_public': True, 'queue_name': 'dbrepo', 'queue_type': 'quorum', 'routing_key': 'dbrepo.c94c9774-8407-49fd-b21f-9e6e4af57d3b.dfe800b3-c959-4943-8643-f3d5b9c8ae10', 'is_public': True, 'num_rows': 150, 'data_length': 16384, 'max_data_length': 0, 'avg_row_length': 109}, {'id': '7149decf-e01b-4c96-8569-6d2527a1487a', 'name': 'iris_v4', 'alias': None, 'identifiers': [], 'owner': {'id': 'a3359ac4-e205-103f-845c-fd40f2df9b0e', 'username': 'reema260995', 'name': 'Reema  Dass', 'orcid': None, 'qualified_name': 'Reema  Dass ‚Äî @reema260995', 'given_name': 'Reema ', 'family_name': 'Dass'}, 'description': 'iris_v4', 'columns': [{'id': 'dc1247ce-afab-4312-831b-46cbeef0cf16', 'name': 'Id', 'alias': None, 'size': None, 'd': None, 'mean': 76, 'median': 76, 'concept': None, 'unit': None, 'description': None, 'enums': [], 'sets': [], 'database_id': 'c94c9774-8407-49fd-b21f-9e6e4af57d3b', 'table_id': '7149decf-e01b-4c96-8569-6d2527a1487a', 'ord': 0, 'internal_name': 'id', 'index_length': None, 'length': None, 'type': 'bigint', 'data_length': None, 'max_data_length': None, 'num_rows': None, 'val_min': None, 'val_max': None, 'std_dev': 43, 'is_null_allowed': False}, {'id': 'b83c6e79-5b63-4061-9f0c-7a94b528a324', 'name': 'SepalLengthCm', 'alias': None, 'size': 40, 'd': 20, 'mean': 0, 'median': 0, 'concept': None, 'unit': None, 'description': None, 'enums': [], 'sets': [], 'database_id': 'c94c9774-8407-49fd-b21f-9e6e4af57d3b', 'table_id': '7149decf-e01b-4c96-8569-6d2527a1487a', 'ord': 1, 'internal_name': 'sepallengthcm', 'index_length': None, 'length': None, 'type': 'decimal', 'data_length': None, 'max_data_length': None, 'num_rows': None, 'val_min': None, 'val_max': None, 'std_dev': 0, 'is_null_allowed': False}, {'id': '23caa19f-a602-4f5c-984f-165cd961b416', 'name': 'SepalWidthCm', 'alias': None, 'size': 40, 'd': 20, 'mean': 0, 'median': 0, 'concept': None, 'unit': None, 'description': None, 'enums': [], 'sets': [], 'database_id': 'c94c9774-8407-49fd-b21f-9e6e4af57d3b', 'table_id': '7149decf-e01b-4c96-8569-6d2527a1487a', 'ord': 2, 'internal_name': 'sepalwidthcm', 'index_length': None, 'length': None, 'type': 'decimal', 'data_length': None, 'max_data_length': None, 'num_rows': None, 'val_min': None, 'val_max': None, 'std_dev': 0, 'is_null_allowed': False}, {'id': 'dabd77a4-3aeb-4b3e-8c9f-de620723da65', 'name': 'PetalLengthCm', 'alias': None, 'size': 40, 'd': 20, 'mean': 0, 'median': 0, 'concept': None, 'unit': None, 'description': None, 'enums': [], 'sets': [], 'database_id': 'c94c9774-8407-49fd-b21f-9e6e4af57d3b', 'table_id': '7149decf-e01b-4c96-8569-6d2527a1487a', 'ord': 3, 'internal_name': 'petallengthcm', 'index_length': None, 'length': None, 'type': 'decimal', 'data_length': None, 'max_data_length': None, 'num_rows': None, 'val_min': None, 'val_max': None, 'std_dev': 0, 'is_null_allowed': False}, {'id': '76b46814-7140-47e0-9637-f3dbe8833201', 'name': 'PetalWidthCm', 'alias': None, 'size': 40, 'd': 20, 'mean': 0, 'median': 0, 'concept': None, 'unit': None, 'description': None, 'enums': [], 'sets': [], 'database_id': 'c94c9774-8407-49fd-b21f-9e6e4af57d3b', 'table_id': '7149decf-e01b-4c96-8569-6d2527a1487a', 'ord': 4, 'internal_name': 'petalwidthcm', 'index_length': None, 'length': None, 'type': 'decimal', 'data_length': None, 'max_data_length': None, 'num_rows': None, 'val_min': None, 'val_max': None, 'std_dev': 0, 'is_null_allowed': False}, {'id': 'cd34f235-94a8-4339-9f82-26cb55e75918', 'name': 'Species', 'alias': None, 'size': 255, 'd': None, 'mean': None, 'median': None, 'concept': None, 'unit': None, 'description': None, 'enums': [], 'sets': [], 'database_id': 'c94c9774-8407-49fd-b21f-9e6e4af57d3b', 'table_id': '7149decf-e01b-4c96-8569-6d2527a1487a', 'ord': 5, 'internal_name': 'species', 'index_length': None, 'length': None, 'type': 'varchar', 'data_length': None, 'max_data_length': None, 'num_rows': None, 'val_min': None, 'val_max': None, 'std_dev': None, 'is_null_allowed': False}], 'constraints': {'uniques': [{'id': 'fcc4ea30-21cd-4c76-95a2-667158427132', 'name': 'uk_iris_v4_0', 'table': {'id': '7149decf-e01b-4c96-8569-6d2527a1487a', 'name': 'iris_v4', 'description': 'iris_v4', 'database_id': 'c94c9774-8407-49fd-b21f-9e6e4af57d3b', 'internal_name': 'iris_v4', 'is_versioned': True, 'is_public': True, 'is_schema_public': True, 'owned_by': 'a3359ac4-e205-103f-845c-fd40f2df9b0e'}, 'columns': [{'id': 'dc1247ce-afab-4312-831b-46cbeef0cf16', 'name': 'Id', 'alias': None, 'database_id': 'c94c9774-8407-49fd-b21f-9e6e4af57d3b', 'table_id': '7149decf-e01b-4c96-8569-6d2527a1487a', 'internal_name': 'id', 'type': 'bigint'}]}], 'checks': [], 'foreign_keys': [], 'primary_key': [{'id': 'c734746c-b8b3-4755-9513-fcca376412d6', 'table': {'id': '7149decf-e01b-4c96-8569-6d2527a1487a', 'name': 'iris_v4', 'description': 'iris_v4', 'database_id': 'c94c9774-8407-49fd-b21f-9e6e4af57d3b', 'internal_name': 'iris_v4', 'is_versioned': True, 'is_public': True, 'is_schema_public': True, 'owned_by': 'a3359ac4-e205-103f-845c-fd40f2df9b0e'}, 'column': {'id': 'dc1247ce-afab-4312-831b-46cbeef0cf16', 'name': 'Id', 'alias': None, 'database_id': 'c94c9774-8407-49fd-b21f-9e6e4af57d3b', 'table_id': '7149decf-e01b-4c96-8569-6d2527a1487a', 'internal_name': 'id', 'type': 'bigint'}}]}, 'created': '2025-06-20 09:38:51', 'last_retrieved': None, 'database_id': 'c94c9774-8407-49fd-b21f-9e6e4af57d3b', 'internal_name': 'iris_v4', 'is_versioned': True, 'is_schema_public': True, 'queue_name': 'dbrepo', 'queue_type': 'quorum', 'routing_key': 'dbrepo.c94c9774-8407-49fd-b21f-9e6e4af57d3b.7149decf-e01b-4c96-8569-6d2527a1487a', 'is_public': True, 'num_rows': 150, 'data_length': 16384, 'max_data_length': 0, 'avg_row_length': 109}, {'id': '2adcf367-baec-43eb-8a7c-8340578beb79', 'name': 'iris_v1', 'alias': None, 'identifiers': [], 'owner': {'id': 'a3359ac4-e205-103f-845c-fd40f2df9b0e', 'username': 'reema260995', 'name': 'Reema  Dass', 'orcid': None, 'qualified_name': 'Reema  Dass ‚Äî @reema260995', 'given_name': 'Reema ', 'family_name': 'Dass'}, 'description': 'iris_v1', 'columns': [{'id': '6a00495c-736c-443f-afe2-a6219fc0686a', 'name': 'Id', 'alias': None, 'size': None, 'd': None, 'mean': 76, 'median': 76, 'concept': None, 'unit': None, 'description': None, 'enums': [], 'sets': [], 'database_id': 'c94c9774-8407-49fd-b21f-9e6e4af57d3b', 'table_id': '2adcf367-baec-43eb-8a7c-8340578beb79', 'ord': 0, 'internal_name': 'id', 'index_length': None, 'length': None, 'type': 'bigint', 'data_length': None, 'max_data_length': None, 'num_rows': None, 'val_min': None, 'val_max': None, 'std_dev': 43, 'is_null_allowed': False}, {'id': '4d5cff04-810c-4d84-9108-44509889a7f4', 'name': 'SepalLengthCm', 'alias': None, 'size': 40, 'd': 20, 'mean': 6, 'median': 6, 'concept': None, 'unit': None, 'description': None, 'enums': [], 'sets': [], 'database_id': 'c94c9774-8407-49fd-b21f-9e6e4af57d3b', 'table_id': '2adcf367-baec-43eb-8a7c-8340578beb79', 'ord': 1, 'internal_name': 'sepallengthcm', 'index_length': None, 'length': None, 'type': 'decimal', 'data_length': None, 'max_data_length': None, 'num_rows': None, 'val_min': None, 'val_max': None, 'std_dev': 1, 'is_null_allowed': False}, {'id': '834f0ea6-e191-4272-ad77-162c3eb3ac45', 'name': 'SepalWidthCm', 'alias': None, 'size': 40, 'd': 20, 'mean': 3, 'median': 3, 'concept': None, 'unit': None, 'description': None, 'enums': [], 'sets': [], 'database_id': 'c94c9774-8407-49fd-b21f-9e6e4af57d3b', 'table_id': '2adcf367-baec-43eb-8a7c-8340578beb79', 'ord': 2, 'internal_name': 'sepalwidthcm', 'index_length': None, 'length': None, 'type': 'decimal', 'data_length': None, 'max_data_length': None, 'num_rows': None, 'val_min': None, 'val_max': None, 'std_dev': 0, 'is_null_allowed': False}, {'id': '53d1d896-a7e4-4e18-8f98-2b33815591c3', 'name': 'PetalLengthCm', 'alias': None, 'size': 40, 'd': 20, 'mean': 4, 'median': 4, 'concept': None, 'unit': None, 'description': None, 'enums': [], 'sets': [], 'database_id': 'c94c9774-8407-49fd-b21f-9e6e4af57d3b', 'table_id': '2adcf367-baec-43eb-8a7c-8340578beb79', 'ord': 3, 'internal_name': 'petallengthcm', 'index_length': None, 'length': None, 'type': 'decimal', 'data_length': None, 'max_data_length': None, 'num_rows': None, 'val_min': None, 'val_max': None, 'std_dev': 2, 'is_null_allowed': False}, {'id': 'f9a5813d-6c76-41ce-b595-3c326a61bd7e', 'name': 'PetalWidthCm', 'alias': None, 'size': 40, 'd': 20, 'mean': 1, 'median': 1, 'concept': None, 'unit': None, 'description': None, 'enums': [], 'sets': [], 'database_id': 'c94c9774-8407-49fd-b21f-9e6e4af57d3b', 'table_id': '2adcf367-baec-43eb-8a7c-8340578beb79', 'ord': 4, 'internal_name': 'petalwidthcm', 'index_length': None, 'length': None, 'type': 'decimal', 'data_length': None, 'max_data_length': None, 'num_rows': None, 'val_min': None, 'val_max': None, 'std_dev': 1, 'is_null_allowed': False}, {'id': '0e7eb6df-752a-4162-b7ef-685440d9c233', 'name': 'Species', 'alias': None, 'size': 255, 'd': None, 'mean': None, 'median': None, 'concept': None, 'unit': None, 'description': None, 'enums': [], 'sets': [], 'database_id': 'c94c9774-8407-49fd-b21f-9e6e4af57d3b', 'table_id': '2adcf367-baec-43eb-8a7c-8340578beb79', 'ord': 5, 'internal_name': 'species', 'index_length': None, 'length': None, 'type': 'varchar', 'data_length': None, 'max_data_length': None, 'num_rows': None, 'val_min': None, 'val_max': None, 'std_dev': None, 'is_null_allowed': False}], 'constraints': {'uniques': [{'id': '0b106b85-490d-462a-b785-d26bd3b02ec3', 'name': 'uk_iris_v1_0', 'table': {'id': '2adcf367-baec-43eb-8a7c-8340578beb79', 'name': 'iris_v1', 'description': 'iris_v1', 'database_id': 'c94c9774-8407-49fd-b21f-9e6e4af57d3b', 'internal_name': 'iris_v1', 'is_versioned': True, 'is_public': True, 'is_schema_public': True, 'owned_by': 'a3359ac4-e205-103f-845c-fd40f2df9b0e'}, 'columns': [{'id': '6a00495c-736c-443f-afe2-a6219fc0686a', 'name': 'Id', 'alias': None, 'database_id': 'c94c9774-8407-49fd-b21f-9e6e4af57d3b', 'table_id': '2adcf367-baec-43eb-8a7c-8340578beb79', 'internal_name': 'id', 'type': 'bigint'}]}], 'checks': [], 'foreign_keys': [], 'primary_key': [{'id': '1b18f2ed-2b9a-4618-8ee9-931f1645f1e0', 'table': {'id': '2adcf367-baec-43eb-8a7c-8340578beb79', 'name': 'iris_v1', 'description': 'iris_v1', 'database_id': 'c94c9774-8407-49fd-b21f-9e6e4af57d3b', 'internal_name': 'iris_v1', 'is_versioned': True, 'is_public': True, 'is_schema_public': True, 'owned_by': 'a3359ac4-e205-103f-845c-fd40f2df9b0e'}, 'column': {'id': '6a00495c-736c-443f-afe2-a6219fc0686a', 'name': 'Id', 'alias': None, 'database_id': 'c94c9774-8407-49fd-b21f-9e6e4af57d3b', 'table_id': '2adcf367-baec-43eb-8a7c-8340578beb79', 'internal_name': 'id', 'type': 'bigint'}}]}, 'created': '2025-06-20 09:37:16', 'last_retrieved': None, 'database_id': 'c94c9774-8407-49fd-b21f-9e6e4af57d3b', 'internal_name': 'iris_v1', 'is_versioned': True, 'is_schema_public': True, 'queue_name': 'dbrepo', 'queue_type': 'quorum', 'routing_key': 'dbrepo.c94c9774-8407-49fd-b21f-9e6e4af57d3b.2adcf367-baec-43eb-8a7c-8340578beb79', 'is_public': True, 'num_rows': 150, 'data_length': 16384, 'max_data_length': 0, 'avg_row_length': 109}, {'id': '0a16d4fd-8567-46b8-8f0c-223bfe29f4a1', 'name': 'iris_v0', 'alias': None, 'identifiers': [], 'owner': {'id': 'a3359ac4-e205-103f-845c-fd40f2df9b0e', 'username': 'reema260995', 'name': 'Reema  Dass', 'orcid': None, 'qualified_name': 'Reema  Dass ‚Äî @reema260995', 'given_name': 'Reema ', 'family_name': 'Dass'}, 'description': 'iris_v0', 'columns': [{'id': 'a015f096-f264-485d-81ea-8623c4044d59', 'name': 'Id', 'alias': None, 'size': None, 'd': None, 'mean': 76, 'median': 76, 'concept': None, 'unit': None, 'description': None, 'enums': [], 'sets': [], 'database_id': 'c94c9774-8407-49fd-b21f-9e6e4af57d3b', 'table_id': '0a16d4fd-8567-46b8-8f0c-223bfe29f4a1', 'ord': 0, 'internal_name': 'id', 'index_length': None, 'length': None, 'type': 'bigint', 'data_length': None, 'max_data_length': None, 'num_rows': None, 'val_min': None, 'val_max': None, 'std_dev': 43, 'is_null_allowed': False}, {'id': '370a9447-2195-4942-bde6-ed6e4810d1fd', 'name': 'SepalLengthCm', 'alias': None, 'size': 40, 'd': 20, 'mean': 6, 'median': 6, 'concept': None, 'unit': None, 'description': None, 'enums': [], 'sets': [], 'database_id': 'c94c9774-8407-49fd-b21f-9e6e4af57d3b', 'table_id': '0a16d4fd-8567-46b8-8f0c-223bfe29f4a1', 'ord': 1, 'internal_name': 'sepallengthcm', 'index_length': None, 'length': None, 'type': 'decimal', 'data_length': None, 'max_data_length': None, 'num_rows': None, 'val_min': None, 'val_max': None, 'std_dev': 1, 'is_null_allowed': False}, {'id': '98a6fc4c-693d-4ce5-bcd2-1a3288893cc1', 'name': 'SepalWidthCm', 'alias': None, 'size': 40, 'd': 20, 'mean': 3, 'median': 3, 'concept': None, 'unit': None, 'description': None, 'enums': [], 'sets': [], 'database_id': 'c94c9774-8407-49fd-b21f-9e6e4af57d3b', 'table_id': '0a16d4fd-8567-46b8-8f0c-223bfe29f4a1', 'ord': 2, 'internal_name': 'sepalwidthcm', 'index_length': None, 'length': None, 'type': 'decimal', 'data_length': None, 'max_data_length': None, 'num_rows': None, 'val_min': None, 'val_max': None, 'std_dev': 0, 'is_null_allowed': False}, {'id': '539fecb9-ce22-4ce0-b5ee-a6515b3c47c8', 'name': 'PetalLengthCm', 'alias': None, 'size': 40, 'd': 20, 'mean': 4, 'median': 4, 'concept': None, 'unit': None, 'description': None, 'enums': [], 'sets': [], 'database_id': 'c94c9774-8407-49fd-b21f-9e6e4af57d3b', 'table_id': '0a16d4fd-8567-46b8-8f0c-223bfe29f4a1', 'ord': 3, 'internal_name': 'petallengthcm', 'index_length': None, 'length': None, 'type': 'decimal', 'data_length': None, 'max_data_length': None, 'num_rows': None, 'val_min': None, 'val_max': None, 'std_dev': 2, 'is_null_allowed': False}, {'id': '461a0372-a25f-45a8-8333-e43b2e97f5c5', 'name': 'PetalWidthCm', 'alias': None, 'size': 40, 'd': 20, 'mean': 1, 'median': 1, 'concept': None, 'unit': None, 'description': None, 'enums': [], 'sets': [], 'database_id': 'c94c9774-8407-49fd-b21f-9e6e4af57d3b', 'table_id': '0a16d4fd-8567-46b8-8f0c-223bfe29f4a1', 'ord': 4, 'internal_name': 'petalwidthcm', 'index_length': None, 'length': None, 'type': 'decimal', 'data_length': None, 'max_data_length': None, 'num_rows': None, 'val_min': None, 'val_max': None, 'std_dev': 1, 'is_null_allowed': False}, {'id': '7c166fa5-4643-44fb-84fb-cc6e4532e974', 'name': 'Species', 'alias': None, 'size': 255, 'd': None, 'mean': None, 'median': None, 'concept': None, 'unit': None, 'description': None, 'enums': [], 'sets': [], 'database_id': 'c94c9774-8407-49fd-b21f-9e6e4af57d3b', 'table_id': '0a16d4fd-8567-46b8-8f0c-223bfe29f4a1', 'ord': 5, 'internal_name': 'species', 'index_length': None, 'length': None, 'type': 'varchar', 'data_length': None, 'max_data_length': None, 'num_rows': None, 'val_min': None, 'val_max': None, 'std_dev': None, 'is_null_allowed': False}], 'constraints': {'uniques': [{'id': 'b88aba91-1803-486b-a761-2a840230909d', 'name': 'uk_iris_v0_0', 'table': {'id': '0a16d4fd-8567-46b8-8f0c-223bfe29f4a1', 'name': 'iris_v0', 'description': 'iris_v0', 'database_id': 'c94c9774-8407-49fd-b21f-9e6e4af57d3b', 'internal_name': 'iris_v0', 'is_versioned': True, 'is_public': True, 'is_schema_public': True, 'owned_by': 'a3359ac4-e205-103f-845c-fd40f2df9b0e'}, 'columns': [{'id': 'a015f096-f264-485d-81ea-8623c4044d59', 'name': 'Id', 'alias': None, 'database_id': 'c94c9774-8407-49fd-b21f-9e6e4af57d3b', 'table_id': '0a16d4fd-8567-46b8-8f0c-223bfe29f4a1', 'internal_name': 'id', 'type': 'bigint'}]}], 'checks': [], 'foreign_keys': [], 'primary_key': [{'id': '71d1dffe-efa8-434f-ae55-81c0773b840b', 'table': {'id': '0a16d4fd-8567-46b8-8f0c-223bfe29f4a1', 'name': 'iris_v0', 'description': 'iris_v0', 'database_id': 'c94c9774-8407-49fd-b21f-9e6e4af57d3b', 'internal_name': 'iris_v0', 'is_versioned': True, 'is_public': True, 'is_schema_public': True, 'owned_by': 'a3359ac4-e205-103f-845c-fd40f2df9b0e'}, 'column': {'id': 'a015f096-f264-485d-81ea-8623c4044d59', 'name': 'Id', 'alias': None, 'database_id': 'c94c9774-8407-49fd-b21f-9e6e4af57d3b', 'table_id': '0a16d4fd-8567-46b8-8f0c-223bfe29f4a1', 'internal_name': 'id', 'type': 'bigint'}}]}, 'created': '2025-06-20 09:36:40', 'last_retrieved': None, 'database_id': 'c94c9774-8407-49fd-b21f-9e6e4af57d3b', 'internal_name': 'iris_v0', 'is_versioned': True, 'is_schema_public': True, 'queue_name': 'dbrepo', 'queue_type': 'quorum', 'routing_key': 'dbrepo.c94c9774-8407-49fd-b21f-9e6e4af57d3b.0a16d4fd-8567-46b8-8f0c-223bfe29f4a1', 'is_public': True, 'num_rows': 150, 'data_length': 16384, 'max_data_length': 0, 'avg_row_length': 109}], 'views': [], 'container': {'id': '6cfb3b8e-1792-4e46-871a-f3d103527203', 'name': 'mariadb:11.3.2', 'image': {'id': 'd79cb089-363c-488b-9717-649e44d8fcc5', 'name': 'mariadb', 'version': '11.1.3', 'operators': [{'id': 'b1069fa7-4bb6-11f0-a70f-02d843f83d22', 'value': '!=', 'documentation': 'https://mariadb.com/kb/en/not-equal/', 'display_name': 'Not equal operator'}, {'id': 'b1069994-4bb6-11f0-a70f-02d843f83d22', 'value': '<', 'documentation': 'https://mariadb.com/kb/en/less-than/', 'display_name': 'Less-than operator'}, {'id': 'b1069ac9-4bb6-11f0-a70f-02d843f83d22', 'value': '<=', 'documentation': 'https://mariadb.com/kb/en/less-than-or-equal/', 'display_name': 'Less than or equal operator'}, {'id': 'b10696af-4bb6-11f0-a70f-02d843f83d22', 'value': '<=>', 'documentation': 'https://mariadb.com/kb/en/null-safe-equal/', 'display_name': 'NULL-safe equal operator'}, {'id': 'b10691cf-4bb6-11f0-a70f-02d843f83d22', 'value': '=', 'documentation': 'https://mariadb.com/kb/en/assignment-operators-assignment-operator/', 'display_name': 'Equal operator'}, {'id': 'b1069cc8-4bb6-11f0-a70f-02d843f83d22', 'value': '>', 'documentation': 'https://mariadb.com/kb/en/greater-than/', 'display_name': 'Greater-than operator'}, {'id': 'b1069ddb-4bb6-11f0-a70f-02d843f83d22', 'value': '>=', 'documentation': 'https://mariadb.com/kb/en/greater-than-or-equal/', 'display_name': 'Greater than or equal operator'}, {'id': 'b106a240-4bb6-11f0-a70f-02d843f83d22', 'value': 'IN', 'documentation': 'https://mariadb.com/kb/en/in/', 'display_name': 'IN'}, {'id': 'b106a3db-4bb6-11f0-a70f-02d843f83d22', 'value': 'IS NOT NULL', 'documentation': 'https://mariadb.com/kb/en/is-not-null/', 'display_name': 'IS NOT NULL'}, {'id': 'b106a4db-4bb6-11f0-a70f-02d843f83d22', 'value': 'IS NULL', 'documentation': 'https://mariadb.com/kb/en/is-null/', 'display_name': 'IS NULL'}, {'id': 'b106a08f-4bb6-11f0-a70f-02d843f83d22', 'value': 'LIKE', 'documentation': 'https://mariadb.com/kb/en/like/', 'display_name': 'LIKE'}, {'id': 'b106a305-4bb6-11f0-a70f-02d843f83d22', 'value': 'NOT IN', 'documentation': 'https://mariadb.com/kb/en/not-in/', 'display_name': 'NOT IN'}, {'id': 'b106a16d-4bb6-11f0-a70f-02d843f83d22', 'value': 'NOT LIKE', 'documentation': 'https://mariadb.com/kb/en/not-like/', 'display_name': 'NOT LIKE'}, {'id': 'b106a6ad-4bb6-11f0-a70f-02d843f83d22', 'value': 'NOT REGEXP', 'documentation': 'https://mariadb.com/kb/en/not-regexp/', 'display_name': 'NOT REGEXP'}, {'id': 'b106a5ca-4bb6-11f0-a70f-02d843f83d22', 'value': 'REGEXP', 'documentation': 'https://mariadb.com/kb/en/regexp/', 'display_name': 'REGEXP'}], 'default': False, 'data_types': [{'id': 'b10568ae-4bb6-11f0-a70f-02d843f83d22', 'value': 'bigint', 'documentation': 'https://mariadb.com/kb/en/bigint/', 'display_name': 'BIGINT(size)', 'size_min': 0, 'size_max': None, 'size_default': None, 'size_required': False, 'd_min': None, 'd_max': None, 'd_default': None, 'd_required': None, 'data_hint': None, 'type_hint': None, 'is_quoted': False, 'is_buildable': True}, {'id': 'b105727e-4bb6-11f0-a70f-02d843f83d22', 'value': 'binary', 'documentation': 'https://mariadb.com/kb/en/binary/', 'display_name': 'BINARY(size)', 'size_min': 0, 'size_max': 255, 'size_default': 255, 'size_required': True, 'd_min': None, 'd_max': None, 'd_default': None, 'd_required': None, 'data_hint': None, 'type_hint': 'size in Bytes', 'is_quoted': False, 'is_buildable': True}, {'id': 'b1057528-4bb6-11f0-a70f-02d843f83d22', 'value': 'bit', 'documentation': 'https://mariadb.com/kb/en/bit/', 'display_name': 'BIT(size)', 'size_min': 0, 'size_max': 64, 'size_default': None, 'size_required': False, 'd_min': None, 'd_max': None, 'd_default': None, 'd_required': None, 'data_hint': None, 'type_hint': None, 'is_quoted': False, 'is_buildable': True}, {'id': 'b10576b7-4bb6-11f0-a70f-02d843f83d22', 'value': 'blob', 'documentation': 'https://mariadb.com/kb/en/blob/', 'display_name': 'BLOB(size)', 'size_min': 0, 'size_max': 65535, 'size_default': None, 'size_required': False, 'd_min': None, 'd_max': None, 'd_default': None, 'd_required': None, 'data_hint': None, 'type_hint': 'size in Bytes', 'is_quoted': False, 'is_buildable': False}, {'id': 'b105776e-4bb6-11f0-a70f-02d843f83d22', 'value': 'bool', 'documentation': 'https://mariadb.com/kb/en/bool/', 'display_name': 'BOOL', 'size_min': None, 'size_max': None, 'size_default': None, 'size_required': None, 'd_min': None, 'd_max': None, 'd_default': None, 'd_required': None, 'data_hint': None, 'type_hint': None, 'is_quoted': False, 'is_buildable': True}, {'id': 'b1057809-4bb6-11f0-a70f-02d843f83d22', 'value': 'char', 'documentation': 'https://mariadb.com/kb/en/char/', 'display_name': 'CHAR(size)', 'size_min': 0, 'size_max': 255, 'size_default': 255, 'size_required': False, 'd_min': None, 'd_max': None, 'd_default': None, 'd_required': None, 'data_hint': None, 'type_hint': None, 'is_quoted': False, 'is_buildable': True}, {'id': 'b10578c2-4bb6-11f0-a70f-02d843f83d22', 'value': 'date', 'documentation': 'https://mariadb.com/kb/en/date/', 'display_name': 'DATE', 'size_min': None, 'size_max': None, 'size_default': None, 'size_required': None, 'd_min': None, 'd_max': None, 'd_default': None, 'd_required': None, 'data_hint': 'e.g. YYYY-MM-DD, YY-MM-DD, YYMMDD, YYYY/MM/DD', 'type_hint': 'min. 1000-01-01, max. 9999-12-31', 'is_quoted': True, 'is_buildable': True}, {'id': 'b1057965-4bb6-11f0-a70f-02d843f83d22', 'value': 'datetime', 'documentation': 'https://mariadb.com/kb/en/datetime/', 'display_name': 'DATETIME(fsp)', 'size_min': 0, 'size_max': 6, 'size_default': None, 'size_required': None, 'd_min': None, 'd_max': None, 'd_default': None, 'd_required': None, 'data_hint': 'e.g. YYYY-MM-DD HH:MM:SS, YY-MM-DD HH:MM:SS, YYYYMMDDHHMMSS, YYMMDDHHMMSS, YYYYMMDD, YYMMDD', 'type_hint': 'fsp=microsecond precision, min. 1000-01-01 00:00:00.0, max. 9999-12-31 23:59:59.9', 'is_quoted': True, 'is_buildable': True}, {'id': 'b10579ff-4bb6-11f0-a70f-02d843f83d22', 'value': 'decimal', 'documentation': 'https://mariadb.com/kb/en/decimal/', 'display_name': 'DECIMAL(size, d)', 'size_min': 0, 'size_max': 65, 'size_default': None, 'size_required': False, 'd_min': 0, 'd_max': 38, 'd_default': None, 'd_required': False, 'data_hint': None, 'type_hint': None, 'is_quoted': False, 'is_buildable': True}, {'id': 'b1057a8e-4bb6-11f0-a70f-02d843f83d22', 'value': 'double', 'documentation': 'https://mariadb.com/kb/en/double/', 'display_name': 'DOUBLE(size, d)', 'size_min': None, 'size_max': None, 'size_default': None, 'size_required': False, 'd_min': None, 'd_max': None, 'd_default': None, 'd_required': False, 'data_hint': None, 'type_hint': None, 'is_quoted': False, 'is_buildable': True}, {'id': 'b1057b17-4bb6-11f0-a70f-02d843f83d22', 'value': 'enum', 'documentation': 'https://mariadb.com/kb/en/enum/', 'display_name': 'ENUM(v1,v2,...)', 'size_min': None, 'size_max': None, 'size_default': None, 'size_required': None, 'd_min': None, 'd_max': None, 'd_default': None, 'd_required': None, 'data_hint': 'e.g. value1, value2, ...', 'type_hint': None, 'is_quoted': True, 'is_buildable': True}, {'id': 'b1057b9c-4bb6-11f0-a70f-02d843f83d22', 'value': 'float', 'documentation': 'https://mariadb.com/kb/en/float/', 'display_name': 'FLOAT(size)', 'size_min': None, 'size_max': None, 'size_default': None, 'size_required': False, 'd_min': None, 'd_max': None, 'd_default': None, 'd_required': None, 'data_hint': None, 'type_hint': None, 'is_quoted': False, 'is_buildable': True}, {'id': 'b1057c22-4bb6-11f0-a70f-02d843f83d22', 'value': 'int', 'documentation': 'https://mariadb.com/kb/en/int/', 'display_name': 'INT(size)', 'size_min': None, 'size_max': None, 'size_default': None, 'size_required': False, 'd_min': None, 'd_max': None, 'd_default': None, 'd_required': None, 'data_hint': None, 'type_hint': 'size in Bytes', 'is_quoted': False, 'is_buildable': True}, {'id': 'b1057ca6-4bb6-11f0-a70f-02d843f83d22', 'value': 'longblob', 'documentation': 'https://mariadb.com/kb/en/longblob/', 'display_name': 'LONGBLOB', 'size_min': None, 'size_max': None, 'size_default': None, 'size_required': None, 'd_min': None, 'd_max': None, 'd_default': None, 'd_required': None, 'data_hint': None, 'type_hint': 'max. 3.999 GiB', 'is_quoted': False, 'is_buildable': True}, {'id': 'b1057d31-4bb6-11f0-a70f-02d843f83d22', 'value': 'longtext', 'documentation': 'https://mariadb.com/kb/en/longtext/', 'display_name': 'LONGTEXT', 'size_min': None, 'size_max': None, 'size_default': None, 'size_required': None, 'd_min': None, 'd_max': None, 'd_default': None, 'd_required': None, 'data_hint': None, 'type_hint': 'max. 3.999 GiB', 'is_quoted': True, 'is_buildable': True}, {'id': 'b1057db7-4bb6-11f0-a70f-02d843f83d22', 'value': 'mediumblob', 'documentation': 'https://mariadb.com/kb/en/mediumblob/', 'display_name': 'MEDIUMBLOB', 'size_min': None, 'size_max': None, 'size_default': None, 'size_required': None, 'd_min': None, 'd_max': None, 'd_default': None, 'd_required': None, 'data_hint': None, 'type_hint': 'max. 15.999 MiB', 'is_quoted': False, 'is_buildable': True}, {'id': 'b1057e3c-4bb6-11f0-a70f-02d843f83d22', 'value': 'mediumint', 'documentation': 'https://mariadb.com/kb/en/mediumint/', 'display_name': 'MEDIUMINT', 'size_min': None, 'size_max': None, 'size_default': None, 'size_required': None, 'd_min': None, 'd_max': None, 'd_default': None, 'd_required': None, 'data_hint': None, 'type_hint': 'size in Bytes', 'is_quoted': False, 'is_buildable': True}, {'id': 'b1057ebc-4bb6-11f0-a70f-02d843f83d22', 'value': 'mediumtext', 'documentation': 'https://mariadb.com/kb/en/mediumtext/', 'display_name': 'MEDIUMTEXT', 'size_min': None, 'size_max': None, 'size_default': None, 'size_required': None, 'd_min': None, 'd_max': None, 'd_default': None, 'd_required': None, 'data_hint': None, 'type_hint': 'size in Bytes', 'is_quoted': True, 'is_buildable': True}, {'id': 'b1057f3a-4bb6-11f0-a70f-02d843f83d22', 'value': 'serial', 'documentation': 'https://mariadb.com/kb/en/bigint/', 'display_name': 'SERIAL', 'size_min': None, 'size_max': None, 'size_default': None, 'size_required': None, 'd_min': None, 'd_max': None, 'd_default': None, 'd_required': None, 'data_hint': None, 'type_hint': None, 'is_quoted': True, 'is_buildable': True}, {'id': 'b1057fca-4bb6-11f0-a70f-02d843f83d22', 'value': 'set', 'documentation': 'https://mariadb.com/kb/en/set/', 'display_name': 'SET(v1,v2,...)', 'size_min': None, 'size_max': None, 'size_default': None, 'size_required': None, 'd_min': None, 'd_max': None, 'd_default': None, 'd_required': None, 'data_hint': 'e.g. value1, value2, ...', 'type_hint': None, 'is_quoted': True, 'is_buildable': True}, {'id': 'b1058057-4bb6-11f0-a70f-02d843f83d22', 'value': 'smallint', 'documentation': 'https://mariadb.com/kb/en/smallint/', 'display_name': 'SMALLINT(size)', 'size_min': 0, 'size_max': None, 'size_default': None, 'size_required': False, 'd_min': None, 'd_max': None, 'd_default': None, 'd_required': None, 'data_hint': None, 'type_hint': 'size in Bytes', 'is_quoted': False, 'is_buildable': True}, {'id': 'b10580dc-4bb6-11f0-a70f-02d843f83d22', 'value': 'text', 'documentation': 'https://mariadb.com/kb/en/text/', 'display_name': 'TEXT(size)', 'size_min': 0, 'size_max': None, 'size_default': None, 'size_required': False, 'd_min': None, 'd_max': None, 'd_default': None, 'd_required': None, 'data_hint': None, 'type_hint': 'size in Bytes', 'is_quoted': True, 'is_buildable': True}, {'id': 'b105815b-4bb6-11f0-a70f-02d843f83d22', 'value': 'time', 'documentation': 'https://mariadb.com/kb/en/time/', 'display_name': 'TIME(fsp)', 'size_min': 0, 'size_max': 6, 'size_default': 0, 'size_required': False, 'd_min': None, 'd_max': None, 'd_default': None, 'd_required': None, 'data_hint': 'e.g. HH:MM:SS, HH:MM, HHMMSS, H:M:S', 'type_hint': 'fsp=microsecond precision, min. 0, max. 6', 'is_quoted': True, 'is_buildable': True}, {'id': 'b10581e3-4bb6-11f0-a70f-02d843f83d22', 'value': 'timestamp', 'documentation': 'https://mariadb.com/kb/en/timestamp/', 'display_name': 'TIMESTAMP(fsp)', 'size_min': 0, 'size_max': 6, 'size_default': 0, 'size_required': False, 'd_min': None, 'd_max': None, 'd_default': None, 'd_required': None, 'data_hint': 'e.g. YYYY-MM-DD HH:MM:SS, YY-MM-DD HH:MM:SS, YYYYMMDDHHMMSS, YYMMDDHHMMSS, YYYYMMDD, YYMMDD', 'type_hint': 'fsp=microsecond precision, min. 0, max. 6', 'is_quoted': True, 'is_buildable': True}, {'id': 'b105826b-4bb6-11f0-a70f-02d843f83d22', 'value': 'tinyblob', 'documentation': 'https://mariadb.com/kb/en/timestamp/', 'display_name': 'TINYBLOB', 'size_min': None, 'size_max': None, 'size_default': None, 'size_required': None, 'd_min': None, 'd_max': None, 'd_default': None, 'd_required': None, 'data_hint': 'fsp=microsecond precision, min. 0, max. 6', 'type_hint': None, 'is_quoted': False, 'is_buildable': True}, {'id': 'b10582ec-4bb6-11f0-a70f-02d843f83d22', 'value': 'tinyint', 'documentation': 'https://mariadb.com/kb/en/tinyint/', 'display_name': 'TINYINT(size)', 'size_min': 0, 'size_max': None, 'size_default': None, 'size_required': False, 'd_min': None, 'd_max': None, 'd_default': None, 'd_required': None, 'data_hint': 'size in Bytes', 'type_hint': None, 'is_quoted': False, 'is_buildable': True}, {'id': 'b105836e-4bb6-11f0-a70f-02d843f83d22', 'value': 'tinytext', 'documentation': 'https://mariadb.com/kb/en/tinytext/', 'display_name': 'TINYTEXT', 'size_min': None, 'size_max': None, 'size_default': None, 'size_required': None, 'd_min': None, 'd_max': None, 'd_default': None, 'd_required': None, 'data_hint': 'max. 255 characters', 'type_hint': None, 'is_quoted': True, 'is_buildable': True}, {'id': 'b10583ed-4bb6-11f0-a70f-02d843f83d22', 'value': 'year', 'documentation': 'https://mariadb.com/kb/en/year/', 'display_name': 'YEAR', 'size_min': 2, 'size_max': 4, 'size_default': None, 'size_required': False, 'd_min': None, 'd_max': None, 'd_default': None, 'd_required': None, 'data_hint': 'e.g. YYYY, YY', 'type_hint': 'min. 1901, max. 2155', 'is_quoted': False, 'is_buildable': True}, {'id': 'b10584f4-4bb6-11f0-a70f-02d843f83d22', 'value': 'varbinary', 'documentation': 'https://mariadb.com/kb/en/varbinary/', 'display_name': 'VARBINARY(size)', 'size_min': 0, 'size_max': None, 'size_default': None, 'size_required': True, 'd_min': None, 'd_max': None, 'd_default': None, 'd_required': None, 'data_hint': None, 'type_hint': None, 'is_quoted': False, 'is_buildable': True}, {'id': 'b1058596-4bb6-11f0-a70f-02d843f83d22', 'value': 'varchar', 'documentation': 'https://mariadb.com/kb/en/varchar/', 'display_name': 'VARCHAR(size)', 'size_min': 0, 'size_max': 65532, 'size_default': 255, 'size_required': True, 'd_min': None, 'd_max': None, 'd_default': None, 'd_required': None, 'data_hint': None, 'type_hint': None, 'is_quoted': False, 'is_buildable': True}]}, 'quota': None, 'count': None, 'username': None, 'password': None, 'last_retrieved': None, 'internal_name': 'mariadb_11_3_2'}, 'accesses': [], 'identifiers': [], 'subsets': [], 'contact': {'id': 'a3359ac4-e205-103f-845c-fd40f2df9b0e', 'username': 'reema260995', 'name': 'Reema  Dass', 'orcid': None, 'qualified_name': 'Reema  Dass ‚Äî @reema260995', 'given_name': 'Reema ', 'family_name': 'Dass'}, 'owner': {'id': 'a3359ac4-e205-103f-845c-fd40f2df9b0e', 'username': 'reema260995', 'name': 'Reema  Dass', 'orcid': None, 'qualified_name': 'Reema  Dass ‚Äî @reema260995', 'given_name': 'Reema ', 'family_name': 'Dass'}, 'created': '2025-06-20 09:36:05', 'last_retrieved': None, 'dashboard_uid': 'fepikz06lebr4a', 'exchange_name': 'dbrepo', 'exchange_type': None, 'internal_name': 'iris_database_xlrb', 'is_public': True, 'is_schema_public': True, 'is_dashboard_enabled': True, 'preview_image': None}\n",
      "[{'timestamp': '2025-06-20T09:37:21.384Z', 'event': 'insert', 'total': 150}]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter test size (e.g., 0.2 for 20% test set):  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid input. Defaulting to 0.2\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter random seed (e.g., 42):  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid input. Defaulting to 42\n",
      "Choose a model to train:\n",
      "1. random_forest\n",
      "2. decision_tree\n",
      "3. logistic_regression\n",
      "4. knn\n",
      "5. svm\n",
      "6. gradient_boosting\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter model number (default 1 for random_forest):  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìù Justification for `n_estimators` (Hyperparameter configuration)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "‚Üí Why did you choose this value?  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìù Justification for `criterion` (Hyperparameter configuration)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "‚Üí Why did you choose this value?  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìù Justification for `max_depth` (Hyperparameter configuration)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "‚Üí Why did you choose this value?  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìù Justification for `min_samples_split` (Hyperparameter configuration)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "‚Üí Why did you choose this value?  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìù Justification for `min_samples_leaf` (Hyperparameter configuration)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "‚Üí Why did you choose this value?  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìù Justification for `max_features` (Hyperparameter configuration)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "‚Üí Why did you choose this value?  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìù Justification for `bootstrap` (Hyperparameter configuration)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "‚Üí Why did you choose this value?  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìù Justification for `oob_score` (Hyperparameter configuration)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "‚Üí Why did you choose this value?  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìù Justification for `class_weight` (Hyperparameter configuration)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "‚Üí Why did you choose this value?  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìù Justification for `verbose` (Hyperparameter configuration)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "‚Üí Why did you choose this value?  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìù Justification for `n_jobs` (Hyperparameter configuration)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "‚Üí Why did you choose this value?  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbeb77019cde45f2b79834604ac3071c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìù Justification for `model_choice`\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "‚Üí Why did you choose this model (e.g., RandomForestClassifier) for this task?  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìù Justification for `target_variable`\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "‚Üí Why did you choose this column as the prediction target?  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìù Justification for `test_split`\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "‚Üí Why this train/test ratio (e.g., 80/20)?  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìù Justification for `metric_choice`\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "‚Üí Why did you use accuracy/f1/ROC-AUC as your evaluation metric?  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìù Justification for `threshold_accuracy`\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "‚Üí Was there a threshold for accuracy? Why?  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìù Justification for `dataset_version`\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "‚Üí Why did you use this specific dataset version?  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìù Justification for `drop_column_X`\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "‚Üí Why did you drop any specific columns from the dataset?  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìù Justification for `experiment_name`\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "‚Üí Any context behind this experiment name or setup?  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìù Justification for `model_limitations`\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "‚Üí Any known model limitations?  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìù Justification for `ethical_considerations`\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "‚Üí Any known model ethical considerations?  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìù Justification for `intended_use`\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "‚Üí Known model intended use?  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìù Justification for `not_intended_for`\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "‚Üí Model not_intended_for?  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\reema\\anaconda3\\Lib\\site-packages\\shap\\plots\\_beeswarm.py:1153: UserWarning: The figure layout has changed to tight\n",
      "  pl.tight_layout()\n",
      "C:\\Users\\reema\\anaconda3\\Lib\\site-packages\\shap\\plots\\_beeswarm.py:761: UserWarning: The figure layout has changed to tight\n",
      "  pl.tight_layout(pad=0, w_pad=0, h_pad=0.0)\n",
      "C:\\Users\\reema\\AppData\\Local\\Temp\\ipykernel_24640\\626432404.py:332: UserWarning: The figure layout has changed to tight\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Commit successful.\n",
      "üöÄ Push successful.\n",
      "‚ö†Ô∏è Commit 67e97344 is not tagged with a version.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "üîñ Enter version tag for this commit (or press Enter to skip):  v67\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Logged tag: DOI_dataset_id\n",
      "‚úÖ Logged tag: DOI_dataset_title\n",
      "‚úÖ Logged tag: DOI_dataset_creator\n",
      "‚úÖ Logged tag: DOI_dataset_publisher\n",
      "‚úÖ Logged tag: DOI_dataset_publication_date\n",
      "‚úÖ Logged tag: DOI_dataset_description\n",
      "‚úÖ Logged tag: DOI_dataset_license\n",
      "‚úÖ Logged tag: DOI_dataset_subjects\n",
      "‚úÖ Logged tag: DOI_dataset_access_url\n",
      "‚úÖ Logged tag: DOI_dataset_documentation\n",
      "‚úÖ Logged tag: DOI_metadata_standard\n",
      "‚úÖ Logged tag: DOI_related_resources\n",
      "‚úÖ Logged tag: DOI_citation_count\n",
      "‚úÖ Logged tag: DOI_citations_over_time\n",
      "‚úÖ Logged tag: DOI_schema_version\n",
      "‚úÖ Logged tag: DOI_registered_date\n",
      "‚úÖ Logged tag: DOI_created\n",
      "‚úÖ Logged tag: DOI_updated\n",
      "‚úÖ Logged tag: DOI_prov_entity\n",
      "‚úÖ Logged tag: DOI_prov_activity\n",
      "‚úÖ Logged tag: DOI_prov_agent_dataset_creator\n",
      "‚úÖ Logged tag: DOI_prov_used\n",
      "‚úÖ Logged tag: DOI_prov_wasDerivedFrom\n",
      "‚úÖ Logged tag: DOI_prov_wasAttributedTo\n",
      "‚úÖ Logged tag: DOI_prov_startedAtTime\n",
      "‚úÖ Logged tag: DOI_prov_role_dataset_creator\n",
      "‚úÖ Logged tag: DOI_prov_role_database_creator\n",
      "üìÅ Full metadata snapshot logged as: doi_metadata_snapshot.json\n",
      "üìÅ Run summary JSON logged at: C:\\Users\\reema\\REPO\\notebooks\\RQ_notebooks\\MODEL_PROVENANCE\\RandomForest_Iris_v20250629_142249\\RandomForest_Iris_v20250629_142249_run_summary.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import hashlib\n",
    "from datetime import datetime\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "    client = MlflowClient()\n",
    "    run_data = client.get_run(run.info.run_id).data\n",
    "    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Session Metadata ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    session_metadata = collect_session_metadata(prompt_fields=True)\n",
    "    mlflow.log_params(session_metadata)  # [PROV, Internal] Session and environment context\n",
    "\n",
    "    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Dataset Metadata ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    doi_metadata = extract_dataset_metadata_from_doi(\"10.24432/C56C76\")  # [FAIR, PROV, FAIR4ML]\n",
    "\n",
    "    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Experiment Start Time ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    start_time = datetime.now().isoformat()\n",
    "    mlflow.set_tag(\"startedAtTime\", start_time)  # [PROV] Activity start time\n",
    "\n",
    "    #######################################################################\n",
    "    ### Preprocessing #####################################################\n",
    "\n",
    "    # ‚îÄ‚îÄ Load into a DataFrame ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    df = pd.DataFrame(dataset)\n",
    "    original_row_count = df.shape[0]\n",
    "    mlflow.log_param(\"input_row_count\", original_row_count)  # [MLSEA] Input data size\n",
    "\n",
    "    # Log column names before transformation\n",
    "    mlflow.set_tag(\"raw_columns\", ','.join(df.columns))  # [FAIR4ML, Internal]\n",
    "\n",
    "    # ‚îÄ‚îÄ Generate row hashes ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    before_hashes = set(df.astype(str).apply(lambda row: hash(tuple(row)), axis=1))\n",
    "    mlflow.set_tag(\"row_hash_tracking\", \"enabled\")  # [Internal] Used for provenance/repeatability\n",
    "\n",
    "    # ‚îÄ‚îÄ Extract target variable ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    target_col = df.columns[-1]\n",
    "    mlflow.set_tag(\"target_variable\", target_col)  # [FAIR4ML, MLSEA]\n",
    "\n",
    "    # ‚îÄ‚îÄ Separate features and labels ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    y = df[target_col]\n",
    "    X = df.drop(columns=[target_col])\n",
    "    mlflow.set_tag(\"feature_columns\", ','.join(X.columns))  # [FAIR4ML, MLSEA]\n",
    "\n",
    "    # ‚îÄ‚îÄ Drop ID columns (case-insensitive) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    id_cols = [c for c in X.columns if c.lower() == \"id\"]\n",
    "    if id_cols:\n",
    "        X = X.drop(columns=id_cols)\n",
    "        mlflow.set_tag(\"dropped_id_columns\", ','.join(id_cols))  # [Internal]\n",
    "\n",
    "    # ‚îÄ‚îÄ Convert columns to numeric where possible ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    numeric_conversion_count = 0\n",
    "    for c in X.columns:\n",
    "        try:\n",
    "            X[c] = pd.to_numeric(X[c])\n",
    "            numeric_conversion_count += 1\n",
    "        except Exception:\n",
    "            continue\n",
    "    mlflow.log_param(\"numeric_columns_converted\", numeric_conversion_count)  # [Internal, FAIR4ML]\n",
    "\n",
    "    # ‚îÄ‚îÄ Print diagnostic info ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    print(\"ML_EXP_Shapes:\", X.shape, y.shape)\n",
    "    mlflow.log_param(\"feature_matrix_shape\", str(X.shape))  # [MLSEA]\n",
    "    mlflow.log_param(\"label_vector_shape\", str(y.shape))    # [MLSEA]\n",
    "#######################################################################################################\n",
    "### 8) Label Encoding and Metadata Logging ############################################################\n",
    "\n",
    "# ‚îÄ‚îÄ Encode class labels numerically ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(y)\n",
    "    print(\"ML_EXP_Classes:\", le.classes_)\n",
    "    \n",
    "    mlflow.set_tag(\"class_names\", ','.join(le.classes_))  # [FAIR4ML, MLSEA]\n",
    "    \n",
    "    # ‚îÄ‚îÄ Count rows and hash comparison before vs after preprocessing ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    count_end = df.shape[0]\n",
    "    after_hashes = set(df.astype(str).apply(lambda row: hash(tuple(row)), axis=1))\n",
    "    \n",
    "    n_insert = len(after_hashes - before_hashes)\n",
    "    n_delete = len(before_hashes - after_hashes)\n",
    "    \n",
    "    #######################################################################################################\n",
    "    ### Metadata Logging (Standardized Format) ############################################################\n",
    "    \n",
    "    # ‚îÄ‚îÄ Extended DB Metadata ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    db_meta = fetch_db_dataset_metadata(db_id, selected_table_id, selected_version, target_col, df.shape[0])  # [Internal]\n",
    "    \n",
    "    mlflow.set_tag(\"Internal_DBRepo_table_last_modified\", db_meta.get(\"dataset_publication_date\", \"unknown\"))\n",
    "  # [PROV]\n",
    "    \n",
    "    # ‚îÄ‚îÄ Row Count Metrics ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    mlflow.log_metric(\"row_count_start\", original_row_count)              # [MLSEA, FAIR4ML]\n",
    "    mlflow.log_metric(\"row_count_end\", count_end)                  # [MLSEA, FAIR4ML]\n",
    "    mlflow.log_metric(\"num_inserted_rows\", n_insert)               # [PROV]\n",
    "    mlflow.log_metric(\"num_deleted_rows\", n_delete)                # [PROV]\n",
    "    \n",
    "    # ‚îÄ‚îÄ Raw Data Source Metadata ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    mlflow.set_tag(\"data_source\", API_URL)                         # [FAIR]\n",
    "    mlflow.log_param(\"retrieval_time_utc\", datetime.utcnow().isoformat())  # [PROV]\n",
    "    mlflow.log_param(\"raw_row_count\", len(df))                     # [MLSEA]\n",
    "    mlflow.log_param(\"raw_columns\", df.columns.tolist())           # [FAIR4ML]\n",
    "    mlflow.log_param(\"dropped_columns\", id_cols)                   # [Internal]\n",
    "    \n",
    "    # ‚îÄ‚îÄ Post-Processing Metadata ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    mlflow.log_param(\"final_num_features\", X.shape[1])             # [MLSEA]\n",
    "    mlflow.log_param(\"final_feature_names\", X.columns.tolist())    # [FAIR4ML]\n",
    "    mlflow.set_tag(\"target_variable_encoded\", target_col)          # [FAIR4ML]\n",
    "    \n",
    "    # ‚îÄ‚îÄ Label Mapping as Artifact ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    label_map = {int(idx): cls for idx, cls in enumerate(le.classes_)}\n",
    "    buffer = io.StringIO()\n",
    "    json.dump(label_map, buffer, indent=2)\n",
    "    buffer.seek(0)\n",
    "    mlflow.log_text(buffer.getvalue(), artifact_file=\"label_mapping.json\")  # [FAIR4ML]\n",
    "    \n",
    "    # ‚îÄ‚îÄ Training Metadata ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    model_name = f\"RandomForest_Iris_v{ts}\"\n",
    "    mlflow.set_tag(\"model_name\", model_name)                       # [MLSEA]\n",
    "    \n",
    "    train_start_ts = datetime.now().isoformat()\n",
    "    mlflow.set_tag(\"training_start_time\", train_start_ts)          # [PROV]\n",
    "########################################################################################################\n",
    "### Model Parameters & Split Metadata ##################################################################\n",
    "\n",
    "# ‚îÄ‚îÄ Prompt test size and seed ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    try:\n",
    "        test_size = float(input(\"Enter test size (e.g., 0.2 for 20% test set): \"))\n",
    "    except ValueError:\n",
    "        print(\"Invalid input. Defaulting to 0.2\")\n",
    "        test_size = 0.2\n",
    "    \n",
    "    try:\n",
    "        random_state = int(input(\"Enter random seed (e.g., 42): \"))\n",
    "    except ValueError:\n",
    "        print(\"Invalid input. Defaulting to 42\")\n",
    "        random_state = 42\n",
    "    \n",
    "    # ‚îÄ‚îÄ Train/test split ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "    \n",
    "    # ‚îÄ‚îÄ Log split config ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    mlflow.log_param(\"test_size\", test_size)                     # [MLSEA]\n",
    "    mlflow.log_param(\"random_seed\", random_state)               # [PROV]\n",
    "    mlflow.log_param(\"n_train_samples\", X_train.shape[0])       # [FAIR4ML]\n",
    "    mlflow.log_param(\"n_test_samples\",  X_test.shape[0])        # [FAIR4ML]\n",
    "    mlflow.log_param(\"n_features\",      X_train.shape[1])       # [MLSEA]\n",
    "    \n",
    "    ########################################################################################################\n",
    "    ### Model Selection & Hyperparameters ##################################################################\n",
    "    \n",
    "    # ‚îÄ‚îÄ Define hyperparameters ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    ML_EXP_hyperparams = {\n",
    "        \"n_estimators\":       100,\n",
    "        \"criterion\":          \"entropy\",\n",
    "        \"max_depth\":          10,\n",
    "        \"min_samples_split\":  3,\n",
    "        \"min_samples_leaf\":   1,\n",
    "        \"max_features\":       \"sqrt\",\n",
    "        \"bootstrap\":          True,\n",
    "        \"oob_score\":          True,\n",
    "        \"class_weight\":       None,\n",
    "        \"verbose\":            1,\n",
    "        \"n_jobs\":             -1\n",
    "    }\n",
    "    \n",
    "    # ‚îÄ‚îÄ Model selection ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    available_models = {\n",
    "        \"random_forest\": RandomForestClassifier,\n",
    "        \"decision_tree\": DecisionTreeClassifier,\n",
    "        \"logistic_regression\": LogisticRegression,\n",
    "        \"knn\": KNeighborsClassifier,\n",
    "        \"svm\": SVC,\n",
    "        \"gradient_boosting\": GradientBoostingClassifier\n",
    "    }\n",
    "    \n",
    "    # User prompt\n",
    "    print(\"Choose a model to train:\")\n",
    "    for i, name in enumerate(available_models.keys()):\n",
    "        print(f\"{i + 1}. {name}\")\n",
    "    \n",
    "    choice = input(\"Enter model number (default 1 for random_forest): \").strip()\n",
    "    choice = int(choice) if choice else 1\n",
    "    selected_key = list(available_models.keys())[choice - 1]\n",
    "    selected_model_class = available_models[selected_key]\n",
    "    mlflow.set_tag(\"selected_model\", selected_key)  # [FAIR4ML, MLSEA]\n",
    "    \n",
    "    # ‚îÄ‚îÄ Initialize model ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    model = selected_model_class(**ML_EXP_hyperparams)\n",
    "    \n",
    "    # ‚îÄ‚îÄ Log hyperparameters with justification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    for key, val in ML_EXP_hyperparams.items():\n",
    "        log_with_justification(mlflow.log_param, key, val, context=\"Hyperparameter configuration\")  # [FAIR4ML, MLSEA]\n",
    "    \n",
    "    ########################################################################################################\n",
    "    ### Model Training & Evaluation ########################################################################\n",
    "    \n",
    "    # ‚îÄ‚îÄ Fit the model ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    model.fit(X_train, y_train)\n",
    "    train_end_ts = datetime.now().isoformat()\n",
    "    mlflow.set_tag(\"training_end_time\", train_end_ts)  # [PROV]\n",
    "    \n",
    "    # ‚îÄ‚îÄ Predictions ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)\n",
    "    \n",
    "    # ‚îÄ‚îÄ Compute and log metrics ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    acc  = accuracy_score(y_test, y_pred)\n",
    "    auc  = roc_auc_score(y_test, y_proba, multi_class=\"ovr\")\n",
    "    prec = precision_score(y_test, y_pred, average=\"macro\")\n",
    "    rec  = recall_score(y_test,  y_pred, average=\"macro\")\n",
    "    f1   = f1_score(y_test,      y_pred, average=\"macro\")\n",
    "    \n",
    "    mlflow.log_metric(\"accuracy\", acc)              # [MLSEA]\n",
    "    mlflow.log_metric(\"roc_auc\", auc)               # [MLSEA]\n",
    "    mlflow.log_metric(\"precision_macro\", prec)      # [MLSEA]\n",
    "    mlflow.log_metric(\"recall_macro\", rec)          # [MLSEA]\n",
    "    mlflow.log_metric(\"f1_macro\", f1)               # [MLSEA]\n",
    "\n",
    "\n",
    "########################################################################################################\n",
    "### Final Logging: Justifications, Metrics, Environment, Dataset Metadata #############################\n",
    "\n",
    "# ‚îÄ‚îÄ Prompt for and log justifications ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    log_justification(\"model_choice\", \"Why did you choose this model (e.g., RandomForestClassifier) for this task?\")\n",
    "    log_justification(\"target_variable\", \"Why did you choose this column as the prediction target?\")\n",
    "    log_justification(\"test_split\", \"Why this train/test ratio (e.g., 80/20)?\")\n",
    "    log_justification(\"metric_choice\", \"Why did you use accuracy/f1/ROC-AUC as your evaluation metric?\")\n",
    "    log_justification(\"threshold_accuracy\", \"Was there a threshold for accuracy? Why?\")\n",
    "    log_justification(\"dataset_version\", \"Why did you use this specific dataset version?\")\n",
    "    log_justification(\"drop_column_X\", \"Why did you drop any specific columns from the dataset?\")\n",
    "    log_justification(\"experiment_name\", \"Any context behind this experiment name or setup?\")\n",
    "    log_justification(\"model_limitations\", \"Any known model limitations?\")\n",
    "    log_justification(\"ethical_considerations\", \"Any known model ethical considerations?\")\n",
    "    log_justification(\"intended_use\", \"Known model intended use?\")\n",
    "    log_justification(\"not_intended_for\", \"Model not_intended_for?\")\n",
    "\n",
    "\n",
    "    # ‚îÄ‚îÄ Log model evaluation metrics ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    mlflow.log_metric(\"precision_macro\", prec)    # [MLSEA]\n",
    "    mlflow.log_metric(\"recall_macro\", rec)        # [MLSEA]\n",
    "    mlflow.log_metric(\"f1_macro\", f1)             # [MLSEA]\n",
    "    mlflow.log_metric(\"accuracy\", acc)            # [MLSEA]\n",
    "    mlflow.log_metric(\"roc_auc\", auc)             # [MLSEA]\n",
    "    \n",
    "    # ‚îÄ‚îÄ Log environment info ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    mlflow.log_params({\n",
    "        \"python_version\":       platform.python_version(),\n",
    "        \"os_platform\":          f\"{platform.system()} {platform.release()}\",\n",
    "        \"sklearn_version\":      sklearn.__version__,\n",
    "        \"pandas_version\":       pd.__version__,\n",
    "        \"numpy_version\":        np.__version__,\n",
    "        \"matplotlib_version\":   matplotlib.__version__,\n",
    "        \"seaborn_version\":      sns.__version__,\n",
    "        \"shap_version\":         shap.__version__,\n",
    "    })  # [PROV, Internal]\n",
    "    \n",
    "    # ‚îÄ‚îÄ Tag notebook name ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    mlflow.set_tag(\"notebook_name\", \"RQ1_2.ipynb\")  # [Internal]\n",
    "    \n",
    "    # ‚îÄ‚îÄ Dataset metadata tags ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    mlflow.set_tag(\"dataset_name\",    db_meta.get(\"dataset_name\", \"unknown\") )    # [FAIR4ML, PROV]\n",
    "    mlflow.set_tag(\"dataset_version\", selected_version)                                           # [FAIR4ML, Internal]\n",
    "    mlflow.set_tag(\"dataset_id\",      selected_table_id)  # [FAIR4ML, Internal]\n",
    "\n",
    "########################################################################################################\n",
    "### Plots: Feature Importance, ROC, PR, Confusion Matrix, SHAP #########################################\n",
    "\n",
    "# ‚îÄ‚îÄ Create plot output directory ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    # plot_dir = os.path.join(\"ML_EXP_plots\", run.info.run_id) ##TODO test this path change\n",
    "\n",
    "    summary_dir = os.path.join(os.getcwd(), \"MODEL_PROVENANCE\", model_name)\n",
    "    os.makedirs(summary_dir, exist_ok=True)\n",
    "    \n",
    "    # os.makedirs(plot_dir, exist_ok=True)\n",
    "    plot_dir = summary_dir  # üëà Use the same directory as the summary\n",
    "\n",
    "    # ‚îÄ‚îÄ 1) Feature Importance Bar Chart ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    if hasattr(model, \"feature_importances_\"):\n",
    "        importances = model.feature_importances_\n",
    "        feature_names = getattr(X_train, \"columns\", [f\"f{i}\" for i in range(X_train.shape[1])])\n",
    "        \n",
    "        fi_path = os.path.join(plot_dir, \"feature_importances.png\")\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.barplot(x=importances, y=feature_names)\n",
    "        plt.title(\"Feature Importances\")\n",
    "        plt.xlabel(\"Importance\")\n",
    "        plt.ylabel(\"Feature\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(fi_path)\n",
    "        mlflow.log_artifact(fi_path)  # [MLSEA]\n",
    "        plt.close()\n",
    "    \n",
    "    # ‚îÄ‚îÄ 2) Multi-class ROC Curves ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    classes = np.unique(y_test)\n",
    "    y_test_bin = label_binarize(y_test, classes=classes)\n",
    "    \n",
    "    for idx, cls in enumerate(classes):\n",
    "        disp = RocCurveDisplay.from_predictions(y_test_bin[:, idx], y_proba[:, idx], name=f\"ROC for class {cls}\")\n",
    "        roc_path = os.path.join(plot_dir, f\"roc_curve_cls_{cls}.png\")\n",
    "        disp.figure_.savefig(roc_path)\n",
    "        mlflow.log_artifact(roc_path)  # [MLSEA]\n",
    "        plt.close(disp.figure_)\n",
    "    \n",
    "    # ‚îÄ‚îÄ 3) Multi-class Precision-Recall Curves ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    for idx, cls in enumerate(classes):\n",
    "        disp = PrecisionRecallDisplay.from_predictions(y_test_bin[:, idx], y_proba[:, idx], name=f\"PR curve for class {cls}\")\n",
    "        pr_path = os.path.join(plot_dir, f\"pr_curve_cls_{cls}.png\")\n",
    "        disp.figure_.savefig(pr_path)\n",
    "        mlflow.log_artifact(pr_path)  # [MLSEA]\n",
    "        plt.close(disp.figure_)\n",
    "    \n",
    "    # ‚îÄ‚îÄ 4) Confusion Matrix Plot ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    cm_path = os.path.join(plot_dir, \"confusion_matrix.png\")\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    plt.figure(figsize=(6, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(cm_path)\n",
    "    mlflow.log_artifact(cm_path)  # [MLSEA]\n",
    "    plt.close()\n",
    "    \n",
    "    # ‚îÄ‚îÄ 5) SHAP Summary Plot ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    shap_path = os.path.join(plot_dir, \"shap_summary.png\")\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer.shap_values(X_test)\n",
    "    \n",
    "    shap.summary_plot(shap_values, X_test, show=False)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(shap_path)\n",
    "    mlflow.log_artifact(shap_path)  # [FAIR4ML, MLSEA]\n",
    "    plt.close()\n",
    "    \n",
    "    ########################################################################################################\n",
    "    ### Final: Metadata Summary Logging ####################################################################\n",
    "    \n",
    "    \n",
    "    log_standard_metadata(\n",
    "    model_name=model_name,\n",
    "    model=model,\n",
    "    hyperparams=ML_EXP_hyperparams,\n",
    "    acc=acc,\n",
    "    prec=prec,\n",
    "    rec=rec,\n",
    "    f1=f1,\n",
    "    auc=auc,\n",
    "    label_map=label_map,\n",
    "    run_id=run.info.run_id,\n",
    "    test_size=test_size,\n",
    "    random_state=random_state,\n",
    "    id_cols=id_cols,         # ‚úÖ list of dropped ID columns\n",
    "    target_col=target_col,   # ‚úÖ your target column, likely defined as df.columns[-1]\n",
    "    X=X,                     # ‚úÖ your features DataFrame\n",
    "    y=y,                     # ‚úÖ your labels array or Series\n",
    "    run_data=run_data        # optional but useful\n",
    "    )\n",
    "\n",
    "########################################################################################################\n",
    "### Export Model (.pkl) and Log as Artifact ############################################################\n",
    "\n",
    "# ‚îÄ‚îÄ Define output path ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    from pathlib import Path\n",
    "\n",
    "    summary_dir = Path(summary_dir)  # Make sure it's a Path object\n",
    "\n",
    "    pkl_path = summary_dir / f\"{model_name}.pkl\"\n",
    "    # os.makedirs(\"Trained_models\", exist_ok=True)  # Ensure the folder exists\n",
    "    \n",
    "    # ‚îÄ‚îÄ Serialize the trained model to disk ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    with open(pkl_path, \"wb\") as f:\n",
    "        pickle.dump(model, f)\n",
    "    \n",
    "    # ‚îÄ‚îÄ Log the serialized model to MLflow as an artifact ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    mlflow.log_artifact(pkl_path, artifact_path=model_name)  # [FAIR4ML, MLSEA]\n",
    "\n",
    "########################################################################################################\n",
    "### COMMIT: Git Integration + Provenance Logging #######################################################\n",
    "\n",
    "    def get_latest_commit_hash(repo_path=\".\"):\n",
    "        res = subprocess.run(\n",
    "            [\"git\", \"-C\", repo_path, \"rev-parse\", \"HEAD\"],\n",
    "            capture_output=True, text=True, check=True\n",
    "        )\n",
    "        return res.stdout.strip()\n",
    "    \n",
    "    def get_remote_url(repo_path=\".\", remote=\"origin\"):\n",
    "        res = subprocess.run(\n",
    "            [\"git\", \"-C\", repo_path, \"config\", \"--get\", f\"remote.{remote}.url\"],\n",
    "            capture_output=True, text=True, check=True\n",
    "        )\n",
    "        return res.stdout.strip()\n",
    "    \n",
    "    def make_commit_link(remote_url, commit_hash):\n",
    "        base = remote_url.rstrip(\".git\")\n",
    "        if base.startswith(\"git@\"):\n",
    "            base = base.replace(\":\", \"/\").replace(\"git@\", \"https://\")\n",
    "        return f\"{base}/commit/{commit_hash}\"\n",
    "    \n",
    "    def simple_commit_and_push_and_log(repo_path=\".\", message=\"Auto commit\", remote=\"origin\", branch=\"main\"):\n",
    "        status = subprocess.run([\"git\", \"-C\", repo_path, \"status\", \"--porcelain\"], capture_output=True, text=True)\n",
    "        if not status.stdout.strip():\n",
    "            print(\"üü° No changes to commit.\")\n",
    "            return None, None\n",
    "    \n",
    "        subprocess.run([\"git\", \"-C\", repo_path, \"add\", \"--all\"], capture_output=True, text=True)\n",
    "        commit = subprocess.run([\"git\", \"-C\", repo_path, \"commit\", \"-m\", message], capture_output=True, text=True)\n",
    "        if commit.returncode:\n",
    "            print(\"‚ùå git commit failed:\\n\", commit.stderr)\n",
    "            return None, None\n",
    "        print(\"‚úÖ Commit successful.\")\n",
    "    \n",
    "        push = subprocess.run([\"git\", \"-C\", repo_path, \"push\", \"-u\", remote, branch], capture_output=True, text=True)\n",
    "        if push.returncode:\n",
    "            print(\"‚ùå git push failed:\\n\", push.stderr)\n",
    "        else:\n",
    "            print(\"üöÄ Push successful.\")\n",
    "    \n",
    "        sha = get_latest_commit_hash(repo_path)\n",
    "        url = get_remote_url(repo_path, remote)\n",
    "        link = make_commit_link(url, sha)\n",
    "        return sha, link\n",
    "    \n",
    "    # ‚îÄ‚îÄ Perform commit and get commit SHA and link ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    sha, link = simple_commit_and_push_and_log(\n",
    "        repo_path=\".\",\n",
    "        message=\"Auto commit after successful training\"\n",
    "    )\n",
    "    \n",
    "    # ‚îÄ‚îÄ Ask for version tag and log it ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    def get_version_tag_for_commit(commit_hash, known_tags=None):\n",
    "        known_tags = known_tags or {}\n",
    "        version_tag = known_tags.get(commit_hash, \"untagged\")\n",
    "        if version_tag == \"untagged\":\n",
    "            print(f\"‚ö†Ô∏è Commit {commit_hash[:8]} is not tagged with a version.\")\n",
    "            user_input = input(\"üîñ Enter version tag for this commit (or press Enter to skip): \").strip()\n",
    "            version_tag = user_input if user_input else \"untagged\"\n",
    "        return commit_hash, version_tag\n",
    "    \n",
    "    commit, version_tag = get_version_tag_for_commit(sha)\n",
    "    mlflow.set_tag(\"GIT_code_version\", version_tag)  # [PROV]\n",
    "    mlflow.set_tag(\"model_version\", version_tag)  # [PROV]\n",
    "\n",
    "    \n",
    "    \n",
    "    # ‚îÄ‚îÄ Log author info ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    def get_git_author():\n",
    "        name = subprocess.check_output([\"git\", \"config\", \"user.name\"]).decode().strip()\n",
    "        email = subprocess.check_output([\"git\", \"config\", \"user.email\"]).decode().strip()\n",
    "        return name, email\n",
    "    \n",
    "    name, email = get_git_author()\n",
    "    mlflow.set_tag(\"GIT_user\", name)               # [PROV]\n",
    "    mlflow.set_tag(\"GIT_user_email\", email)        # [PROV]\n",
    "    \n",
    "    # ‚îÄ‚îÄ Log Git diff between this and previous commit ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    if sha and link:\n",
    "        previous_commit_hash = db_meta.get(\"code_commit_hash\", \"\")  # Fallback for comparison\n",
    "        if previous_commit_hash:\n",
    "            diff_text = subprocess.check_output(\n",
    "                [\"git\", \"-C\", \".\", \"diff\", previous_commit_hash, sha],\n",
    "                encoding=\"utf-8\", errors=\"ignore\"\n",
    "            )\n",
    "    \n",
    "            remote_url = get_remote_url(\".\")\n",
    "            remote_url = remote_url.rstrip(\".git\")\n",
    "            if remote_url.startswith(\"git@\"):\n",
    "                remote_url = remote_url.replace(\":\", \"/\").replace(\"git@\", \"https://\")\n",
    "    \n",
    "            previous_commit_url = f\"{remote_url}/commit/{previous_commit_hash}\"\n",
    "            current_commit_url  = f\"{remote_url}/commit/{sha}\"\n",
    "    \n",
    "            diff_data = {\n",
    "                \"GIT_previous_commit\":        previous_commit_hash,\n",
    "                \"GIT_previous_commit_url\":    previous_commit_url,\n",
    "                \"GIT_current_commit\":         sha,\n",
    "                \"GIT_current_commit_url\":     current_commit_url,\n",
    "                \"GIT_diff\":                   diff_text\n",
    "            }\n",
    "    \n",
    "            mlflow.log_dict(diff_data, artifact_file=\"GIT_commit_diff.json\")  # [PROV]\n",
    "            mlflow.set_tag(\"GIT_previous_commit_hash\", previous_commit_hash)\n",
    "            mlflow.set_tag(\"GIT_current_commit_hash\", sha)\n",
    "            mlflow.set_tag(\"GIT_current_commit_url\", link)\n",
    "########################################################################################################\n",
    "### Reproducibility Metadata Extraction + Text Log #####################################################\n",
    "\n",
    "# ‚îÄ‚îÄ Log all categorized metadata (FAIR, PROV\n",
    "    , DBRepo, etc.) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    # log_metadata_dict_to_mlflow(categorized_fields)  # [FAIR4ML, PROV, Internal]\n",
    "\n",
    "    log_metadata_dict_to_mlflow(\n",
    "        metadata=doi_metadata,\n",
    "        prefix=\"DOI_\",\n",
    "        snapshot_name=\"doi_metadata_snapshot.json\"\n",
    "    )\n",
    "    # ‚îÄ‚îÄ Retrieve full run metadata ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    run_id    = run.info.run_id\n",
    "    run_info  = client.get_run(run_id).info\n",
    "    run_data  = client.get_run(run_id).data\n",
    "    \n",
    "    params  = dict(run_data.params)\n",
    "    metrics = dict(run_data.metrics)\n",
    "    tags    = dict(run_data.tags)\n",
    "    \n",
    "    # ‚îÄ‚îÄ List all artifacts in the run ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    artifact_uri  = run_info.artifact_uri\n",
    "    artifact_meta = []\n",
    "    \n",
    "    def _gather(path=\"\"):\n",
    "        for af in client.list_artifacts(run_id, path):\n",
    "            if af.is_dir:\n",
    "                _gather(af.path)\n",
    "            else:\n",
    "                rel_path = af.path.lower()\n",
    "                if rel_path.endswith((\".json\", \".txt\", \".patch\")):\n",
    "                    artifact_meta.append({\"path\": af.path, \"type\": \"text\"})\n",
    "                elif rel_path.endswith((\".png\", \".jpg\", \".jpeg\", \".svg\")):\n",
    "                    artifact_meta.append({\"path\": af.path, \"type\": \"image\"})\n",
    "                else:\n",
    "                    artifact_meta.append({\"path\": af.path, \"type\": \"other\"})\n",
    "    \n",
    "    _gather()\n",
    "    \n",
    "    # ‚îÄ‚îÄ (Optional) Store artifact meta if needed ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    mlflow.log_dict({\"artifacts\": artifact_meta}, artifact_file=\"artifact_summary.json\")  # [Internal]\n",
    "    \n",
    "    # ‚îÄ‚îÄ Notebook directory (for trace/log location reference) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    notebook_dir = os.getcwd()\n",
    "    \n",
    "    ########################################################################################################\n",
    "    ### Generate Reproducibility Instructions ##############################################################\n",
    "    \n",
    "    # ‚îÄ‚îÄ Generate reproducibility .txt log with key details ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    repro_txt_path = generate_reproducibility_txt_log(\n",
    "        model_name=model_name,\n",
    "        dataset_name=db_meta.get(\"dataset_name\", \"unknown\"),\n",
    "        dataset_version=selected_version,\n",
    "        hyperparams=ML_EXP_hyperparams,\n",
    "        metrics={\n",
    "            \"accuracy\": acc,\n",
    "            \"f1_macro\": f1,\n",
    "            \"precision_macro\": prec,\n",
    "            \"recall_macro\": rec,\n",
    "            \"roc_auc\": auc\n",
    "        },\n",
    "        git_commit=sha,\n",
    "        run_id=run_id\n",
    "    )\n",
    "    \n",
    "    # ‚îÄ‚îÄ Log the .txt path to MLflow for traceability ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    mlflow.log_param(\"reproducibility_log_path\", repro_txt_path)  # [Internal, FAIR4ML]\n",
    "########################################################################################################\n",
    "### COMBINE: Export Full Run Summary as JSON ###########################################################\n",
    "\n",
    "    # ‚îÄ‚îÄ Prepare run summary dict ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    summary = {\n",
    "        \"run_id\":         run_id,\n",
    "        \"run_name\":       run_info.run_name,\n",
    "        \"experiment_id\":  run_info.experiment_id,\n",
    "        \"start_time\":     run_info.start_time,\n",
    "        \"end_time\":       run_info.end_time,\n",
    "        \"params\":         params,\n",
    "        \"metrics\":        metrics,\n",
    "        \"tags\":           tags,\n",
    "        \"artifacts\":      artifact_meta\n",
    "    }\n",
    "    \n",
    "    # ‚îÄ‚îÄ Write summary to JSON file ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    summary_filename    = f\"{model_name}_run_summary.json\"\n",
    "    summary_local_path  = os.path.join(summary_dir, summary_filename)\n",
    "    \n",
    "    with open(summary_local_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "    \n",
    "    # ‚îÄ‚îÄ Log summary JSON to MLflow ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    mlflow.log_artifact(summary_local_path, artifact_path=\"run_summaries\")  # [FAIR4ML, Internal]\n",
    "    print(\"üìÅ Run summary JSON logged at:\", summary_local_path)\n",
    "    \n",
    "    # ‚îÄ‚îÄ End MLflow run with PROV-O end timestamp ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    end_time = datetime.now().isoformat()\n",
    "    mlflow.set_tag(\"endedAtTime\", end_time)  # [PROV]\n",
    "    mlflow.end_run()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "62a4d9a4-032f-4b76-b74e-6a3a54ebaf0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest_Iris_v20250629_142249\n"
     ]
    }
   ],
   "source": [
    "upload_name = summary_dir.name\n",
    "print(upload_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b51a1a-b4ee-42d6-9724-bba5419553b4",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "This script generates a minimal `requirements.txt` file by:\n",
    "- Running `pip freeze` to list all installed Python packages.\n",
    "- Filtering the packages to include only those that match a predefined set of required keywords.\n",
    "- Writing the filtered package list (with versions) to `requirements.txt`.\n",
    "\n",
    "This ensures that only relevant dependencies are included for reproducibility and lightweight environment setup.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cee2f35d-1cb5-481a-aa26-3212cabca3f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Renamed metadata saved to: C:\\Users\\reema\\REPO\\notebooks\\RQ_notebooks\\MODEL_PROVENANCE\\RandomForest_Iris_v20250629_142249\\requirements.txt\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "required_keywords = [\n",
    "    \"mlflow\", \"scikit-learn\", \"pandas\", \"numpy\", \"pyyaml\", \"seaborn\",\n",
    "    \"matplotlib\", \"shap\", \"rdflib\", \"requests\", \"python-dotenv\", \"gitpython\", \"psutil\", \"pyld\"\n",
    "]\n",
    "\n",
    "# Run pip freeze\n",
    "result = subprocess.run([\"pip\", \"freeze\"], stdout=subprocess.PIPE, text=True)\n",
    "all_packages = result.stdout.splitlines()\n",
    "\n",
    "# Filter based on matching names\n",
    "filtered = [pkg for pkg in all_packages if any(kw.lower() in pkg.lower() for kw in required_keywords)]\n",
    "\n",
    "# Ensure summary_dir is a Path object\n",
    "summary_dir = Path(summary_dir)\n",
    "\n",
    "# Define your custom file name with .txt extension\n",
    "custom_name = \"requirements.txt\"\n",
    "\n",
    "# Create full output path\n",
    "custom_output_path = summary_dir / custom_name\n",
    "\n",
    "# Save the renamed metadata in text format\n",
    "with open(custom_output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(filtered, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"‚úÖ Renamed metadata saved to: {custom_output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950e5171-41c0-48e6-be9b-898ae82401e6",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "This script reads a saved MLflow run summary JSON file and programmatically inserts \n",
    "the extracted metadata into various tables of a remote database (via REST API). \n",
    "It covers:\n",
    "\n",
    "1. Session Metadata: Captures runtime details (username, OS, script name, etc.).\n",
    "2. Experiment Metadata: Stores run/session/model linkage and timestamps.\n",
    "3. Git Metadata: Tracks versioning, author, and repository details.\n",
    "4. Dataset Metadata: Logs dataset version, structure, and FAIR-related fields.\n",
    "5. Model Metadata: Includes algorithm, features used, training split, and provenance info.\n",
    "6. Metrics + Justifications: Extracts evaluation metrics and manually logged justifications.\n",
    "\n",
    "Each metadata section is mapped to a dedicated table via unique table IDs and inserted \n",
    "using `POST` requests to the configured database API.\n",
    "\n",
    "‚ö†Ô∏è Assumes the summary file path is stored in `summary_local_path`.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "82fe4cc5-396c-48ae-8561-df4e0a44fbe7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Session Metadata POST\n",
      "‚û°Ô∏è URL: http://localhost/api/database/003080b8-13d7-4cd1-86a6-b6b1b1e025b9/table/2cc388fc-7cb7-46de-88a6-aebdff9f1a2a/data\n",
      "üì¶ Payload:\n",
      "üì§ Status Code: 201\n",
      "üìù Response Text: \n",
      "\n",
      "üîç Experiment Metadata POST\n",
      "‚û°Ô∏è URL: http://localhost/api/database/003080b8-13d7-4cd1-86a6-b6b1b1e025b9/table/ad2257b4-a339-410f-9cf0-966f1f5a0a9d/data\n",
      "üì¶ Payload:\n",
      "üì§ Status Code: 201\n",
      "üìù Response Text: \n",
      "\n",
      "üîç Git Metadata POST\n",
      "‚û°Ô∏è URL: http://localhost/api/database/003080b8-13d7-4cd1-86a6-b6b1b1e025b9/table/5c9d4d81-9d36-4d0f-902b-46fcb051c454/data\n",
      "üì¶ Payload:\n",
      "üì§ Status Code: 201\n",
      "üìù Response Text: \n",
      "\n",
      "üîç Dataset Metadata POST\n",
      "‚û°Ô∏è URL: http://localhost/api/database/003080b8-13d7-4cd1-86a6-b6b1b1e025b9/table/54449d09-5513-4b0b-8221-8d601e811fda/data\n",
      "üì¶ Payload:\n",
      "üì§ Status Code: 201\n",
      "üìù Response Text: \n",
      "üì¨ Headers: {'Server': 'nginx', 'Date': 'Sun, 29 Jun 2025 12:27:08 GMT', 'Content-Length': '0', 'Connection': 'keep-alive', 'Vary': 'Origin, Access-Control-Request-Method, Access-Control-Request-Headers', 'X-Content-Type-Options': 'nosniff', 'X-XSS-Protection': '0', 'Cache-Control': 'no-cache, no-store, max-age=0, must-revalidate', 'Pragma': 'no-cache', 'Expires': '0', 'X-Frame-Options': 'DENY, SAMEORIGIN'}\n",
      "üì¶ Payload Sent:\n",
      "\n",
      "üîç MODEL METADATA POST\n",
      "‚û°Ô∏è URL: http://localhost/api/database/003080b8-13d7-4cd1-86a6-b6b1b1e025b9/table/dfdbcdfa-b1fa-40fb-87d2-993e9b43fe69/data\n",
      "üì¶ Payload:\n",
      "üì§ Status Code: 201\n",
      "üìù Response Text: \n",
      "\n",
      "üîç Cleaned Metrics + Justification POST\n",
      "‚û°Ô∏è URL: http://localhost/api/database/003080b8-13d7-4cd1-86a6-b6b1b1e025b9/table/d6bdb07a-e60b-4f3d-bca8-4a132aa9fc75/data\n",
      "üì¶ Payload:\n",
      "üì§ Status Code: 201\n",
      "üìù Response Text: \n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "from datetime import datetime\n",
    "\n",
    "# --- Configuration ---\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "auth = (\"reema260995\", \"Toothless!26\")\n",
    "BASE = \"http://localhost/api/database/003080b8-13d7-4cd1-86a6-b6b1b1e025b9/table\"\n",
    "TABLES = {\n",
    "    \"session_metadata\": \"2cc388fc-7cb7-46de-88a6-aebdff9f1a2a\",\n",
    "    \"experiment_metadata\": \"ad2257b4-a339-410f-9cf0-966f1f5a0a9d\",\n",
    "    \"git_metadata\": \"5c9d4d81-9d36-4d0f-902b-46fcb051c454\",\n",
    "    \"dataset_metadata\": \"54449d09-5513-4b0b-8221-8d601e811fda\",\n",
    "    \"model_metadata\": \"dfdbcdfa-b1fa-40fb-87d2-993e9b43fe69\",\n",
    "    \"justification_metadata\": \"d6bdb07a-e60b-4f3d-bca8-4a132aa9fc75\"\n",
    "}\n",
    "import uuid\n",
    "\n",
    "# Generate a unique dataset_id using UUID\n",
    "dataset_guid = str(uuid.uuid4())\n",
    "# --- Load metadata file ---\n",
    "# with open(\"MODEL_PROVENANCE/b788db5d12174c28bc175589898f7f95/RandomForest_Iris_v20250516_193049_run_summary.json\", \"r\") as f:\n",
    "with open(summary_local_path, \"r\") as f:\n",
    "\n",
    "    meta = json.load(f)\n",
    "\n",
    "# --- Helper ---\n",
    "def to_mysql_datetime(ts):\n",
    "    return datetime.strptime(ts.split(\".\")[0], \"%Y-%m-%dT%H:%M:%S\").isoformat() + \"+00:00\"\n",
    "\n",
    "# --- Extract shared values ---\n",
    "run_id = meta[\"run_id\"]\n",
    "session_id = meta[\"params\"][\"session_id\"]\n",
    "dataset_id = meta[\"tags\"][\"dataset_id\"]\n",
    "model_id = \"model_\" + meta[\"tags\"][\"model_name\"].lower() + f\"_{ts}\"\n",
    "git_commit = meta[\"tags\"][\"git_commit\"]\n",
    "git_version = meta[\"tags\"][\"GIT_code_version\"]\n",
    "timestamp_utc = meta[\"params\"][\"timestamp_utc\"]\n",
    "username = meta[\"params\"][\"username\"]\n",
    "platform = meta[\"params\"][\"platform\"]\n",
    "hostname = meta[\"params\"][\"hostname\"]\n",
    "target_var = meta[\"tags\"][\"target_variable\"]\n",
    "label_map = meta[\"tags\"][\"label_map\"]\n",
    "feature_list = meta[\"params\"][\"final_feature_names\"]\n",
    "dataset_name = meta[\"tags\"][\"dataset_name\"]\n",
    "dataset_version = meta[\"tags\"][\"dataset_version\"]\n",
    "estimator = meta[\"tags\"][\"estimator_name\"]\n",
    "feature_select = meta[\"tags\"][\"feature_columns\"]\n",
    "label_snap = meta[\"tags\"][\"target_variable_encoded\"]\n",
    "model_name = meta[\"tags\"][\"model_name\"]\n",
    "imbalance_ratio = 1.0 if \"imbalance_ratio\" not in meta[\"tags\"] else meta[\"tags\"][\"imbalance_ratio\"]\n",
    "\n",
    "# --- Extract shared values (exact keys from JSON) ---\n",
    "python_version = meta[\"params\"].get(\"python_version\")\n",
    "os_platform = meta[\"params\"].get(\"os_platform\")\n",
    "role = meta[\"params\"].get(\"role\")\n",
    "project_id = meta[\"params\"].get(\"project_id\")\n",
    "script_name = meta[\"params\"].get(\"source_file_name\", \"None_specified\")\n",
    "\n",
    "# --- Build full session payload (VARCHAR timestamp, full mapping) ---\n",
    "session_payload = {\n",
    "    \"session_id\": session_id,\n",
    "    \"username\": username,\n",
    "    \"timestamp\": timestamp_utc,\n",
    "    \"hostname\": hostname,\n",
    "    \"platform\": platform,\n",
    "    \"python_version\": python_version,\n",
    "    \"os_platform\": os_platform,\n",
    "    \"role\": role,\n",
    "    \"project_id\": project_id,\n",
    "    \"script_name\": script_name\n",
    "}\n",
    "\n",
    "session_url = f\"{BASE}/{TABLES['session_metadata']}/data\"\n",
    "\n",
    "response = requests.post(\n",
    "    session_url,\n",
    "    headers=headers,\n",
    "    auth=auth,\n",
    "    json={\"data\": session_payload}\n",
    ")\n",
    "\n",
    "# --- Logging ---\n",
    "print(\"\\nüîç Session Metadata POST\")\n",
    "print(\"‚û°Ô∏è URL:\", session_url)\n",
    "print(\"üì¶ Payload:\")\n",
    "# print(json.dumps(session_payload, indent=2))\n",
    "print(\"üì§ Status Code:\", response.status_code)\n",
    "print(\"üìù Response Text:\", response.text)\n",
    "#######################################################\n",
    "\n",
    "# # --- 2. Experiment Metadata ---\n",
    "exp_payload = {\n",
    "    \"runid\": run_id,\n",
    "    \"sessionid\": session_id,\n",
    "    \"modelid\": model_id,\n",
    "    \"datasetid\": dataset_guid,\n",
    "    \"git_commit\": meta[\"tags\"].get(\"git_commit\",\"None_specified\"),\n",
    "    \"invenioid\": meta[\"tags\"].get(\"DOI_dataset_id\",\"None_specified\"),\n",
    "    \"timestamp\": timestamp_utc,  # keep as VARCHAR\n",
    "\n",
    "    # NEW fields\n",
    "    \"experiment_id\": meta[\"tags\"].get(\"experiment_id\",\"None_specified\"),\n",
    "    \"run_name\": meta.get(\"run_name\",\"None_specified\"),\n",
    "    \"training_start_time\": meta[\"tags\"].get(\"training_start_time\",\"None_specified\"),\n",
    "    \"training_end_time\": meta[\"tags\"].get(\"training_end_time\",\"None_specified\"),\n",
    "    \"source_file\": meta[\"tags\"].get(\"mlflow.source.name\",\"None_specified\"),\n",
    "    \"source_notebook\": meta[\"tags\"].get(\"notebook_name\",\"None_specified\")\n",
    "}\n",
    "\n",
    "exp_url = f\"{BASE}/{TABLES['experiment_metadata']}/data\"\n",
    "\n",
    "response = requests.post(\n",
    "    exp_url,\n",
    "    headers=headers,\n",
    "    auth=auth,\n",
    "    json={\"data\": exp_payload}\n",
    ")\n",
    "\n",
    "# --- Logging ---\n",
    "print(\"\\nüîç Experiment Metadata POST\")\n",
    "print(\"‚û°Ô∏è URL:\", exp_url)\n",
    "print(\"üì¶ Payload:\")\n",
    "# print(json.dumps(exp_payload, indent=2))\n",
    "print(\"üì§ Status Code:\", response.status_code)\n",
    "print(\"üìù Response Text:\", response.text)\n",
    "\n",
    "\n",
    "# --- 3. Git Metadata ---\n",
    "git_payload = {\n",
    "    \"commit_hash\": meta[\"tags\"][\"git_commit\"],\n",
    "    \"repo_url\": meta[\"tags\"].get(\"DOI_prov_used\",\"None_specified\"),\n",
    "    \"branch\": meta[\"tags\"].get(\"GIT_branch\", \"main\"),\n",
    "    \"author\": meta[\"tags\"].get(\"GIT_user\",\"None_specified\"),\n",
    "    \"author_email\": meta[\"tags\"].get(\"GIT_user_email\",\"None_specified\"),\n",
    "    \"version\": meta[\"tags\"].get(\"GIT_code_version\",\"None_specified\"),\n",
    "    \"origin_url\": meta[\"tags\"].get(\"GIT_origin_url\",\"None_specified\"),\n",
    "    \"timestamp\": meta[\"params\"].get(\"timestamp_utc\",\"None_specified\")\n",
    "}\n",
    "\n",
    "\n",
    "git_url = f\"{BASE}/{TABLES['git_metadata']}/data\"\n",
    "\n",
    "response = requests.post(\n",
    "    git_url,\n",
    "    headers=headers,\n",
    "    auth=auth,\n",
    "    json={\"data\": git_payload}\n",
    ")\n",
    "\n",
    "# --- Logging ---\n",
    "print(\"\\nüîç Git Metadata POST\")\n",
    "print(\"‚û°Ô∏è URL:\", git_url)\n",
    "print(\"üì¶ Payload:\")\n",
    "# print(json.dumps(git_payload, indent=2))\n",
    "print(\"üì§ Status Code:\", response.status_code)\n",
    "print(\"üìù Response Text:\", response.text)\n",
    "\n",
    "import requests\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "DEFAULT_TIMESTAMP = \"1970-01-01 00:00:01\"\n",
    "\n",
    "# --- Utility cleaning functions ---\n",
    "def clean(value, fallback=\"unknown\"):\n",
    "    if value in [None, \"\", \"None_specified\", \"[]\", \"‚Äî\", \"not specified\", \"null\", \"None\"]:\n",
    "        return fallback\n",
    "    return value\n",
    "\n",
    "def clean_date_for_timestamp(value):\n",
    "    try:\n",
    "        if isinstance(value, str):\n",
    "            value = value.replace(\"T\", \" \").replace(\"Z\", \"\")\n",
    "            dt = datetime.fromisoformat(value.split(\".\")[0])\n",
    "            return dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    except Exception:\n",
    "        pass\n",
    "    return None\n",
    "\n",
    "def safe_int(value, default=0):\n",
    "    try:\n",
    "        return int(value)\n",
    "    except:\n",
    "        return default\n",
    "\n",
    "# --- Build payload dynamically ---\n",
    "dataset_payload = {\n",
    "    \"dataset_guid\": dataset_guid,\n",
    "    \"dataset_id\": dataset_id,\n",
    "    \"table_name\": clean(meta[\"tags\"].get(\"dataset_name\")),\n",
    "    \"detailed_type\": \"CSV\",\n",
    "    \"classes\": safe_int(meta[\"tags\"].get(\"dataset_num_classes\", 3)),\n",
    "    \"features\": safe_int(meta[\"params\"].get(\"final_num_features\", 4)),\n",
    "    \"output_type\": clean(meta[\"tags\"].get(\"output_type\", \"categorical\")),\n",
    "    \"version\": clean(meta[\"tags\"].get(\"dataset_version\")),\n",
    "    \"source_url\": clean(meta[\"tags\"].get(\"DOI_dataset_access_url\")),\n",
    "    \"title\": clean(meta[\"tags\"].get(\"DOI_dataset_title\")),\n",
    "    \"description\": clean(meta[\"tags\"].get(\"DOI_dataset_documentation\")),\n",
    "    \"license\": clean(meta[\"tags\"].get(\"DOI_dataset_license\")),\n",
    "    \"creator\": clean(meta[\"tags\"].get(\"DOI_dataset_creator\")),\n",
    "    \"publisher\": clean(meta[\"tags\"].get(\"DOI_dataset_publisher\")),\n",
    "    \"publication_year\": safe_int(meta[\"tags\"].get(\"DOI_dataset_publication_date\")),\n",
    "    \"language\": clean(meta[\"tags\"].get(\"DOI_dataset_language\")),\n",
    "    \"citation_count\": safe_int(meta[\"tags\"].get(\"DOI_citation_count\", 0)),\n",
    "    \"subjects\": clean(meta[\"tags\"].get(\"DOI_dataset_subjects\", \"info not available\")),\n",
    "    \"related_resources\": json.dumps(meta[\"tags\"].get(\"DOI_related_resources\", []))[:255],\n",
    "    \"schema_version\": clean(meta[\"tags\"].get(\"DOI_schema_version\", \"unknown\")),\n",
    "    \"registered\": clean_date_for_timestamp(meta[\"tags\"].get(\"DOI_registered_date\")) or DEFAULT_TIMESTAMP,\n",
    "    \"citations_over_time\": json.dumps(meta[\"tags\"].get(\"DOI_citations_over_time\", []))[:255],\n",
    "    \"created\": clean_date_for_timestamp(meta[\"tags\"].get(\"DOI_created\")) or DEFAULT_TIMESTAMP,\n",
    "    \"updated\": clean_date_for_timestamp(meta[\"tags\"].get(\"DOI_updated\")) or DEFAULT_TIMESTAMP\n",
    "}\n",
    "\n",
    "# --- Build URL ---\n",
    "dataset_url = f\"{BASE}/{TABLES['dataset_metadata']}/data\"\n",
    "\n",
    "# --- Send POST request ---\n",
    "response = requests.post(\n",
    "    dataset_url,\n",
    "    headers=headers,\n",
    "    auth=auth,\n",
    "    json={\"data\": dataset_payload}\n",
    ")\n",
    "\n",
    "# --- Log request/response ---\n",
    "print(\"\\nüîç Dataset Metadata POST\")\n",
    "print(\"‚û°Ô∏è URL:\", dataset_url)\n",
    "print(\"üì¶ Payload:\")\n",
    "# print(json.dumps(dataset_payload, indent=2))\n",
    "print(\"üì§ Status Code:\", response.status_code)\n",
    "print(\"üìù Response Text:\", response.text)\n",
    "print(\"üì¨ Headers:\", dict(response.headers))\n",
    "print(\"üì¶ Payload Sent:\")\n",
    "# print(json.dumps(dataset_payload, indent=2))\n",
    "\n",
    "\n",
    "# -- Log POST request for model metadata --\n",
    "model_payload = {\n",
    "    \"model_id\": model_id,\n",
    "    \"name\": model_name,\n",
    "    \"algo\": estimator,\n",
    "    \"architecture\": meta[\"tags\"].get(\"model_architecture\"),\n",
    "    \"features\": meta[\"params\"].get(\"final_feature_names\"),\n",
    "    \"label_snap\": meta[\"tags\"].get(\"target_variable_encoded\"),\n",
    "    \"train_split\": float(meta[\"params\"][\"n_train_samples\"]) / int(meta[\"params\"][\"input_row_count\"]),\n",
    "    \"test_split\": float(meta[\"params\"][\"n_test_samples\"]) / int(meta[\"params\"][\"input_row_count\"]),\n",
    "    \"target_var\": meta[\"tags\"].get(\"target_variable\"),\n",
    "    \"label_map\": meta[\"tags\"].get(\"label_map\"),\n",
    "    \"feature_select\": meta[\"tags\"].get(\"feature_columns\"),\n",
    "    \"imbalance_ratio\": meta[\"tags\"].get(\"imbalance_ratio\", 1.0),\n",
    "    \"version\": meta[\"tags\"].get(\"model_version\"),\n",
    "    \"serialization_format\": meta[\"tags\"].get(\"model_serialization\"),\n",
    "    \"model_path\": meta[\"tags\"].get(\"model_path\"),\n",
    "    \"model_short_name\": meta[\"tags\"].get(\"selected_model\"),\n",
    "    \"hyperparameters\": meta[\"tags\"].get(\"hyperparameters\"),\n",
    "    \"preprocessing_info\": meta[\"tags\"].get(\"preprocessing_info\")\n",
    "}\n",
    "\n",
    "\n",
    "model_url = f\"{BASE}/{TABLES['model_metadata']}/data\"\n",
    "response = requests.post(\n",
    "    model_url,\n",
    "    headers=headers,\n",
    "    auth=auth,\n",
    "    json={\"data\": model_payload}\n",
    ")\n",
    "\n",
    "# --- Logging ---\n",
    "print(\"\\nüîç MODEL METADATA POST\")\n",
    "print(\"‚û°Ô∏è URL:\", model_url)\n",
    "print(\"üì¶ Payload:\")\n",
    "# print(json.dumps(model_payload, indent=2))\n",
    "print(\"üì§ Status Code:\", response.status_code)\n",
    "print(\"üìù Response Text:\", response.text)\n",
    "\n",
    "# --- Extract Metrics + Justification (final section) ------------------------------------\n",
    "# --- Allowed lowercase fields from your DB schema ---\n",
    "allowed_fields = {\n",
    "    \"run_id\", \"accuracy\", \"f1_macro\", \"num_deleted_rows\", \"num_inserted_rows\",\n",
    "    \"precision_macro\", \"recall_macro\", \"roc_auc\", \"row_count_end\", \"row_count_start\",\n",
    "    \"training_accuracy_score\", \"training_f1_score\", \"training_log_loss\",\n",
    "    \"training_precision_score\", \"training_recall_score\", \"training_roc_auc\", \"training_score\",\n",
    "    \"justification_bootstrap\", \"justification_class_weight\", \"justification_criterion\",\n",
    "    \"justification_dataset_version\", \"justification_drop_column_x\", \"justification_ethical_considerations\",\n",
    "    \"justification_experiment_name\", \"justification_intended_use\", \"justification_max_depth\",\n",
    "    \"justification_max_features\", \"justification_metric_choice\", \"justification_min_samples_leaf\",\n",
    "    \"justification_min_samples_split\", \"justification_model_choice\", \"justification_model_limitations\",\n",
    "    \"justification_not_intended_for\", \"justification_n_estimators\", \"justification_n_jobs\",\n",
    "    \"justification_oob_score\", \"justification_target_variable\", \"justification_test_split\",\n",
    "    \"justification_threshold_accuracy\", \"justification_verbose\"\n",
    "}\n",
    "\n",
    "# --- Build raw payload from JSON ---\n",
    "raw_payload = {\n",
    "    \"run_id\": meta.get(\"run_id\", \"unknown_run\"),\n",
    "    **meta.get(\"metrics\", {}),\n",
    "    **{\n",
    "        k: v for k, v in meta.get(\"tags\", {}).items()\n",
    "        if k.startswith(\"justification_\") or k.startswith(\"justification_MLSEA_\")\n",
    "    }\n",
    "}\n",
    "\n",
    "# --- Normalize keys and filter only valid ones ---\n",
    "clean_payload = {\n",
    "    k.lower(): v for k, v in raw_payload.items()\n",
    "    if k.lower() in allowed_fields\n",
    "}\n",
    "\n",
    "# --- POST request ---\n",
    "metrics_url = f\"{BASE}/{TABLES['justification_metadata']}/data\"\n",
    "response = requests.post(\n",
    "    metrics_url,\n",
    "    headers=headers,\n",
    "    auth=auth,\n",
    "    json={\"data\": clean_payload}\n",
    ")\n",
    "\n",
    "# --- Log Result ---\n",
    "print(\"\\nüîç Cleaned Metrics + Justification POST\")\n",
    "print(\"‚û°Ô∏è URL:\", metrics_url)\n",
    "print(\"üì¶ Payload:\")\n",
    "# print(json.dumps(clean_payload, indent=2))\n",
    "print(\"üì§ Status Code:\", response.status_code)\n",
    "print(\"üìù Response Text:\", response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d29f3d37-d830-40b8-a147-dcdc1c491fab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nüîé Cross-Reference MLflow Run Metadata from All Tables in Local DB\\n\\nThis script fetches and cross-references metadata records for a specific `run_id`\\nacross multiple database tables in a local VRE system via REST API.\\n\\nIt attempts to:\\n- Retrieve all records from the six defined metadata tables (session, experiment, git, dataset, model, metrics).\\n- Match each table's relevant entry based on foreign key references from `experiment_metadata`.\\n- Collect matched records in a dictionary (`table_objects`) and print them in a structured JSON format.\\n\\nUseful for:\\n- Debugging provenance trace for a single run\\n- Verifying if all expected metadata entries were successfully stored\\n- Inspecting broken or incomplete relationships between tables\\n\\nNote:\\n- Assumes `run_id` is defined and valid\\n- Queries the API at `http://localhost`, expecting an accessible backend\\n\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "üîé Cross-Reference MLflow Run Metadata from All Tables in Local DB\n",
    "\n",
    "This script fetches and cross-references metadata records for a specific `run_id`\n",
    "across multiple database tables in a local VRE system via REST API.\n",
    "\n",
    "It attempts to:\n",
    "- Retrieve all records from the six defined metadata tables (session, experiment, git, dataset, model, metrics).\n",
    "- Match each table's relevant entry based on foreign key references from `experiment_metadata`.\n",
    "- Collect matched records in a dictionary (`table_objects`) and print them in a structured JSON format.\n",
    "\n",
    "Useful for:\n",
    "- Debugging provenance trace for a single run\n",
    "- Verifying if all expected metadata entries were successfully stored\n",
    "- Inspecting broken or incomplete relationships between tables\n",
    "\n",
    "Note:\n",
    "- Assumes `run_id` is defined and valid\n",
    "- Queries the API at `http://localhost`, expecting an accessible backend\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ee29480c-3428-4ffe-b326-e0d4b2744a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Constants\n",
    "DB_ID = \"003080b8-13d7-4cd1-86a6-b6b1b1e025b9\"\n",
    "HEADERS = {\"Accept\": \"application/json\"}\n",
    "# BASE = \"http://localhost/api/database/003080b8-13d7-4cd1-86a6-b6b1b1e025b9/table\"\n",
    "TABLES = {\n",
    "    \"session_metadata\": \"2cc388fc-7cb7-46de-88a6-aebdff9f1a2a\",\n",
    "    \"experiment_metadata\": \"ad2257b4-a339-410f-9cf0-966f1f5a0a9d\",\n",
    "    \"git_metadata\": \"5c9d4d81-9d36-4d0f-902b-46fcb051c454\",\n",
    "    \"dataset_metadata\": \"54449d09-5513-4b0b-8221-8d601e811fda\",\n",
    "    \"model_metadata\": \"dfdbcdfa-b1fa-40fb-87d2-993e9b43fe69\",\n",
    "    \"justification_metadata\": \"d6bdb07a-e60b-4f3d-bca8-4a132aa9fc75\"\n",
    "}\n",
    "# Replace this with your actual run ID\n",
    "run_id = run_id\n",
    "\n",
    "# Dictionary to store results\n",
    "table_objects = {}\n",
    "\n",
    "# Step 1: Fetch experiment_metadata first\n",
    "try:\n",
    "    url = f\"http://localhost/api/database/{DB_ID}/table/{TABLES['experiment_metadata']}/data?size=100000&page=0\"\n",
    "    r = requests.get(url, headers=HEADERS)\n",
    "    r.raise_for_status()\n",
    "    records = r.json()\n",
    "    experiment = next((x for x in records if x.get(\"runid\") == run_id), None)\n",
    "    table_objects[\"experiment_metadata\"] = experiment or \"‚ùå No match for experiment_metadata\"\n",
    "except Exception as e:\n",
    "    experiment = None\n",
    "    table_objects[\"experiment_metadata\"] = f\"‚ö†Ô∏è Request failed: {e}\"\n",
    "\n",
    "# Step 2: Extract related identifiers\n",
    "sid = experiment.get(\"sessionid\") if experiment else None\n",
    "mid = experiment.get(\"modelid\") if experiment else None\n",
    "did = experiment.get(\"datasetid\") if experiment else None\n",
    "ghash = experiment.get(\"git_commit\") if experiment else None\n",
    "\n",
    "# Step 3: Fetch the rest of the metadata tables\n",
    "for table, table_id in TABLES.items():\n",
    "    if table == \"experiment_metadata\":\n",
    "        continue  # already handled\n",
    "\n",
    "    url = f\"http://localhost/api/database/{DB_ID}/table/{table_id}/data?size=100000&page=0\"\n",
    "    try:\n",
    "        r = requests.get(url, headers=HEADERS)\n",
    "        r.raise_for_status()\n",
    "        records = r.json()\n",
    "\n",
    "        if table == \"justification_metadata\":\n",
    "            match = next((x for x in records if x.get(\"run_id\") == run_id), None)\n",
    "        elif table == \"model_metadata\":\n",
    "            match = next((x for x in records if x.get(\"model_id\") == mid), None)\n",
    "        elif table == \"dataset_metadata\":\n",
    "            match = next((x for x in records if x.get(\"dataset_guid\") == did), None)\n",
    "        elif table == \"session_metadata\":\n",
    "            if not sid:\n",
    "                match = None\n",
    "            else:\n",
    "               sid = str(sid).strip()\n",
    "            match = next((x for x in records if str(x.get(\"session_id\", \"\")).strip() == sid), None)\n",
    "\n",
    "\n",
    "        elif table == \"git_metadata\":\n",
    "            match = next((x for x in records if x.get(\"commit_hash\") == ghash), None)\n",
    "        else:\n",
    "            match = None\n",
    "\n",
    "        table_objects[table] = match or f\"‚ùå No match for {table}\"\n",
    "\n",
    "    except Exception as e:\n",
    "        table_objects[table] = f\"‚ö†Ô∏è Request failed: {e}\"\n",
    "\n",
    "# # Step 4: Save the results to a file\n",
    "# output_path = f\"run_metadata_trace_{run_id}.json\"\n",
    "# with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "#     json.dump(table_objects, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "# print(f\"‚úÖ Metadata trace saved to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3af02016-3e12-4745-a612-de0ac1bc4411",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'experiment_metadata': {'runid': '97490d0e514b47c880fdf101a73faa69',\n",
       "  'sessionid': '8bcc7998-eab4-4389-92f2-da58da349ff1',\n",
       "  'modelid': 'model_randomforest_iris_v20250629_142249_20250629_142249',\n",
       "  'datasetid': '7d9056d2-b695-4295-bb24-9e5f5df52408',\n",
       "  'git_commit': '7408cb11e43739dfed7246b9cdd3ff2e74abc4a8',\n",
       "  'invenioid': '10.24432/C56C76',\n",
       "  'timestamp': '2025-06-29 12:22:44.0',\n",
       "  'run_name': 'amazing-pig-662',\n",
       "  'experiment_id': 'None_specified',\n",
       "  'training_start_time': '2025-06-29T14:22:49.455909',\n",
       "  'training_end_time': '2025-06-29T14:26:39.023396',\n",
       "  'source_file': 'C:\\\\Users\\\\reema\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\site-packages\\\\ipykernel_launcher.py',\n",
       "  'source_notebook': 'RQ1_2.ipynb'},\n",
       " 'session_metadata': {'session_id': '8bcc7998-eab4-4389-92f2-da58da349ff1',\n",
       "  'username': 'reema',\n",
       "  'timestamp': '2025-06-29T12:22:44.560333',\n",
       "  'hostname': 'Purplish',\n",
       "  'platform': 'Windows',\n",
       "  'python_version': '3.11.5',\n",
       "  'os_platform': 'Windows 10',\n",
       "  'role': 'collaborator',\n",
       "  'project_id': 'default_project',\n",
       "  'script_name': 'None_specified'},\n",
       " 'git_metadata': {'commit_hash': '7408cb11e43739dfed7246b9cdd3ff2e74abc4a8',\n",
       "  'repo_url': 'https://archive.ics.uci.edu/dataset/53',\n",
       "  'branch': 'main',\n",
       "  'author': 'Reema George',\n",
       "  'author_email': '106236154+reema-dass26@users.noreply.github.com',\n",
       "  'version': 'v67',\n",
       "  'origin_url': 'None_specified',\n",
       "  'timestamp': '2025-06-29T12:22:44.560333'},\n",
       " 'dataset_metadata': {'dataset_guid': '7d9056d2-b695-4295-bb24-9e5f5df52408',\n",
       "  'dataset_id': '2adcf367-baec-43eb-8a7c-8340578beb79',\n",
       "  'table_name': 'iris_v1',\n",
       "  'detailed_type': 'CSV',\n",
       "  'classes': '3',\n",
       "  'features': '4',\n",
       "  'output_type': 'categorical',\n",
       "  'version': 'v1',\n",
       "  'source_url': 'https://archive.ics.uci.edu/dataset/53',\n",
       "  'title': 'Iris',\n",
       "  'description': 'https://archive.ics.uci.edu/dataset/53',\n",
       "  'license': 'info not available',\n",
       "  'creator': 'R. A. Fisher',\n",
       "  'created': '2023-03-16 12:57:44',\n",
       "  'updated': '2025-04-18 08:55:20',\n",
       "  'publisher': 'UCI Machine Learning Repository',\n",
       "  'publication_year': '1936',\n",
       "  'language': 'unknown',\n",
       "  'citation_count': '23',\n",
       "  'subjects': 'info not available',\n",
       "  'related_resources': '\"[]\"',\n",
       "  'schema_version': 'http://datacite.org/schema/kernel-4',\n",
       "  'registered': '2023-03-16 12:57:45',\n",
       "  'citations_over_time': '\"[{\\\\\"year\\\\\": \\\\\"2023\\\\\", \\\\\"total\\\\\": 5}, {\\\\\"year\\\\\": \\\\\"2024\\\\\", \\\\\"total\\\\\": 11}, {\\\\\"year\\\\\": \\\\\"2025\\\\\", \\\\\"total\\\\\": 7}]\"'},\n",
       " 'model_metadata': {'model_id': 'model_randomforest_iris_v20250629_142249_20250629_142249',\n",
       "  'name': 'RandomForest_Iris_v20250629_142249',\n",
       "  'algo': 'RandomForestClassifier',\n",
       "  'architecture': 'RandomForestClassifier',\n",
       "  'features': \"['sepallengthcm', 'sepalwidthcm', 'petallengthcm', 'petalwidthcm']\",\n",
       "  'label_snap': 'species',\n",
       "  'train_split': '0.800000000000000000',\n",
       "  'test_split': '0.200000000000000000',\n",
       "  'target_var': 'species',\n",
       "  'label_map': '{\"0\": \"Iris-setosa\", \"1\": \"Iris-versicolor\", \"2\": \"Iris-virginica\"}',\n",
       "  'feature_select': 'id,sepallengthcm,sepalwidthcm,petallengthcm,petalwidthcm',\n",
       "  'imbalance_ratio': '1.000000000000000000',\n",
       "  'version': 'v67',\n",
       "  'serialization_format': 'pickle',\n",
       "  'model_path': 'RandomForest_Iris_v20250629_142249.pkl',\n",
       "  'model_short_name': 'random_forest',\n",
       "  'hyperparameters': '{\"n_estimators\": 100, \"criterion\": \"entropy\", \"max_depth\": 10, \"min_samples_split\": 3, \"min_samples_leaf\": 1, \"max_features\": \"sqrt\", \"bootstrap\": true, \"oob_score\": true, \"class_weight\": null, \"verbose\": 1, \"n_jobs\": -1}',\n",
       "  'preprocessing_info': '{\"dropped_columns\": [\"id\"], \"numeric_columns\": [\"sepallengthcm\", \"sepalwidthcm\", \"petallengthcm\", \"petalwidthcm\"], \"target_column\": \"species\", \"stratified\": false, \"coercion_strategy\": \"Numeric cast (auto)\", \"feature_engineering\": \"None\", \"missing_value_strategy\": \"None\", \"outlier_detection\": \"None\", \"encoding_strategy\": \"LabelEncoder (target only)\", \"scaling\": \"None\", \"sampling\": \"None\", \"feature_selection\": \"None\", \"train_test_split\": {\"test_size\": 0.2, \"random_state\": 42}, \"imbalance_ratio\": \"{0: 50, 1: 50, 2: 50}\", \"preprocessing_timestamp\": \"2025-06-29T14:26:53.454724\"}'},\n",
       " 'justification_metadata': {'run_id': '97490d0e514b47c880fdf101a73faa69',\n",
       "  'accuracy': '1.000000000000000000',\n",
       "  'f1_macro': '1.000000000000000000',\n",
       "  'num_deleted_rows': '0E-18',\n",
       "  'num_inserted_rows': '0E-18',\n",
       "  'precision_macro': '1.000000000000000000',\n",
       "  'recall_macro': '1.000000000000000000',\n",
       "  'roc_auc': '1.000000000000000000',\n",
       "  'row_count_end': '150.000000000000000000',\n",
       "  'row_count_start': '150.000000000000000000',\n",
       "  'training_accuracy_score': '1.000000000000000000',\n",
       "  'training_f1_score': '1.000000000000000000',\n",
       "  'training_log_loss': '0.041690251533094226',\n",
       "  'training_precision_score': '1.000000000000000000',\n",
       "  'training_recall_score': '1.000000000000000000',\n",
       "  'training_roc_auc': '1.000000000000000000',\n",
       "  'training_score': '1.000000000000000000',\n",
       "  'justification_bootstrap': 'No justification provided',\n",
       "  'justification_class_weight': 'No justification provided',\n",
       "  'justification_criterion': 'No justification provided',\n",
       "  'justification_dataset_version': 'No justification provided',\n",
       "  'justification_drop_column_x': 'No justification provided',\n",
       "  'justification_ethical_considerations': 'No justification provided',\n",
       "  'justification_experiment_name': 'No justification provided',\n",
       "  'justification_intended_use': 'No justification provided',\n",
       "  'justification_max_depth': 'No justification provided',\n",
       "  'justification_max_features': 'No justification provided',\n",
       "  'justification_metric_choice': 'No justification provided',\n",
       "  'justification_min_samples_leaf': 'No justification provided',\n",
       "  'justification_min_samples_split': 'No justification provided',\n",
       "  'justification_model_choice': 'No justification provided',\n",
       "  'justification_model_limitations': 'No justification provided',\n",
       "  'justification_not_intended_for': 'No justification provided',\n",
       "  'justification_n_estimators': 'No justification provided',\n",
       "  'justification_n_jobs': 'No justification provided',\n",
       "  'justification_oob_score': 'No justification provided',\n",
       "  'justification_target_variable': 'No justification provided',\n",
       "  'justification_test_split': 'No justification provided',\n",
       "  'justification_threshold_accuracy': 'No justification provided',\n",
       "  'justification_verbose': 'No justification provided'}}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287f4057-4b08-4dd3-91ce-7b5b51a729f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fc084d1d-a570-4f53-bd27-d95dcc068d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_structured_metadata(data: dict) -> dict:\n",
    "    structured = {\n",
    "        \"FAIR\": {},\n",
    "        \"FAIR4ML\": {},\n",
    "        \"MLSEA\": {},\n",
    "        \"Croissant\": {},\n",
    "        \"PROV-O\": {},\n",
    "        \"Uncategorized\": {}\n",
    "    }\n",
    "\n",
    "    ds = data.get(\"dataset_metadata\", {})\n",
    "    model = data.get(\"model_metadata\", {})\n",
    "    just = data.get(\"justification_metadata\", {})\n",
    "    exp = data.get(\"experiment_metadata\", {})\n",
    "    session = data.get(\"session_metadata\", {})\n",
    "    git = data.get(\"git_metadata\", {})\n",
    "\n",
    "    # FAIR\n",
    "    structured[\"FAIR\"].update({\n",
    "        \"identifier\": ds.get(\"dataset_id\"),\n",
    "        \"title\": ds.get(\"title\"),\n",
    "        \"description\": ds.get(\"description\"),\n",
    "        \"creator\": ds.get(\"creator\"),\n",
    "        \"license\": ds.get(\"license\"),\n",
    "        \"version\": ds.get(\"version\"),\n",
    "        \"created\": ds.get(\"created\"),\n",
    "        \"updated\": ds.get(\"updated\"),\n",
    "        \"url\": ds.get(\"source_url\"),\n",
    "        \"publisher\": ds.get(\"publisher\"),\n",
    "        \"publication_year\": ds.get(\"publication_year\"),\n",
    "        \"language\": ds.get(\"language\"),\n",
    "        \"citation_count\": ds.get(\"citation_count\"),\n",
    "        \"subject\": ds.get(\"subjects\"),\n",
    "        \"related_resources\": ds.get(\"related_resources\"),\n",
    "        \"schema_version\": ds.get(\"schema_version\"),\n",
    "        \"registered\": ds.get(\"registered\"),\n",
    "        \"citations_over_time\": ds.get(\"citations_over_time\"),\n",
    "        \"issued\": ds.get(\"publication_year\")\n",
    "    })\n",
    "\n",
    "    # FAIR4ML\n",
    "    structured[\"FAIR4ML\"].update({\n",
    "        \"experiment_id\": exp.get(\"experiment_id\"),\n",
    "        \"run_id\": exp.get(\"runid\"),\n",
    "        \"session_id\": exp.get(\"sessionid\"),\n",
    "        \"model_id\": exp.get(\"modelid\"),\n",
    "        \"dataset_id\": exp.get(\"datasetid\"),\n",
    "        \"trainedOn\": ds.get(\"title\"),\n",
    "        \"modelType\": \"Classifier\",\n",
    "        \"invenio_id\": exp.get(\"invenioid\"),\n",
    "        \"trainingStartTime\": exp.get(\"training_start_time\"),\n",
    "        \"trainingEndTime\": exp.get(\"training_end_time\"),\n",
    "        \"targetVariable\": model.get(\"target_var\"),\n",
    "        \"trainingScriptVersion\": git.get(\"commit_hash\"),\n",
    "        \"runEnvironment\": f\"{session.get('os_platform')} | Python {session.get('python_version')}\"\n",
    "    })\n",
    "\n",
    "    # PROV-O\n",
    "    structured[\"PROV-O\"].update({\n",
    "        \"Entity\": ds.get(\"dataset_id\"),\n",
    "        \"Activity\": exp.get(\"runid\"),\n",
    "        \"Agent\": session.get(\"username\"),\n",
    "        \"wasGeneratedBy\": exp.get(\"runid\"),\n",
    "        \"wasAssociatedWith\": session.get(\"project_id\"),\n",
    "        \"startedAtTime\": exp.get(\"training_start_time\"),\n",
    "        \"endedAtTime\": exp.get(\"training_end_time\"),\n",
    "        \"used\": exp.get(\"source_file\"),\n",
    "        \"usedNotebook\": exp.get(\"source_notebook\"),\n",
    "        \"session_id\": session.get(\"session_id\"),\n",
    "        \"hostname\": session.get(\"hostname\"),\n",
    "        \"platform\": session.get(\"platform\"),\n",
    "        \"python_version\": session.get(\"python_version\"),\n",
    "        \"os_platform\": session.get(\"os_platform\"),\n",
    "        \"role\": session.get(\"role\"),\n",
    "        \"script_name\": session.get(\"script_name\"),\n",
    "        \"git_commit\": exp.get(\"git_commit\"),\n",
    "        \"git_timestamp\": git.get(\"timestamp\"),\n",
    "        \"git_author\": git.get(\"author\"),\n",
    "        \"git_email\": git.get(\"author_email\"),\n",
    "        \"git_branch\": git.get(\"branch\"),\n",
    "        \"git_repo\": git.get(\"repo_url\")\n",
    "    })\n",
    "\n",
    "    # MLSEA ‚Äì includes metrics, justifications, and splits\n",
    "    structured[\"MLSEA\"].update({\n",
    "        k: v for k, v in just.items()\n",
    "        if any(metric in k for metric in [\n",
    "            \"score\", \"accuracy\", \"f1\", \"roc\", \"precision\", \"recall\",\n",
    "            \"log_loss\", \"row_count\", \"num_deleted\", \"num_inserted\", \"justification_\"\n",
    "        ])\n",
    "    })\n",
    "    structured[\"MLSEA\"].update({\n",
    "        \"train_split\": model.get(\"train_split\"),\n",
    "        \"test_split\": model.get(\"test_split\"),\n",
    "        \"feature_select\": model.get(\"feature_select\"),\n",
    "        \"label_map\": model.get(\"label_map\"),\n",
    "        \"imbalance_ratio\": model.get(\"imbalance_ratio\")\n",
    "    })\n",
    "\n",
    "    # Croissant\n",
    "    structured[\"Croissant\"].update({\n",
    "        \"model_id\": model.get(\"model_id\"),\n",
    "        \"name\": model.get(\"name\"),\n",
    "        \"algo\": model.get(\"algo\"),\n",
    "        \"architecture\": model.get(\"architecture\"),\n",
    "        \"features\": model.get(\"features\"),\n",
    "        \"target_variable\": model.get(\"target_var\"),\n",
    "        \"label_encoding\": model.get(\"label_snap\"),\n",
    "        \"model_path\": model.get(\"model_path\"),\n",
    "        \"serialization_format\": model.get(\"serialization_format\"),\n",
    "        \"model_version\": model.get(\"version\"),\n",
    "        \"hyperparameters\": model.get(\"hyperparameters\"),\n",
    "        \"preprocessing_info\": model.get(\"preprocessing_info\"),\n",
    "        \"hasInput\": ds.get(\"title\"),\n",
    "        \"hasOutput\": ds.get(\"output_type\")\n",
    "    })\n",
    "\n",
    "    # Uncategorized\n",
    "    structured[\"Uncategorized\"].update({\n",
    "        \"run_name\": exp.get(\"run_name\"),\n",
    "        \"origin_url\": git.get(\"origin_url\"),\n",
    "    })\n",
    "\n",
    "    return structured\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c7a8ad8a-70c6-4871-a6c9-9f6de8199f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_structured_metadata(structured: dict) -> dict:\n",
    "    rename_map = {\n",
    "        \"FAIR\": {\n",
    "            \"identifier\": \"dcterms:identifier\",\n",
    "            \"title\": \"dc:title\",\n",
    "            \"description\": \"dc:description\",\n",
    "            \"creator\": \"dc:creator\",\n",
    "            \"license\": \"dc:license\",\n",
    "            \"version\": \"dcterms:hasVersion\",\n",
    "            \"created\": \"dcterms:created\",\n",
    "            \"updated\": \"dcterms:modified\",\n",
    "            \"url\": \"dcat:landingPage\",\n",
    "            \"publisher\": \"dc:publisher\",\n",
    "            \"publication_year\": \"dcterms:issued\",\n",
    "            \"language\": \"dc:language\",\n",
    "            \"citation_count\": \"dcat:citationCount\",\n",
    "            \"subject\": \"dc:subject\",\n",
    "            \"related_resources\": \"dcat:relatedResource\",\n",
    "            \"schema_version\": \"dcat:schemaVersion\",\n",
    "            \"registered\": \"dcat:registered\",\n",
    "            \"citations_over_time\": \"dcat:citationsOverTime\",\n",
    "            \"issued\": \"dcterms:issued\"\n",
    "        },\n",
    "\n",
    "        \"FAIR4ML\": {\n",
    "            \"experiment_id\": \"fair4ml:experimentID\",\n",
    "            \"run_id\": \"fair4ml:runID\",\n",
    "            \"session_id\": \"fair4ml:sessionID\",\n",
    "            \"model_id\": \"fair4ml:modelID\",\n",
    "            \"dataset_id\": \"fair4ml:datasetID\",\n",
    "            \"trainedOn\": \"fair4ml:trainedOn\",\n",
    "            \"modelType\": \"fair4ml:modelType\",\n",
    "            \"invenio_id\": \"dcterms:source\",\n",
    "            \"trainingStartTime\": \"fair4ml:trainingStartTime\",\n",
    "            \"trainingEndTime\": \"fair4ml:trainingEndTime\",\n",
    "            \"targetVariable\": \"fair4ml:targetVariable\",\n",
    "            \"trainingScriptVersion\": \"fair4ml:trainingScriptVersion\",\n",
    "            \"runEnvironment\": \"fair4ml:runEnvironment\"\n",
    "        },\n",
    "\n",
    "        \"PROV-O\": {\n",
    "            \"Entity\": \"prov:Entity\",\n",
    "            \"Activity\": \"prov:Activity\",\n",
    "            \"Agent\": \"prov:Agent\",\n",
    "            \"wasGeneratedBy\": \"prov:wasGeneratedBy\",\n",
    "            \"wasAssociatedWith\": \"prov:wasAssociatedWith\",\n",
    "            \"startedAtTime\": \"prov:startedAtTime\",\n",
    "            \"endedAtTime\": \"prov:endedAtTime\",\n",
    "            \"used\": \"prov:used\",\n",
    "            \"usedNotebook\": \"fair4ml:usedNotebook\",\n",
    "            \"session_id\": \"prov:sessionID\",\n",
    "            \"hostname\": \"prov:location\",\n",
    "            \"platform\": \"prov:platform\",\n",
    "            \"python_version\": \"prov:pythonVersion\",\n",
    "            \"os_platform\": \"prov:osPlatform\",\n",
    "            \"role\": \"prov:role\",\n",
    "            \"script_name\": \"prov:scriptName\",\n",
    "            \"git_commit\": \"prov:commit\",\n",
    "            \"git_timestamp\": \"prov:commitTime\",\n",
    "            \"git_author\": \"prov:commitAuthor\",\n",
    "            \"git_email\": \"prov:commitEmail\",\n",
    "            \"git_branch\": \"prov:branch\",\n",
    "            \"git_repo\": \"prov:repository\"\n",
    "        },\n",
    "\n",
    "        \"MLSEA\": {\n",
    "            \"run_id\": \"mlsea:run_id\",\n",
    "            \"accuracy\": \"mlsea:accuracy\",\n",
    "            \"f1_macro\": \"mlsea:f1_score\",\n",
    "            \"precision_macro\": \"mlsea:precision\",\n",
    "            \"recall_macro\": \"mlsea:recall\",\n",
    "            \"roc_auc\": \"mlsea:roc_auc\",\n",
    "            \"training_accuracy_score\": \"mlsea:training_accuracy_score\",\n",
    "            \"training_f1_score\": \"mlsea:training_f1_score\",\n",
    "            \"training_log_loss\": \"mlsea:training_log_loss\",\n",
    "            \"training_precision_score\": \"mlsea:training_precision_score\",\n",
    "            \"training_recall_score\": \"mlsea:training_recall_score\",\n",
    "            \"training_roc_auc\": \"mlsea:training_roc_auc\",\n",
    "            \"training_score\": \"mlsea:training_score\",\n",
    "            \"row_count_start\": \"mlsea:row_count_start\",\n",
    "            \"row_count_end\": \"mlsea:row_count_end\",\n",
    "            \"num_inserted_rows\": \"mlsea:num_inserted_rows\",\n",
    "            \"num_deleted_rows\": \"mlsea:num_deleted_rows\",\n",
    "            \"train_split\": \"mlsea:trainSplit\",\n",
    "            \"test_split\": \"mlsea:testSplit\",\n",
    "            \"feature_select\": \"mlsea:featureSelection\",\n",
    "            \"label_map\": \"mlsea:labelMap\",\n",
    "            \"imbalance_ratio\": \"mlsea:imbalanceRatio\"\n",
    "        },\n",
    "\n",
    "        \"Croissant\": {\n",
    "            \"model_id\": \"mls:modelID\",\n",
    "            \"name\": \"mls:modelName\",\n",
    "            \"algo\": \"mls:learningAlgorithm\",\n",
    "            \"architecture\": \"mls:modelArchitecture\",\n",
    "            \"features\": \"mls:featureList\",\n",
    "            \"target_variable\": \"mls:targetVariable\",\n",
    "            \"label_encoding\": \"mls:labelEncoding\",\n",
    "            \"model_path\": \"mls:modelPath\",\n",
    "            \"serialization_format\": \"mls:serializationFormat\",\n",
    "            \"model_version\": \"mls:modelVersion\",\n",
    "            \"hyperparameters\": \"mls:hyperparameters\",\n",
    "            \"preprocessing_info\": \"mls:preprocessingSteps\",\n",
    "            \"hasInput\": \"mls:hasInput\",\n",
    "            \"hasOutput\": \"mls:hasOutput\"\n",
    "        }\n",
    "    }\n",
    "\n",
    "    renamed = {}\n",
    "    for category, fields in structured.items():\n",
    "        renamed_fields = {}\n",
    "        for k, v in fields.items():\n",
    "            new_key = rename_map.get(category, {}).get(k, k)  # fallback to original if not mapped\n",
    "            renamed_fields[new_key] = v\n",
    "        renamed[category] = renamed_fields\n",
    "\n",
    "    return renamed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3e0ecc-5acb-43dd-81f4-46cf1385bca2",
   "metadata": {},
   "source": [
    "test code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b65e6a76-b659-4d5e-8e23-c08bb18ac734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_structured_metadata(data: dict) -> dict:\n",
    "#     structured = {\n",
    "#         \"FAIR\": {},\n",
    "#         \"FAIR4ML\": {},\n",
    "#         \"MLSEA\": {},\n",
    "#         \"Croissant\": {},\n",
    "#         \"Uncategorized\": {}\n",
    "#     }\n",
    "\n",
    "#     ds = data.get(\"dataset_metadata\", {})\n",
    "#     exp = data.get(\"experiment_metadata\", {})\n",
    "#     session = data.get(\"session_metadata\", {})\n",
    "\n",
    "#     # FAIR\n",
    "#     structured[\"FAIR\"].update({\n",
    "#         \"identifier\": ds.get(\"dataset_id\"),\n",
    "#         \"title\": ds.get(\"title\"),\n",
    "#         \"description\": ds.get(\"description\"),\n",
    "#         \"creator\": ds.get(\"creator\"),\n",
    "#         \"license\": ds.get(\"license\"),\n",
    "#         \"version\": ds.get(\"version\"),\n",
    "#         \"created\": ds.get(\"created\"),\n",
    "#         \"updated\": ds.get(\"updated\"),\n",
    "#         \"url\": ds.get(\"source_url\"),\n",
    "#         \"publisher\": ds.get(\"publisher\"),\n",
    "#         \"publication_year\": ds.get(\"publication_year\"),\n",
    "#         \"language\": ds.get(\"language\"),\n",
    "#         \"citation_count\": ds.get(\"citation_count\"),\n",
    "#         \"subject\": ds.get(\"subjects\"),\n",
    "#         \"related_resources\": ds.get(\"related_resources\"),\n",
    "#         \"schema_version\": ds.get(\"schema_version\"),\n",
    "#         \"registered\": ds.get(\"registered\"),\n",
    "#         \"citations_over_time\": ds.get(\"citations_over_time\"),\n",
    "#         \"issued\": ds.get(\"publication_year\")\n",
    "#     })\n",
    "\n",
    "#     # FAIR4ML\n",
    "#     structured[\"FAIR4ML\"].update({\n",
    "#         \"experiment_id\": exp.get(\"experiment_id\"),\n",
    "#         \"run_id\": exp.get(\"runid\"),\n",
    "#         \"session_id\": exp.get(\"sessionid\"),\n",
    "#         \"model_id\": exp.get(\"modelid\"),\n",
    "#         \"dataset_id\": exp.get(\"datasetid\"),\n",
    "#         \"timestamp\": exp.get(\"timestamp\"),\n",
    "#         \"training_start_time\": exp.get(\"training_start_time\"),\n",
    "#         \"training_end_time\": exp.get(\"training_end_time\"),\n",
    "#         \"source_file\": exp.get(\"source_file\"),\n",
    "#         \"source_notebook\": exp.get(\"source_notebook\"),\n",
    "#         \"invenio_id\": exp.get(\"invenioid\"),\n",
    "#         \"trainedOn\": ds.get(\"title\", \"Unknown Dataset\"),\n",
    "#         \"Entity\": ds.get(\"dataset_id\", \"Unknown Entity\"),\n",
    "#         \"Activity\": exp.get(\"experiment_id\", \"Unknown Activity\"),\n",
    "#         \"Agent\": session.get(\"username\", \"Unknown Agent\"),\n",
    "#         \"wasGeneratedBy\": exp.get(\"runid\", \"Unknown Run ID\"),\n",
    "#         \"wasAssociatedWith\": session.get(\"project_id\"),  # NEW\n",
    "#         \"modelType\": \"Classifier\" ,                       # NEW\n",
    "#         \"wasAssociatedWith\": session.get(\"project_id\", \"Unknown Project\")\n",
    "\n",
    "#     })\n",
    "\n",
    "#     # MLSEA\n",
    "#     if \"justification_metadata\" in data:\n",
    "#         metrics = data[\"justification_metadata\"]\n",
    "#         structured[\"MLSEA\"].update({\n",
    "#             k: v for k, v in metrics.items()\n",
    "#             if any(key in k for key in [\"score\", \"accuracy\", \"f1\", \"roc\", \"precision\", \"recall\", \"log_loss\", \"justification_\"])\n",
    "#         })\n",
    "\n",
    "#     # Croissant\n",
    "#     if \"model_metadata\" in data:\n",
    "#         model = data[\"model_metadata\"]\n",
    "#         structured[\"Croissant\"].update({\n",
    "#             \"model_id\": model.get(\"model_id\"),\n",
    "#             \"name\": model.get(\"name\"),\n",
    "#             \"algo\": model.get(\"algo\"),\n",
    "#             \"architecture\": model.get(\"architecture\"),\n",
    "#             \"features\": model.get(\"features\"),\n",
    "#             \"target_variable\": model.get(\"target_var\"),\n",
    "#             \"label_encoding\": model.get(\"label_snap\"),\n",
    "#             \"model_path\": model.get(\"model_path\"),\n",
    "#             \"serialization_format\": model.get(\"serialization_format\"),\n",
    "#             \"model_version\": model.get(\"version\"),\n",
    "#             \"hyperparameters\": model.get(\"hyperparameters\"),\n",
    "#             \"preprocessing_info\": model.get(\"preprocessing_info\"),\n",
    "#             \"hasInput\": ds.get(\"title\", \"Unknown Dataset\"),\n",
    "#             \"hasOutput\": ds.get(\"output_type\", \"Predicted Output\")\n",
    "#         })\n",
    "\n",
    "#     # Uncategorized\n",
    "#     structured[\"Uncategorized\"][\"session_metadata\"] = session\n",
    "#     structured[\"Uncategorized\"][\"git_metadata\"] = data.get(\"git_metadata\", {})\n",
    "\n",
    "#     return structured\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "111ed1ec-7940-4737-9533-f9c04c8b3a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def rename_structured_metadata(structured: dict) -> dict:\n",
    "#     rename_map = {\n",
    "#         \"FAIR\": {\n",
    "#             \"identifier\": \"dcterms:identifier\",\n",
    "#             \"title\": \"dc:title\",\n",
    "#             \"description\": \"dc:description\",\n",
    "#             \"creator\": \"dc:creator\",\n",
    "#             \"license\": \"dc:license\",\n",
    "#             \"version\": \"dcterms:hasVersion\",\n",
    "#             \"created\": \"dcterms:created\",\n",
    "#             \"updated\": \"dcterms:modified\",\n",
    "#             \"url\": \"dcat:landingPage\",\n",
    "#             \"language\": \"dc:language\",\n",
    "#             \"publisher\": \"dc:publisher\",\n",
    "#             \"subject\": \"dc:subject\",\n",
    "#             \"issued\": \"dc:issued\"\n",
    "#         },\n",
    "#         \"FAIR4ML\": {\n",
    "#             \"experiment_id\": \"fair4ml:experimentID\",\n",
    "#             \"run_id\": \"fair4ml:runID\",\n",
    "#             \"session_id\": \"fair4ml:sessionID\",\n",
    "#             \"model_id\": \"fair4ml:modelID\",\n",
    "#             \"dataset_id\": \"fair4ml:datasetID\",\n",
    "#             \"timestamp\": \"prov:startedAtTime\",\n",
    "#             \"training_start_time\": \"fair4ml:trainingStartTime\",\n",
    "#             \"training_end_time\": \"fair4ml:trainingEndTime\",\n",
    "#             \"source_file\": \"prov:usedFile\",\n",
    "#             \"source_notebook\": \"fair4ml:usedNotebook\",\n",
    "#             \"invenio_id\": \"dcterms:source\",\n",
    "#             \"trainedOn\": \"fair4ml:trainedOn\",\n",
    "#             \"Entity\": \"prov:Entity\",\n",
    "#             \"Activity\": \"prov:Activity\",\n",
    "#             \"Agent\": \"prov:Agent\",\n",
    "#             \"wasGeneratedBy\": \"prov:wasGeneratedBy\",\n",
    "#             \"wasAssociatedWith\": \"prov:wasAssociatedWith\",  # NEW\n",
    "#             \"modelType\": \"fair4ml:modelType\"   ,             # NEW\n",
    "#             \"wasAssociatedWith\": \"prov:wasAssociatedWith\",\n",
    "\n",
    "\n",
    "#         },\n",
    "#         \"MLSEA\": {\n",
    "#             \"run_id\": \"mlsea:run_id\",\n",
    "#             \"accuracy\": \"mlsea:accuracy\",\n",
    "#             \"f1_macro\": \"mlsea:f1_macro\",\n",
    "#             \"precision_macro\": \"mlsea:precision_macro\",\n",
    "#             \"recall_macro\": \"mlsea:recall_macro\",\n",
    "#             \"roc_auc\": \"mlsea:roc_auc\",\n",
    "#             \"training_accuracy_score\": \"mlsea:training_accuracy_score\",\n",
    "#             \"training_f1_score\": \"mlsea:training_f1_score\",\n",
    "#             \"training_log_loss\": \"mlsea:training_log_loss\",\n",
    "#             \"training_precision_score\": \"mlsea:training_precision_score\",\n",
    "#             \"training_recall_score\": \"mlsea:training_recall_score\",\n",
    "#             \"training_roc_auc\": \"mlsea:training_roc_auc\",\n",
    "#             \"training_score\": \"mlsea:training_score\",\n",
    "#             \"row_count_start\": \"mlsea:row_count_start\",\n",
    "#             \"row_count_end\": \"mlsea:row_count_end\",\n",
    "#             \"num_inserted_rows\": \"mlsea:num_inserted_rows\",\n",
    "#             \"num_deleted_rows\": \"mlsea:num_deleted_rows\"\n",
    "#         },\n",
    "#         \"Croissant\": {\n",
    "#             \"model_id\": \"mls:modelID\",\n",
    "#             \"name\": \"mls:modelName\",\n",
    "#             \"algo\": \"mls:learningAlgorithm\",\n",
    "#             \"architecture\": \"mls:modelArchitecture\",\n",
    "#             \"features\": \"mls:featureList\",\n",
    "#             \"target_variable\": \"mls:targetVariable\",\n",
    "#             \"label_encoding\": \"mls:labelEncoding\",\n",
    "#             \"model_path\": \"mls:modelPath\",\n",
    "#             \"serialization_format\": \"mls:serializationFormat\",\n",
    "#             \"model_version\": \"mls:modelVersion\",\n",
    "#             \"hyperparameters\": \"mls:hyperparameters\",\n",
    "#             \"preprocessing_info\": \"mls:preprocessingSteps\",\n",
    "#             \"hasInput\": \"mls:hasInput\",\n",
    "#             \"hasOutput\": \"mls:hasOutput\"\n",
    "#         }\n",
    "#     }\n",
    "\n",
    "#     renamed = {}\n",
    "#     for category, fields in structured.items():\n",
    "#         renamed_fields = {}\n",
    "#         for k, v in fields.items():\n",
    "#             new_key = rename_map.get(category, {}).get(k, k)\n",
    "#             renamed_fields[new_key] = v\n",
    "#         renamed[category] = renamed_fields\n",
    "\n",
    "#     return renamed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea35bea-0e64-4e38-a6b2-86c32a38b5f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f59fe3b-6665-413a-a68c-d3a19a59d247",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81621bd5-163a-4817-a252-7aaf502f6310",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "35aa7801-68c0-4cbb-a897-4d69ae6c409b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Renamed metadata saved to: C:\\Users\\reema\\REPO\\notebooks\\RQ_notebooks\\MODEL_PROVENANCE\\RandomForest_Iris_v20250629_142249\\structured_metadata.json\n"
     ]
    }
   ],
   "source": [
    "structured_metadata = generate_structured_metadata(table_objects)\n",
    "renamed_metadata = rename_structured_metadata(structured_metadata)\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# Ensure summary_dir is a Path object\n",
    "summary_dir = Path(summary_dir)\n",
    "\n",
    "# Define your custom file name\n",
    "custom_name = \"structured_metadata.json\"\n",
    "\n",
    "# Create full output path\n",
    "custom_output_path = summary_dir / custom_name\n",
    "\n",
    "# Save the renamed metadata\n",
    "with open(custom_output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(renamed_metadata, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"‚úÖ Renamed metadata saved to: {custom_output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8b1938c4-b78d-4dfb-91ab-9d89ce0e1fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary_dir =\"MODEL_PROVENANCE/RandomForest_Iris_v20250616_204051\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ba895421-a512-45ac-b078-3f9eb1dc84f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datetime import datetime\n",
    "# import os\n",
    "# import json\n",
    "# from pathlib import Path\n",
    "# from rdflib import Graph, Literal, RDF, URIRef, Namespace\n",
    "# from rdflib.namespace import XSD, FOAF, PROV, DC, DCTERMS\n",
    "\n",
    "# # === Paths ===\n",
    "# summary_dir = Path(summary_dir)\n",
    "# structured_path = summary_dir / \"structured_metadata.json\"\n",
    "\n",
    "# # === Helpers ===\n",
    "# def safe_literal(value):\n",
    "#     return value not in [None, \"\", \"None_specified\", \"no justification provided\", \"‚Äî\", \"null\", \"None\"]\n",
    "\n",
    "# def iso_datetime(value):\n",
    "#     try:\n",
    "#         value = str(value).strip().replace(\" \", \"T\")\n",
    "#         dt = datetime.fromisoformat(value.split(\".\")[0])\n",
    "#         return dt.isoformat()\n",
    "#     except Exception:\n",
    "#         return None\n",
    "\n",
    "# def safe_uri(base, value):\n",
    "#     if not safe_literal(value):\n",
    "#         return None\n",
    "#     cleaned = str(value).strip().replace(\" \", \"_\").replace(\"/\", \"_\").replace(\":\", \"_\")\n",
    "#     return URIRef(base + cleaned)\n",
    "\n",
    "# # === Load table_objects if not defined ===\n",
    "# if \"table_objects\" not in globals():\n",
    "#     with open(structured_path, \"r\", encoding=\"utf-8\") as f:\n",
    "#         table_objects = json.load(f)\n",
    "\n",
    "# # === Entity extraction ===\n",
    "# experiment = table_objects.get(\"experiment_metadata\", {})\n",
    "# model = table_objects.get(\"model_metadata\", {})\n",
    "# dataset = table_objects.get(\"dataset_metadata\", {})\n",
    "# git = table_objects.get(\"git_metadata\", {})\n",
    "# session = table_objects.get(\"session_metadata\", {})\n",
    "# metrics = table_objects.get(\"justification_metadata\", {})\n",
    "\n",
    "# # === Namespaces ===\n",
    "# base_uri = f\"https://github.com/reema-dass26/ml-provenance/provenance/run_{experiment.get('runid', 'default')}/\"\n",
    "# EX = Namespace(base_uri)\n",
    "\n",
    "# g = Graph()\n",
    "# g.bind(\"prov\", PROV)\n",
    "# g.bind(\"foaf\", FOAF)\n",
    "# g.bind(\"dc\", DC)\n",
    "# g.bind(\"dcterms\", DCTERMS)\n",
    "# g.bind(\"ex\", EX)\n",
    "\n",
    "# # === Create URIs with fallback defaults ===\n",
    "# model_uri = safe_uri(EX, f\"model/{model.get('model_id')}\") or URIRef(EX[\"model/default\"])\n",
    "# dataset_uri = safe_uri(EX, f\"dataset/{experiment.get('datasetid')}\") or URIRef(EX[\"dataset/default\"])\n",
    "# code_uri = safe_uri(EX, f\"code/{git.get('commit_hash')}\") or URIRef(EX[\"code/default\"])\n",
    "# activity_uri = safe_uri(EX, f\"run/{experiment.get('runid')}\") or URIRef(EX[\"run/default\"])\n",
    "# agent_uri = safe_uri(EX, f\"agent/{session.get('username')}\") or URIRef(EX[\"agent/default\"])\n",
    "\n",
    "# # === RDF types ===\n",
    "# g.add((model_uri, RDF.type, PROV.Entity))\n",
    "# g.add((dataset_uri, RDF.type, PROV.Entity))\n",
    "# g.add((code_uri, RDF.type, PROV.Entity))\n",
    "# g.add((activity_uri, RDF.type, PROV.Activity))\n",
    "# g.add((agent_uri, RDF.type, PROV.Agent))\n",
    "# g.add((agent_uri, FOAF.name, Literal(session.get(\"username\", \"unknown\"))))\n",
    "\n",
    "# # === PROV Relationships ===\n",
    "# if safe_literal(experiment.get(\"training_start_time\")):\n",
    "#     iso_val = iso_datetime(experiment[\"training_start_time\"])\n",
    "#     if iso_val:\n",
    "#         g.add((activity_uri, PROV.startedAtTime, Literal(iso_val, datatype=XSD.dateTime)))\n",
    "\n",
    "# if safe_literal(experiment.get(\"training_end_time\")):\n",
    "#     iso_val = iso_datetime(experiment[\"training_end_time\"])\n",
    "#     if iso_val:\n",
    "#         g.add((activity_uri, PROV.endedAtTime, Literal(iso_val, datatype=XSD.dateTime)))\n",
    "\n",
    "# g.add((activity_uri, PROV.used, dataset_uri))\n",
    "# g.add((activity_uri, PROV.used, code_uri))\n",
    "# g.add((model_uri, PROV.wasGeneratedBy, activity_uri))\n",
    "# g.add((activity_uri, PROV.wasAssociatedWith, agent_uri))\n",
    "\n",
    "# # === Add all fields as literals ===\n",
    "# def add_literals(data: dict, subject):\n",
    "#     for k, v in data.items():\n",
    "#         if safe_literal(v):\n",
    "#             g.add((subject, EX[k], Literal(v)))\n",
    "\n",
    "# # Inject all segments\n",
    "# for data, uri in [\n",
    "#     (model, model_uri),\n",
    "#     (dataset, dataset_uri),\n",
    "#     (git, code_uri),\n",
    "#     (experiment, activity_uri),\n",
    "#     (session, agent_uri),\n",
    "#     (metrics, activity_uri)\n",
    "# ]:\n",
    "#     add_literals(data, uri)\n",
    "\n",
    "# # === Save RDF/JSON-LD ===\n",
    "# jsonld_path = summary_dir / \"prov_JSONLD_export.jsonld\"\n",
    "# rdfxml_path = summary_dir / \"prov_RDFXML_export.rdf\"\n",
    "\n",
    "# with open(jsonld_path, \"w\", encoding=\"utf-8\") as f:\n",
    "#     f.write(g.serialize(format=\"json-ld\", indent=2))\n",
    "\n",
    "# with open(rdfxml_path, \"wb\") as f:\n",
    "#     f.write(g.serialize(format=\"xml\", encoding=\"utf-8\"))\n",
    "\n",
    "# print(f\"‚úÖ Exported to: {jsonld_path.name}, {rdfxml_path.name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f7555efb-64b8-4aca-92e1-6fdf0bc5c81a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('prov_JSONLD_export.jsonld', 'prov_RDFXML_export.rdf')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rdflib import Graph, Literal, RDF, URIRef, Namespace\n",
    "from rdflib.namespace import XSD, FOAF, PROV, DC, DCTERMS\n",
    "from datetime import datetime\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Reload structured metadata\n",
    "summary_dir = Path(summary_dir)\n",
    "structured_path = summary_dir / \"structured_metadata.json\"\n",
    "with open(structured_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    structured_metadata = json.load(f)\n",
    "\n",
    "# Set base URI\n",
    "run_id = structured_metadata.get(\"FAIR4ML\", {}).get(\"fair4ml:runID\", \"default\")\n",
    "base_uri = f\"https://github.com/reema-dass26/ml-provenance/provenance/run_{run_id}/\"\n",
    "EX = Namespace(base_uri)\n",
    "\n",
    "# Create graph and bind namespaces\n",
    "g = Graph()\n",
    "g.bind(\"prov\", PROV)\n",
    "g.bind(\"foaf\", FOAF)\n",
    "g.bind(\"dc\", DC)\n",
    "g.bind(\"dcterms\", DCTERMS)\n",
    "g.bind(\"ex\", EX)\n",
    "\n",
    "# === Helpers ===\n",
    "def safe_literal(value):\n",
    "    return value not in [None, \"\", \"None_specified\", \"no justification provided\", \"‚Äî\", \"null\", \"None\"]\n",
    "\n",
    "def iso_datetime(value):\n",
    "    try:\n",
    "        value = str(value).strip().replace(\" \", \"T\")\n",
    "        dt = datetime.fromisoformat(value.split(\".\")[0])\n",
    "        return dt.isoformat()\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def safe_uri(base, value):\n",
    "    if not safe_literal(value):\n",
    "        return None\n",
    "    cleaned = str(value).strip().replace(\" \", \"_\").replace(\"/\", \"_\").replace(\":\", \"_\")\n",
    "    return URIRef(base + cleaned)\n",
    "\n",
    "def add_literals(data: dict, subject):\n",
    "    for k, v in data.items():\n",
    "        if safe_literal(v):\n",
    "            g.add((subject, EX[k], Literal(v)))\n",
    "\n",
    "# === Define core URIs ===\n",
    "model_uri = safe_uri(EX, f\"model/{structured_metadata['Croissant'].get('mls:modelID')}\") or URIRef(EX[\"model/default\"])\n",
    "dataset_uri = safe_uri(EX, f\"dataset/{structured_metadata['FAIR'].get('dcterms:identifier')}\") or URIRef(EX[\"dataset/default\"])\n",
    "code_uri = safe_uri(EX, f\"code/{structured_metadata['PROV-O'].get('prov:commit')}\") or URIRef(EX[\"code/default\"])\n",
    "activity_uri = safe_uri(EX, f\"run/{run_id}\") or URIRef(EX[\"run/default\"])\n",
    "agent_uri = safe_uri(EX, f\"agent/{structured_metadata['PROV-O'].get('prov:Agent')}\") or URIRef(EX[\"agent/default\"])\n",
    "\n",
    "# === Define RDF types ===\n",
    "g.add((model_uri, RDF.type, PROV.Entity))\n",
    "g.add((dataset_uri, RDF.type, PROV.Entity))\n",
    "g.add((code_uri, RDF.type, PROV.Entity))\n",
    "g.add((activity_uri, RDF.type, PROV.Activity))\n",
    "g.add((agent_uri, RDF.type, PROV.Agent))\n",
    "g.add((agent_uri, FOAF.name, Literal(structured_metadata['PROV-O'].get(\"prov:Agent\", \"unknown\"))))\n",
    "\n",
    "# === Provenance relationships ===\n",
    "start_time = structured_metadata['PROV-O'].get(\"prov:startedAtTime\")\n",
    "if safe_literal(start_time):\n",
    "    iso_val = iso_datetime(start_time)\n",
    "    if iso_val:\n",
    "        g.add((activity_uri, PROV.startedAtTime, Literal(iso_val, datatype=XSD.dateTime)))\n",
    "\n",
    "end_time = structured_metadata['PROV-O'].get(\"prov:endedAtTime\")\n",
    "if safe_literal(end_time):\n",
    "    iso_val = iso_datetime(end_time)\n",
    "    if iso_val:\n",
    "        g.add((activity_uri, PROV.endedAtTime, Literal(iso_val, datatype=XSD.dateTime)))\n",
    "\n",
    "g.add((activity_uri, PROV.used, dataset_uri))\n",
    "g.add((activity_uri, PROV.used, code_uri))\n",
    "g.add((model_uri, PROV.wasGeneratedBy, activity_uri))\n",
    "g.add((activity_uri, PROV.wasAssociatedWith, agent_uri))\n",
    "\n",
    "# === Inject all literals ===\n",
    "for category, subject in [\n",
    "    (\"Croissant\", model_uri),\n",
    "    (\"FAIR\", dataset_uri),\n",
    "    (\"PROV-O\", code_uri),\n",
    "    (\"FAIR4ML\", activity_uri),\n",
    "    (\"MLSEA\", activity_uri)\n",
    "]:\n",
    "    add_literals(structured_metadata.get(category, {}), subject)\n",
    "\n",
    "# === Export ===\n",
    "jsonld_path = structured_path.parent / \"prov_JSONLD_export.jsonld\"\n",
    "rdfxml_path = structured_path.parent / \"prov_RDFXML_export.rdf\"\n",
    "\n",
    "with open(jsonld_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(g.serialize(format=\"json-ld\", indent=2))\n",
    "\n",
    "with open(rdfxml_path, \"wb\") as f:\n",
    "    f.write(g.serialize(format=\"xml\", encoding=\"utf-8\"))\n",
    "\n",
    "jsonld_path.name, rdfxml_path.name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5e3bbb-0288-47d0-9dc4-2855d7e4801a",
   "metadata": {},
   "source": [
    "########################################################################\n",
    "# Post metadata to INVENIO\n",
    "########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "745dc1c9-ed88-45dc-bd8c-1065c9c17aa3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# # -----------------------------------------------------------------------------\n",
    "# # Configuration\n",
    "# # -----------------------------------------------------------------------------\n",
    "# API_BASE   = \"https://127.0.0.1:5000\"\n",
    "# TOKEN      = \"MoWvZMgAFsFIVfaEx1klbtB3pnf71wWHcTdS37hygmLGus9fqEGqXgmW6cRl\"\n",
    "# VERIFY_SSL = False  # only for self‚Äêsigned dev\n",
    "\n",
    "# HEADERS_JSON = {\n",
    "#     \"Accept\":        \"application/json\",\n",
    "#     \"Content-Type\":  \"application/json\",\n",
    "#     \"Authorization\": f\"Bearer {TOKEN}\",\n",
    "# }\n",
    "\n",
    "# HEADERS_OCTET = {\n",
    "#     \"Content-Type\":  \"application/octet-stream\",\n",
    "#     \"Authorization\": f\"Bearer {TOKEN}\",\n",
    "# }\n",
    "\n",
    "# # The folders you want to walk & upload:\n",
    "# TO_UPLOAD = [\"Trained_models\", \"MODEL_PROVENANCE\"]\n",
    "\n",
    "# upload_name = summary_dir.name\n",
    "\n",
    "# # -----------------------------------------------------------------------------\n",
    "# # 1) Create draft with ALL required metadata\n",
    "# # -----------------------------------------------------------------------------\n",
    "# def create_draft():\n",
    "#     payload = {\n",
    "#   \"metadata\": {\n",
    "#     \"title\": upload_name,\n",
    "#     \"creators\": [ {\n",
    "#       \"person_or_org\": {\n",
    "#         \"type\":        \"personal\",\n",
    "#         \"given_name\":  \"Reema\",\n",
    "#         \"family_name\": \"Dass\"\n",
    "#       }\n",
    "#     } ],\n",
    "#     \"publication_date\": \"2025-04-24\",\n",
    "#     \"resource_type\":    { \"id\": \"software\" },\n",
    "#     \"access\": {\n",
    "#       \"record\": \"public\",\n",
    "#       \"files\":  \"public\"\n",
    "#     }\n",
    "#   }\n",
    "# }\n",
    "#     r = requests.post(f\"{API_BASE}/api/records\",\n",
    "#                       headers=HEADERS_JSON,\n",
    "#                       json=payload,\n",
    "#                       verify=VERIFY_SSL)\n",
    "#     r.raise_for_status()\n",
    "#     draft = r.json()\n",
    "#     print(\"‚úÖ Draft created:\", draft[\"id\"])\n",
    "#     return draft[\"id\"], draft[\"links\"]\n",
    "\n",
    "\n",
    "# # -----------------------------------------------------------------------------\n",
    "# # 2) Register, upload and commit a single file\n",
    "# # -----------------------------------------------------------------------------\n",
    "# def upload_and_commit(links, key, path):\n",
    "#     # 2a) register the filename in the draft\n",
    "#     r1 = requests.post(links[\"files\"],\n",
    "#                        headers=HEADERS_JSON,\n",
    "#                        json=[{\"key\": key}],\n",
    "#                        verify=VERIFY_SSL)\n",
    "#     r1.raise_for_status()\n",
    "#     entry = next(e for e in r1.json()[\"entries\"] if e[\"key\"] == key)\n",
    "#     file_links = entry[\"links\"]\n",
    "\n",
    "#     # 2b) upload the bytes\n",
    "#     with open(path, \"rb\") as fp:\n",
    "#         r2 = requests.put(file_links[\"content\"],\n",
    "#                           headers=HEADERS_OCTET,\n",
    "#                           data=fp,\n",
    "#                           verify=VERIFY_SSL)\n",
    "#     r2.raise_for_status()\n",
    "\n",
    "#     # 2c) commit the upload\n",
    "#     r3 = requests.post(file_links[\"commit\"],\n",
    "#                        headers=HEADERS_JSON,\n",
    "#                        verify=VERIFY_SSL)\n",
    "#     r3.raise_for_status()\n",
    "#     print(f\"  ‚Ä¢ Uploaded {key}\")\n",
    "\n",
    "\n",
    "# # -----------------------------------------------------------------------------\n",
    "# # 3) Walk each folder and upload every file\n",
    "# # -----------------------------------------------------------------------------\n",
    "# def upload_folder(links):\n",
    "#     for folder in TO_UPLOAD:\n",
    "#         if not os.path.isdir(folder):\n",
    "#             print(f\"‚ö†Ô∏è Skipping missing folder {folder}\")\n",
    "#             continue\n",
    "#         base = os.path.dirname(folder) or folder\n",
    "#         for root, _, files in os.walk(folder):\n",
    "#             for fn in files:\n",
    "#                 local = os.path.join(root, fn)\n",
    "#                 # create a POSIX‚Äêstyle key preserving subfolders\n",
    "#                 key = os.path.relpath(local, start=base).replace(os.sep, \"/\")\n",
    "#                 upload_and_commit(links, key, local)\n",
    "\n",
    "\n",
    "# # -----------------------------------------------------------------------------\n",
    "# # 4) Publish the draft\n",
    "# # -----------------------------------------------------------------------------\n",
    "# def publish(links):\n",
    "#     r = requests.post(links[\"publish\"],\n",
    "#                       headers=HEADERS_JSON,\n",
    "#                       verify=VERIFY_SSL)\n",
    "#     if not r.ok:\n",
    "#         print(\"‚ùå Publish failed:\", r.status_code, r.text)\n",
    "#         try: print(r.json())\n",
    "#         except: pass\n",
    "#         r.raise_for_status()\n",
    "#     print(\"‚úÖ Published:\", r.json()[\"id\"])\n",
    "\n",
    "\n",
    "# # -----------------------------------------------------------------------------\n",
    "# # Main\n",
    "# # -----------------------------------------------------------------------------\n",
    "# if __name__ == \"__main__\":\n",
    "#     recid, links = create_draft()\n",
    "#     upload_folder(links)\n",
    "#     publish(links)\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ce5f1434-003c-4a75-837b-d4650b5644c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\reema\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:1056: InsecureRequestWarning: Unverified HTTPS request is being made to host '127.0.0.1'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Draft created: cy03g-1c997\n",
      "üì¶ Registering file: RandomForest_Iris_v20250629_142249/confusion_matrix.png ‚Üí MODEL_PROVENANCE/RandomForest_Iris_v20250629_142249\\confusion_matrix.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\reema\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:1056: InsecureRequestWarning: Unverified HTTPS request is being made to host '127.0.0.1'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "C:\\Users\\reema\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:1056: InsecureRequestWarning: Unverified HTTPS request is being made to host '127.0.0.1'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "C:\\Users\\reema\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:1056: InsecureRequestWarning: Unverified HTTPS request is being made to host '127.0.0.1'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Uploaded: RandomForest_Iris_v20250629_142249/confusion_matrix.png\n",
      "üì¶ Registering file: RandomForest_Iris_v20250629_142249/feature_importances.png ‚Üí MODEL_PROVENANCE/RandomForest_Iris_v20250629_142249\\feature_importances.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\reema\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:1056: InsecureRequestWarning: Unverified HTTPS request is being made to host '127.0.0.1'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "C:\\Users\\reema\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:1056: InsecureRequestWarning: Unverified HTTPS request is being made to host '127.0.0.1'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "C:\\Users\\reema\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:1056: InsecureRequestWarning: Unverified HTTPS request is being made to host '127.0.0.1'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Uploaded: RandomForest_Iris_v20250629_142249/feature_importances.png\n",
      "üì¶ Registering file: RandomForest_Iris_v20250629_142249/prov_JSONLD_export.jsonld ‚Üí MODEL_PROVENANCE/RandomForest_Iris_v20250629_142249\\prov_JSONLD_export.jsonld\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\reema\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:1056: InsecureRequestWarning: Unverified HTTPS request is being made to host '127.0.0.1'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "C:\\Users\\reema\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:1056: InsecureRequestWarning: Unverified HTTPS request is being made to host '127.0.0.1'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "C:\\Users\\reema\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:1056: InsecureRequestWarning: Unverified HTTPS request is being made to host '127.0.0.1'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Uploaded: RandomForest_Iris_v20250629_142249/prov_JSONLD_export.jsonld\n",
      "üì¶ Registering file: RandomForest_Iris_v20250629_142249/prov_RDFXML_export.rdf ‚Üí MODEL_PROVENANCE/RandomForest_Iris_v20250629_142249\\prov_RDFXML_export.rdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\reema\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:1056: InsecureRequestWarning: Unverified HTTPS request is being made to host '127.0.0.1'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "C:\\Users\\reema\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:1056: InsecureRequestWarning: Unverified HTTPS request is being made to host '127.0.0.1'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "C:\\Users\\reema\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:1056: InsecureRequestWarning: Unverified HTTPS request is being made to host '127.0.0.1'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Uploaded: RandomForest_Iris_v20250629_142249/prov_RDFXML_export.rdf\n",
      "üì¶ Registering file: RandomForest_Iris_v20250629_142249/pr_curve_cls_0.png ‚Üí MODEL_PROVENANCE/RandomForest_Iris_v20250629_142249\\pr_curve_cls_0.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\reema\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:1056: InsecureRequestWarning: Unverified HTTPS request is being made to host '127.0.0.1'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "C:\\Users\\reema\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:1056: InsecureRequestWarning: Unverified HTTPS request is being made to host '127.0.0.1'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "C:\\Users\\reema\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:1056: InsecureRequestWarning: Unverified HTTPS request is being made to host '127.0.0.1'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Uploaded: RandomForest_Iris_v20250629_142249/pr_curve_cls_0.png\n",
      "üì¶ Registering file: RandomForest_Iris_v20250629_142249/pr_curve_cls_1.png ‚Üí MODEL_PROVENANCE/RandomForest_Iris_v20250629_142249\\pr_curve_cls_1.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\reema\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:1056: InsecureRequestWarning: Unverified HTTPS request is being made to host '127.0.0.1'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "C:\\Users\\reema\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:1056: InsecureRequestWarning: Unverified HTTPS request is being made to host '127.0.0.1'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "C:\\Users\\reema\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:1056: InsecureRequestWarning: Unverified HTTPS request is being made to host '127.0.0.1'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Uploaded: RandomForest_Iris_v20250629_142249/pr_curve_cls_1.png\n",
      "üì¶ Registering file: RandomForest_Iris_v20250629_142249/pr_curve_cls_2.png ‚Üí MODEL_PROVENANCE/RandomForest_Iris_v20250629_142249\\pr_curve_cls_2.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\reema\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:1056: InsecureRequestWarning: Unverified HTTPS request is being made to host '127.0.0.1'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "C:\\Users\\reema\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:1056: InsecureRequestWarning: Unverified HTTPS request is being made to host '127.0.0.1'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "C:\\Users\\reema\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:1056: InsecureRequestWarning: Unverified HTTPS request is being made to host '127.0.0.1'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Uploaded: RandomForest_Iris_v20250629_142249/pr_curve_cls_2.png\n",
      "üì¶ Registering file: RandomForest_Iris_v20250629_142249/RandomForest_Iris_v20250629_142249.pkl ‚Üí MODEL_PROVENANCE/RandomForest_Iris_v20250629_142249\\RandomForest_Iris_v20250629_142249.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\reema\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:1056: InsecureRequestWarning: Unverified HTTPS request is being made to host '127.0.0.1'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "C:\\Users\\reema\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:1056: InsecureRequestWarning: Unverified HTTPS request is being made to host '127.0.0.1'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "C:\\Users\\reema\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:1056: InsecureRequestWarning: Unverified HTTPS request is being made to host '127.0.0.1'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Uploaded: RandomForest_Iris_v20250629_142249/RandomForest_Iris_v20250629_142249.pkl\n",
      "üì¶ Registering file: RandomForest_Iris_v20250629_142249/RandomForest_Iris_v20250629_142249_reproducibility.txt ‚Üí MODEL_PROVENANCE/RandomForest_Iris_v20250629_142249\\RandomForest_Iris_v20250629_142249_reproducibility.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\reema\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:1056: InsecureRequestWarning: Unverified HTTPS request is being made to host '127.0.0.1'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "C:\\Users\\reema\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:1056: InsecureRequestWarning: Unverified HTTPS request is being made to host '127.0.0.1'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "C:\\Users\\reema\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:1056: InsecureRequestWarning: Unverified HTTPS request is being made to host '127.0.0.1'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Uploaded: RandomForest_Iris_v20250629_142249/RandomForest_Iris_v20250629_142249_reproducibility.txt\n",
      "üì¶ Registering file: RandomForest_Iris_v20250629_142249/RandomForest_Iris_v20250629_142249_run_summary.json ‚Üí MODEL_PROVENANCE/RandomForest_Iris_v20250629_142249\\RandomForest_Iris_v20250629_142249_run_summary.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\reema\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:1056: InsecureRequestWarning: Unverified HTTPS request is being made to host '127.0.0.1'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "C:\\Users\\reema\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:1056: InsecureRequestWarning: Unverified HTTPS request is being made to host '127.0.0.1'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "C:\\Users\\reema\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:1056: InsecureRequestWarning: Unverified HTTPS request is being made to host '127.0.0.1'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Uploaded: RandomForest_Iris_v20250629_142249/RandomForest_Iris_v20250629_142249_run_summary.json\n",
      "üì¶ Registering file: RandomForest_Iris_v20250629_142249/requirements.txt ‚Üí MODEL_PROVENANCE/RandomForest_Iris_v20250629_142249\\requirements.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\reema\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:1056: InsecureRequestWarning: Unverified HTTPS request is being made to host '127.0.0.1'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "C:\\Users\\reema\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:1056: InsecureRequestWarning: Unverified HTTPS request is being made to host '127.0.0.1'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "C:\\Users\\reema\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:1056: InsecureRequestWarning: Unverified HTTPS request is being made to host '127.0.0.1'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Uploaded: RandomForest_Iris_v20250629_142249/requirements.txt\n",
      "üì¶ Registering file: RandomForest_Iris_v20250629_142249/roc_curve_cls_0.png ‚Üí MODEL_PROVENANCE/RandomForest_Iris_v20250629_142249\\roc_curve_cls_0.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\reema\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:1056: InsecureRequestWarning: Unverified HTTPS request is being made to host '127.0.0.1'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "C:\\Users\\reema\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:1056: InsecureRequestWarning: Unverified HTTPS request is being made to host '127.0.0.1'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "C:\\Users\\reema\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:1056: InsecureRequestWarning: Unverified HTTPS request is being made to host '127.0.0.1'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Uploaded: RandomForest_Iris_v20250629_142249/roc_curve_cls_0.png\n",
      "üì¶ Registering file: RandomForest_Iris_v20250629_142249/roc_curve_cls_1.png ‚Üí MODEL_PROVENANCE/RandomForest_Iris_v20250629_142249\\roc_curve_cls_1.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\reema\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:1056: InsecureRequestWarning: Unverified HTTPS request is being made to host '127.0.0.1'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "C:\\Users\\reema\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:1056: InsecureRequestWarning: Unverified HTTPS request is being made to host '127.0.0.1'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "C:\\Users\\reema\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:1056: InsecureRequestWarning: Unverified HTTPS request is being made to host '127.0.0.1'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Uploaded: RandomForest_Iris_v20250629_142249/roc_curve_cls_1.png\n",
      "üì¶ Registering file: RandomForest_Iris_v20250629_142249/roc_curve_cls_2.png ‚Üí MODEL_PROVENANCE/RandomForest_Iris_v20250629_142249\\roc_curve_cls_2.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\reema\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:1056: InsecureRequestWarning: Unverified HTTPS request is being made to host '127.0.0.1'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "C:\\Users\\reema\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:1056: InsecureRequestWarning: Unverified HTTPS request is being made to host '127.0.0.1'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "C:\\Users\\reema\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:1056: InsecureRequestWarning: Unverified HTTPS request is being made to host '127.0.0.1'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Uploaded: RandomForest_Iris_v20250629_142249/roc_curve_cls_2.png\n",
      "üì¶ Registering file: RandomForest_Iris_v20250629_142249/shap_summary.png ‚Üí MODEL_PROVENANCE/RandomForest_Iris_v20250629_142249\\shap_summary.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\reema\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:1056: InsecureRequestWarning: Unverified HTTPS request is being made to host '127.0.0.1'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "C:\\Users\\reema\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:1056: InsecureRequestWarning: Unverified HTTPS request is being made to host '127.0.0.1'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "C:\\Users\\reema\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:1056: InsecureRequestWarning: Unverified HTTPS request is being made to host '127.0.0.1'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Uploaded: RandomForest_Iris_v20250629_142249/shap_summary.png\n",
      "üì¶ Registering file: RandomForest_Iris_v20250629_142249/structured_metadata.json ‚Üí MODEL_PROVENANCE/RandomForest_Iris_v20250629_142249\\structured_metadata.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\reema\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:1056: InsecureRequestWarning: Unverified HTTPS request is being made to host '127.0.0.1'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "C:\\Users\\reema\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:1056: InsecureRequestWarning: Unverified HTTPS request is being made to host '127.0.0.1'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "C:\\Users\\reema\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:1056: InsecureRequestWarning: Unverified HTTPS request is being made to host '127.0.0.1'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Uploaded: RandomForest_Iris_v20250629_142249/structured_metadata.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\reema\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:1056: InsecureRequestWarning: Unverified HTTPS request is being made to host '127.0.0.1'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Published: cy03g-1c997\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Configuration\n",
    "# -----------------------------------------------------------------------------\n",
    "API_BASE   = \"https://127.0.0.1:5000\"\n",
    "TOKEN      = \"MoWvZMgAFsFIVfaEx1klbtB3pnf71wWHcTdS37hygmLGus9fqEGqXgmW6cRl\"\n",
    "VERIFY_SSL = False  # only for self‚Äêsigned dev\n",
    "\n",
    "HEADERS_JSON = {\n",
    "    \"Accept\":        \"application/json\",\n",
    "    \"Content-Type\":  \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {TOKEN}\",\n",
    "}\n",
    "\n",
    "HEADERS_OCTET = {\n",
    "    \"Content-Type\":  \"application/octet-stream\",\n",
    "    \"Authorization\": f\"Bearer {TOKEN}\",\n",
    "}\n",
    "\n",
    "TO_UPLOAD = [f\"MODEL_PROVENANCE/{model_name}\"]\n",
    "upload_name = os.path.basename(os.getcwd())  # fallback name if summary_dir missing\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 1) Create draft\n",
    "# -----------------------------------------------------------------------------\n",
    "def create_draft():\n",
    "    payload = {\n",
    "        \"metadata\": {\n",
    "            \"title\": upload_name,\n",
    "            \"creators\": [{\n",
    "                \"person_or_org\": {\n",
    "                    \"type\": \"personal\",\n",
    "                    \"given_name\": \"Reema\",\n",
    "                    \"family_name\": \"Dass\"\n",
    "                }\n",
    "            }],\n",
    "            \"publication_date\": \"2025-04-24\",\n",
    "            \"resource_type\": {\"id\": \"software\"},\n",
    "            \"access\": {\"record\": \"public\", \"files\": \"public\"}\n",
    "        }\n",
    "    }\n",
    "    r = requests.post(f\"{API_BASE}/api/records\",\n",
    "                      headers=HEADERS_JSON,\n",
    "                      json=payload,\n",
    "                      verify=VERIFY_SSL)\n",
    "    r.raise_for_status()\n",
    "    draft = r.json()\n",
    "    print(\"‚úÖ Draft created:\", draft[\"id\"])\n",
    "    return draft[\"id\"], draft[\"links\"]\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 2) Upload and commit a single file\n",
    "# -----------------------------------------------------------------------------\n",
    "def upload_and_commit(links, key, path):\n",
    "    print(f\"üì¶ Registering file: {key} ‚Üí {path}\")\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"‚ö†Ô∏è  File not found: {path}\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        # Register filename\n",
    "        r1 = requests.post(links[\"files\"],\n",
    "                           headers=HEADERS_JSON,\n",
    "                           json=[{\"key\": key}],\n",
    "                           verify=VERIFY_SSL)\n",
    "        if not r1.ok:\n",
    "            print(f\"‚ùå File registration failed for {key}: {r1.status_code} {r1.text}\")\n",
    "            return\n",
    "        entry = next(e for e in r1.json()[\"entries\"] if e[\"key\"] == key)\n",
    "        file_links = entry[\"links\"]\n",
    "\n",
    "        # Upload file\n",
    "        with open(path, \"rb\") as fp:\n",
    "            r2 = requests.put(file_links[\"content\"],\n",
    "                              headers=HEADERS_OCTET,\n",
    "                              data=fp,\n",
    "                              verify=VERIFY_SSL)\n",
    "        if not r2.ok:\n",
    "            print(f\"‚ùå Upload failed for {key}: {r2.status_code} {r2.text}\")\n",
    "            return\n",
    "\n",
    "        # Commit upload\n",
    "        r3 = requests.post(file_links[\"commit\"],\n",
    "                           headers=HEADERS_JSON,\n",
    "                           verify=VERIFY_SSL)\n",
    "        if not r3.ok:\n",
    "            print(f\"‚ùå Commit failed for {key}: {r3.status_code} {r3.text}\")\n",
    "            return\n",
    "\n",
    "        print(f\"‚úÖ Uploaded: {key}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Exception during upload of {key}: {e}\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 3) Upload all files from folders\n",
    "# -----------------------------------------------------------------------------\n",
    "def upload_folder(links):\n",
    "    for folder in TO_UPLOAD:\n",
    "        if not os.path.isdir(folder):\n",
    "            print(f\"‚ö†Ô∏è Skipping missing folder: {folder}\")\n",
    "            continue\n",
    "        base = os.path.dirname(folder) or folder\n",
    "        for root, _, files in os.walk(folder):\n",
    "            for fn in files:\n",
    "                local = os.path.join(root, fn)\n",
    "                key = os.path.relpath(local, start=base).replace(os.sep, \"/\")\n",
    "                upload_and_commit(links, key, local)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 4) Publish draft\n",
    "# -----------------------------------------------------------------------------\n",
    "def publish(links):\n",
    "    r = requests.post(links[\"publish\"],\n",
    "                      headers=HEADERS_JSON,\n",
    "                      verify=VERIFY_SSL)\n",
    "    if not r.ok:\n",
    "        print(\"‚ùå Publish failed:\", r.status_code, r.text)\n",
    "        try: print(r.json())\n",
    "        except: pass\n",
    "        r.raise_for_status()\n",
    "    print(\"‚úÖ Published:\", r.json()[\"id\"])\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Run\n",
    "# -----------------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    recid, links = create_draft()\n",
    "    upload_folder(links)\n",
    "    publish(links)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b463223e-5425-465c-ae63-815cbb053301",
   "metadata": {},
   "source": [
    "########################################################################\n",
    "# FETCH metadata from INVENIO\n",
    "########################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7423f2-0ff3-4104-913e-50eeb32d9d0f",
   "metadata": {},
   "source": [
    "METADATA EXTRACTION FROM INVENIO and ADD it to main Provenence FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "10d5968b-997e-4458-bf6b-a14dcc883698",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "import requests\n",
    "import urllib3\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "def fetch_and_embed_invenio_metadata(record_id, model_name, api_base, headers, verify_ssl=True):\n",
    "    # === Fetch Invenio Metadata ===\n",
    "    print(\"üì° Fetching Invenio metadata...\")\n",
    "    response = requests.get(f\"{api_base}/api/records/{record_id}\", headers=headers, verify=False)\n",
    "    response.raise_for_status()\n",
    "    metadata = response.json()\n",
    "    print(\"‚úÖ Metadata fetched successfully\")\n",
    "    print(\"‚ÑπÔ∏è ID:\", metadata.get(\"id\", \"N/A\"))\n",
    "\n",
    "\n",
    "    # === Extract Required Fields ===\n",
    "    extracted = {\n",
    "        \"id\": metadata.get(\"id\", \"\"),\n",
    "        \"title\": metadata.get(\"metadata\", {}).get(\"title\", \"\"),\n",
    "        \"creator\": \", \".join([\n",
    "            c[\"person_or_org\"].get(\"name\", \"\")\n",
    "            for c in metadata.get(\"metadata\", {}).get(\"creators\", [])\n",
    "        ]),\n",
    "        \"publication_date\": metadata.get(\"metadata\", {}).get(\"publication_date\", \"\"),\n",
    "        \"files\": [],\n",
    "        \"pids\": metadata.get(\"pids\", {}),\n",
    "        \"version_info\": metadata.get(\"versions\", {}),\n",
    "        \"status\": metadata.get(\"status\", \"\"),\n",
    "        \"views\": metadata.get(\"stats\", {}).get(\"this_version\", {}).get(\"views\", 0),\n",
    "        \"downloads\": metadata.get(\"stats\", {}).get(\"this_version\", {}).get(\"downloads\", 0),\n",
    "    }\n",
    "\n",
    "    for key, file_info in metadata.get(\"files\", {}).get(\"entries\", {}).items():\n",
    "        extracted[\"files\"].append({\n",
    "            \"key\": key,\n",
    "            \"url\": file_info[\"links\"].get(\"content\", \"\"),\n",
    "            \"size\": file_info.get(\"size\", 0),\n",
    "            \"mimetype\": file_info.get(\"mimetype\", \"\"),\n",
    "            \"checksum\": file_info.get(\"checksum\", \"\"),\n",
    "            \"metadata\": file_info.get(\"metadata\", {}),\n",
    "        })\n",
    "\n",
    "    print(\"üì§ Extracted Metadata Preview:\")\n",
    "    print(json.dumps(extracted, indent=2)[:1000])\n",
    "\n",
    "    # === Load structured_metadata.json ===\n",
    "    structured_path = Path(f\"MODEL_PROVENANCE/{model_name}/structured_metadata.json\")\n",
    "    if not structured_path.exists():\n",
    "        print(f\"‚ö†Ô∏è structured_metadata.json not found at {structured_path}\")\n",
    "        return\n",
    "\n",
    "    with open(structured_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        structured_metadata = json.load(f)\n",
    "\n",
    "    if not isinstance(structured_metadata, dict):\n",
    "        structured_metadata = {}\n",
    "\n",
    "    if \"Uncategorized\" not in structured_metadata:\n",
    "        structured_metadata[\"Uncategorized\"] = {}\n",
    "\n",
    "    # === Inject Metadata ===\n",
    "    structured_metadata[\"Uncategorized\"][\"invenio_metadata\"] = extracted\n",
    "\n",
    "    # === Save Back ===\n",
    "    with open(structured_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(structured_metadata, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    print(f\"‚úÖ Invenio metadata embedded into: {structured_path}\")\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# fetch_and_embed_invenio_metadata(recid, model_name, API_BASE, HEADERS_JSON)\n",
    "API_BASE   = \"https://127.0.0.1:5000\"\n",
    "HEADERS_JSON = {\n",
    "    \"Accept\":        \"application/json\",\n",
    "    \"Content-Type\":  \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {TOKEN}\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f87e6109-de5e-4ba4-baae-7de79c1fb131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì° Fetching Invenio metadata...\n",
      "‚úÖ Metadata fetched successfully\n",
      "‚ÑπÔ∏è ID: cy03g-1c997\n",
      "üì§ Extracted Metadata Preview:\n",
      "{\n",
      "  \"id\": \"cy03g-1c997\",\n",
      "  \"title\": \"RQ_notebooks\",\n",
      "  \"creator\": \"Dass, Reema\",\n",
      "  \"publication_date\": \"2025-04-24\",\n",
      "  \"files\": [\n",
      "    {\n",
      "      \"key\": \"RandomForest_Iris_v20250629_142249/confusion_matrix.png\",\n",
      "      \"url\": \"https://127.0.0.1:5000/api/records/cy03g-1c997/files/RandomForest_Iris_v20250629_142249/confusion_matrix.png/content\",\n",
      "      \"size\": 14623,\n",
      "      \"mimetype\": \"image/png\",\n",
      "      \"checksum\": \"md5:c74643bc910d8d9a4eda8648aae6b040\",\n",
      "      \"metadata\": {\n",
      "        \"width\": 600,\n",
      "        \"height\": 600\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"key\": \"RandomForest_Iris_v20250629_142249/RandomForest_Iris_v20250629_142249_reproducibility.txt\",\n",
      "      \"url\": \"https://127.0.0.1:5000/api/records/cy03g-1c997/files/RandomForest_Iris_v20250629_142249/RandomForest_Iris_v20250629_142249_reproducibility.txt/content\",\n",
      "      \"size\": 3457,\n",
      "      \"mimetype\": \"text/plain\",\n",
      "      \"checksum\": \"md5:7fed719c7f7564639647096d45f605e9\",\n",
      "      \"metadata\": {}\n",
      "    },\n",
      "    {\n",
      "      \"key\": \"RandomForest_Iris_v20250629_142249\n",
      "‚úÖ Invenio metadata embedded into: MODEL_PROVENANCE\\RandomForest_Iris_v20250629_142249\\structured_metadata.json\n"
     ]
    }
   ],
   "source": [
    "fetch_and_embed_invenio_metadata(\n",
    "    record_id=recid,\n",
    "    model_name=model_name,\n",
    "    api_base=\"https://127.0.0.1:5000\",\n",
    "    headers={\"Accept\": \"application/json\"}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed3a719-602d-46bf-b1ee-96494649ede1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
