{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ff24f2a-931c-4543-b179-dc8bf1bfd74d",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "########################################################\n",
    "# EXPERIMENT CODE\n",
    "########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1f97a375-387a-4368-a629-556f56f51dcc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your role (default: collaborator):  \n",
      "Enter project ID (default: default_project):  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìå Session Metadata:\n",
      "  session_id: 1b1126e7-6971-49c5-b6d2-a582207d05b0\n",
      "  username: reema\n",
      "  timestamp_utc: 2025-05-03T19:05:00.655283\n",
      "  hostname: Purplish\n",
      "  platform: Windows\n",
      "  os_version: 10.0.26100\n",
      "  python_version: 3.11.5\n",
      "  role: collaborator\n",
      "  project_id: default_project\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'session_id': '1b1126e7-6971-49c5-b6d2-a582207d05b0',\n",
       " 'username': 'reema',\n",
       " 'timestamp_utc': '2025-05-03T19:05:00.655283',\n",
       " 'hostname': 'Purplish',\n",
       " 'platform': 'Windows',\n",
       " 'os_version': '10.0.26100',\n",
       " 'python_version': '3.11.5',\n",
       " 'role': 'collaborator',\n",
       " 'project_id': 'default_project'}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialization Cell for Researcher Metadata\n",
    "\n",
    "import os\n",
    "import getpass\n",
    "import platform\n",
    "import sys\n",
    "import uuid\n",
    "from datetime import datetime\n",
    "\n",
    "def prompt_if_none(env_key, prompt_text, default_value=\"unknown\"):\n",
    "    val = os.getenv(env_key)\n",
    "    if not val:\n",
    "        try:\n",
    "            val = input(f\"{prompt_text} (default: {default_value}): \").strip() or default_value\n",
    "        except Exception:\n",
    "            val = default_value\n",
    "    return val\n",
    "\n",
    "def collect_session_metadata(\n",
    "    prompt_fields=True,\n",
    "    fixed_role=None,\n",
    "    fixed_project_id=None,\n",
    "    fixed_exercise_id=None\n",
    "):\n",
    "    metadata = {\n",
    "        \"session_id\": str(uuid.uuid4()),\n",
    "        \"username\": os.getenv(\"JUPYTERHUB_USER\", getpass.getuser()),\n",
    "        \"timestamp_utc\": datetime.utcnow().isoformat(),\n",
    "        \"hostname\": platform.node(),\n",
    "        \"platform\": platform.system(),\n",
    "        \"os_version\": platform.version(),\n",
    "        \"python_version\": sys.version.split()[0],\n",
    "    }\n",
    "\n",
    "    if prompt_fields:\n",
    "        metadata[\"role\"] = fixed_role or prompt_if_none(\"RESEARCHER_ROLE\", \"Enter your role\", \"collaborator\")\n",
    "        metadata[\"project_id\"] = fixed_project_id or prompt_if_none(\"PROJECT_ID\", \"Enter project ID\", \"default_project\")\n",
    "    else:\n",
    "        metadata[\"role\"] = fixed_role or os.getenv(\"RESEARCHER_ROLE\", \"researcher\")\n",
    "        metadata[\"project_id\"] = fixed_project_id or os.getenv(\"PROJECT_ID\", \"default_project\")\n",
    "\n",
    "    print(\"\\nüìå Session Metadata:\")\n",
    "    for k, v in metadata.items():\n",
    "        print(f\"  {k}: {v}\")\n",
    "\n",
    "    return metadata\n",
    "session_metadata = collect_session_metadata(prompt_fields=True)\n",
    "# mlflow.log_params(session_metadata)\n",
    "session_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ce1a579-f08b-40bd-b4db-21b388aaea74",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================\n",
    "# ‚öôÔ∏è Install Dependencies (if needed )\n",
    "# ============================\n",
    "# !pip install mlflow scikit-learn pandas numpy matplotlib seaborn shap requests GitPython\n",
    "# !pip install --upgrade threadpoolctl\n",
    "# !pip install setuptools\n",
    "# !pip install ace_tools \n",
    "# !pip install rdflib\n",
    "# !pip install streamlit-option-menu\n",
    "# !pip install streamlit-agraph\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca4f0ae-39ee-4b22-b013-dfb1fa1b5694",
   "metadata": {},
   "source": [
    "LIBRARY IMPORTS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8ca332e5-6501-4310-920b-2b769477b46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# üì¶ Standard Library Imports\n",
    "# ============================\n",
    "import os\n",
    "import glob\n",
    "import io\n",
    "import json\n",
    "import time\n",
    "import ast\n",
    "import pickle\n",
    "import platform\n",
    "import subprocess\n",
    "from datetime import datetime, timezone\n",
    "from pprint import pprint\n",
    "from typing import List, Dict, Any\n",
    "import xml.etree.ElementTree as ET\n",
    "import urllib.parse\n",
    "\n",
    "# ============================\n",
    "# üìä Data and Visualization\n",
    "# ============================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ============================\n",
    "# ü§ñ Machine Learning\n",
    "# ============================\n",
    "import sklearn\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, label_binarize\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    roc_auc_score,\n",
    "    confusion_matrix,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    RocCurveDisplay,\n",
    "    PrecisionRecallDisplay\n",
    ")\n",
    "\n",
    "# ============================\n",
    "# üî¨ Experiment Tracking\n",
    "# ============================\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow import MlflowClient\n",
    "\n",
    "# ============================\n",
    "# üåê Web / API / Networking\n",
    "# ============================\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ============================\n",
    "# üß™ Git & Version Control\n",
    "# ============================\n",
    "import git\n",
    "from git import Repo, GitCommandError\n",
    "\n",
    "# ============================\n",
    "# üß† SHAP for Explainability\n",
    "# ============================\n",
    "import shap\n",
    "\n",
    "# ============================\n",
    "# üß¨ RDF & Provenance (rdflib)\n",
    "# ============================\n",
    "from rdflib import Graph, URIRef, Literal\n",
    "from rdflib.namespace import PROV, XSD\n",
    "\n",
    "# ============================\n",
    "# ‚öôÔ∏è System Monitoring\n",
    "# ============================\n",
    "import psutil\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfde18b5-ae9c-442c-a5b3-7dfb06957646",
   "metadata": {},
   "source": [
    "#Dataset metadata!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0b99f09b-7e54-4260-bc31-95c8d077f44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the categorized fields in JSON structure\n",
    "categorized_fields = {\n",
    "    \"FAIR\": [\n",
    "        \"dataset_identifier\",\n",
    "        \"dataset_title\",\n",
    "        \"dataset_description\",\n",
    "        \"dataset_creator\",\n",
    "        \"dataset_publisher\",\n",
    "        \"dataset_publication_date\",\n",
    "        \"dataset_version\",\n",
    "        \"dataset_license\",\n",
    "        \"dataset_keywords\",\n",
    "        \"dataset_access_url\",\n",
    "        \"dataset_documentation\",\n",
    "        \"metadata_standard\",\n",
    "        \"related_resources\"\n",
    "    ],\n",
    "    \"PROV-O\": {\n",
    "        \"prov:Entity\": \"\",                       # The dataset being described\n",
    "        \"prov:Activity\": \"\",                     # High-level process involving multiple agents\n",
    "        \"prov:Agent\": {\n",
    "            \"dataset_creator\": \"\",\n",
    "            \"database_creator\": \"\"\n",
    "        },\n",
    "        \"prov:wasGeneratedBy\": \"\",               # Who made the database available\n",
    "        \"prov:used\": \"\",                         # Access URL used as data source\n",
    "        \"prov:wasDerivedFrom\": \"\",               # Original dataset ID\n",
    "        \"prov:wasAttributedTo\": \"\",              # Attribution to dataset author\n",
    "        \"prov:wasAssociatedWith\": \"\",            # Organization releasing the DB\n",
    "        \"prov:startedAtTime\": \"\",                # When dataset was published\n",
    "        \"prov:endedAtTime\": \"\",                  # When DB version was published\n",
    "        \"prov:location\": \"\",                     # Final hosting location\n",
    "        \"prov:role\": {\n",
    "            \"dataset_creator_role\": \"\",\n",
    "            \"database_creator_role\": \"\"\n",
    "        }\n",
    "    },\n",
    "    \"FAIR4ML\": [\n",
    "        \"dataset_dataset_type\",\n",
    "        \"columns\",\n",
    "        \"target_variable\",\n",
    "        \"ml_task\",\n",
    "        \"num_samples\",\n",
    "        \"data_distribution\",\n",
    "        \"known_issues\",\n",
    "        \"trainedOn\",\n",
    "        \"testedOn\",\n",
    "        \"validatedOn\",\n",
    "        \"modelRisks\",\n",
    "        \"usageInstructions\",\n",
    "        \"ethicalLegalSocial\"\n",
    "    ],\n",
    "    \"Internal/DBRepo\": [\n",
    "        \"database_identifier\",\n",
    "        \"database_title\",\n",
    "        \"database_description\",\n",
    "        \"database_creator\",\n",
    "        \"database_publisher\",\n",
    "        \"database_publication_date\",\n",
    "        \"database_version\",\n",
    "        \"database_schema_public\",\n",
    "        \"database_access_url\"\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a394398-cd25-45b5-89ac-6d909b65d417",
   "metadata": {},
   "source": [
    "#Metadata from ZONEDO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ceba00ff-139b-4433-ab7d-2170cd137012",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import requests\n",
    "\n",
    "def update_categorized_fields_fair(doi_url: str, categorized_fields: dict):\n",
    "    headers = {\"Accept\": \"application/vnd.citationstyles.csl+json\"}\n",
    "    r = requests.get(doi_url, headers=headers)\n",
    "    r.raise_for_status()\n",
    "    meta = r.json()\n",
    "    print(meta)\n",
    "    authors = [f\"{a.get('family', '')} {a.get('given', '')}\".strip()\n",
    "               for a in meta.get(\"author\", [])]\n",
    "    pubdate = \"-\".join(str(x) for x in meta.get(\"issued\", {}).get(\"date-parts\", [[]])[0])\n",
    "\n",
    "    categorized_fields[\"FAIR\"] = {\n",
    "        \"dataset_identifier\": meta.get(\"DOI\", \"info not available\"),\n",
    "        \"dataset_title\": meta.get(\"title\", \"info not available\"),\n",
    "        \"dataset_description\": meta.get(\"abstract\", \"info not available\"),\n",
    "        \"dataset_creator\": \"; \".join(authors) if authors else \"info not available\",\n",
    "        \"dataset_publisher\": meta.get(\"publisher\", \"info not available\"),\n",
    "        \"dataset_publication_date\": pubdate if pubdate else \"info not available\",\n",
    "        \"dataset_version\": meta.get(\"version\", \"info not available\"),\n",
    "        \"dataset_license\": meta.get(\"license\", \"info not available\"),\n",
    "        \"dataset_keywords\": \", \".join(meta.get(\"keywords\", [])) if meta.get(\"keywords\") else \"info not available\",\n",
    "        \"dataset_access_url\": meta.get(\"DOI\", \"info not available\"),\n",
    "        \"dataset_documentation\": meta.get(\"URL\", \"info not available\"),\n",
    "        \"metadata_standard\": meta.get(\"type\", \"info not available\"),\n",
    "        \"related_resources\": meta.get(\"URL\", \"info not available\")\n",
    "    }\n",
    "    categorized_fields[ \"PROV-O\"] = {\n",
    "        \"prov:Entity\": meta.get(\"dataset_title\", \"info not available\"),  # The dataset being described\n",
    "        \"prov:Activity\": \"Ingestion and Publication\",  # High-level process involving multiple agents\n",
    "        \"prov:Agent\": {\n",
    "            \"dataset_creator\": meta.get(\"author\", \"info not available\"),\n",
    "        },\n",
    "        \"prov:used\": meta.get(\"URL\", \"info not available\"),  # Access URL used as data source\n",
    "        \"prov:wasDerivedFrom\": meta.get(\"DOI\", \"info not available\"),  # Original dataset ID\n",
    "        \"prov:wasAttributedTo\": meta.get(\"author\", \"info not available\"),  # Attribution to dataset author\n",
    "        \"prov:startedAtTime\": pubdate if pubdate else \"info not available\",  # When dataset was published\n",
    "        \"prov:role\": {\n",
    "            \"dataset_creator_role\": \"Original Data Author\",\n",
    "            \"database_creator_role\": \"Database Ingestor and Maintainer\"\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0c0572bc-2220-4a3c-8cbf-69889733e7df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'dataset', 'id': 'https://doi.org/10.5281/zenodo.1404173', 'author': [{'family': 'Marshall', 'given': 'Michael'}], 'issued': {'date-parts': [[2018, 8, 27]]}, 'abstract': '<strong>Data Set Characteristics:</strong>\\n\\nNumber of Instances:\\n150 (50 in each of three classes)\\nNumber of Attributes:\\n\\n4 numeric, predictive attributes and the class\\nAttribute Information:\\n\\n\\n\\tsepal length in cm\\n\\tsepal width in cm\\n\\tpetal length in cm\\n\\tpetal width in cm\\n\\t\\n\\tclass:\\n\\n\\t\\n\\t\\tIris-Setosa\\n\\t\\tIris-Versicolour\\n\\t\\tIris-Virginica', 'DOI': '10.5281/ZENODO.1404173', 'publisher': 'Zenodo', 'title': 'Scikit-Learn Iris', 'URL': 'https://zenodo.org/record/1404173', 'copyright': 'Creative Commons Attribution 4.0'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'FAIR': {'dataset_identifier': '10.5281/ZENODO.1404173',\n",
       "  'dataset_title': 'Scikit-Learn Iris',\n",
       "  'dataset_description': '<strong>Data Set Characteristics:</strong>\\n\\nNumber of Instances:\\n150 (50 in each of three classes)\\nNumber of Attributes:\\n\\n4 numeric, predictive attributes and the class\\nAttribute Information:\\n\\n\\n\\tsepal length in cm\\n\\tsepal width in cm\\n\\tpetal length in cm\\n\\tpetal width in cm\\n\\t\\n\\tclass:\\n\\n\\t\\n\\t\\tIris-Setosa\\n\\t\\tIris-Versicolour\\n\\t\\tIris-Virginica',\n",
       "  'dataset_creator': 'Marshall Michael',\n",
       "  'dataset_publisher': 'Zenodo',\n",
       "  'dataset_publication_date': '2018-8-27',\n",
       "  'dataset_version': 'info not available',\n",
       "  'dataset_license': 'info not available',\n",
       "  'dataset_keywords': 'info not available',\n",
       "  'dataset_access_url': '10.5281/ZENODO.1404173',\n",
       "  'dataset_documentation': 'https://zenodo.org/record/1404173',\n",
       "  'metadata_standard': 'dataset',\n",
       "  'related_resources': 'https://zenodo.org/record/1404173'},\n",
       " 'PROV-O': {'prov:Entity': 'info not available',\n",
       "  'prov:Activity': 'Ingestion and Publication',\n",
       "  'prov:Agent': {'dataset_creator': [{'family': 'Marshall',\n",
       "     'given': 'Michael'}]},\n",
       "  'prov:used': 'https://zenodo.org/record/1404173',\n",
       "  'prov:wasDerivedFrom': '10.5281/ZENODO.1404173',\n",
       "  'prov:wasAttributedTo': [{'family': 'Marshall', 'given': 'Michael'}],\n",
       "  'prov:startedAtTime': '2018-8-27',\n",
       "  'prov:role': {'dataset_creator_role': 'Original Data Author',\n",
       "   'database_creator_role': 'Database Ingestor and Maintainer'}},\n",
       " 'FAIR4ML': ['dataset_dataset_type',\n",
       "  'columns',\n",
       "  'target_variable',\n",
       "  'ml_task',\n",
       "  'num_samples',\n",
       "  'data_distribution',\n",
       "  'known_issues',\n",
       "  'trainedOn',\n",
       "  'testedOn',\n",
       "  'validatedOn',\n",
       "  'modelRisks',\n",
       "  'usageInstructions',\n",
       "  'ethicalLegalSocial'],\n",
       " 'Internal/DBRepo': ['database_identifier',\n",
       "  'database_title',\n",
       "  'database_description',\n",
       "  'database_creator',\n",
       "  'database_publisher',\n",
       "  'database_publication_date',\n",
       "  'database_version',\n",
       "  'database_schema_public',\n",
       "  'database_access_url']}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta = update_categorized_fields_fair(\"https://doi.org/10.5281/zenodo.1404173\", categorized_fields)\n",
    "\n",
    "categorized_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ec5d4a87-aea1-4162-9a60-9b9ccc023f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetch DBREPO metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "7ee5cf89-7c47-4601-b57c-04415d5966c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import requests\n",
    "\n",
    "DB_API = \"http://localhost/api/database/{db_id}\"\n",
    "HISTORY_API = \"http://localhost/api/database/{db_id}/table/{table_id}/history\"\n",
    "\n",
    "def fetch_db_metadata(db_id: str, table_id: str) -> dict:\n",
    "    try:\n",
    "        # Fetch main DB metadata\n",
    "        db_url = DB_API.format(db_id=db_id)\n",
    "        db_response = requests.get(db_url)\n",
    "        db_response.raise_for_status()\n",
    "        db_data = db_response.json()\n",
    "\n",
    "        # Fetch table history metadata\n",
    "        history_url = HISTORY_API.format(db_id=db_id, table_id=table_id)\n",
    "        history_response = requests.get(history_url)\n",
    "        if history_response.status_code == 200:\n",
    "            history_data = history_response.json()\n",
    "            print(history_data)\n",
    "\n",
    "            timestamp = history_data[0].get(\"timestamp\") if history_data and isinstance(history_data[0], dict) else \"info not available\"\n",
    "        else:\n",
    "            print(f\"Error: Received status code {history_response.status_code}\")\n",
    "            print(\"Response content:\", history_response.text)\n",
    "            timestamp = \"info not available\"\n",
    "\n",
    "        ml_task = \"classification\"\n",
    "        categorized_fields[ \"PROV-O\"] = {\n",
    "                \"prov:Entity\": db_data.get(\"name\", \"info not available\"),\n",
    "                \"prov:Activity\": \"Ingestion and Publication\",\n",
    "                \"prov:Agent\": {\n",
    "                    \"dataset_creator\": \"info not available\",  # Not present in DB data\n",
    "                    \"database_creator\": db_data.get('owner', {}).get('name', 'info not available')\n",
    "                },\n",
    "                \"prov:wasGeneratedBy\": db_data.get('owner', {}).get('name', 'info not available'),\n",
    "                \"prov:used\": db_url,\n",
    "                \"prov:wasDerivedFrom\": \"info not available\",\n",
    "                \"prov:wasAttributedTo\": \"info not available\",\n",
    "                \"prov:wasAssociatedWith\": db_data.get('owner', {}).get('name', 'info not available'),\n",
    "                \"prov:startedAtTime\": \"info not available\",\n",
    "                \"prov:endedAtTime\": timestamp,\n",
    "                \"prov:location\": db_url,\n",
    "                \"prov:role\": {\n",
    "                    \"dataset_creator_role\": \"\",\n",
    "                    \"database_creator_role\": \"Database Ingestor and Maintainer\"\n",
    "                }\n",
    "            }\n",
    "        categorized_fields[ \"FAIR4ML\"] = {\n",
    "                \"dataset_dataset_type\": \"tabular\",\n",
    "                \"columns\": db_data.get(\"columns\", \"info not available\"),\n",
    "                \"target_variable\": \"\",  # TODO\n",
    "                \"ml_task\": ml_task,\n",
    "                \"num_samples\": \"\",  # TODO\n",
    "                \"data_distribution\": \"info not available\",  # TODO\n",
    "                \"known_issues\": \"info not available\",  # TODO\n",
    "                \"trainedOn\": \"info not available\",  # TODO\n",
    "                \"testedOn\": \"info not available\",  # TODO\n",
    "                \"validatedOn\": \"info not available\",  # TODO\n",
    "                \"modelRisks\": \"info not available\",  # TODO\n",
    "                \"usageInstructions\": \"info not available\",  # TODO\n",
    "                \"ethicalLegalSocial\": \"info not available\",  # TODO\n",
    "            }\n",
    "        categorized_fields[ \"Internal/DBRepo\"] =  {\n",
    "                \"database_identifier\": db_data.get(\"id\", \"info not available\"),\n",
    "                \"database_title\": db_data.get(\"name\", \"info not available\"),\n",
    "                \"database_description\": db_data.get(\"description\", \"info not available\"),\n",
    "                \"database_creator\": db_data.get(\"owner\", {}).get(\"name\", \"info not available\"),\n",
    "                \"database_publisher\": db_data.get(\"owner\", {}).get(\"name\", \"info not available\"),\n",
    "                \"database_publication_date\": timestamp,\n",
    "                \"database_version\": db_data.get(\"is_versioned\", \"info not available\"),\n",
    "                \"database_schema_public\": db_data.get(\"is_schema_public\", \"info not available\"),\n",
    "                \"database_access_url\": db_url\n",
    "            }\n",
    "        \n",
    "\n",
    "        return categorized_fields\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"[‚ö†Ô∏è Error] Failed to fetch DB metadata for {db_id}: {e}\")\n",
    "        return {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "91e0611d-d579-485a-ac24-094c1890bc2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'timestamp': '2025-04-23T20:42:29.501Z', 'event': 'insert', 'total': 150}]\n"
     ]
    }
   ],
   "source": [
    " #Datasbase info logging\n",
    "db_id = \"c3a42d17-42b7-43c9-a504-2363fb4c9c8d\"\n",
    "db_meta = fetch_db_metadata(db_id,\"5315e7da-64fb-4fdb-b493-95b4138c765f\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "de8e1fb5-efb5-468a-988e-d0a156fc4b48",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FAIR': {'dataset_identifier': '10.5281/ZENODO.1404173',\n",
       "  'dataset_title': 'Scikit-Learn Iris',\n",
       "  'dataset_description': '<strong>Data Set Characteristics:</strong>\\n\\nNumber of Instances:\\n150 (50 in each of three classes)\\nNumber of Attributes:\\n\\n4 numeric, predictive attributes and the class\\nAttribute Information:\\n\\n\\n\\tsepal length in cm\\n\\tsepal width in cm\\n\\tpetal length in cm\\n\\tpetal width in cm\\n\\t\\n\\tclass:\\n\\n\\t\\n\\t\\tIris-Setosa\\n\\t\\tIris-Versicolour\\n\\t\\tIris-Virginica',\n",
       "  'dataset_creator': 'Marshall Michael',\n",
       "  'dataset_publisher': 'Zenodo',\n",
       "  'dataset_publication_date': '2018-8-27',\n",
       "  'dataset_version': 'info not available',\n",
       "  'dataset_license': 'info not available',\n",
       "  'dataset_keywords': 'info not available',\n",
       "  'dataset_access_url': '10.5281/ZENODO.1404173',\n",
       "  'dataset_documentation': 'https://zenodo.org/record/1404173',\n",
       "  'metadata_standard': 'dataset',\n",
       "  'related_resources': 'https://zenodo.org/record/1404173'},\n",
       " 'PROV-O': {'prov:Entity': 'Iris',\n",
       "  'prov:Activity': 'Ingestion and Publication',\n",
       "  'prov:Agent': {'dataset_creator': 'info not available',\n",
       "   'database_creator': 'Reema George Dass'},\n",
       "  'prov:wasGeneratedBy': 'Reema George Dass',\n",
       "  'prov:used': 'http://localhost/api/database/c3a42d17-42b7-43c9-a504-2363fb4c9c8d',\n",
       "  'prov:wasDerivedFrom': 'info not available',\n",
       "  'prov:wasAttributedTo': 'info not available',\n",
       "  'prov:wasAssociatedWith': 'Reema George Dass',\n",
       "  'prov:startedAtTime': 'info not available',\n",
       "  'prov:endedAtTime': '2025-04-23T20:42:29.501Z',\n",
       "  'prov:location': 'http://localhost/api/database/c3a42d17-42b7-43c9-a504-2363fb4c9c8d',\n",
       "  'prov:role': {'dataset_creator_role': '',\n",
       "   'database_creator_role': 'Database Ingestor and Maintainer'}},\n",
       " 'FAIR4ML': {'dataset_dataset_type': 'tabular',\n",
       "  'columns': 'info not available',\n",
       "  'target_variable': '',\n",
       "  'ml_task': 'classification',\n",
       "  'num_samples': '',\n",
       "  'data_distribution': 'info not available',\n",
       "  'known_issues': 'info not available',\n",
       "  'trainedOn': 'info not available',\n",
       "  'testedOn': 'info not available',\n",
       "  'validatedOn': 'info not available',\n",
       "  'modelRisks': 'info not available',\n",
       "  'usageInstructions': 'info not available',\n",
       "  'ethicalLegalSocial': 'info not available'},\n",
       " 'Internal/DBRepo': {'database_identifier': 'c3a42d17-42b7-43c9-a504-2363fb4c9c8d',\n",
       "  'database_title': 'Iris',\n",
       "  'database_description': None,\n",
       "  'database_creator': 'Reema George Dass',\n",
       "  'database_publisher': 'Reema George Dass',\n",
       "  'database_publication_date': '2025-04-23T20:42:29.501Z',\n",
       "  'database_version': 'info not available',\n",
       "  'database_schema_public': True,\n",
       "  'database_access_url': 'http://localhost/api/database/c3a42d17-42b7-43c9-a504-2363fb4c9c8d'}}"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorized_fields\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "aab28b04-4db7-43bf-8320-f6382120984a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_categorized_fields_to_mlflow(categorized_fields: dict):\n",
    "    def safe_tag(key, value):\n",
    "        # MLflow-safe keys (no colons or invalid characters)\n",
    "        key_clean = key.replace(\":\", \"_\").replace(\"/\", \"_\").replace(\" \", \"_\")\n",
    "        try:\n",
    "            mlflow.set_tag(key_clean, json.dumps(value) if isinstance(value, (dict, list)) else str(value))\n",
    "        except Exception as e:\n",
    "            print(f\"[‚ö†Ô∏è Tag error] {key_clean}: {e}\")\n",
    "\n",
    "    for section, fields in categorized_fields.items():\n",
    "        if isinstance(fields, dict):\n",
    "            for key, value in fields.items():\n",
    "                if isinstance(value, dict):  # e.g. nested like prov:Agent\n",
    "                    for subkey, subval in value.items():\n",
    "                        full_key = f\"{section}_{key}_{subkey}\"\n",
    "                        safe_tag(full_key, subval)\n",
    "                else:\n",
    "                    full_key = f\"{section}_{key}\"\n",
    "                    safe_tag(full_key, value)\n",
    "        else:\n",
    "            print(f\"[‚ö†Ô∏è Skip] {section} ‚Üí Not a dict: {fields}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d4d6b8-34a9-47b5-974d-5927c0ee2256",
   "metadata": {},
   "source": [
    "DBREPO INTEGRETION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "8e3570e2-9a60-45b4-8653-28060071e728",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': '1', 'sepallengthcm': '5.100000000000000000', 'sepalwidthcm': '3.500000000000000000', 'petallengthcm': '1.400000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '2', 'sepallengthcm': '4.900000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '1.400000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '3', 'sepallengthcm': '4.700000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '1.300000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '4', 'sepallengthcm': '4.600000000000000000', 'sepalwidthcm': '3.100000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '5', 'sepallengthcm': '5.000000000000000000', 'sepalwidthcm': '3.600000000000000000', 'petallengthcm': '1.400000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '6', 'sepallengthcm': '5.400000000000000000', 'sepalwidthcm': '3.900000000000000000', 'petallengthcm': '1.700000000000000000', 'petalwidthcm': '0.400000000000000000', 'species': 'Iris-setosa'}, {'id': '7', 'sepallengthcm': '4.600000000000000000', 'sepalwidthcm': '3.400000000000000000', 'petallengthcm': '1.400000000000000000', 'petalwidthcm': '0.300000000000000000', 'species': 'Iris-setosa'}, {'id': '8', 'sepallengthcm': '5.000000000000000000', 'sepalwidthcm': '3.400000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '9', 'sepallengthcm': '4.400000000000000000', 'sepalwidthcm': '2.900000000000000000', 'petallengthcm': '1.400000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '10', 'sepallengthcm': '4.900000000000000000', 'sepalwidthcm': '3.100000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.100000000000000000', 'species': 'Iris-setosa'}, {'id': '11', 'sepallengthcm': '5.400000000000000000', 'sepalwidthcm': '3.700000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '12', 'sepallengthcm': '4.800000000000000000', 'sepalwidthcm': '3.400000000000000000', 'petallengthcm': '1.600000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '13', 'sepallengthcm': '4.800000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '1.400000000000000000', 'petalwidthcm': '0.100000000000000000', 'species': 'Iris-setosa'}, {'id': '14', 'sepallengthcm': '4.300000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '1.100000000000000000', 'petalwidthcm': '0.100000000000000000', 'species': 'Iris-setosa'}, {'id': '15', 'sepallengthcm': '5.800000000000000000', 'sepalwidthcm': '4.000000000000000000', 'petallengthcm': '1.200000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '16', 'sepallengthcm': '5.700000000000000000', 'sepalwidthcm': '4.400000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.400000000000000000', 'species': 'Iris-setosa'}, {'id': '17', 'sepallengthcm': '5.400000000000000000', 'sepalwidthcm': '3.900000000000000000', 'petallengthcm': '1.300000000000000000', 'petalwidthcm': '0.400000000000000000', 'species': 'Iris-setosa'}, {'id': '18', 'sepallengthcm': '5.100000000000000000', 'sepalwidthcm': '3.500000000000000000', 'petallengthcm': '1.400000000000000000', 'petalwidthcm': '0.300000000000000000', 'species': 'Iris-setosa'}, {'id': '19', 'sepallengthcm': '5.700000000000000000', 'sepalwidthcm': '3.800000000000000000', 'petallengthcm': '1.700000000000000000', 'petalwidthcm': '0.300000000000000000', 'species': 'Iris-setosa'}, {'id': '20', 'sepallengthcm': '5.100000000000000000', 'sepalwidthcm': '3.800000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.300000000000000000', 'species': 'Iris-setosa'}, {'id': '21', 'sepallengthcm': '5.400000000000000000', 'sepalwidthcm': '3.400000000000000000', 'petallengthcm': '1.700000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '22', 'sepallengthcm': '5.100000000000000000', 'sepalwidthcm': '3.700000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.400000000000000000', 'species': 'Iris-setosa'}, {'id': '23', 'sepallengthcm': '4.600000000000000000', 'sepalwidthcm': '3.600000000000000000', 'petallengthcm': '1.000000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '24', 'sepallengthcm': '5.100000000000000000', 'sepalwidthcm': '3.300000000000000000', 'petallengthcm': '1.700000000000000000', 'petalwidthcm': '0.500000000000000000', 'species': 'Iris-setosa'}, {'id': '25', 'sepallengthcm': '4.800000000000000000', 'sepalwidthcm': '3.400000000000000000', 'petallengthcm': '1.900000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '26', 'sepallengthcm': '5.000000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '1.600000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '27', 'sepallengthcm': '5.000000000000000000', 'sepalwidthcm': '3.400000000000000000', 'petallengthcm': '1.600000000000000000', 'petalwidthcm': '0.400000000000000000', 'species': 'Iris-setosa'}, {'id': '28', 'sepallengthcm': '5.200000000000000000', 'sepalwidthcm': '3.500000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '29', 'sepallengthcm': '5.200000000000000000', 'sepalwidthcm': '3.400000000000000000', 'petallengthcm': '1.400000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '30', 'sepallengthcm': '4.700000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '1.600000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '31', 'sepallengthcm': '4.800000000000000000', 'sepalwidthcm': '3.100000000000000000', 'petallengthcm': '1.600000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '32', 'sepallengthcm': '5.400000000000000000', 'sepalwidthcm': '3.400000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.400000000000000000', 'species': 'Iris-setosa'}, {'id': '33', 'sepallengthcm': '5.200000000000000000', 'sepalwidthcm': '4.100000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.100000000000000000', 'species': 'Iris-setosa'}, {'id': '34', 'sepallengthcm': '5.500000000000000000', 'sepalwidthcm': '4.200000000000000000', 'petallengthcm': '1.400000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '35', 'sepallengthcm': '4.900000000000000000', 'sepalwidthcm': '3.100000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.100000000000000000', 'species': 'Iris-setosa'}, {'id': '36', 'sepallengthcm': '5.000000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '1.200000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '37', 'sepallengthcm': '5.500000000000000000', 'sepalwidthcm': '3.500000000000000000', 'petallengthcm': '1.300000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '38', 'sepallengthcm': '4.900000000000000000', 'sepalwidthcm': '3.100000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.100000000000000000', 'species': 'Iris-setosa'}, {'id': '39', 'sepallengthcm': '4.400000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '1.300000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '40', 'sepallengthcm': '5.100000000000000000', 'sepalwidthcm': '3.400000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '41', 'sepallengthcm': '5.000000000000000000', 'sepalwidthcm': '3.500000000000000000', 'petallengthcm': '1.300000000000000000', 'petalwidthcm': '0.300000000000000000', 'species': 'Iris-setosa'}, {'id': '42', 'sepallengthcm': '4.500000000000000000', 'sepalwidthcm': '2.300000000000000000', 'petallengthcm': '1.300000000000000000', 'petalwidthcm': '0.300000000000000000', 'species': 'Iris-setosa'}, {'id': '43', 'sepallengthcm': '4.400000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '1.300000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '44', 'sepallengthcm': '5.000000000000000000', 'sepalwidthcm': '3.500000000000000000', 'petallengthcm': '1.600000000000000000', 'petalwidthcm': '0.600000000000000000', 'species': 'Iris-setosa'}, {'id': '45', 'sepallengthcm': '5.100000000000000000', 'sepalwidthcm': '3.800000000000000000', 'petallengthcm': '1.900000000000000000', 'petalwidthcm': '0.400000000000000000', 'species': 'Iris-setosa'}, {'id': '46', 'sepallengthcm': '4.800000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '1.400000000000000000', 'petalwidthcm': '0.300000000000000000', 'species': 'Iris-setosa'}, {'id': '47', 'sepallengthcm': '5.100000000000000000', 'sepalwidthcm': '3.800000000000000000', 'petallengthcm': '1.600000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '48', 'sepallengthcm': '4.600000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '1.400000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '49', 'sepallengthcm': '5.300000000000000000', 'sepalwidthcm': '3.700000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '50', 'sepallengthcm': '5.000000000000000000', 'sepalwidthcm': '3.300000000000000000', 'petallengthcm': '1.400000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '51', 'sepallengthcm': '7.000000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '4.700000000000000000', 'petalwidthcm': '1.400000000000000000', 'species': 'Iris-versicolor'}, {'id': '52', 'sepallengthcm': '6.400000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '4.500000000000000000', 'petalwidthcm': '1.500000000000000000', 'species': 'Iris-versicolor'}, {'id': '53', 'sepallengthcm': '6.900000000000000000', 'sepalwidthcm': '3.100000000000000000', 'petallengthcm': '4.900000000000000000', 'petalwidthcm': '1.500000000000000000', 'species': 'Iris-versicolor'}, {'id': '54', 'sepallengthcm': '5.500000000000000000', 'sepalwidthcm': '2.300000000000000000', 'petallengthcm': '4.000000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '55', 'sepallengthcm': '6.500000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '4.600000000000000000', 'petalwidthcm': '1.500000000000000000', 'species': 'Iris-versicolor'}, {'id': '56', 'sepallengthcm': '5.700000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '4.500000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '57', 'sepallengthcm': '6.300000000000000000', 'sepalwidthcm': '3.300000000000000000', 'petallengthcm': '4.700000000000000000', 'petalwidthcm': '1.600000000000000000', 'species': 'Iris-versicolor'}, {'id': '58', 'sepallengthcm': '4.900000000000000000', 'sepalwidthcm': '2.400000000000000000', 'petallengthcm': '3.300000000000000000', 'petalwidthcm': '1.000000000000000000', 'species': 'Iris-versicolor'}, {'id': '59', 'sepallengthcm': '6.600000000000000000', 'sepalwidthcm': '2.900000000000000000', 'petallengthcm': '4.600000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '60', 'sepallengthcm': '5.200000000000000000', 'sepalwidthcm': '2.700000000000000000', 'petallengthcm': '3.900000000000000000', 'petalwidthcm': '1.400000000000000000', 'species': 'Iris-versicolor'}, {'id': '61', 'sepallengthcm': '5.000000000000000000', 'sepalwidthcm': '2.000000000000000000', 'petallengthcm': '3.500000000000000000', 'petalwidthcm': '1.000000000000000000', 'species': 'Iris-versicolor'}, {'id': '62', 'sepallengthcm': '5.900000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '4.200000000000000000', 'petalwidthcm': '1.500000000000000000', 'species': 'Iris-versicolor'}, {'id': '63', 'sepallengthcm': '6.000000000000000000', 'sepalwidthcm': '2.200000000000000000', 'petallengthcm': '4.000000000000000000', 'petalwidthcm': '1.000000000000000000', 'species': 'Iris-versicolor'}, {'id': '64', 'sepallengthcm': '6.100000000000000000', 'sepalwidthcm': '2.900000000000000000', 'petallengthcm': '4.700000000000000000', 'petalwidthcm': '1.400000000000000000', 'species': 'Iris-versicolor'}, {'id': '65', 'sepallengthcm': '5.600000000000000000', 'sepalwidthcm': '2.900000000000000000', 'petallengthcm': '3.600000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '66', 'sepallengthcm': '6.700000000000000000', 'sepalwidthcm': '3.100000000000000000', 'petallengthcm': '4.400000000000000000', 'petalwidthcm': '1.400000000000000000', 'species': 'Iris-versicolor'}, {'id': '67', 'sepallengthcm': '5.600000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '4.500000000000000000', 'petalwidthcm': '1.500000000000000000', 'species': 'Iris-versicolor'}, {'id': '68', 'sepallengthcm': '5.800000000000000000', 'sepalwidthcm': '2.700000000000000000', 'petallengthcm': '4.100000000000000000', 'petalwidthcm': '1.000000000000000000', 'species': 'Iris-versicolor'}, {'id': '69', 'sepallengthcm': '6.200000000000000000', 'sepalwidthcm': '2.200000000000000000', 'petallengthcm': '4.500000000000000000', 'petalwidthcm': '1.500000000000000000', 'species': 'Iris-versicolor'}, {'id': '70', 'sepallengthcm': '5.600000000000000000', 'sepalwidthcm': '2.500000000000000000', 'petallengthcm': '3.900000000000000000', 'petalwidthcm': '1.100000000000000000', 'species': 'Iris-versicolor'}, {'id': '71', 'sepallengthcm': '5.900000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '4.800000000000000000', 'petalwidthcm': '1.800000000000000000', 'species': 'Iris-versicolor'}, {'id': '72', 'sepallengthcm': '6.100000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '4.000000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '73', 'sepallengthcm': '6.300000000000000000', 'sepalwidthcm': '2.500000000000000000', 'petallengthcm': '4.900000000000000000', 'petalwidthcm': '1.500000000000000000', 'species': 'Iris-versicolor'}, {'id': '74', 'sepallengthcm': '6.100000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '4.700000000000000000', 'petalwidthcm': '1.200000000000000000', 'species': 'Iris-versicolor'}, {'id': '75', 'sepallengthcm': '6.400000000000000000', 'sepalwidthcm': '2.900000000000000000', 'petallengthcm': '4.300000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '76', 'sepallengthcm': '6.600000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '4.400000000000000000', 'petalwidthcm': '1.400000000000000000', 'species': 'Iris-versicolor'}, {'id': '77', 'sepallengthcm': '6.800000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '4.800000000000000000', 'petalwidthcm': '1.400000000000000000', 'species': 'Iris-versicolor'}, {'id': '78', 'sepallengthcm': '6.700000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '5.000000000000000000', 'petalwidthcm': '1.700000000000000000', 'species': 'Iris-versicolor'}, {'id': '79', 'sepallengthcm': '6.000000000000000000', 'sepalwidthcm': '2.900000000000000000', 'petallengthcm': '4.500000000000000000', 'petalwidthcm': '1.500000000000000000', 'species': 'Iris-versicolor'}, {'id': '80', 'sepallengthcm': '5.700000000000000000', 'sepalwidthcm': '2.600000000000000000', 'petallengthcm': '3.500000000000000000', 'petalwidthcm': '1.000000000000000000', 'species': 'Iris-versicolor'}, {'id': '81', 'sepallengthcm': '5.500000000000000000', 'sepalwidthcm': '2.400000000000000000', 'petallengthcm': '3.800000000000000000', 'petalwidthcm': '1.100000000000000000', 'species': 'Iris-versicolor'}, {'id': '82', 'sepallengthcm': '5.500000000000000000', 'sepalwidthcm': '2.400000000000000000', 'petallengthcm': '3.700000000000000000', 'petalwidthcm': '1.000000000000000000', 'species': 'Iris-versicolor'}, {'id': '83', 'sepallengthcm': '5.800000000000000000', 'sepalwidthcm': '2.700000000000000000', 'petallengthcm': '3.900000000000000000', 'petalwidthcm': '1.200000000000000000', 'species': 'Iris-versicolor'}, {'id': '84', 'sepallengthcm': '6.000000000000000000', 'sepalwidthcm': '2.700000000000000000', 'petallengthcm': '5.100000000000000000', 'petalwidthcm': '1.600000000000000000', 'species': 'Iris-versicolor'}, {'id': '85', 'sepallengthcm': '5.400000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '4.500000000000000000', 'petalwidthcm': '1.500000000000000000', 'species': 'Iris-versicolor'}, {'id': '86', 'sepallengthcm': '6.000000000000000000', 'sepalwidthcm': '3.400000000000000000', 'petallengthcm': '4.500000000000000000', 'petalwidthcm': '1.600000000000000000', 'species': 'Iris-versicolor'}, {'id': '87', 'sepallengthcm': '6.700000000000000000', 'sepalwidthcm': '3.100000000000000000', 'petallengthcm': '4.700000000000000000', 'petalwidthcm': '1.500000000000000000', 'species': 'Iris-versicolor'}, {'id': '88', 'sepallengthcm': '6.300000000000000000', 'sepalwidthcm': '2.300000000000000000', 'petallengthcm': '4.400000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '89', 'sepallengthcm': '5.600000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '4.100000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '90', 'sepallengthcm': '5.500000000000000000', 'sepalwidthcm': '2.500000000000000000', 'petallengthcm': '4.000000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '91', 'sepallengthcm': '5.500000000000000000', 'sepalwidthcm': '2.600000000000000000', 'petallengthcm': '4.400000000000000000', 'petalwidthcm': '1.200000000000000000', 'species': 'Iris-versicolor'}, {'id': '92', 'sepallengthcm': '6.100000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '4.600000000000000000', 'petalwidthcm': '1.400000000000000000', 'species': 'Iris-versicolor'}, {'id': '93', 'sepallengthcm': '5.800000000000000000', 'sepalwidthcm': '2.600000000000000000', 'petallengthcm': '4.000000000000000000', 'petalwidthcm': '1.200000000000000000', 'species': 'Iris-versicolor'}, {'id': '94', 'sepallengthcm': '5.000000000000000000', 'sepalwidthcm': '2.300000000000000000', 'petallengthcm': '3.300000000000000000', 'petalwidthcm': '1.000000000000000000', 'species': 'Iris-versicolor'}, {'id': '95', 'sepallengthcm': '5.600000000000000000', 'sepalwidthcm': '2.700000000000000000', 'petallengthcm': '4.200000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '96', 'sepallengthcm': '5.700000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '4.200000000000000000', 'petalwidthcm': '1.200000000000000000', 'species': 'Iris-versicolor'}, {'id': '97', 'sepallengthcm': '5.700000000000000000', 'sepalwidthcm': '2.900000000000000000', 'petallengthcm': '4.200000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '98', 'sepallengthcm': '6.200000000000000000', 'sepalwidthcm': '2.900000000000000000', 'petallengthcm': '4.300000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '99', 'sepallengthcm': '5.100000000000000000', 'sepalwidthcm': '2.500000000000000000', 'petallengthcm': '3.000000000000000000', 'petalwidthcm': '1.100000000000000000', 'species': 'Iris-versicolor'}, {'id': '100', 'sepallengthcm': '5.700000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '4.100000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '101', 'sepallengthcm': '6.300000000000000000', 'sepalwidthcm': '3.300000000000000000', 'petallengthcm': '6.000000000000000000', 'petalwidthcm': '2.500000000000000000', 'species': 'Iris-virginica'}, {'id': '102', 'sepallengthcm': '5.800000000000000000', 'sepalwidthcm': '2.700000000000000000', 'petallengthcm': '5.100000000000000000', 'petalwidthcm': '1.900000000000000000', 'species': 'Iris-virginica'}, {'id': '103', 'sepallengthcm': '7.100000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '5.900000000000000000', 'petalwidthcm': '2.100000000000000000', 'species': 'Iris-virginica'}, {'id': '104', 'sepallengthcm': '6.300000000000000000', 'sepalwidthcm': '2.900000000000000000', 'petallengthcm': '5.600000000000000000', 'petalwidthcm': '1.800000000000000000', 'species': 'Iris-virginica'}, {'id': '105', 'sepallengthcm': '6.500000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '5.800000000000000000', 'petalwidthcm': '2.200000000000000000', 'species': 'Iris-virginica'}, {'id': '106', 'sepallengthcm': '7.600000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '6.600000000000000000', 'petalwidthcm': '2.100000000000000000', 'species': 'Iris-virginica'}, {'id': '107', 'sepallengthcm': '4.900000000000000000', 'sepalwidthcm': '2.500000000000000000', 'petallengthcm': '4.500000000000000000', 'petalwidthcm': '1.700000000000000000', 'species': 'Iris-virginica'}, {'id': '108', 'sepallengthcm': '7.300000000000000000', 'sepalwidthcm': '2.900000000000000000', 'petallengthcm': '6.300000000000000000', 'petalwidthcm': '1.800000000000000000', 'species': 'Iris-virginica'}, {'id': '109', 'sepallengthcm': '6.700000000000000000', 'sepalwidthcm': '2.500000000000000000', 'petallengthcm': '5.800000000000000000', 'petalwidthcm': '1.800000000000000000', 'species': 'Iris-virginica'}, {'id': '110', 'sepallengthcm': '7.200000000000000000', 'sepalwidthcm': '3.600000000000000000', 'petallengthcm': '6.100000000000000000', 'petalwidthcm': '2.500000000000000000', 'species': 'Iris-virginica'}, {'id': '111', 'sepallengthcm': '6.500000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '5.100000000000000000', 'petalwidthcm': '2.000000000000000000', 'species': 'Iris-virginica'}, {'id': '112', 'sepallengthcm': '6.400000000000000000', 'sepalwidthcm': '2.700000000000000000', 'petallengthcm': '5.300000000000000000', 'petalwidthcm': '1.900000000000000000', 'species': 'Iris-virginica'}, {'id': '113', 'sepallengthcm': '6.800000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '5.500000000000000000', 'petalwidthcm': '2.100000000000000000', 'species': 'Iris-virginica'}, {'id': '114', 'sepallengthcm': '5.700000000000000000', 'sepalwidthcm': '2.500000000000000000', 'petallengthcm': '5.000000000000000000', 'petalwidthcm': '2.000000000000000000', 'species': 'Iris-virginica'}, {'id': '115', 'sepallengthcm': '5.800000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '5.100000000000000000', 'petalwidthcm': '2.400000000000000000', 'species': 'Iris-virginica'}, {'id': '116', 'sepallengthcm': '6.400000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '5.300000000000000000', 'petalwidthcm': '2.300000000000000000', 'species': 'Iris-virginica'}, {'id': '117', 'sepallengthcm': '6.500000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '5.500000000000000000', 'petalwidthcm': '1.800000000000000000', 'species': 'Iris-virginica'}, {'id': '118', 'sepallengthcm': '7.700000000000000000', 'sepalwidthcm': '3.800000000000000000', 'petallengthcm': '6.700000000000000000', 'petalwidthcm': '2.200000000000000000', 'species': 'Iris-virginica'}, {'id': '119', 'sepallengthcm': '7.700000000000000000', 'sepalwidthcm': '2.600000000000000000', 'petallengthcm': '6.900000000000000000', 'petalwidthcm': '2.300000000000000000', 'species': 'Iris-virginica'}, {'id': '120', 'sepallengthcm': '6.000000000000000000', 'sepalwidthcm': '2.200000000000000000', 'petallengthcm': '5.000000000000000000', 'petalwidthcm': '1.500000000000000000', 'species': 'Iris-virginica'}, {'id': '121', 'sepallengthcm': '6.900000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '5.700000000000000000', 'petalwidthcm': '2.300000000000000000', 'species': 'Iris-virginica'}, {'id': '122', 'sepallengthcm': '5.600000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '4.900000000000000000', 'petalwidthcm': '2.000000000000000000', 'species': 'Iris-virginica'}, {'id': '123', 'sepallengthcm': '7.700000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '6.700000000000000000', 'petalwidthcm': '2.000000000000000000', 'species': 'Iris-virginica'}, {'id': '124', 'sepallengthcm': '6.300000000000000000', 'sepalwidthcm': '2.700000000000000000', 'petallengthcm': '4.900000000000000000', 'petalwidthcm': '1.800000000000000000', 'species': 'Iris-virginica'}, {'id': '125', 'sepallengthcm': '6.700000000000000000', 'sepalwidthcm': '3.300000000000000000', 'petallengthcm': '5.700000000000000000', 'petalwidthcm': '2.100000000000000000', 'species': 'Iris-virginica'}, {'id': '126', 'sepallengthcm': '7.200000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '6.000000000000000000', 'petalwidthcm': '1.800000000000000000', 'species': 'Iris-virginica'}, {'id': '127', 'sepallengthcm': '6.200000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '4.800000000000000000', 'petalwidthcm': '1.800000000000000000', 'species': 'Iris-virginica'}, {'id': '128', 'sepallengthcm': '6.100000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '4.900000000000000000', 'petalwidthcm': '1.800000000000000000', 'species': 'Iris-virginica'}, {'id': '129', 'sepallengthcm': '6.400000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '5.600000000000000000', 'petalwidthcm': '2.100000000000000000', 'species': 'Iris-virginica'}, {'id': '130', 'sepallengthcm': '7.200000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '5.800000000000000000', 'petalwidthcm': '1.600000000000000000', 'species': 'Iris-virginica'}, {'id': '131', 'sepallengthcm': '7.400000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '6.100000000000000000', 'petalwidthcm': '1.900000000000000000', 'species': 'Iris-virginica'}, {'id': '132', 'sepallengthcm': '7.900000000000000000', 'sepalwidthcm': '3.800000000000000000', 'petallengthcm': '6.400000000000000000', 'petalwidthcm': '2.000000000000000000', 'species': 'Iris-virginica'}, {'id': '133', 'sepallengthcm': '6.400000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '5.600000000000000000', 'petalwidthcm': '2.200000000000000000', 'species': 'Iris-virginica'}, {'id': '134', 'sepallengthcm': '6.300000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '5.100000000000000000', 'petalwidthcm': '1.500000000000000000', 'species': 'Iris-virginica'}, {'id': '135', 'sepallengthcm': '6.100000000000000000', 'sepalwidthcm': '2.600000000000000000', 'petallengthcm': '5.600000000000000000', 'petalwidthcm': '1.400000000000000000', 'species': 'Iris-virginica'}, {'id': '136', 'sepallengthcm': '7.700000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '6.100000000000000000', 'petalwidthcm': '2.300000000000000000', 'species': 'Iris-virginica'}, {'id': '137', 'sepallengthcm': '6.300000000000000000', 'sepalwidthcm': '3.400000000000000000', 'petallengthcm': '5.600000000000000000', 'petalwidthcm': '2.400000000000000000', 'species': 'Iris-virginica'}, {'id': '138', 'sepallengthcm': '6.400000000000000000', 'sepalwidthcm': '3.100000000000000000', 'petallengthcm': '5.500000000000000000', 'petalwidthcm': '1.800000000000000000', 'species': 'Iris-virginica'}, {'id': '139', 'sepallengthcm': '6.000000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '4.800000000000000000', 'petalwidthcm': '1.800000000000000000', 'species': 'Iris-virginica'}, {'id': '140', 'sepallengthcm': '6.900000000000000000', 'sepalwidthcm': '3.100000000000000000', 'petallengthcm': '5.400000000000000000', 'petalwidthcm': '2.100000000000000000', 'species': 'Iris-virginica'}, {'id': '141', 'sepallengthcm': '6.700000000000000000', 'sepalwidthcm': '3.100000000000000000', 'petallengthcm': '5.600000000000000000', 'petalwidthcm': '2.400000000000000000', 'species': 'Iris-virginica'}, {'id': '142', 'sepallengthcm': '6.900000000000000000', 'sepalwidthcm': '3.100000000000000000', 'petallengthcm': '5.100000000000000000', 'petalwidthcm': '2.300000000000000000', 'species': 'Iris-virginica'}, {'id': '143', 'sepallengthcm': '5.800000000000000000', 'sepalwidthcm': '2.700000000000000000', 'petallengthcm': '5.100000000000000000', 'petalwidthcm': '1.900000000000000000', 'species': 'Iris-virginica'}, {'id': '144', 'sepallengthcm': '6.800000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '5.900000000000000000', 'petalwidthcm': '2.300000000000000000', 'species': 'Iris-virginica'}, {'id': '145', 'sepallengthcm': '6.700000000000000000', 'sepalwidthcm': '3.300000000000000000', 'petallengthcm': '5.700000000000000000', 'petalwidthcm': '2.500000000000000000', 'species': 'Iris-virginica'}, {'id': '146', 'sepallengthcm': '6.700000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '5.200000000000000000', 'petalwidthcm': '2.300000000000000000', 'species': 'Iris-virginica'}, {'id': '147', 'sepallengthcm': '6.300000000000000000', 'sepalwidthcm': '2.500000000000000000', 'petallengthcm': '5.000000000000000000', 'petalwidthcm': '1.900000000000000000', 'species': 'Iris-virginica'}, {'id': '148', 'sepallengthcm': '6.500000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '5.200000000000000000', 'petalwidthcm': '2.000000000000000000', 'species': 'Iris-virginica'}, {'id': '149', 'sepallengthcm': '6.200000000000000000', 'sepalwidthcm': '3.400000000000000000', 'petallengthcm': '5.400000000000000000', 'petalwidthcm': '2.300000000000000000', 'species': 'Iris-virginica'}, {'id': '150', 'sepallengthcm': '5.900000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '5.100000000000000000', 'petalwidthcm': '1.800000000000000000', 'species': 'Iris-virginica'}]\n"
     ]
    }
   ],
   "source": [
    "# API endpoint URL\n",
    "API_URL = \"http://localhost/api/database/c3a42d17-42b7-43c9-a504-2363fb4c9c8d/table/5315e7da-64fb-4fdb-b493-95b4138c765f/data?size=100000&page=0\"\n",
    "\n",
    "# Define the headers\n",
    "headers = {\n",
    "    \"Accept\": \"application/json\"  # Specify the expected response format\n",
    "}\n",
    "\n",
    "try:\n",
    "    # Send a GET request to the API with the Accept header\n",
    "    response = requests.get(API_URL, headers=headers)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Parse the JSON response\n",
    "        dataset = response.json()\n",
    "        \n",
    "        \n",
    "        print( dataset)\n",
    "    else:\n",
    "        print(f\"Error: Received status code {response.status_code}\")\n",
    "        print(\"Response content:\", response.text)\n",
    "       \n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"Request failed: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09557f94-325c-4bd6-882a-069a9e3c5ecd",
   "metadata": {},
   "source": [
    "replacing dynamic fetching of data When and if DBREPO isnt running "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce6e020d-cb80-49ec-8bcc-687b1e08885c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Read the JSON file id the API isnt available this data is saved locally but the data is from the API endpoint\n",
    "with open(\"iris_data.json\", \"r\") as f:\n",
    "    dataset = json.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c6007a-2126-4b1a-90ee-3326eb39a362",
   "metadata": {},
   "source": [
    "Metadata fetching from db repo API CALLS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9165f478-a44e-4125-8929-a8d77fdcb4c5",
   "metadata": {},
   "source": [
    "METADATA ON DATABASE LEVEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cbd7eb-0d97-4326-9bfc-f6fcee14ef9c",
   "metadata": {},
   "source": [
    "MATADATA FROM: <ns0:OAI-PMH xmlns:ns0=\"http://www.openarchives.org/OAI/2.0/\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c92e13-eb57-418d-b354-83777f88aa98",
   "metadata": {},
   "source": [
    "##################################################################\n",
    "# DATA PREPROCESSING STEPS\n",
    "###################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9832d0df-af0a-4eee-90d0-fab926e03e85",
   "metadata": {},
   "source": [
    "STEP 1: LOAD DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6862e341-3ea1-43f6-a1ac-9a51188fe614",
   "metadata": {},
   "source": [
    "STEP2: seperate Dependent and Independent variables and drop unnecessary columns like ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367d6256-a30a-4f91-bc64-f20966d828ab",
   "metadata": {},
   "source": [
    "STEP3: Label Encoding as the target values are class names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcf2244-14dd-4e3d-b8cf-f7f3ba34f80f",
   "metadata": {},
   "source": [
    "# ============================\n",
    "# üìÇ Setup MLflow\n",
    "# ============================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cbe91ec0-6447-4586-b7cc-2c1f74d4218f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///C:/Users/reema/REPO/notebooks/RQ_notebooks/mlrunlogs/mlflow.db/615223710259862608', creation_time=1745329164532, experiment_id='615223710259862608', last_update_time=1745329164532, lifecycle_stage='active', name='RandomForest-Iris-CSV', tags={}>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "project_dir = os.getcwd()\n",
    "mlflow.set_tracking_uri(\"mlrunlogs/mlflow.db\")\n",
    "mlflow.set_experiment(\"RandomForest-Iris-CSV\")\n",
    "# mlflow.sklearn.autolog()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2c2c5f-cc36-41a3-9643-83ef95b9f55e",
   "metadata": {},
   "source": [
    "# ============================\n",
    "# üîÑ Git Commit Hash for previous commit for metadata\n",
    "# ============================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "838dd233-25dc-4725-974d-4da89c257782",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "repo_dir = \"C:/Users/reema/REPO\"\n",
    "previous_commit_repo = git.Repo(repo_dir)\n",
    "previous_commit_hash = previous_commit_repo.head.object.hexsha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430d15ef-3432-4e45-88fb-b7048a5b10a9",
   "metadata": {},
   "source": [
    "# ============================\n",
    "# Make threadpoolctl safe so MLflow‚Äôs autologger won‚Äôt crash ‚îÄ‚îÄ‚îÄ\n",
    "# ============================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "9668451f-4352-4bdc-8b6b-bbe49074212a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/04 11:14:19 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
      "2025/05/04 11:14:19 INFO mlflow.tracking.fluent: Autologging successfully enabled for statsmodels.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import threadpoolctl\n",
    "    _orig = threadpoolctl.threadpool_info\n",
    "    def _safe_threadpool_info(*args, **kwargs):\n",
    "        try:\n",
    "            return _orig(*args, **kwargs)\n",
    "        except Exception:\n",
    "            return []\n",
    "    threadpoolctl.threadpool_info = _safe_threadpool_info\n",
    "except ImportError:\n",
    "    pass  # if threadpoolctl isn‚Äôt installed, autolog will skip unsupported versions\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 1) Enable generic autolog (will auto-patch sklearn under the hood) ‚îÄ‚îÄ‚îÄ\n",
    "import mlflow\n",
    "mlflow.autolog(\n",
    "    log_input_examples=True,\n",
    "    log_model_signatures=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "2b608670-96a5-42b0-b69b-263ac1e452eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil\n",
    "import platform\n",
    "import json\n",
    "import os\n",
    "\n",
    "def log_standard_metadata(\n",
    "    model_name: str,\n",
    "    model,\n",
    "    hyperparams: dict,\n",
    "    acc: float,\n",
    "    prec: float,\n",
    "    rec: float,\n",
    "    f1: float,\n",
    "    auc: float,\n",
    "    label_map: dict,\n",
    "    run_id: str,\n",
    "    test_size: float,\n",
    "    random_state: int,\n",
    "    run_data=None\n",
    "):\n",
    "    # ========== FAIR4ML (model-related only) ==========\n",
    "    mlflow.set_tag(\"FAIR4ML_intendedUse\", \"Multiclass classification using RandomForest\")\n",
    "    mlflow.set_tag(\"FAIR4ML_fineTunedFrom\", model_name if \"fine-tuned\" in model_name.lower() else \"None\")\n",
    "    mlflow.set_tag(\"FAIR4ML_usageInstructions\", \"Call `.predict()` on a feature-aligned DataFrame\")\n",
    "    mlflow.set_tag(\"FAIR4ML_ethicalLegalSocial\", \"No ethical risks; trained on open dataset\")\n",
    "    mlflow.set_tag(\"FAIR4ML_modelRisks\", \"May misclassify overlapping species\")\n",
    "    mlflow.set_tag(\"FAIR4ML_hasCO2eEmissions\", \"Low; trained locally on a small dataset\")\n",
    "    mlflow.set_tag(\"FAIR4ML_sharedBy\", \"Your Name or Organization\")\n",
    "    mlflow.set_tag(\"FAIR4ML_serializationFormat\", \"pickle\")\n",
    "\n",
    "    # ========== Croissant structure (minimal) ==========\n",
    "    mlflow.set_tag(\"CR_RecordSet\", \"Feature vectors for model training\")\n",
    "    mlflow.set_tag(\"CR_Field\", \"Input features used for training\")\n",
    "    mlflow.set_tag(\"CR_encodingFormat\", \"text/csv\")\n",
    "\n",
    "    # ========== MLSEA ==========\n",
    "    mlflow.set_tag(\"MLSEA_experimentId\", run_id)\n",
    "    mlflow.set_tag(\"MLSEA_modelArchitecture\", model.__class__.__name__)\n",
    "    mlflow.set_tag(\"MLSEA_hyperparameters\", json.dumps(hyperparams))\n",
    "    mlflow.set_tag(\"MLSEA_trainingProcedure\", f\"train_test_split with test_size={test_size}, random_state={random_state}\")\n",
    "    mlflow.set_tag(\"MLSEA_evaluationMetrics\", json.dumps({\n",
    "        \"accuracy\": acc,\n",
    "        \"precision_macro\": prec,\n",
    "        \"recall_macro\": rec,\n",
    "        \"f1_macro\": f1,\n",
    "        \"roc_auc\": auc\n",
    "    }))\n",
    "   preprocessing_info = {\n",
    "    \"label_encoding\": label_map,\n",
    "    \"dropped_columns\": id_cols,\n",
    "    \"numeric_coercion_attempted\": list(X.columns),\n",
    "    \"final_feature_columns\": list(X.columns),\n",
    "    \"target_column\": target_col,\n",
    "    \"coercion_strategy\": \"Tried to cast all features to numeric\",\n",
    "    \"missing_value_strategy\": \"None detected in dataset\",\n",
    "    \"outlier_detection\": \"None applied\",\n",
    "    \"categorical_encoding\": \"LabelEncoder for target, none for features\",\n",
    "    \"feature_selection\": {\n",
    "        \"method\": \"None\",\n",
    "        \"selected_features\": list(X.columns)\n",
    "    },\n",
    "    \"train_test_split\": {\n",
    "        \"test_size\": test_size,\n",
    "        \"random_state\": random_state,\n",
    "        \"stratified\": False\n",
    "    },\n",
    "    \"pipeline_used\": False,\n",
    "    \"feature_engineering\": \"None\",\n",
    "    \"preprocessing_version\": \"v1.0\",\n",
    "    \"preprocessing_timestamp\": datetime.now().isoformat()\n",
    "    \"scaling_applied\": \"None\",\n",
    "    \"feature_normalization\": False,\n",
    "    \"duplicate_rows_removed\": False,\n",
    "    \"sampling_strategy\": \"None\",\n",
    "    \"imbalance_ratio\": str(dict(zip(*np.unique(y, return_counts=True))))\n",
    "    }\n",
    "     # Hash for reproducibility\n",
    "    preprocessing_hash = hashlib.sha256(json.dumps(preprocessing_info).encode()).hexdigest()\n",
    "    mlflow.set_tag(\"MLSEA_preprocessing_hash\", preprocessing_hash)\n",
    "\n",
    "    mlflow.set_tag(\"MLSEA_dataPreprocessing\", json.dumps(preprocessing_info))\n",
    "    mlflow.set_tag(\"MLSEA_modelPath\", f\"{model_name}.pkl\")\n",
    "    mlflow.set_tag(\"MLSEA_computeEnvironment\", json.dumps(compute_env))\n",
    "\n",
    "    mlflow.set_tag(\"MLSEA_performanceInterpretation\", (\n",
    "        \"Model performs well with F1 macro > 0.90. \"\n",
    "        \"ROC AUC confirms balanced performance across all classes.\"\n",
    "    ))\n",
    "\n",
    "    # Git commit hash (optional, safe fallback)\n",
    "    try:\n",
    "        from subprocess import check_output\n",
    "        sha = check_output([\"git\", \"rev-parse\", \"HEAD\"], text=True).strip()\n",
    "    except Exception:\n",
    "        sha = \"unknown\"\n",
    "    mlflow.set_tag(\"MLSEA_trainingCodeSnapshot\", sha)\n",
    "\n",
    "    mlflow.set_tag(\"MLSEA_previousModelRunId\", \"None\")\n",
    "    mlflow.set_tag(\"MLSEA_improvedFrom\", \"baseline_randomforest_2024\")\n",
    "\n",
    "    # Compute environment\n",
    "    compute_env = {\n",
    "        \"os\": f\"{platform.system()} {platform.release()}\",\n",
    "        \"cpu\": platform.processor(),\n",
    "        \"ram_gb\": round(psutil.virtual_memory().total / (1024 ** 3), 2),\n",
    "        \"python_version\": platform.python_version(),\n",
    "        \"sklearn_version\": sklearn.__version__,\n",
    "        \"pandas_version\": pd.__version__,\n",
    "        \"numpy_version\": np.__version__,\n",
    "    }\n",
    "    mlflow.set_tag(\"MLSEA_computeEnvironment\", json.dumps(compute_env))\n",
    "\n",
    "    mlflow.set_tag(\"MLSEA_performanceInterpretation\", (\n",
    "        \"Model performs well with F1 macro > 0.90. \"\n",
    "        \"ROC AUC confirms balanced performance across all classes.\"\n",
    "    ))\n",
    "\n",
    "    # Justifications (already captured as justification_X ‚Üí re-tag under mlsea)\n",
    "    if run_data is not None:\n",
    "        for key, val in run_data.tags.items():\n",
    "            if key.startswith(\"justification_\"):\n",
    "                new_key = \"MLSEA_justification_\" + key.replace(\"justification_\", \"\")\n",
    "                mlflow.set_tag(new_key, val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "b04861da-f69b-4b73-b237-b79d340c59c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9058319a-adba-4a6b-93e9-d17080c0594d",
   "metadata": {},
   "source": [
    "# ============================\n",
    "# üöÄ Start MLflow Run \n",
    "# ============================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "14c62f08-a116-4060-9689-f69968e9f240",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ML_EXP_Shapes: (150, 4) (150,)\n",
      "ML_EXP_Classes: ['Iris-setosa' 'Iris-versicolor' 'Iris-virginica']\n",
      "[{'timestamp': '2025-04-23T20:42:29.501Z', 'event': 'insert', 'total': 150}]\n",
      "\n",
      "üìù Justification for `n_estimators` (Hyperparameter configuration)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "‚Üí Why did you choose this value?  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìù Justification for `criterion` (Hyperparameter configuration)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "‚Üí Why did you choose this value?  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìù Justification for `max_depth` (Hyperparameter configuration)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "‚Üí Why did you choose this value?  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìù Justification for `min_samples_split` (Hyperparameter configuration)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "‚Üí Why did you choose this value?  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìù Justification for `min_samples_leaf` (Hyperparameter configuration)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "‚Üí Why did you choose this value?  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìù Justification for `max_features` (Hyperparameter configuration)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "‚Üí Why did you choose this value?  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìù Justification for `bootstrap` (Hyperparameter configuration)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "‚Üí Why did you choose this value?  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìù Justification for `oob_score` (Hyperparameter configuration)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "‚Üí Why did you choose this value?  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìù Justification for `class_weight` (Hyperparameter configuration)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "‚Üí Why did you choose this value?  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìù Justification for `random_state` (Hyperparameter configuration)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "‚Üí Why did you choose this value?  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìù Justification for `verbose` (Hyperparameter configuration)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "‚Üí Why did you choose this value?  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìù Justification for `n_jobs` (Hyperparameter configuration)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "‚Üí Why did you choose this value?  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìù Justification for `ML_EXP_model_choice`\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "‚Üí Why did you choose RandomForestClassifier for this task?  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìù Justification for `ML_EXP_target_variable`\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "‚Üí Why did you choose this column as the prediction target?  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìù Justification for `ML_EXP_test_split`\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "‚Üí Why this train/test ratio (e.g., 80/20)?  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìù Justification for `ML_EXP_metric_choice`\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "‚Üí Why accuracy/f1/ROC-AUC as your evaluation metric?  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìù Justification for `ML_EXP_threshold_accuracy`\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "‚Üí Why 0.95 as performance threshold?  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìù Justification for `ML_EXP_dataset_version`\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "‚Üí Why use this specific dataset version?  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìù Justification for `ML_EXP_drop_column_X`\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "‚Üí Why drop any specific columns from the dataset?  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìù Justification for `ML_EXP_experiment_name`\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "‚Üí Any context behind this experiment name or setup?  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 200 out of 200 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "042a88d91df946e189ae63dde673a8ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "C:\\Users\\reema\\anaconda3\\Lib\\site-packages\\shap\\plots\\_beeswarm.py:1153: UserWarning: The figure layout has changed to tight\n",
      "  pl.tight_layout()\n",
      "C:\\Users\\reema\\anaconda3\\Lib\\site-packages\\shap\\plots\\_beeswarm.py:761: UserWarning: The figure layout has changed to tight\n",
      "  pl.tight_layout(pad=0, w_pad=0, h_pad=0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Commit successful.\n",
      "üöÄ Push successful.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 600x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1150x660 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "with mlflow.start_run() as run:\n",
    "    # Start time\n",
    "    start_time = datetime.now().isoformat()\n",
    "    mlflow.set_tag(\"PROV_startedAtTime\", start_time)\n",
    "\n",
    "#################################################\n",
    "# Justification LOGGER\n",
    "################################################\n",
    "    mlflow.log_params(session_metadata)\n",
    "\n",
    "    # ‚îÄ‚îÄ 2) Load into a DataFrame ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    df = pd.DataFrame(dataset)\n",
    "\n",
    "    target_col = df.columns[-1]      # e.g. \"species\"\n",
    "    categorized_fields[\"FAIR4ML\"] = {\n",
    "        \"target_variable\": target_col,\n",
    "         \"num_samples\":df.shape[0]\n",
    "    }\n",
    "    log_categorized_fields_to_mlflow(categorized_fields)\n",
    "\n",
    "    # 2) extract y as the Series of labels\n",
    "    y = df[target_col]               # length == n_samples\n",
    "    \n",
    "    # 3) build X by dropping just that one column\n",
    "    X = df.drop(columns=[target_col])\n",
    "    \n",
    "    # 4) drop any ID column (case-insensitive)\n",
    "    id_cols = [c for c in X.columns if c.lower() == \"id\"]\n",
    "    if id_cols:\n",
    "        X = X.drop(columns=id_cols)\n",
    "    \n",
    "    # 5) coerce numeric where possible\n",
    "    for c in X.columns:\n",
    "        try:\n",
    "            X[c] = pd.to_numeric(X[c])\n",
    "        except Exception:\n",
    "            pass\n",
    "    \n",
    "    print(\"ML_EXP_Shapes:\", X.shape, y.shape)\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(y)  \n",
    "    \n",
    "    # now y_enc is a 1d numpy array of ints 0,1,2\n",
    "    print(\"ML_EXP_Classes:\", le.classes_)  \n",
    "    \n",
    "    # ‚îÄ‚îÄ 4) Cast feature columns to numeric where possible ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    for col in X.columns:\n",
    "        try:\n",
    "            X[col] = pd.to_numeric(X[col])   # no errors=\"ignore\"\n",
    "        except ValueError:\n",
    "            # if it can‚Äôt be cast, just leave it as-is\n",
    "            pass\n",
    "    # ‚îÄ‚îÄ 5) Drop any ‚Äúid‚Äù column (case-insensitive) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    dropped = [c for c in X.columns if c.lower() == \"id\"]\n",
    "    X = X.drop(columns=dropped, errors=\"ignore\")\n",
    "    \n",
    "    def log_with_justification(log_func, key, value, context=\"\"):\n",
    "        \"\"\"\n",
    "        Log a parameter/metric/tag using `log_func` and ask for justification via console.\n",
    "        \"\"\"\n",
    "        log_func(key, value)\n",
    "        print(f\"\\nüìù Justification for `{key}` ({context})\")\n",
    "        user_reason = input(\"‚Üí Why did you choose this value? \")\n",
    "        mlflow.set_tag(f\"justification_{key}\", user_reason or \"No justification provided\")\n",
    "\n",
    "    def log_justification(key: str, question: str):\n",
    "        print(f\"\\nüìù Justification for `{key}`\")\n",
    "        user_reason = input(f\"‚Üí {question} \")\n",
    "        mlflow.set_tag(f\"justification_{key}\", user_reason or \"No justification provided\")\n",
    "\n",
    "\n",
    "\n",
    "    meta = fetch_and_log_dataset_metadata_nested(\n",
    "            \"https://doi.org/10.5281/zenodo.1404173\",\n",
    "           \n",
    "        )\n",
    "\n",
    "    #Datasbase info logging\n",
    "    db_id = \"c3a42d17-42b7-43c9-a504-2363fb4c9c8d\"\n",
    "    table_id=\"5315e7da-64fb-4fdb-b493-95b4138c765f\"\n",
    "    db_meta = fetch_db_metadata(db_id,table_id)\n",
    "    # log_db_metadata(db_meta)\n",
    "\n",
    "   \n",
    "    # provenance tags\n",
    "    mlflow.set_tag(\"Internal_DBRepo_table_last_modified\", ts_last)\n",
    "\n",
    "    # row-count metrics\n",
    "    mlflow.log_metric(\"Internal_DBRepo_row_count_start\", count_start)\n",
    "    mlflow.log_metric(\"Internal_DBRepo_row_count_end\",   count_end)\n",
    "\n",
    "    # change-event metrics\n",
    "    mlflow.log_metric(\"Internal_DBRepo_num_inserts\", n_insert)\n",
    "    mlflow.log_metric(\"Internal_DBRepo_num_deletes\", n_delete)\n",
    "    \n",
    "    # 2) Capture raw metadata\n",
    "    mlflow.set_tag(\"Internal_DBRepo_data_source\", API_URL)\n",
    "    mlflow.log_param(\"Internal_DBRepo_retrieval_time\", datetime.utcnow().isoformat())\n",
    "    mlflow.log_param(\"Internal_DBRepo_n_records\", len(df))\n",
    "    mlflow.log_param(\"Internal_DBRepo_columns_raw\", df.columns.tolist())\n",
    "    mlflow.log_param(\"Internal_DBRepo_dropped_columns\", id_cols)\n",
    "\n",
    "    # 4) Post‚Äêprocessing metadata\n",
    "    mlflow.log_param(\"Internal_DBRepo_n_features_final\", X.shape[1])\n",
    "    mlflow.log_param(\"Internal_DBRepo_feature_names\", X.columns.tolist())\n",
    "    mlflow.set_tag(\"Internal_DBRepo_target_name\", y)\n",
    "\n",
    "       # Label encoding\n",
    "    label_map = {int(idx): cls for idx, cls in enumerate(le.classes_)}\n",
    "    \n",
    "    # Save to an in-memory file\n",
    "    buffer = io.StringIO()\n",
    "    json.dump(label_map, buffer, indent=2)\n",
    "    buffer.seek(0)\n",
    "    \n",
    "    # Log it to MLflow\n",
    "    mlflow.log_text(buffer.getvalue(), artifact_file=\"label_mapping.json\")\n",
    "   \n",
    "    ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    model_name = f\"RandomForest_Iris_v{ts}\"\n",
    "    mlflow.set_tag(\"ML_EXP_model_name\",model_name)\n",
    "    \n",
    "    train_start_ts = datetime.now().isoformat()\n",
    "    mlflow.set_tag(\"ML_EXP_training_start_time\", train_start_ts)\n",
    "\n",
    "    test_size    = 0.2\n",
    "    random_state = 42\n",
    "    \n",
    "    # üìà Model Training\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "    \n",
    "    # ‚îÄ‚îÄ 2) Log dataset split params ‚îÄ‚îÄ\n",
    "    mlflow.log_param(\"ML_EXP_test_size\", test_size)\n",
    "    mlflow.log_param(\"ML_EXP_random_state\", random_state)\n",
    "    mlflow.log_param(\"ML_EXP_n_train_samples\", X_train.shape[0])\n",
    "    mlflow.log_param(\"ML_EXP_n_test_samples\",  X_test.shape[0])\n",
    "    mlflow.log_param(\"ML_EXP_n_features\",      X_train.shape[1])\n",
    "    mlflow.log_param(\"ML_EXP_n_test_samples\",  X_test.shape[0])\n",
    "    mlflow.log_param(\"ML_EXP_n_features\",      X_train.shape[1])\n",
    "\n",
    "     # 1) Define a more complex hyperparameter dict\n",
    "    ML_EXP_hyperparams = {\n",
    "        \"n_estimators\":       200,\n",
    "        \"criterion\":          \"entropy\",\n",
    "        \"max_depth\":          12,\n",
    "        \"min_samples_split\":  5,\n",
    "        \"min_samples_leaf\":   2,\n",
    "        \"max_features\":       \"sqrt\",\n",
    "        \"bootstrap\":          True,\n",
    "        \"oob_score\":          False,\n",
    "        \"class_weight\":       None,\n",
    "        \"random_state\":       42,\n",
    "        \"verbose\":            1,\n",
    "        \"n_jobs\":             -1\n",
    "    }\n",
    "    \n",
    "    # 2) Log them ALL at once\n",
    "    mlflow.log_params(ML_EXP_hyperparams)\n",
    "    model = RandomForestClassifier(**hyperparams)\n",
    "\n",
    "    for key, val in hyperparams.items():\n",
    "        log_with_justification(mlflow.log_param, key, val, context=\"Hyperparameter configuration\")\n",
    "\n",
    "    # Prompt for and log justifications for high-level modeling decisions\n",
    "    log_justification(\"ML_EXP_model_choice\", \"Why did you choose RandomForestClassifier for this task?\")\n",
    "    log_justification(\"ML_EXP_target_variable\", \"Why did you choose this column as the prediction target?\")\n",
    "    log_justification(\"ML_EXP_test_split\", \"Why this train/test ratio (e.g., 80/20)?\")\n",
    "    log_justification(\"ML_EXP_metric_choice\", \"Why accuracy/f1/ROC-AUC as your evaluation metric?\")\n",
    "    log_justification(\"ML_EXP_threshold_accuracy\", \"Why 0.95 as performance threshold?\")\n",
    "    log_justification(\"ML_EXP_dataset_version\", \"Why use this specific dataset version?\")\n",
    "    log_justification(\"ML_EXP_drop_column_X\", \"Why drop any specific columns from the dataset?\")\n",
    "    log_justification(\"ML_EXP_experiment_name\", \"Any context behind this experiment name or setup?\")\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    train_end_ts = datetime.now().isoformat()\n",
    "    mlflow.set_tag(\"ML_EXP_training_end_time\", train_end_ts)\n",
    "\n",
    "     # ‚îÄ‚îÄ 6) Predict & log metrics ‚îÄ‚îÄ\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_proba, multi_class=\"ovr\")\n",
    "    prec = precision_score(y_test, y_pred, average=\"macro\")\n",
    "    rec  = recall_score(y_test,    y_pred, average=\"macro\")\n",
    "    f1   = f1_score(y_test,      y_pred, average=\"macro\")\n",
    "    \n",
    "    mlflow.log_metric(\"ML_EXP_precision_macro\", prec)\n",
    "    mlflow.log_metric(\"ML_EXP_recall_macro\",    rec)\n",
    "    mlflow.log_metric(\"ML_EXP_f1_macro\",        f1)\n",
    "    mlflow.log_metric(\"ML_EXP_accuracy\", acc)\n",
    "    mlflow.log_metric(\"ML_EXP_roc_auc\",   auc)\n",
    "\n",
    "    # ‚úÖ Log Environment Automatically\n",
    "    mlflow.log_params({\n",
    "        \"python_version\": platform.python_version(),\n",
    "        \"os_platform\": f\"{platform.system()} {platform.release()}\",\n",
    "        \"sklearn_version\": sklearn.__version__,\n",
    "        \"pandas_version\": pd.__version__,\n",
    "        \"numpy_version\": np.__version__,\n",
    "        \"matplotlib_version\": matplotlib.__version__,\n",
    "        \"seaborn_version\": sns.__version__,\n",
    "        \"shap_version\": shap.__version__,\n",
    "    })\n",
    "\n",
    "    # ‚úÖ Git and Notebook Metadata\n",
    "    mlflow.set_tag(\"ML_EXP_notebook_name\", \"RQ1.ipynb\")\n",
    "\n",
    "    # ‚úÖ Dataset Metadata Tags\n",
    "    mlflow.set_tag(\"ML_EXP_dataset_name\", \"Iris\") #TODO\n",
    "    mlflow.set_tag(\"ML_EXP_dataset_version\", \"1.0.0\") #TODO\n",
    "    mlflow.set_tag(\"ML_EXP_dataset_id\", \"iris_local\") #TODO\n",
    "\n",
    "\n",
    "    # ‚îÄ‚îÄ‚îÄ 2) Create a folder for this run‚Äôs plots ‚îÄ‚îÄ‚îÄ\n",
    "    plot_dir = os.path.join(\"ML_EXP_plots\", model_name)\n",
    "    os.makedirs(plot_dir, exist_ok=True)\n",
    "\n",
    "    # 1) Feature Importance Bar Chart\n",
    "    importances = model.feature_importances_\n",
    "    try:\n",
    "        feature_names = X_train.columns\n",
    "    except AttributeError:\n",
    "        feature_names = [f\"f{i}\" for i in range(X_train.shape[1])]\n",
    "    fi_path = os.path.join(plot_dir, \"feature_importances.png\")\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.barplot(x=importances, y=feature_names)\n",
    "    plt.title(\"Feature Importances\")\n",
    "    plt.xlabel(\"Importance\")\n",
    "    plt.ylabel(\"Feature\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(fi_path)\n",
    "    mlflow.log_artifact(fi_path)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# 2) Multi-class ROC Curves\n",
    "# Binarize labels for one-vs-rest\n",
    "    classes = np.unique(y_test)\n",
    "    y_test_bin = label_binarize(y_test, classes=classes)\n",
    "    \n",
    "    for idx, cls in enumerate(classes):\n",
    "        disp = RocCurveDisplay.from_predictions(\n",
    "            y_test_bin[:, idx], \n",
    "            y_proba[:, idx],\n",
    "            name=f\"ROC for class {cls}\"\n",
    "        )\n",
    "        roc_path = os.path.join(plot_dir, f\"roc_curve_cls_{cls}.png\")\n",
    "        disp.figure_.savefig(roc_path)\n",
    "        mlflow.log_artifact(roc_path)\n",
    "        plt.close(disp.figure_)\n",
    "\n",
    "\n",
    "    # 3) Multi-class Precision-Recall Curves\n",
    "    for idx, cls in enumerate(classes):\n",
    "        disp = PrecisionRecallDisplay.from_predictions(\n",
    "            y_test_bin[:, idx], \n",
    "            y_proba[:, idx],\n",
    "            name=f\"PR curve for class {cls}\"\n",
    "        )\n",
    "        pr_path = os.path.join(plot_dir, f\"pr_curve_cls_{cls}.png\")\n",
    "        disp.figure_.savefig(pr_path)\n",
    "        mlflow.log_artifact(pr_path)\n",
    "        plt.close(disp.figure_)\n",
    "        \n",
    "    # ‚úÖ Confusion Matrix Plot\n",
    "    cm_path = os.path.join(plot_dir, \"confusion_matrix.png\")\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.savefig(cm_path)\n",
    "    mlflow.log_artifact(cm_path)\n",
    "\n",
    "    # ‚úÖ SHAP Summary\n",
    "    shap_path = os.path.join(plot_dir, \"shap_summary.png\")\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer.shap_values(X_test)\n",
    "    shap.summary_plot(shap_values, X_test, show=False)\n",
    "    plt.savefig(shap_path)\n",
    "    mlflow.log_artifact(shap_path)\n",
    "\n",
    "\n",
    "    client = MlflowClient()\n",
    "    run_data = client.get_run(run.info.run_id).data\n",
    "    \n",
    "    log_standard_metadata(\n",
    "    model_name=model_name,\n",
    "    model=model,\n",
    "    hyperparams=hyperparams,\n",
    "    acc=acc,\n",
    "    prec=prec,\n",
    "    rec=rec,\n",
    "    f1=f1,\n",
    "    auc=auc,\n",
    "    label_map=label_map,\n",
    "    run_id=run.info.run_id,\n",
    "    test_size=test_size,\n",
    "    random_state=random_state,\n",
    "    run_data=run_data # captured via client.get_run(run.info.run_id).data\n",
    "    )\n",
    "    # ‚îÄ‚îÄ‚îÄ 1) Build a .pkl filename (you can include your model_name for clarity)\n",
    "    pkl_path = f\"Trained_models/{model_name}.pkl\"\n",
    "    \n",
    "    # ‚îÄ‚îÄ‚îÄ 2) Serialize your trained model to disk\n",
    "    with open(pkl_path, \"wb\") as f:\n",
    "        pickle.dump(model, f)\n",
    "    \n",
    "    # ‚îÄ‚îÄ‚îÄ 3) Log that pickle file as an MLflow artifact\n",
    "    #     It will appear under Artifacts ‚Üí models/RandomForest_Iris_vYYYYMMDD_HHMMSS.pkl\n",
    "    mlflow.log_artifact(pkl_path, artifact_path=model_name)\n",
    "        \n",
    "    def get_latest_commit_hash(repo_path=\".\"):\n",
    "        # returns the full SHA of HEAD\n",
    "        res = subprocess.run(\n",
    "            [\"git\", \"-C\", repo_path, \"rev-parse\", \"HEAD\"],\n",
    "            capture_output=True, text=True, check=True)\n",
    "        \n",
    "        return res.stdout.strip()\n",
    "\n",
    "    def get_remote_url(repo_path=\".\", remote=\"origin\"):\n",
    "        # returns something like git@github.com:user/repo.git or https://...\n",
    "        res = subprocess.run(\n",
    "            [\"git\", \"-C\", repo_path, \"config\", \"--get\", f\"remote.{remote}.url\"],\n",
    "            capture_output=True, text=True, check=True\n",
    "        )\n",
    "        return res.stdout.strip()\n",
    "    \n",
    "    def make_commit_link(remote_url, commit_hash):\n",
    "        # handle GitHub/GitLab convention; strip ‚Äú.git‚Äù if present\n",
    "        base = remote_url.rstrip(\".git\")\n",
    "        # if SSH form (git@github.com:owner/repo), convert to https\n",
    "        if base.startswith(\"git@\"):\n",
    "            base = base.replace(\":\", \"/\").replace(\"git@\", \"https://\")\n",
    "        return f\"{base}/commit/{commit_hash}\"\n",
    "\n",
    "    \n",
    "    def simple_commit_and_push_and_log(repo_path=\".\", message=\"Auto commit\", remote=\"origin\", branch=\"main\"):\n",
    "    # 1) Check for changes\n",
    "        status = subprocess.run(\n",
    "            [\"git\", \"-C\", repo_path, \"status\", \"--porcelain\"],\n",
    "            capture_output=True, text=True\n",
    "        )\n",
    "        if not status.stdout.strip():\n",
    "            print(\"üü° No changes to commit.\")\n",
    "            return None, None\n",
    "    \n",
    "        # 2) Stage everything\n",
    "        add = subprocess.run(\n",
    "            [\"git\", \"-C\", repo_path, \"add\", \"--all\"],\n",
    "            capture_output=True, text=True\n",
    "        )\n",
    "        if add.returncode:\n",
    "            print(\"‚ùå git add failed:\\n\", add.stderr)\n",
    "            return None, None\n",
    "    \n",
    "        # 3) Commit\n",
    "        commit = subprocess.run(\n",
    "            [\"git\", \"-C\", repo_path, \"commit\", \"-m\", message],\n",
    "            capture_output=True, text=True\n",
    "        )\n",
    "        if commit.returncode:\n",
    "            print(\"‚ùå git commit failed:\\n\", commit.stderr)\n",
    "            return None, None\n",
    "        print(\"‚úÖ Commit successful.\")\n",
    "    \n",
    "        # 4) Push\n",
    "        push = subprocess.run(\n",
    "            [\"git\", \"-C\", repo_path, \"push\", \"-u\", remote, branch],\n",
    "            capture_output=True, text=True\n",
    "        )\n",
    "        if push.returncode:\n",
    "            print(\"‚ùå git push failed:\\n\", push.stderr)\n",
    "        else:\n",
    "            print(\"üöÄ Push successful.\")\n",
    "    \n",
    "        # 5) Retrieve hash & remote URL\n",
    "        sha = get_latest_commit_hash(repo_path)\n",
    "        url = get_remote_url(repo_path, remote)\n",
    "        link = make_commit_link(url, sha)\n",
    "    \n",
    "        return sha, link\n",
    "    \n",
    "      \n",
    "    sha, link = simple_commit_and_push_and_log(\n",
    "        repo_path=\".\",\n",
    "        message=\"Auto commit after successful training\"\n",
    "    )\n",
    "    if sha and link:\n",
    "        diff_text = subprocess.check_output(\n",
    "            [\"git\", \"-C\", \".\", \"diff\", previous_commit_hash, sha],\n",
    "            encoding=\"utf-8\",\n",
    "            errors=\"ignore\"    # or \"replace\"\n",
    "        )\n",
    "                \n",
    "        # 1) Get your repo‚Äôs remote URL and normalize to HTTPS\n",
    "        remote_url = subprocess.check_output(\n",
    "            [\"git\", \"config\", \"--get\", \"remote.origin.url\"],\n",
    "            text=True\n",
    "        ).strip().rstrip(\".git\")\n",
    "        if remote_url.startswith(\"git@\"):\n",
    "            # git@github.com:owner/repo.git ‚Üí https://github.com/owner/repo\n",
    "            remote_url = remote_url.replace(\":\", \"/\").replace(\"git@\", \"https://\")\n",
    "        \n",
    "        # 2) Build commit URLs\n",
    "        previous_commit_url  = f\"{remote_url}/commit/{previous_commit_hash}\"\n",
    "        current_commit_url = f\"{remote_url}/commit/{sha}\"\n",
    "        diff_data = {\n",
    "            \"GIT_previous_commit\":  previous_commit_hash,\n",
    "            \"GIT_previous_commit_url\":previous_commit_url,\n",
    "            \"GIT_current_commit_url\":current_commit_url,\n",
    "            \"GIT_current_commit\": sha,\n",
    "            \"GIT_diff\": diff_text\n",
    "        }\n",
    "        mlflow.log_dict(\n",
    "            diff_data,\n",
    "            artifact_file=\"GIT_commit_diff.json\"\n",
    "        )\n",
    "        mlflow.set_tag(\"GIT_previous_commit_hash\", previous_commit_hash)\n",
    "        mlflow.set_tag(\"GIT_current_commit_hash\", sha)\n",
    "        mlflow.set_tag(\"GIT_current_commit_url\", link) \n",
    "\n",
    "\n",
    "    client   = MlflowClient()\n",
    "    run_id    = run.info.run_id\n",
    "    run_info  = client.get_run(run_id).info\n",
    "    run_data  = client.get_run(run_id).data\n",
    "    \n",
    "    # 1) params, metrics, tags\n",
    "    params  = dict(run_data.params)\n",
    "    metrics = dict(run_data.metrics)\n",
    "    tags    = dict(run_data.tags)\n",
    "\n",
    "    # (4) List artifacts under a specific subfolder\n",
    "    run_meta     = client.get_run(run_id).info\n",
    "    artifact_uri = run_meta.artifact_uri  # base URI for all artifacts\n",
    "    \n",
    "    artifact_meta = []\n",
    "\n",
    "    def _gather(path=\"\"):\n",
    "            for af in client.list_artifacts(run_id, path):\n",
    "                if af.is_dir:\n",
    "                    _gather(af.path)\n",
    "                    continue\n",
    "        \n",
    "                rel_path = af.path\n",
    "                lower = rel_path.lower()\n",
    "        \n",
    "                if lower.endswith((\".json\", \".txt\", \".patch\")):\n",
    "                    artifact_meta.append({\"path\": rel_path, \"type\": \"text\"})\n",
    "                elif lower.endswith((\".png\", \".jpg\", \".jpeg\", \".svg\")):\n",
    "                    artifact_meta.append({\"path\": rel_path, \"type\": \"image\"})\n",
    "                else:\n",
    "                    artifact_meta.append({\"path\": rel_path, \"type\": \"other\"})\n",
    "    # Run the gather\n",
    "    _gather()\n",
    "     \n",
    "    summary = {\n",
    "        \"ML_EXP_run_id\":         run_id,\n",
    "        \"ML_EXP_run_name\": run_info.run_name,\n",
    "        \"ML_EXP_experiment_id\":  run_info.experiment_id,\n",
    "        \"ML_EXP_start_time\":     run_info.start_time,\n",
    "        \"ML_EXP_end_time\":       run_info.end_time,\n",
    "        \"ML_EXP_params\":         params,\n",
    "        \"ML_EXP_metrics\":        metrics,\n",
    "        \"ML_EXP_tags\":           tags,\n",
    "        \"ML_EXP_artifacts\":      artifact_meta\n",
    "    }\n",
    "    \n",
    "\n",
    "    # 1) Determine notebook directory (where your .ipynb lives)\n",
    "    notebook_dir = os.getcwd()\n",
    "    \n",
    "    # ‚úÖ Create a subdirectory inside MODEL_PROVENANCE for the model\n",
    "    summary_dir = os.path.join(os.getcwd(), \"MODEL_PROVENANCE\", model_name)\n",
    "    os.makedirs(summary_dir, exist_ok=True)\n",
    "    \n",
    "   # 2) Pick a filename based on your model_name\n",
    "    summary_filename   = f\"{model_name}_run_summary.json\"\n",
    "    summary_local_path = os.path.join(summary_dir, summary_filename)\n",
    "   # 3) Write the JSON locally\n",
    "    with open(summary_local_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "    \n",
    "    # 4) (Optional) Mirror it into MLflow artifacts under a single folder\n",
    "    mlflow.log_artifact(summary_local_path, artifact_path=\"run_summaries\")\n",
    "    # End time\n",
    "    end_time = datetime.now().isoformat()\n",
    "    mlflow.set_tag(\"PROV_endedAtTime\", end_time)\n",
    "    mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c4e1b2-9fa9-4606-8128-6ac66b5c6e78",
   "metadata": {},
   "source": [
    "what does it create: \n",
    "lable_mapping in the current dir\n",
    "provenence file :REPO/notebooks/RQ_notebooks/MODEL_PROVENANCE/RandomForest_Iris_v20250425_120045_run_summary.json\n",
    "plots based on run:REPO/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120045/shap_summary.png\n",
    "mlrun:REPO/notebooks/RQ_notebooks/mlrunlogs/mlflow.db/615223710259862608/5d1fa0fc65af47128f3200628b1afaea\n",
    "trained model:REPO/notebooks/RQ_notebooks/Trained_models/RandomForest_Iris_v20250425_120852.pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5e3bbb-0288-47d0-9dc4-2855d7e4801a",
   "metadata": {},
   "source": [
    "1. Standards-compliant export (JSON-LD + Turtle)\n",
    "I already have your plain run_summary.json , wrap it in a JSON-LD context that maps your fields into PROV-O terms, then use rdflib to emit Turtle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ed1cfb-930a-4f17-a48f-30e4cffb7f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Load the JSON file\n",
    "json_path = \"/mnt/data/REPO/notebooks/RQ_notebooks/MODEL_PROVENANCE/RandomForest_Iris_v20250425_125653/RandomForest_Iris_v20250425_125653_run_summary.json\"\n",
    "with open(json_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Extract justification tags\n",
    "justifications = {\n",
    "    k: v for k, v in data.get(\"tags\", {}).items()\n",
    "    if k.startswith(\"justification_\")\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "justification_df = pd.DataFrame([\n",
    "    {\"Decision\": k.replace(\"justification_\", \"\"), \"Justification\": v}\n",
    "    for k, v in justifications.items()\n",
    "])\n",
    "\n",
    "import ace_tools as tools; tools.display_dataframe_to_user(name=\"Researcher Justifications\", dataframe=justification_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5cf88da4-69f8-4982-a594-28cf25e4f79a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted RandomForest_Iris_v20250425_121328_run_summary.json ‚Üí RandomForest_Iris_v20250425_121328.jsonld, RandomForest_Iris_v20250425_121328.ttl\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def iso8601(ms):\n",
    "    \"\"\"Convert milliseconds since epoch to ISO8601 UTC.\"\"\"\n",
    "    return datetime.fromtimestamp(ms / 1000, tz=timezone.utc).isoformat()\n",
    "\n",
    "for json_path in glob.glob(\"MODEL_PROVENANCE/*/*_run_summary.json\"):\n",
    "    basename   = os.path.basename(json_path)\n",
    "    model_name = basename.rsplit(\"_run_summary.json\", 1)[0]\n",
    "\n",
    "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        summary = json.load(f)\n",
    "\n",
    "    #‚Äì‚Äì Minimal override context: keep all your flat fields as-is,\n",
    "    #‚Äì‚Äì and only map the actual PROV terms to their IRIs.\n",
    "    ctx = {\n",
    "        # keep these flat\n",
    "        \"run_id\":       { \"@id\": \"run_id\" },\n",
    "        \"run_name\":     { \"@id\": \"run_name\" },\n",
    "        \"experiment_id\":{ \"@id\": \"experiment_id\" },\n",
    "        \"params\":       { \"@id\": \"params\" },\n",
    "        \"metrics\":      { \"@id\": \"metrics\" },\n",
    "        \"artifacts\":    { \"@id\": \"artifacts\" },\n",
    "        \"tags\":         { \"@id\": \"tags\" },\n",
    "\n",
    "        # provenance namespace\n",
    "        \"prov\": \"http://www.w3.org/ns/prov#\",\n",
    "        \"xsd\":  \"http://www.w3.org/2001/XMLSchema#\",\n",
    "\n",
    "        # map your timestamp fields into PROV\n",
    "        \"start_time\": { \"@id\": \"prov:startedAtTime\", \"@type\": \"xsd:dateTime\" },\n",
    "        \"end_time\":   { \"@id\": \"prov:endedAtTime\",   \"@type\": \"xsd:dateTime\" },\n",
    "\n",
    "        # PROV-used/generated\n",
    "        \"used\":      { \"@id\": \"prov:used\",      \"@type\": \"@id\" },\n",
    "        \"generated\": { \"@id\": \"prov:generated\", \"@type\": \"@id\" },\n",
    "\n",
    "        # JSON-LD boilerplate\n",
    "        \"@id\":   \"@id\",\n",
    "        \"@type\": \"@type\"\n",
    "    }\n",
    "\n",
    "    #‚Äì‚Äì Build JSON-LD document, re-using your original keys verbatim\n",
    "    doc = {\n",
    "        \"@context\":      ctx,\n",
    "        \"run_id\":        summary[\"run_id\"],\n",
    "        \"run_name\":      summary.get(\"run_name\"),\n",
    "        \"experiment_id\": summary.get(\"experiment_id\"),\n",
    "        \"params\":        summary.get(\"params\", {}),\n",
    "        \"metrics\":       summary.get(\"metrics\", {}),\n",
    "        \"artifacts\":     summary.get(\"artifacts\", []),\n",
    "        \"tags\":          summary.get(\"tags\", {}),\n",
    "\n",
    "        # PROV fields:\n",
    "        \"start_time\": iso8601(summary[\"start_time\"])\n",
    "    }\n",
    "\n",
    "    if summary.get(\"end_time\") is not None:\n",
    "        doc[\"end_time\"] = iso8601(summary[\"end_time\"])\n",
    "\n",
    "    # for used/generated, just point at your dataset/model URIs\n",
    "    # (or blank-node them if you prefer richer structure)\n",
    "    doc[\"used\"] = summary.get(\"tags\", {}).get(\"dataset_uri\") or []\n",
    "    doc[\"generated\"] = [\n",
    "        art.get(\"uri\") or art.get(\"path\")\n",
    "        for art in summary.get(\"artifacts\", [])\n",
    "    ]\n",
    "\n",
    "    #‚Äì‚Äì write JSON-LD\n",
    "    out_jsonld = os.path.join(\"MODEL_PROVENANCE\", model_name, f\"{model_name}.jsonld\")\n",
    "    with open(out_jsonld, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(doc, f, indent=2)\n",
    "\n",
    "    #‚Äì‚Äì parse & serialize to Turtle\n",
    "    g = Graph().parse(data=json.dumps(doc), format=\"json-ld\")\n",
    "    out_ttl = os.path.join(\"MODEL_PROVENANCE\", model_name, f\"{model_name}.ttl\")\n",
    "    g.serialize(destination=out_ttl, format=\"turtle\")\n",
    "\n",
    "    print(f\"Converted {basename} ‚Üí {os.path.basename(out_jsonld)}, {os.path.basename(out_ttl)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d6d524-01da-4f20-8131-0d4a3ac005e2",
   "metadata": {},
   "source": [
    "This code programatically, finds diff between generated Json file and created JsonLD and .TTL file to make it easier to understand if there is any discrepency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "77a420c0-230d-41c0-9b63-f3dbbca1e670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== JSON-LD vs TTL ==\n",
      "Change summary:\n",
      "type\n",
      "changed    1 \n",
      "\n",
      "First 10 ‚Äòchanged‚Äô entries:\n",
      "Top-level adds/removes:\n",
      "Empty DataFrame\n",
      "Columns: [path, type, a, b]\n",
      "Index: []\n",
      "\n",
      "== JSON vs JSON-LD ==\n",
      "Change summary:\n",
      "type\n",
      "added      3\n",
      "removed    1\n",
      "changed    1 \n",
      "\n",
      "First 10 ‚Äòchanged‚Äô entries:\n",
      "Top-level adds/removes:\n",
      "Empty DataFrame\n",
      "Columns: [path, type, a, b]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def load_as_dict(path):\n",
    "    if path.endswith((\".ttl\", \".turtle\")):\n",
    "        g = Graph()\n",
    "        g.parse(path, format=\"turtle\")\n",
    "        # normalize to JSON-LD dict\n",
    "        return json.loads(g.serialize(format=\"json-ld\", indent=2))\n",
    "    else:\n",
    "        with open(path, encoding=\"utf-8\") as f:\n",
    "            return json.load(f)\n",
    "\n",
    "def compare_json(a, b, path=\"\"):\n",
    "    diffs = []\n",
    "    if isinstance(a, dict) and isinstance(b, dict):\n",
    "        all_keys = set(a) | set(b)\n",
    "        for k in all_keys:\n",
    "            new_path = f\"{path}/{k}\" if path else k\n",
    "            if k not in a:\n",
    "                diffs.append({\"path\": new_path, \"type\": \"added\",   \"a\": None,    \"b\": b[k]})\n",
    "            elif k not in b:\n",
    "                diffs.append({\"path\": new_path, \"type\": \"removed\", \"a\": a[k],   \"b\": None})\n",
    "            else:\n",
    "                diffs.extend(compare_json(a[k], b[k], new_path))\n",
    "    elif isinstance(a, list) and isinstance(b, list):\n",
    "        for i, (ia, ib) in enumerate(zip(a, b)):\n",
    "            diffs.extend(compare_json(ia, ib, f\"{path}[{i}]\"))\n",
    "        # handle length mismatches\n",
    "        if len(a) < len(b):\n",
    "            for i in range(len(a), len(b)):\n",
    "                diffs.append({\"path\": f\"{path}[{i}]\", \"type\": \"added\",   \"a\": None,  \"b\": b[i]})\n",
    "        elif len(a) > len(b):\n",
    "            for i in range(len(b), len(a)):\n",
    "                diffs.append({\"path\": f\"{path}[{i}]\", \"type\": \"removed\", \"a\": a[i],  \"b\": None})\n",
    "    else:\n",
    "        if a != b:\n",
    "            diffs.append({\"path\": path, \"type\": \"changed\", \"a\": a, \"b\": b})\n",
    "    return diffs\n",
    "\n",
    "# --- Usage example -----------------------------------------------\n",
    "# REPO/notebooks/RQ_notebooks/MODEL_PROVENANCE/RandomForest_Iris_v20250425_121328/RandomForest_Iris_v20250425_121328_run_summary.json\n",
    "# # Compare JSON-LD vs Turtle:\n",
    "# a = load_as_dict(\"MODEL_PROVENANCE/RandomForest_Iris_v20250423_230422_run_summary.json\")\n",
    "# b = load_as_dict(\"MODEL_PROVENANCE/RandomForest_Iris_v20250423_230422.ttl\")\n",
    "# diffs_jsonld_vs_ttl = compare_json(a, b)\n",
    "\n",
    "# # Compare JSON vs JSON-LD:\n",
    "# c = load_as_dict(\"MODEL_PROVENANCE/RandomForest_Iris_v20250423_230422_run_summary.json\")\n",
    "# d = load_as_dict(\"MODEL_PROVENANCE/RandomForest_Iris_v20250423_230422.jsonld\")\n",
    "# diffs_json_vs_jsonld = compare_json(c, d)\n",
    "\n",
    "# Define base directory\n",
    "base_dir = os.path.join(\"MODEL_PROVENANCE\", model_name)\n",
    "\n",
    "# Build full paths for the files to compare\n",
    "summary_json    = os.path.join(base_dir, f\"{model_name}_run_summary.json\")\n",
    "turtle_file     = os.path.join(base_dir, f\"{model_name}.ttl\")\n",
    "jsonld_file     = os.path.join(base_dir, f\"{model_name}.jsonld\")\n",
    "\n",
    "# Load files\n",
    "a = load_as_dict(summary_json)\n",
    "b = load_as_dict(turtle_file)\n",
    "c = load_as_dict(summary_json)\n",
    "d = load_as_dict(jsonld_file)\n",
    "\n",
    "# Perform comparisons\n",
    "diffs_jsonld_vs_ttl = compare_json(a, b)\n",
    "diffs_json_vs_jsonld = compare_json(c, d)\n",
    "\n",
    "# Build DataFrames for interactive inspection\n",
    "df1 = pd.DataFrame(diffs_jsonld_vs_ttl)\n",
    "df2 = pd.DataFrame(diffs_json_vs_jsonld)\n",
    "\n",
    "# --- Summaries & Filtering ---------------------------------------\n",
    "\n",
    "def summarize_and_preview(df, preview_n=10):\n",
    "    print(\"Change summary:\")\n",
    "    print(df['type'].value_counts().to_string(), \"\\n\")\n",
    "    \n",
    "    print(f\"First {preview_n} ‚Äòchanged‚Äô entries:\")\n",
    "    # print(df[df['type']==\"changed\"].head(preview_n).to_string(index=False), \"\\n\")\n",
    "    \n",
    "    # Top‚Äêlevel (one slash) adds/removes\n",
    "    top = df[df['path'].str.count(\"/\") == 1]\n",
    "    print(\"Top-level adds/removes:\")\n",
    "    print(top[top['type'].isin(['added','removed'])].to_string(index=False))\n",
    "\n",
    "print(\"== JSON-LD vs TTL ==\")\n",
    "summarize_and_preview(df1)\n",
    "\n",
    "print(\"\\n== JSON vs JSON-LD ==\")\n",
    "summarize_and_preview(df2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "41af9d6e-c683-45f9-bac1-296611b4d0b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed in JSON-LD comparison:\n",
      "    path\n",
      "end_time\n",
      "\n",
      "Added in JSON-LD comparison:\n",
      "     path\n",
      " @context\n",
      "     used\n",
      "generated\n"
     ]
    }
   ],
   "source": [
    "# show all the removed paths (in JSON but not in JSON-LD)\n",
    "print(\"Removed in JSON-LD comparison:\")\n",
    "print(df2[df2['type']==\"removed\"][['path']].to_string(index=False))\n",
    "\n",
    "# show all the added paths (in JSON-LD but not in JSON)\n",
    "print(\"\\nAdded in JSON-LD comparison:\")\n",
    "print(df2[df2['type']==\"added\"][['path']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f0d6f92a-5cd9-4c78-9c2a-0cd3247137c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed in .ttl comparison:\n",
      "Empty DataFrame\n",
      "Columns: [path]\n",
      "Index: []\n",
      "\n",
      "Added in .ttl comparison:\n",
      "Empty DataFrame\n",
      "Columns: [path]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# show all the removed paths (in JSON but not in JSON-LD)\n",
    "print(\"Removed in .ttl comparison:\")\n",
    "print(df1[df1['type']==\"removed\"][['path']].to_string(index=False))\n",
    "\n",
    "# show all the added paths (in JSON-LD but not in JSON)\n",
    "print(\"\\nAdded in .ttl comparison:\")\n",
    "print(df1[df1['type']==\"added\"][['path']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69efd0d0-9277-4efa-88cf-d2fd1b90d74c",
   "metadata": {},
   "source": [
    "Checks for completeness and mapping and time taken, needs work #TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "165a13eb-7679-4f4c-b346-24f25da72cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0/0 runs passed completeness checks (0.0%).\n",
      "\n",
      "Mapping integrity: 0/0 runs have zero diffs ‚Äî 0.0%\n",
      "Overall quality score: 0.0%\n",
      "\n",
      "Benchmarking train_and_log() overhead:\n",
      "  ‚Ä¢ No MLflow : 0.502s\n",
      "  ‚Ä¢ With MLflow: 0.601s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ‚îÄ‚îÄ User configuration ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "# Which keys must appear in every run_summary.json?\n",
    "REQUIRED_TOPLEVEL = {\n",
    "    \"run_id\", \"start_time\", \"end_time\",\n",
    "    \"params\", \"metrics\", \"tags\", \"artifacts\"\n",
    "}\n",
    "\n",
    "# A couple of sub-fields we also want to spot-check:\n",
    "REQUIRED_PARAMS  = {\"random_state\"}\n",
    "REQUIRED_METRICS = {\"accuracy\"}\n",
    "\n",
    "JSON_SUMMARIES = glob.glob(\"MODEL_PROVENANCE/*_run_summary.json\")\n",
    "\n",
    "\n",
    "# ‚îÄ‚îÄ Helpers ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "def iso8601(ms):\n",
    "    return datetime.fromtimestamp(ms/1000, tz=timezone.utc).isoformat()\n",
    "\n",
    "\n",
    "def load_json(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "\n",
    "def write_json(path, obj):\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(obj, f, indent=2)\n",
    "\n",
    "\n",
    "def convert_to_jsonld_and_ttl(summary, basename):\n",
    "    # build @context\n",
    "    ctx = {\n",
    "        \"prov\":    \"http://www.w3.org/ns/prov#\",\n",
    "        \"xsd\":     \"http://www.w3.org/2001/XMLSchema#\",\n",
    "        \"run\":     \"prov:Activity\",\n",
    "        \"start\":   \"prov:startedAtTime\",\n",
    "        \"end\":     \"prov:endedAtTime\",\n",
    "        \"used\":    \"prov:used\",\n",
    "        \"gen\":     \"prov:generated\",\n",
    "        \"param\":   \"prov:hadParameter\",\n",
    "        \"metric\":  \"prov:hadQuality\",\n",
    "        \"entity\":  \"prov:Entity\",\n",
    "        \"label\":   \"prov:label\",\n",
    "        \"value\":   \"prov:value\",\n",
    "        \"version\": \"prov:hadRevision\",\n",
    "        \"id\":      \"@id\",\n",
    "        \"type\":    \"@type\"\n",
    "    }\n",
    "\n",
    "    jsonld = {\n",
    "        \"@context\": ctx,\n",
    "        \"@id\":      f\"urn:run:{summary['run_id']}\",\n",
    "        \"@type\":    \"run\",\n",
    "        \"start\": {\n",
    "            \"@type\":  \"xsd:dateTime\",\n",
    "            \"@value\": iso8601(summary[\"start_time\"])\n",
    "        }\n",
    "    }\n",
    "    if summary.get(\"end_time\") is not None:\n",
    "        jsonld[\"end\"] = {\n",
    "            \"@type\":  \"xsd:dateTime\",\n",
    "            \"@value\": iso8601(summary[\"end_time\"])\n",
    "        }\n",
    "\n",
    "    # params\n",
    "    jsonld[\"param\"] = [\n",
    "        {\"@type\":\"entity\",\"label\":k,\"value\":str(v)}\n",
    "        for k,v in summary.get(\"params\",{}).items()\n",
    "    ]\n",
    "    # metrics\n",
    "    jsonld[\"metric\"] = [\n",
    "        {\"@type\":\"entity\",\"label\":k,\n",
    "         \"value\":{\"@type\":\"xsd:decimal\",\"@value\":v}}\n",
    "        for k,v in summary.get(\"metrics\",{}).items()\n",
    "    ]\n",
    "    # artifacts\n",
    "    jsonld[\"gen\"] = [\n",
    "        {\n",
    "            \"@type\":\"entity\",\n",
    "            \"label\": art.get(\"path\") or art.get(\"label\"),\n",
    "            \"prov:location\": (\n",
    "                art.get(\"uri\")\n",
    "                or (art.get(\"content\",\"\")[:30]+\"‚Ä¶\")\n",
    "                if isinstance(art.get(\"content\"),str)\n",
    "                else \"\"\n",
    "            )\n",
    "        }\n",
    "        for art in summary.get(\"artifacts\",[])\n",
    "    ]\n",
    "    # dataset used\n",
    "    jsonld[\"used\"] = {\n",
    "        \"@type\":\"entity\",\n",
    "        \"label\": summary[\"tags\"].get(\"dataset_name\"),\n",
    "        \"version\": summary[\"tags\"].get(\"dataset_version\")\n",
    "    }\n",
    "\n",
    "    # write JSON-LD\n",
    "    out_jsonld = f\"MODEL_PROVENANCE/{basename}.jsonld\"\n",
    "    write_json(out_jsonld, jsonld)\n",
    "\n",
    "    # serialize TTL\n",
    "    g = Graph().parse(data=json.dumps(jsonld), format=\"json-ld\")\n",
    "    out_ttl = f\"MODEL_PROVENANCE/{basename}.ttl\"\n",
    "    g.serialize(destination=out_ttl, format=\"turtle\")\n",
    "\n",
    "    return out_jsonld, out_ttl\n",
    "\n",
    "\n",
    "def normalize_jsonld(js):\n",
    "    \"\"\"Simple deep-sort so compare_json doesn‚Äôt trip over ordering.\"\"\"\n",
    "    if isinstance(js, dict):\n",
    "        return {k: normalize_jsonld(js[k]) for k in sorted(js)}\n",
    "    if isinstance(js, list):\n",
    "        return sorted((normalize_jsonld(el) for el in js),\n",
    "                      key=lambda x: json.dumps(x, sort_keys=True))\n",
    "    return js\n",
    "\n",
    "\n",
    "def diff_roundtrip(orig_json, jsonld_path, ttl_path):\n",
    "    orig = load_json(orig_json)\n",
    "    ld   = load_json(jsonld_path)\n",
    "\n",
    "    # parse TTL back to JSON-LD\n",
    "    g = Graph().parse(ttl_path, format=\"turtle\")\n",
    "    ttl_as_ld = json.loads(g.serialize(format=\"json-ld\"))\n",
    "\n",
    "    # normalize\n",
    "    nl = normalize_jsonld(ld)\n",
    "    nt = normalize_jsonld(ttl_as_ld)\n",
    "\n",
    "    return {\n",
    "        \"orig_vs_jsonld\":   compare_json(orig, ld),\n",
    "        \"jsonld_vs_ttl_ld\": compare_json(nl, nt)\n",
    "    }\n",
    "\n",
    "\n",
    "# ‚îÄ‚îÄ Main flow ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "def main():\n",
    "    ok = 0\n",
    "    total = len(JSON_SUMMARIES)\n",
    "    missing_reports = []\n",
    "    cases = {}  # store diff results per run\n",
    "\n",
    "    for js_path in JSON_SUMMARIES:\n",
    "        summary = load_json(js_path)\n",
    "        base    = os.path.basename(js_path).split(\"_run_summary.json\")[0]\n",
    "\n",
    "        # 1) completeness check\n",
    "        if not REQUIRED_TOPLEVEL.issubset(summary):\n",
    "            missing = REQUIRED_TOPLEVEL - set(summary)\n",
    "            missing_reports.append((js_path, f\"missing fields {missing}\"))\n",
    "            continue\n",
    "\n",
    "        if not (REQUIRED_PARAMS <= summary[\"params\"].keys()):\n",
    "            missing_reports.append((js_path, f\"params missing {REQUIRED_PARAMS - summary['params'].keys()}\"))\n",
    "            continue\n",
    "\n",
    "        if not (REQUIRED_METRICS <= summary[\"metrics\"].keys()):\n",
    "            missing_reports.append((js_path, f\"metrics missing {REQUIRED_METRICS - summary['metrics'].keys()}\"))\n",
    "            continue\n",
    "\n",
    "        ok += 1\n",
    "\n",
    "        # 2) convert\n",
    "        jsonld_path, ttl_path = convert_to_jsonld_and_ttl(summary, base)\n",
    "\n",
    "        # 3) diff\n",
    "        diffs = diff_roundtrip(js_path, jsonld_path, ttl_path)\n",
    "        cases[base] = diffs\n",
    "        print(f\"\\n‚îÄ‚îÄ {base} diffs ‚îÄ‚îÄ\")\n",
    "        print(\"  ‚Ä¢ JSON ‚Üí JSON-LD:\", len(diffs[\"orig_vs_jsonld\"]), \"differences\")\n",
    "        print(\"  ‚Ä¢ JSON-LD ‚Üí TTL ‚Üí JSON-LD:\", len(diffs[\"jsonld_vs_ttl_ld\"]), \"differences\")\n",
    "\n",
    "    # 4) completeness summary\n",
    "    completeness_pct = (100 * ok / total) if total else 0\n",
    "    print(f\"\\n{ok}/{total} runs passed completeness checks ({completeness_pct:.1f}%).\")\n",
    "    if missing_reports:\n",
    "        print(\"\\nFailures:\")\n",
    "        for path, reason in missing_reports:\n",
    "            print(f\" ‚Ä¢ {path}: {reason}\")\n",
    "\n",
    "    # 5) integrity check\n",
    "    total_runs = len(cases)\n",
    "    zero_diff_runs = sum(\n",
    "        1\n",
    "        for diffs in cases.values()\n",
    "        if not diffs[\"orig_vs_jsonld\"] and not diffs[\"jsonld_vs_ttl_ld\"]\n",
    "    )\n",
    "    integrity_pct = (100 * zero_diff_runs / total_runs) if total_runs else 0\n",
    "    print(f\"\\nMapping integrity: {zero_diff_runs}/{total_runs} runs have zero diffs ‚Äî {integrity_pct:.1f}%\")\n",
    "\n",
    "    # 6) overall quality score\n",
    "    overall_score = (completeness_pct + integrity_pct) / 2\n",
    "    print(f\"Overall quality score: {overall_score:.1f}%\")\n",
    "\n",
    "    # 7) Benchmark your training fn\n",
    "    print(\"\\nBenchmarking train_and_log() overhead:\")\n",
    "    def train_and_log(use_mlflow=False):\n",
    "        # ‚Üê your real instrumentation + fit logic here\n",
    "        time.sleep(0.5 + (0.1 if use_mlflow else 0))  # stub\n",
    "        return\n",
    "\n",
    "    for flag in (False, True):\n",
    "        start = time.time()\n",
    "        train_and_log(use_mlflow=flag)\n",
    "        elapsed = time.time() - start\n",
    "        label = \"With MLflow\" if flag else \"No MLflow\"\n",
    "        print(f\"  ‚Ä¢ {label:10s}: {elapsed:.3f}s\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5883f673-371e-415e-a73e-5c9c88b56fb1",
   "metadata": {},
   "source": [
    "RQ2  implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6d07ac1c-ea80-4787-bcb9-da047d12167d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['run_id', 'param_bootstrap', 'param_ccp_alpha', 'param_class_weight',\n",
       "       'param_columns_raw', 'param_criterion', 'param_database.description',\n",
       "       'param_database.id', 'param_database.name', 'param_database.owner',\n",
       "       'param_dataset.authors', 'param_dataset.doi', 'param_dataset.published',\n",
       "       'param_dataset.publisher', 'param_dataset.title',\n",
       "       'param_dropped_columns', 'param_feature_names',\n",
       "       'param_matplotlib_version', 'param_max_depth', 'param_max_features',\n",
       "       'param_max_leaf_nodes', 'param_max_samples',\n",
       "       'param_min_impurity_decrease', 'param_min_samples_leaf',\n",
       "       'param_min_samples_split', 'param_min_weight_fraction_leaf',\n",
       "       'param_numpy_version', 'param_n_estimators', 'param_n_features',\n",
       "       'param_n_features_final', 'param_n_jobs', 'param_n_records',\n",
       "       'param_n_test_samples', 'param_n_train_samples', 'param_oob_score',\n",
       "       'param_os_platform', 'param_pandas_version', 'param_python_version',\n",
       "       'param_random_state', 'param_retrieval_time', 'param_seaborn_version',\n",
       "       'param_shap_version', 'param_sklearn_version', 'param_test_size',\n",
       "       'param_verbose', 'param_warm_start', 'metric_accuracy',\n",
       "       'metric_accuracy_score_X_test', 'metric_dbrepo.num_deletes',\n",
       "       'metric_dbrepo.num_inserts', 'metric_dbrepo.row_count_end',\n",
       "       'metric_dbrepo.row_count_start', 'metric_f1_macro',\n",
       "       'metric_f1_score_X_test', 'metric_precision_macro',\n",
       "       'metric_precision_score_X_test', 'metric_recall_macro',\n",
       "       'metric_recall_score_X_test', 'metric_roc_auc',\n",
       "       'metric_roc_auc_score_X_test', 'metric_training_accuracy_score',\n",
       "       'metric_training_f1_score', 'metric_training_log_loss',\n",
       "       'metric_training_precision_score', 'metric_training_recall_score',\n",
       "       'metric_training_roc_auc', 'metric_training_score', 'tag_dataset_id',\n",
       "       'tag_dataset_name', 'tag_dataset_version', 'tag_data_source',\n",
       "       'tag_dbrepo.admin_email', 'tag_dbrepo.base_url',\n",
       "       'tag_dbrepo.granularity', 'tag_dbrepo.protocol_version',\n",
       "       'tag_dbrepo.repository_name', 'tag_dbrepo.table_last_modified',\n",
       "       'tag_estimator_class', 'tag_estimator_name',\n",
       "       'tag_git_current_commit_hash', 'tag_git_previous_commit_hash',\n",
       "       'tag_git__current_commit_url', 'tag_mlflow.log-model.history',\n",
       "       'tag_mlflow.runName', 'tag_mlflow.source.name',\n",
       "       'tag_mlflow.source.type', 'tag_mlflow.user', 'tag_model_name',\n",
       "       'tag_notebook_name', 'tag_target_name', 'tag_training_end_time',\n",
       "       'tag_training_start_time'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Load all run summary JSON files\n",
    "files = glob.glob(\"MODEL_PROVENANCE/*/*_run_summary.json\")\n",
    "rows = []\n",
    "for f in files:\n",
    "    with open(f) as fh:\n",
    "        summary = json.load(fh)\n",
    "    # Flatten parameters and metrics\n",
    "    row = {\"run_id\": summary[\"run_id\"]}\n",
    "    row.update({f\"param_{k}\": v for k, v in summary.get(\"params\", {}).items()})\n",
    "    row.update({f\"metric_{k}\": v for k, v in summary.get(\"metrics\", {}).items()})\n",
    "    row.update({f\"tag_{k}\": v for k, v in summary.get(\"tags\", {}).items()})\n",
    "    rows.append(row)\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "# Display the DataFrame\n",
    "df.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba148da6-6ce5-45cf-a985-f164a53c969b",
   "metadata": {},
   "source": [
    "1) Tracing preprocessing steps\n",
    ":\n",
    "Here are the top 4 Iris‚Äêfocused preprocessing‚Äêtracing use cases I‚Äôd tackle first:\n",
    "\n",
    "Reconstruct a run‚Äôs exact preprocessing\n",
    "Fetch a run‚Äôs run_id, columns_raw, dropped_columns, feature_names and test_size so you can replay the exact data pull & split.\n",
    "\n",
    "Feature‚Äêdrop impact analysis\n",
    "Identify runs where one or more measurements (e.g. petalwidthcm) were dropped and compare their test accuracies.\n",
    "\n",
    "Best feature subset discovery\n",
    "Group runs by which features they used (sepals only vs petals only vs both) and rank them by test F1 or accuracy.\n",
    "\n",
    "Common steps in high-accuracy runs\n",
    "Filter for runs with accuracy_score_X_test ‚â• 0.95 and list the shared preprocessing settings (dropped columns, test_size, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6e147555-afbf-4bba-b6da-7e90ff391920",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/25 12:23:44 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'df84c36b36cc4ebd90a999db3ebc4ad4', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'run_id': '28f01e38b7f04d2f948fe21f57f41d0c', 'param_dataset.title': 'Scikit-Learn Iris', 'param_columns_raw': \"['id', 'sepallengthcm', 'sepalwidthcm', 'petallengthcm', 'petalwidthcm', 'species']\", 'param_dropped_columns': \"['id']\", 'param_feature_names': \"['sepallengthcm', 'sepalwidthcm', 'petallengthcm', 'petalwidthcm']\", 'param_dataset.authors': '[\"Marshall Michael\"]', 'param_dataset.doi': '10.5281/ZENODO.1404173', 'param_dataset.published': '2018-8-27', 'param_test_size': '0.2', 'param_criterion': 'entropy', 'param_max_depth': '12', 'param_max_leaf_nodes': 'None', 'param_max_samples': 'None', 'metric_accuracy': 1.0, 'metric_f1_macro': 1.0, 'metric_roc_auc': 1.0}]\n",
      "[]\n",
      "[{'param_dropped_columns': \"['id']\", 'param_test_size': '0.2', 'param_feature_names': \"['sepallengthcm', 'sepalwidthcm', 'petallengthcm', 'petalwidthcm']\"}]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d931b602947d4db8872f254d48e22027",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/25 12:23:52 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '41261519e1a643c5b1335701aee1bf95', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'features': ['sepallengthcm', 'sepalwidthcm'], 'accuracy': 0.7666666666666667}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83ff1224205a4a8eb0c351a7f299dd93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/25 12:23:58 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'e0955d231fa6488e9339086b5845064c', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1eaa6c141e064593b73b6c72ce0b00cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/25 12:24:04 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '21d299b426ac42a0ad799604e9e7ff88', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dropped_feature': 'petallengthcm', 'baseline_acc': 1.0, 'dropped_acc': 0.9666666666666667, 'impact': 0.033333333333333326}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c04ce12f62f49a29f48509b1483f16b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/25 12:24:10 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '8ca4591a1b53402f854187104d1e7ee0', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66bf06c45648410daa144c12f85658c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/25 12:24:16 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '0c8a66e5e4b244f9a6a8e9fa02d26828', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d71b6d9b58d4e5a9db241baeaa79d53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/25 12:24:22 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '53994143a51e481abd23e988be2466b1', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fa13db4a66940d59cf37a30cb7a3cbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/25 12:24:28 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '35588f1cd8c34ce28770848de714d3c4', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "273c026f2e0b464f98090472792b3a87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'dropped_feature': 'sepallengthcm', 'baseline_acc': 1.0, 'dropped_acc': 1.0, 'impact': 0.0}, {'dropped_feature': 'sepalwidthcm', 'baseline_acc': 1.0, 'dropped_acc': 1.0, 'impact': 0.0}, {'dropped_feature': 'petallengthcm', 'baseline_acc': 1.0, 'dropped_acc': 0.9666666666666667, 'impact': 0.0333}, {'dropped_feature': 'petalwidthcm', 'baseline_acc': 1.0, 'dropped_acc': 0.9666666666666667, 'impact': 0.0333}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Helper to get the ‚Äúofficial‚Äù feature_names from your summary DF\n",
    "def _get_all_features(df):\n",
    "    # assumes every row has the same param_feature_names\n",
    "    raw = df.loc[0, 'param_feature_names']\n",
    "    return ast.literal_eval(raw)\n",
    "\n",
    "# Train & eval RF on just these columns of Iris\n",
    "def evaluate_subset(features, test_size=0.2, random_state=42, n_estimators=200):\n",
    "    iris = load_iris()\n",
    "    X = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "    # map sklearn‚Äôs names to your param names, e.g. \"sepal length (cm)\" ‚Üí \"sepallengthcm\"\n",
    "    canon = _get_all_features(df)\n",
    "    mapping = dict(zip(iris.feature_names, canon))\n",
    "    X = X.rename(columns=mapping)\n",
    "    X_sub = X[features]\n",
    "    y = iris.target\n",
    "    Xtr, Xte, ytr, yte = train_test_split(X_sub, y, test_size=test_size, random_state=random_state)\n",
    "    m = RandomForestClassifier(n_estimators=n_estimators, random_state=random_state)\n",
    "    m.fit(Xtr, ytr)\n",
    "    return accuracy_score(yte, m.predict(Xte))\n",
    "def trace_preprocessing(df, run_id=None):\n",
    "    cols = ['run_id',\n",
    "            'param_dataset.title',\n",
    "            'param_columns_raw',\n",
    "            'param_dropped_columns',\n",
    "            'param_feature_names',\n",
    "            'param_dataset.authors', 'param_dataset.doi', 'param_dataset.published',\n",
    "            'param_test_size',\n",
    "            'param_criterion',\n",
    "            'param_max_depth','param_max_leaf_nodes', 'param_max_samples',\n",
    "           'metric_accuracy','metric_f1_macro','metric_roc_auc']\n",
    "    if run_id is None:\n",
    "        subset = df.loc[:, cols]\n",
    "    else:\n",
    "        subset = df.loc[df['run_id'] == run_id, cols]\n",
    "    return subset.to_dict(orient='records')\n",
    "\n",
    "\n",
    "def drop_impact(df, feature, **_):\n",
    "    all_feats = _get_all_features(df)\n",
    "    baseline = evaluate_subset(all_feats)\n",
    "    without = [f for f in all_feats if f!=feature]\n",
    "    dropped = evaluate_subset(without)\n",
    "    return {\n",
    "      'dropped_feature': feature,\n",
    "      'baseline_acc': baseline,\n",
    "      'dropped_acc': dropped,\n",
    "      'impact': baseline - dropped\n",
    "    }\n",
    "\n",
    "def drop_impact_all(df: pd.DataFrame) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Compute drop-impact for every feature in the dataset.\n",
    "    Returns list of dicts with dropped_feature, baseline_acc, dropped_acc, impact.\n",
    "    \"\"\"\n",
    "    feats = _get_all_features(df)\n",
    "    baseline = evaluate_subset(feats)\n",
    "    summary = []\n",
    "    for feat in feats:\n",
    "        without = [f for f in feats if f != feat]\n",
    "        acc = evaluate_subset(without)\n",
    "        summary.append({\n",
    "            'dropped_feature': feat,\n",
    "            'baseline_acc': baseline,\n",
    "            'dropped_acc': acc,\n",
    "            'impact': round(baseline - acc, 4)\n",
    "        })\n",
    "    return summary\n",
    "\n",
    "def best_feature_subset(df, features, **_):\n",
    "    acc = evaluate_subset(features)\n",
    "    return {'features': features, 'accuracy': acc}\n",
    "\n",
    "def common_high_accuracy(df: pd.DataFrame, threshold: float = 0.95) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Filter runs with test accuracy >= threshold and list unique shared preprocessing settings.\n",
    "    \"\"\"\n",
    "    high = df[df['metric_accuracy_score_X_test'] >= threshold]\n",
    "    cols = ['param_dropped_columns', 'param_test_size', 'param_feature_names']\n",
    "    return high[cols].drop_duplicates().to_dict(orient='records')\n",
    "\n",
    "\n",
    "# --------------------------------------------\n",
    "# Use Case Registry with parameter order for minimal input\n",
    "# --------------------------------------------\n",
    "USE_CASES = {\n",
    "    'trace_preprocessing': {\n",
    "        'func': trace_preprocessing,\n",
    "        'required_params': [],            # none strictly required\n",
    "        'optional_params': ['run_id'],    # run_id can be supplied or not\n",
    "    },\n",
    "    'drop_impact': {\n",
    "        'func': drop_impact,\n",
    "        'required_params': ['feature'],\n",
    "        'optional_params': [],\n",
    "    },\n",
    "     'drop_impact_all': {\n",
    "        'func': drop_impact_all,\n",
    "        'required_params': [],\n",
    "        'optional_params': [],\n",
    "    },\n",
    "    'best_feature_subset': {\n",
    "        'func': best_feature_subset,\n",
    "        'required_params': ['features'],\n",
    "        'optional_params': [],\n",
    "    },\n",
    "    'common_high_accuracy': {\n",
    "        'func': common_high_accuracy,\n",
    "        'required_params': ['threshold'],\n",
    "        'optional_params': [],\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "def call_use_case(df, use_case_name, **kwargs):\n",
    "    if use_case_name not in USE_CASES:\n",
    "        raise ValueError(f\"Unknown use case: {use_case_name}\")\n",
    "    case = USE_CASES[use_case_name]\n",
    "    func = case['func']\n",
    "    # check required\n",
    "    missing = [p for p in case['required_params'] if p not in kwargs]\n",
    "    if missing:\n",
    "        raise ValueError(f\"{use_case_name} missing required params: {missing}\")\n",
    "    # build args\n",
    "    args = {p: kwargs[p] for p in case['required_params']}\n",
    "    for p in case['optional_params']:\n",
    "        args[p] = kwargs.get(p)\n",
    "    return func(df, **args)\n",
    "\n",
    "# --------------------------------------------\n",
    "# Example Usage\n",
    "# --------------------------------------------\n",
    "if __name__ == '__main__':\n",
    "   # # 1) trace_preprocessing for all runs\n",
    "    print(call_use_case(df, 'trace_preprocessing'))\n",
    "    \n",
    "    # 2) trace_preprocessing for a single run_id\n",
    "    print(call_use_case(df, 'trace_preprocessing', run_id='361daa12f99f4129a06cd20b78dd6fa7'))\n",
    "\n",
    "    # 5) common_high_accuracy\n",
    "    print(call_use_case(df, 'common_high_accuracy', threshold=0.99))\n",
    "\n",
    "    # 4) Best‚Äêsubset on just sepals:\n",
    "    print(call_use_case(df, 'best_feature_subset', features=['sepallengthcm','sepalwidthcm']))\n",
    "\n",
    "    # 3) Drop‚Äêimpact for ‚Äúpetallengthcm‚Äù:\n",
    "    print(call_use_case(df, 'drop_impact', feature='petallengthcm'))\n",
    "\n",
    "    print(call_use_case(df, 'drop_impact_all'))  # summary for all features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f912d6-0e84-4155-858a-9668bef63f6e",
   "metadata": {},
   "source": [
    " ‚Ä¢ Detecting models trained with deprecated code versions\n",
    " ‚Ä¢ Mapping models to specific datasets used during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "34a02c9a-5459-478f-a3c5-7f7a58ff22b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'param_dataset.doi': '10.5281/ZENODO.1404173',\n",
      "  'param_dataset.published': '2018-8-27',\n",
      "  'param_dataset.publisher': 'Zenodo',\n",
      "  'param_dataset.title': 'Scikit-Learn Iris',\n",
      "  'run_id': '28f01e38b7f04d2f948fe21f57f41d0c',\n",
      "  'tag_model_name': 'RandomForest_Iris_v20250425_121328'}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def detect_deprecated_code(df: pd.DataFrame, deprecated_commits: List[str], **_) -> List[Dict[str, Any]]:\n",
    "    # we know the column is called tag_git_current_commit_hash\n",
    "    commit_col = 'tag_git_current_commit_hash'\n",
    "    if commit_col not in df.columns:\n",
    "        raise KeyError(f\"Missing {commit_col} in DataFrame\")\n",
    "    out = df[df[commit_col].isin(deprecated_commits)]\n",
    "    # include run_id and notebook/runName for context\n",
    "    cols = ['run_id', commit_col, 'tag_notebook_name', 'tag_mlflow.runName']\n",
    "    # drop any that don‚Äôt exist\n",
    "    cols = [c for c in cols if c in df.columns]\n",
    "    return out[cols].to_dict(orient='records')\n",
    "\n",
    "\n",
    "def map_model_dataset(df: pd.DataFrame, **_) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    For each run, return its model name (or run_id) alongside the dataset\n",
    "    title, DOI, published date and publisher.\n",
    "    \"\"\"\n",
    "    # pick whichever model-name column you have\n",
    "    model_col = 'tag_model_name' if 'tag_model_name' in df.columns else 'param_model_name'\n",
    "    cols = [\n",
    "        'run_id',\n",
    "        model_col,\n",
    "        'param_dataset.title',\n",
    "        'param_dataset.doi',\n",
    "        'param_dataset.published',\n",
    "        'param_dataset.publisher'\n",
    "    ]\n",
    "    # filter out any columns that don‚Äôt actually exist\n",
    "    cols = [c for c in cols if c in df.columns]\n",
    "    return df[cols].to_dict(orient='records')\n",
    "\n",
    "# --------------------------------------------\n",
    "# Extend Use-Case Registry\n",
    "# --------------------------------------------\n",
    "USE_CASES.update({\n",
    "    'detect_deprecated_code': {\n",
    "        'func': detect_deprecated_code,\n",
    "        'required_params': ['deprecated_commits'],\n",
    "        'optional_params': []\n",
    "    },\n",
    "    'map_model_dataset': {\n",
    "        'func': map_model_dataset,\n",
    "        'required_params': [],\n",
    "        'optional_params': []\n",
    "    },\n",
    "})\n",
    "# 1) Detect runs on deprecated commits:\n",
    "deprecated = [\n",
    "    \"a07434af4f547af2daab044d6873eb7081162293\",\n",
    "    \"d329c92495e196ec0f39fbb19dfdd367131a77d9\"\n",
    "]\n",
    "# print(call_use_case(df, \"detect_deprecated_code\", deprecated_commits=deprecated))\n",
    "pprint(call_use_case(df, 'map_model_dataset'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52607ad-5849-4a2d-97ef-e8fc1ca16dc7",
   "metadata": {},
   "source": [
    "Goal: Notify collaborators who have forked the GitHub repo if their fork is outdated (i.e., behind the current commit used to train a model)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29c8ad9-00bb-4c1e-ac3b-ee6861991acd",
   "metadata": {},
   "source": [
    "üß† What We Need\n",
    "Current training run‚Äôs Git commit hash\n",
    "\n",
    "GitHub API to fetch all forks of your repo\n",
    "\n",
    "Compare each fork‚Äôs main or master branch head commit\n",
    "\n",
    "Create an issue on their fork or on your repo tagging them if they‚Äôre behind"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72bed50-fb56-442d-a21e-bb7991892d07",
   "metadata": {},
   "source": [
    ": Notify via issues on your own repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "852f147c-9d0a-4d7f-a4ab-545d1e2375fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want to notify collaborators whose forks are behind? (y/N):  N\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No action taken.\n"
     ]
    }
   ],
   "source": [
    "def notify_outdated_forks():\n",
    "    load_dotenv()\n",
    "    token     = os.getenv(\"THESIS_TOKEN\")\n",
    "    owner     = \"reema-dass26\"\n",
    "    repo      = \"REPO\"\n",
    "\n",
    "    if not token:\n",
    "        print(\"‚ö†Ô∏è GITHUB_TOKEN not set.\")\n",
    "        return\n",
    "\n",
    "    headers = {\n",
    "        \"Authorization\": f\"token {token}\",\n",
    "        \"Accept\":        \"application/vnd.github.v3+json\"\n",
    "    }\n",
    "\n",
    "    # 1) Get latest upstream commit\n",
    "    main_commits = requests.get(\n",
    "        f\"https://api.github.com/repos/{owner}/{repo}/commits\",\n",
    "        headers=headers,\n",
    "        params={\"per_page\": 1}\n",
    "    )\n",
    "    main_commits.raise_for_status()\n",
    "    new_commit_hash = main_commits.json()[0][\"sha\"]\n",
    "    print(f\"Latest upstream commit: {new_commit_hash}\")\n",
    "\n",
    "    # 2) List forks\n",
    "    forks_resp = requests.get(f\"https://api.github.com/repos/{owner}/{repo}/forks\", headers=headers)\n",
    "    forks_resp.raise_for_status()\n",
    "    forks = forks_resp.json()\n",
    "\n",
    "    # 3) Compare each fork\n",
    "    outdated = []\n",
    "    for fork in forks:\n",
    "        fork_owner = fork[\"owner\"][\"login\"]\n",
    "        fork_comm = requests.get(\n",
    "            fork[\"url\"] + \"/commits\",\n",
    "            headers=headers,\n",
    "            params={\"per_page\": 1}\n",
    "        )\n",
    "        if fork_comm.status_code != 200:\n",
    "            print(f\"¬†¬†‚Äì could not fetch commits for {fork_owner}, skipping.\")\n",
    "            continue\n",
    "\n",
    "        fork_sha = fork_comm.json()[0][\"sha\"]\n",
    "        if fork_sha != new_commit_hash:\n",
    "            outdated.append(f\"@{fork_owner}\")\n",
    "\n",
    "    # 4) Open an issue if any are behind\n",
    "    if outdated:\n",
    "        title = \"üîî Notification: Your fork is behind the latest commit\"\n",
    "        body  = (\n",
    "            f\"Hi {' '.join(outdated)},\\n\\n\"\n",
    "            f\"The main repository has been updated to commit `{new_commit_hash}`.\\n\"\n",
    "            \"Please consider pulling the latest changes to stay in sync.\\n\\n\"\n",
    "            \"Thanks!\"\n",
    "        )\n",
    "        issues_url = f\"https://api.github.com/repos/{owner}/{repo}/issues\"\n",
    "        resp = requests.post(\n",
    "        issues_url,\n",
    "        headers=headers,\n",
    "        json={\"title\": title, \"body\": body}\n",
    "    )\n",
    "\n",
    "    # DEBUGGING OUTPUT\n",
    "    print(f\"‚Üí POST {issues_url}\")\n",
    "    print(\"‚Üí Status code:\", resp.status_code)\n",
    "    print(\"‚Üí Response headers:\", resp.headers)\n",
    "    try:\n",
    "        data = resp.json()\n",
    "        print(\"‚Üí Response JSON:\", data)\n",
    "        print(\"‚Üí html_url field:\", data.get(\"html_url\"))\n",
    "    except ValueError:\n",
    "        print(\"‚Üí No JSON response body; raw text:\", resp.text)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    answer = input(\"Do you want to notify collaborators whose forks are behind? (y/N): \").strip().lower()\n",
    "    if answer in (\"y\", \"yes\"):\n",
    "        notify_outdated_forks()\n",
    "    else:\n",
    "        print(\"No action taken.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda31f16-fbe9-40ce-ac1b-9ebc898c8820",
   "metadata": {},
   "source": [
    "INVENIO INTEGRETION to upload the necessary files and publish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e5a7fc-3b03-45c8-bc90-817ea5ba7352",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################\n",
    "# TEST CODE FOR INVENIO INTEGRETION\n",
    "#############################################################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# API_BASE = \"https://127.0.0.1:5000\"\n",
    "# TOKEN    = \"8LnqJuz3TsBHffnDJ3isPLHYHtRbWrC0M667Nb5haEbnXpWqGbFRyfDApymr\"\n",
    "\n",
    "# # 1) Test read‚Äêscope by listing records (no size param or size=1)\n",
    "# resp = requests.get(\n",
    "#     f\"{API_BASE}/api/records\",\n",
    "#     headers={\"Authorization\": f\"Bearer {TOKEN}\"},\n",
    "#     verify=False\n",
    "# )\n",
    "# print(resp.status_code)\n",
    "# # should be 200 and a JSON page of records\n",
    "\n",
    "# # or explicitly:\n",
    "# resp = requests.get(\n",
    "#     f\"{API_BASE}/api/records?size=1\",\n",
    "#     headers={\"Authorization\": f\"Bearer {TOKEN}\"},\n",
    "#     verify=False\n",
    "# )\n",
    "# print(resp.status_code, resp.json())\n",
    "# #################################################################################################\n",
    "# API_BASE = \"https://127.0.0.1:5000\"\n",
    "# TOKEN    = \"8LnqJuz3TsBHffnDJ3isPLHYHtRbWrC0M667Nb5haEbnXpWqGbFRyfDApymr\"\n",
    "\n",
    "# resp = requests.options(\n",
    "#     f\"{API_BASE}/api/records\",\n",
    "#     headers={\"Authorization\": f\"Bearer {TOKEN}\"},\n",
    "#     verify=False\n",
    "# )\n",
    "# print(\"Allowed methods:\", resp.headers.get(\"Allow\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745dc1c9-ed88-45dc-bd8c-1065c9c17aa3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Configuration\n",
    "# -----------------------------------------------------------------------------\n",
    "API_BASE   = \"https://127.0.0.1:5000\"\n",
    "TOKEN      = \"8LnqJuz3TsBHffnDJ3isPLHYHtRbWrC0M667Nb5haEbnXpWqGbFRyfDApymr\"\n",
    "VERIFY_SSL = False  # only for self‚Äêsigned dev\n",
    "\n",
    "HEADERS_JSON = {\n",
    "    \"Accept\":        \"application/json\",\n",
    "    \"Content-Type\":  \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {TOKEN}\",\n",
    "}\n",
    "\n",
    "HEADERS_OCTET = {\n",
    "    \"Content-Type\":  \"application/octet-stream\",\n",
    "    \"Authorization\": f\"Bearer {TOKEN}\",\n",
    "}\n",
    "\n",
    "# The folders you want to walk & upload:\n",
    "TO_UPLOAD = [\"Trained_models\", \"plots\", \"MODEL_PROVENANCE\"]\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 1) Create draft with ALL required metadata\n",
    "# -----------------------------------------------------------------------------\n",
    "def create_draft():\n",
    "    payload = {\n",
    "  \"metadata\": {\n",
    "    \"title\":            \"RandomForest Iris Model Artifacts\",\n",
    "    \"creators\": [ {\n",
    "      \"person_or_org\": {\n",
    "        \"type\":        \"personal\",\n",
    "        \"given_name\":  \"Reema\",\n",
    "        \"family_name\": \"Dass\"\n",
    "      }\n",
    "    } ],\n",
    "    \"publication_date\": \"2025-04-24\",\n",
    "    \"resource_type\":    { \"id\": \"software\" },\n",
    "    \"access\": {\n",
    "      \"record\": \"public\",\n",
    "      \"files\":  \"public\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "    r = requests.post(f\"{API_BASE}/api/records\",\n",
    "                      headers=HEADERS_JSON,\n",
    "                      json=payload,\n",
    "                      verify=VERIFY_SSL)\n",
    "    r.raise_for_status()\n",
    "    draft = r.json()\n",
    "    print(\"‚úÖ Draft created:\", draft[\"id\"])\n",
    "    return draft[\"id\"], draft[\"links\"]\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 2) Register, upload and commit a single file\n",
    "# -----------------------------------------------------------------------------\n",
    "def upload_and_commit(links, key, path):\n",
    "    # 2a) register the filename in the draft\n",
    "    r1 = requests.post(links[\"files\"],\n",
    "                       headers=HEADERS_JSON,\n",
    "                       json=[{\"key\": key}],\n",
    "                       verify=VERIFY_SSL)\n",
    "    r1.raise_for_status()\n",
    "    entry = next(e for e in r1.json()[\"entries\"] if e[\"key\"] == key)\n",
    "    file_links = entry[\"links\"]\n",
    "\n",
    "    # 2b) upload the bytes\n",
    "    with open(path, \"rb\") as fp:\n",
    "        r2 = requests.put(file_links[\"content\"],\n",
    "                          headers=HEADERS_OCTET,\n",
    "                          data=fp,\n",
    "                          verify=VERIFY_SSL)\n",
    "    r2.raise_for_status()\n",
    "\n",
    "    # 2c) commit the upload\n",
    "    r3 = requests.post(file_links[\"commit\"],\n",
    "                       headers=HEADERS_JSON,\n",
    "                       verify=VERIFY_SSL)\n",
    "    r3.raise_for_status()\n",
    "    print(f\"  ‚Ä¢ Uploaded {key}\")\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 3) Walk each folder and upload every file\n",
    "# -----------------------------------------------------------------------------\n",
    "def upload_folder(links):\n",
    "    for folder in TO_UPLOAD:\n",
    "        if not os.path.isdir(folder):\n",
    "            print(f\"‚ö†Ô∏è Skipping missing folder {folder}\")\n",
    "            continue\n",
    "        base = os.path.dirname(folder) or folder\n",
    "        for root, _, files in os.walk(folder):\n",
    "            for fn in files:\n",
    "                local = os.path.join(root, fn)\n",
    "                # create a POSIX‚Äêstyle key preserving subfolders\n",
    "                key = os.path.relpath(local, start=base).replace(os.sep, \"/\")\n",
    "                upload_and_commit(links, key, local)\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 4) Publish the draft\n",
    "# -----------------------------------------------------------------------------\n",
    "def publish(links):\n",
    "    r = requests.post(links[\"publish\"],\n",
    "                      headers=HEADERS_JSON,\n",
    "                      verify=VERIFY_SSL)\n",
    "    if not r.ok:\n",
    "        print(\"‚ùå Publish failed:\", r.status_code, r.text)\n",
    "        try: print(r.json())\n",
    "        except: pass\n",
    "        r.raise_for_status()\n",
    "    print(\"‚úÖ Published:\", r.json()[\"id\"])\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Main\n",
    "# -----------------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    recid, links = create_draft()\n",
    "    upload_folder(links)\n",
    "    publish(links)\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b463223e-5425-465c-ae63-815cbb053301",
   "metadata": {},
   "source": [
    "########################################################################\n",
    "# FETCH metadata from INVENIO\n",
    "########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ee538759-38b9-4ea8-bdc6-41cc65ede642",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\reema\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:1056: InsecureRequestWarning: Unverified HTTPS request is being made to host '127.0.0.1'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Metadata fetched successfully\n",
      "‚úÖ Metadata saved at Invenio_metadata\\RandomForest_Iris_v20250425_135900_invenio.json\n",
      "Invenio_metadata\\RandomForest_Iris_v20250425_135900_invenio.json\n"
     ]
    }
   ],
   "source": [
    "def fetch_metadata(record_id, model_name, api_base, headers, verify_ssl=True):\n",
    "    \"\"\"\n",
    "    Fetch Invenio metadata and save to a file named after the model inside 'Invenio_metadata' folder.\n",
    "    \"\"\"\n",
    "    response = requests.get(f\"{API_BASE}/api/records/{record_id}\",\n",
    "                            headers=headers,\n",
    "                            verify=VERIFY_SSL)\n",
    "    response.raise_for_status()\n",
    "    metadata = response.json()\n",
    "\n",
    "    print(\"‚úÖ Metadata fetched successfully\")\n",
    "\n",
    "    # Create the folder if it doesn't exist\n",
    "    os.makedirs(\"Invenio_metadata\", exist_ok=True)\n",
    "\n",
    "    # Construct path and save\n",
    "    file_path = os.path.join(\"Invenio_metadata\", f\"{model_name}_invenio.json\")\n",
    "    with open(file_path, \"w\") as f:\n",
    "        json.dump(metadata, f, indent=4)\n",
    "\n",
    "    print(f\"‚úÖ Metadata saved at {file_path}\")\n",
    "    return file_path\n",
    "path = fetch_metadata(recid, model_name, api_base=API_BASE, headers=HEADERS_JSON)\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7423f2-0ff3-4104-913e-50eeb32d9d0f",
   "metadata": {},
   "source": [
    "METADATA EXTRACTION FROM INVENIO and ADD it to main Provenence FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "10d5968b-997e-4458-bf6b-a14dcc883698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Metadata loaded successfully\n",
      "‚ÑπÔ∏è ID: 892h2-fq661\n",
      "üîç Extracting required fields...\n",
      "üì§ Extracted Metadata Preview:\n",
      "{\n",
      "    \"invenio_metadata\": {\n",
      "        \"id\": \"892h2-fq661\",\n",
      "        \"title\": \"RandomForest Iris Model Artifacts\",\n",
      "        \"creator\": \"Dass, Reema\",\n",
      "        \"publication_date\": \"2025-04-24\",\n",
      "        \"files\": [\n",
      "            {\n",
      "                \"key\": \"RandomForest_Iris_v20250423_230422.pkl\",\n",
      "                \"url\": \"https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250423_230422.pkl/content\",\n",
      "                \"size\": 282910,\n",
      "                \"mimetype\": \"application/octet-stream\",\n",
      "                \"checksum\": \"md5:a9f9e15b9c808d94c8e5737089beaa7d\",\n",
      "                \"metadata\": {}\n",
      "            },\n",
      "            {\n",
      "                \"key\": \"RandomForest_Iris_v20250425_125653.pkl\",\n",
      "                \"url\": \"https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250425_125653.pkl/content\",\n",
      "                \"size\": 282910,\n",
      "                \"mimetype\": \"application/octet-stream\",\n",
      "                \"checksum\": \"md5:503fdd8a19da9f48029eccc32d473a36\",\n",
      "                \"metadata\"\n",
      "‚úÖ Invenio metadata embedded successfully into: MODEL_PROVENANCE/RandomForest_Iris_v20250425_135900/RandomForest_Iris_v20250425_135900_run_summary.json\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# Function: Extract metadata\n",
    "# ----------------------------\n",
    "def extract_metadata(metadata):\n",
    "    print(\"‚úÖ Metadata loaded successfully\")\n",
    "    print(\"‚ÑπÔ∏è ID:\", metadata.get(\"id\", \"N/A\"))\n",
    "    print(\"üîç Extracting required fields...\")\n",
    "\n",
    "    extracted_data = {\n",
    "        \"invenio_metadata\": {\n",
    "            \"id\": metadata.get(\"id\", \"\"),\n",
    "            \"title\": metadata.get(\"metadata\", {}).get(\"title\", \"\"),\n",
    "            \"creator\": \", \".join([\n",
    "                creator[\"person_or_org\"].get(\"name\", \"\")\n",
    "                for creator in metadata.get(\"metadata\", {}).get(\"creators\", [])\n",
    "            ]),\n",
    "            \"publication_date\": metadata.get(\"metadata\", {}).get(\"publication_date\", \"\"),\n",
    "            \"files\": [],\n",
    "            \"pids\": metadata.get(\"pids\", {}),\n",
    "            \"version_info\": metadata.get(\"versions\", {}),\n",
    "            \"status\": metadata.get(\"status\", \"\"),\n",
    "            \"views\": metadata.get(\"stats\", {}).get(\"this_version\", {}).get(\"views\", 0),\n",
    "            \"downloads\": metadata.get(\"stats\", {}).get(\"this_version\", {}).get(\"downloads\", 0),\n",
    "        }\n",
    "    }\n",
    "\n",
    "    for key, file_info in metadata.get(\"files\", {}).get(\"entries\", {}).items():\n",
    "        file_detail = {\n",
    "            \"key\": key,\n",
    "            \"url\": file_info[\"links\"].get(\"content\", \"\"),\n",
    "            \"size\": file_info.get(\"size\", 0),\n",
    "            \"mimetype\": file_info.get(\"mimetype\", \"\"),\n",
    "            \"checksum\": file_info.get(\"checksum\", \"\"),\n",
    "            \"metadata\": file_info.get(\"metadata\", {}),\n",
    "        }\n",
    "        extracted_data[\"invenio_metadata\"][\"files\"].append(file_detail)\n",
    "\n",
    "    return extracted_data\n",
    "\n",
    "\n",
    "invenio_path = f\"Invenio_metadata/{model_name}_invenio.json\"\n",
    "run_summary_path = f\"MODEL_PROVENANCE/{model_name}/{model_name}_run_summary.json\"\n",
    "\n",
    "# ----------------------------\n",
    "# Step 1: Load Invenio metadata\n",
    "# ----------------------------\n",
    "with open(invenio_path, \"r\") as f:\n",
    "    original_metadata = json.load(f)\n",
    "\n",
    "# ----------------------------\n",
    "# Step 2: Extract metadata\n",
    "# ----------------------------\n",
    "extracted_metadata = extract_metadata(original_metadata)\n",
    "print(\"üì§ Extracted Metadata Preview:\")\n",
    "print(json.dumps(extracted_metadata, indent=4)[:1000])  # Preview\n",
    "\n",
    "# ----------------------------\n",
    "# Step 3: Load run summary\n",
    "# ----------------------------\n",
    "with open(run_summary_path, \"r\") as f:\n",
    "    existing_metadata = json.load(f)\n",
    "\n",
    "# ----------------------------\n",
    "# Step 4: Merge metadata\n",
    "# ----------------------------\n",
    "existing_metadata.update(extracted_metadata)\n",
    "\n",
    "# ----------------------------\n",
    "# Step 5: Save updated summary\n",
    "# ----------------------------\n",
    "with open(run_summary_path, \"w\") as f:\n",
    "    json.dump(existing_metadata, f, indent=4)\n",
    "\n",
    "print(f\"‚úÖ Invenio metadata embedded successfully into: {run_summary_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa460d3-f443-46b1-ba5e-4f1339ba4eee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
