{
    "run_id": "3ec1102377b049589537b68a9494fbfc",
    "run_name": "indecisive-duck-252",
    "experiment_id": "615223710259862608",
    "start_time": 1745582147903,
    "end_time": null,
    "params": {
        "bootstrap": "True",
        "ccp_alpha": "0.0",
        "class_weight": "None",
        "columns_raw": "['run_id', 'param_bootstrap', 'param_ccp_alpha', 'param_class_weight', 'param_columns_raw', 'param_criterion', 'param_database.description', 'param_database.id', 'param_database.name', 'param_database.owner', 'param_dataset.authors', 'param_dataset.doi', 'param_dataset.published', 'param_dataset.publisher', 'param_dataset.title', 'param_dropped_columns', 'param_feature_names', 'param_matplotlib_version', 'param_max_depth', 'param_max_features', 'param_max_leaf_nodes', 'param_max_samples', 'param_min_impurity_decrease', 'param_min_samples_leaf', 'param_min_samples_split', 'param_min_weight_fraction_leaf', 'param_numpy_version', 'param_n_estimators', 'param_n_features', 'param_n_features_final', 'param_n_jobs', 'param_n_records', 'param_n_test_samples', 'param_n_train_samples', 'param_oob_score', 'param_os_platform', 'param_pandas_version', 'param_python_version', 'param_random_state', 'param_retrieval_time', 'param_seaborn_version', 'param_shap_version', 'param_sklearn_version', 'param_test_size', 'param_verbose', 'param_warm_start', 'metric_accuracy', 'metric_accuracy_score_X_test', 'metric_dbrepo.num_deletes', 'metric_dbrepo.num_inserts', 'metric_dbrepo.row_count_end', 'metric_dbrepo.row_count_start', 'metric_f1_macro', 'metric_f1_score_X_test', 'metric_precision_macro', 'metric_precision_score_X_test', 'metric_recall_macro', 'metric_recall_score_X_test', 'metric_roc_auc', 'metric_roc_auc_score_X_test', 'metric_training_accuracy_score', 'metric_training_f1_score', 'metric_training_log_loss', 'metric_training_precision_score', 'metric_training_recall_score', 'metric_training_roc_auc', 'metric_training_score', 'tag_dataset_id', 'tag_dataset_name', 'tag_dataset_version', 'tag_data_source', 'tag_dbrepo.admin_email', 'tag_dbrepo.base_url', 'tag_dbrepo.granularity', 'tag_dbrepo.protocol_version', 'tag_dbrepo.repository_name', 'tag_dbrepo.table_last_modified', 'tag_estimator_class', 'tag_estimator_name', 'tag_git_current_commit_hash', 'tag_git_previous_commit_hash', 'tag_git__current_commit_url', 'tag_mlflow.log-model.history', 'tag_mlflow.runName', 'tag_mlflow.source.name', 'tag_mlflow.source.type', 'tag_mlflow.user', 'tag_model_name', 'tag_notebook_name', 'tag_target_name', 'tag_training_end_time', 'tag_training_start_time']",
        "criterion": "entropy",
        "database.description": "",
        "database.id": "",
        "database.name": "",
        "database.owner": "",
        "dataset.authors": "[\"Marshall Michael\"]",
        "dataset.doi": "10.5281/ZENODO.1404173",
        "dataset.published": "2018-8-27",
        "dataset.publisher": "Zenodo",
        "dataset.title": "Scikit-Learn Iris",
        "dropped_columns": "['id']",
        "feature_names": "['sepallengthcm', 'sepalwidthcm', 'petallengthcm', 'petalwidthcm']",
        "matplotlib_version": "3.7.2",
        "max_depth": "12",
        "max_features": "sqrt",
        "max_leaf_nodes": "None",
        "max_samples": "None",
        "min_impurity_decrease": "0.0",
        "min_samples_leaf": "2",
        "min_samples_split": "5",
        "min_weight_fraction_leaf": "0.0",
        "numpy_version": "1.24.4",
        "n_estimators": "200",
        "n_features": "4",
        "n_features_final": "4",
        "n_jobs": "-1",
        "n_records": "1",
        "n_test_samples": "30",
        "n_train_samples": "120",
        "oob_score": "False",
        "os_platform": "Windows 10",
        "pandas_version": "2.2.3",
        "python_version": "3.11.5",
        "random_state": "42",
        "retrieval_time": "2025-04-25T11:55:53.172659",
        "seaborn_version": "0.12.2",
        "shap_version": "0.47.1",
        "sklearn_version": "1.3.0",
        "test_size": "0.2",
        "verbose": "1",
        "warm_start": "False"
    },
    "metrics": {
        "accuracy": 1.0,
        "accuracy_score_X_test": 1.0,
        "dbrepo.num_deletes": 0.0,
        "dbrepo.num_inserts": 1.0,
        "dbrepo.row_count_end": 150.0,
        "dbrepo.row_count_start": 150.0,
        "f1_macro": 1.0,
        "f1_score_X_test": 1.0,
        "precision_macro": 1.0,
        "precision_score_X_test": 1.0,
        "recall_macro": 1.0,
        "recall_score_X_test": 1.0,
        "roc_auc": 1.0,
        "roc_auc_score_X_test": 1.0,
        "training_accuracy_score": 0.9666666666666667,
        "training_f1_score": 0.9666666666666667,
        "training_log_loss": 0.0653522301195834,
        "training_precision_score": 0.9674588284344383,
        "training_recall_score": 0.9666666666666667,
        "training_roc_auc": 0.9987492182614135,
        "training_score": 0.9666666666666667
    },
    "tags": {
        "dataset_id": "iris_local",
        "dataset_name": "Iris",
        "dataset_version": "1.0.0",
        "data_source": "http://localhost/api/database/c3a42d17-42b7-43c9-a504-2363fb4c9c8d/table/5315e7da-64fb-4fdb-b493-95b4138c765f/data?size=100000&page=0",
        "dbrepo.admin_email": "noreply@localhost",
        "dbrepo.base_url": "http://localhost",
        "dbrepo.granularity": "YYYY-MM-DDThh:mm:ssZ",
        "dbrepo.protocol_version": "2.0",
        "dbrepo.repository_name": "Database Repository",
        "dbrepo.table_last_modified": "2025-04-23T20:42:29.501Z",
        "estimator_class": "sklearn.ensemble._forest.RandomForestClassifier",
        "estimator_name": "RandomForestClassifier",
        "git_current_commit_hash": "4b8fba2dcf4ab75088838668b5abc6d94c92f502",
        "git_previous_commit_hash": "8c5c1cb1d6a5e4a1d63b6ffdef1f78328209301a",
        "git__current_commit_url": "https://github.com/reema-dass26/REPO/commit/4b8fba2dcf4ab75088838668b5abc6d94c92f502",
        "justification_bootstrap": "test",
        "justification_class_weight": "test",
        "justification_criterion": "test",
        "justification_dataset_version": "test",
        "justification_drop_column_X": "test",
        "justification_experiment_name": "test",
        "justification_max_depth": "test",
        "justification_max_features": "test",
        "justification_metric_choice": "test",
        "justification_min_samples_leaf": "test",
        "justification_min_samples_split": "test",
        "justification_model_choice": "test",
        "justification_n_estimators": "test",
        "justification_n_jobs": "test",
        "justification_oob_score": "test",
        "justification_random_state": "test",
        "justification_target_variable": "test",
        "justification_test_split": "test",
        "justification_threshold_accuracy": "test",
        "justification_verbose": "test",
        "mlflow.log-model.history": "[{\"run_id\": \"3ec1102377b049589537b68a9494fbfc\", \"artifact_path\": \"model\", \"utc_time_created\": \"2025-04-25 11:56:25.656713\", \"model_uuid\": \"06af3bed7a5b4144b39f555e3fb4ad4b\", \"flavors\": {\"python_function\": {\"model_path\": \"model.pkl\", \"predict_fn\": \"predict\", \"loader_module\": \"mlflow.sklearn\", \"python_version\": \"3.11.5\", \"env\": {\"conda\": \"conda.yaml\", \"virtualenv\": \"python_env.yaml\"}}, \"sklearn\": {\"pickled_model\": \"model.pkl\", \"sklearn_version\": \"1.3.0\", \"serialization_format\": \"cloudpickle\", \"code\": null}}}]",
        "mlflow.runName": "indecisive-duck-252",
        "mlflow.source.name": "C:\\Users\\reema\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel_launcher.py",
        "mlflow.source.type": "LOCAL",
        "mlflow.user": "reema",
        "model_name": "RandomForest_Iris_v20250425_135553",
        "notebook_name": "RQ1.ipynb",
        "target_name": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]",
        "training_end_time": "2025-04-25T13:56:32.733515",
        "training_start_time": "2025-04-25T13:55:53.215972"
    },
    "artifacts": [
        {
            "path": "RandomForest_Iris_v20250425_135553/RandomForest_Iris_v20250425_135553.pkl",
            "type": "other",
            "uri": "file:///C:/Users/reema/REPO/notebooks/RQ_notebooks/mlrunlogs/mlflow.db/615223710259862608/3ec1102377b049589537b68a9494fbfc/artifacts/RandomForest_Iris_v20250425_135553/RandomForest_Iris_v20250425_135553.pkl"
        },
        {
            "path": "commit_diff.json",
            "type": "text",
            "content": "{\n  \"previous_commit\": \"8c5c1cb1d6a5e4a1d63b6ffdef1f78328209301a\",\n  \"previous_commit_url\": \"https://github.com/reema-dass26/REPO/commit/8c5c1cb1d6a5e4a1d63b6ffdef1f78328209301a\",\n  \"current_commit_url\": \"https://github.com/reema-dass26/REPO/commit/4b8fba2dcf4ab75088838668b5abc6d94c92f502\",\n  \"current_commit\": \"4b8fba2dcf4ab75088838668b5abc6d94c92f502\",\n  \"diff\": \"diff --git a/notebooks/RQ_notebooks/MODEL_PROVENANCE/RandomForest_Iris_v20250423_230422.jsonld b/notebooks/RQ_notebooks/MODEL_PROVENANCE/RandomForest_Iris_v20250423_230422.jsonld\\ndeleted file mode 100644\\nindex 9a18980..0000000\\n--- a/notebooks/RQ_notebooks/MODEL_PROVENANCE/RandomForest_Iris_v20250423_230422.jsonld\\n+++ /dev/null\\n@@ -1,544 +0,0 @@\\n-{\\n-  \\\"@context\\\": {\\n-    \\\"prov\\\": \\\"http://www.w3.org/ns/prov#\\\",\\n-    \\\"xsd\\\": \\\"http://www.w3.org/2001/XMLSchema#\\\",\\n-    \\\"run\\\": \\\"prov:Activity\\\",\\n-    \\\"start\\\": \\\"prov:startedAtTime\\\",\\n-    \\\"end\\\": \\\"prov:endedAtTime\\\",\\n-    \\\"used\\\": \\\"prov:used\\\",\\n-    \\\"gen\\\": \\\"prov:generated\\\",\\n-    \\\"param\\\": \\\"prov:hadParameter\\\",\\n-    \\\"metric\\\": \\\"prov:hadQuality\\\",\\n-    \\\"entity\\\": \\\"prov:Entity\\\",\\n-    \\\"label\\\": \\\"prov:label\\\",\\n-    \\\"value\\\": \\\"prov:value\\\",\\n-    \\\"version\\\": \\\"prov:hadRevision\\\",\\n-    \\\"id\\\": \\\"@id\\\",\\n-    \\\"type\\\": \\\"@type\\\"\\n-  },\\n-  \\\"@id\\\": \\\"urn:run:361daa12f99f4129a06cd20b78dd6fa7\\\",\\n-  \\\"@type\\\": \\\"run\\\",\\n-  \\\"start\\\": {\\n-    \\\"@type\\\": \\\"xsd:dateTime\\\",\\n-    \\\"@value\\\": \\\"2025-04-23T21:04:21.262000+00:00\\\"\\n-  },\\n-  \\\"param\\\": [\\n-    {\\n-      \\\"@type\\\": \\\"entity\\\",\\n-      \\\"label\\\": \\\"bootstrap\\\",\\n-      \\\"value\\\": \\\"True\\\"\\n-    },\\n-    {\\n-      \\\"@type\\\": \\\"entity\\\",\\n-      \\\"label\\\": \\\"ccp_alpha\\\",\\n-      \\\"value\\\": \\\"0.0\\\"\\n-    },\\n-    {\\n-      \\\"@type\\\": \\\"entity\\\",\\n-      \\\"label\\\": \\\"class_weight\\\",\\n-      \\\"value\\\": \\\"None\\\"\\n-    },\\n-    {\\n-      \\\"@type\\\": \\\"entity\\\",\\n-      \\\"label\\\": \\\"columns_raw\\\",\\n-      \\\"value\\\": \\\"['id', 'sepallengthcm', 'sepalwidthcm', 'petallengthcm', 'petalwidthcm', 'species']\\\"\\n-    },\\n-    {\\n-      \\\"@type\\\": \\\"entity\\\",\\n-      \\\"label\\\": \\\"criterion\\\",\\n-      \\\"value\\\": \\\"entropy\\\"\\n-    },\\n-    {\\n-      \\\"@type\\\": \\\"entity\\\",\\n-      \\\"label\\\": \\\"database.description\\\",\\n-      \\\"value\\\": \\\"None\\\"\\n-    },\\n-    {\\n-      \\\"@type\\\": \\\"entity\\\",\\n-      \\\"label\\\": \\\"database.id\\\",\\n-      \\\"value\\\": \\\"c3a42d17-42b7-43c9-a504-2363fb4c9c8d\\\"\\n-    },\\n-    {\\n-      \\\"@type\\\": \\\"entity\\\",\\n-      \\\"label\\\": \\\"database.name\\\",\\n-      \\\"value\\\": \\\"Iris\\\"\\n-    },\\n-    {\\n-      \\\"@type\\\": \\\"entity\\\",\\n-      \\\"label\\\": \\\"database.owner\\\",\\n-      \\\"value\\\": \\\"reema\\\"\\n-    },\\n-    {\\n-      \\\"@type\\\": \\\"entity\\\",\\n-      \\\"label\\\": \\\"dataset.authors\\\",\\n-      \\\"value\\\": \\\"[\\\\\\\"Marshall Michael\\\\\\\"]\\\"\\n-    },\\n-    {\\n-      \\\"@type\\\": \\\"entity\\\",\\n-      \\\"label\\\": \\\"dataset.doi\\\",\\n-      \\\"value\\\": \\\"10.5281/ZENODO.1404173\\\"\\n-    },\\n-    {\\n-      \\\"@type\\\": \\\"entity\\\",\\n-      \\\"label\\\": \\\"dataset.published\\\",\\n-      \\\"value\\\": \\\"2018-8-27\\\"\\n-    },\\n-    {\\n-      \\\"@type\\\": \\\"entity\\\",\\n-      \\\"label\\\": \\\"dataset.publisher\\\",\\n-      \\\"value\\\": \\\"Zenodo\\\"\\n-    },\\n-    {\\n-      \\\"@type\\\": \\\"entity\\\",\\n-      \\\"label\\\": \\\"dataset.title\\\",\\n-      \\\"value\\\": \\\"Scikit-Learn Iris\\\"\\n-    },\\n-    {\\n-      \\\"@type\\\": \\\"entity\\\",\\n-      \\\"label\\\": \\\"dropped_columns\\\",\\n-      \\\"value\\\": \\\"[]\\\"\\n-    },\\n-    {\\n-      \\\"@type\\\": \\\"entity\\\",\\n-      \\\"label\\\": \\\"feature_names\\\",\\n-      \\\"value\\\": \\\"['sepallengthcm', 'sepalwidthcm', 'petallengthcm', 'petalwidthcm']\\\"\\n-    },\\n-    {\\n-      \\\"@type\\\": \\\"entity\\\",\\n-      \\\"label\\\": \\\"matplotlib_version\\\",\\n-      \\\"value\\\": \\\"3.7.2\\\"\\n-    },\\n-    {\\n-      \\\"@type\\\": \\\"entity\\\",\\n-      \\\"label\\\": \\\"max_depth\\\",\\n-      \\\"value\\\": \\\"12\\\"\\n-    },\\n-    {\\n-      \\\"@type\\\": \\\"entity\\\",\\n-      \\\"label\\\": \\\"max_features\\\",\\n-      \\\"value\\\": \\\"sqrt\\\"\\n-    },\\n-    {\\n-      \\\"@type\\\": \\\"entity\\\",\\n-      \\\"label\\\": \\\"max_leaf_nodes\\\",\\n-      \\\"value\\\": \\\"None\\\"\\n-    },\\n-    {\\n-      \\\"@type\\\": \\\"entity\\\",\\n-      \\\"label\\\": \\\"max_samples\\\",\\n-      \\\"value\\\": \\\"None\\\"\\n-    },\\n-    {\\n-      \\\"@type\\\": \\\"entity\\\",\\n-      \\\"label\\\": \\\"min_impurity_decrease\\\",\\n-      \\\"value\\\": \\\"0.0\\\"\\n-    },\\n-    {\\n-      \\\"@type\\\": \\\"entity\\\",\\n-      \\\"label\\\": \\\"min_samples_leaf\\\",\\n-      \\\"value\\\": \\\"2\\\"\\n-    },\\n-    {\\n-      \\\"@type\\\": \\\"entity\\\",\\n-      \\\"label\\\": \\\"min_samples_split\\\",\\n-      \\\"value\\\": \\\"5\\\"\\n-    },\\n-    {\\n-      \\\"@type\\\": \\\"entity\\\",\\n-      \\\"label\\\": \\\"min_weight_fraction_leaf\\\",\\n-      \\\"value\\\": \\\"0.0\\\"\\n-    },\\n-    {\\n-      \\\"@type\\\": \\\"entity\\\",\\n-      \\\"label\\\": \\\"numpy_version\\\",\\n-      \\\"value\\\": \\\"1.24.4\\\"\\n-    },\\n-    {\\n-      \\\"@type\\\": \\\"entity\\\",\\n-      \\\"label\\\": \\\"n_estimators\\\",\\n-      \\\"value\\\": \\\"200\\\"\\n-    },\\n-    {\\n-      \\\"@type\\\": \\\"entity\\\",\\n-      \\\"label\\\": \\\"n_features\\\",\\n-      \\\"value\\\": \\\"4\\\"\\n-    },\\n-    {\\n-      \\\"@type\\\": \\\"entity\\\",\\n-      \\\"label\\\": \\\"n_features_final\\\",\\n-      \\\"value\\\": \\\"4\\\"\\n-    },\\n-    {\\n-      \\\"@type\\\": \\\"entity\\\",\\n-      \\\"label\\\": \\\"n_jobs\\\",\\n-      \\\"value\\\": \\\"-1\\\"\\n-    },\\n-    {\\n-      \\\"@type\\\": \\\"entity\\\",\\n-      \\\"label\\\": \\\"n_records\\\",\\n-      \\\"value\\\": \\\"150\\\"\\n-    },\\n-    {\\n-      \\\"@type\\\": \\\"entity\\\",\\n-      \\\"label\\\": \\\"n_test_samples\\\",\\n-      \\\"value\\\": \\\"30\\\"\\n-    },\\n-    {\\n-      \\\"@type\\\": \\\"entity\\\",\\n-      \\\"label\\\": \\\"n_train_samples\\\",\\n-      \\\"value\\\": \\\"120\\\"\\n-    },\\n-    {\\n-      \\\"@type\\\": \\\"entity\\\",\\n-      \\\"label\\\": \\\"oob_score\\\",\\n-      \\\"value\\\": \\\"False\\\"\\n-    },\\n-    {\\n-      \\\"@type\\\": \\\"entity\\\",\\n-      \\\"label\\\": \\\"os_platform\\\",\\n-      \\\"value\\\": \\\"Windows 10\\\"\\n-    },\\n-    {\\n-      \\\"@type\\\": \\\"entity\\\",\\n-      \\\"label\\\": \\\"pandas_version\\\",\\n-      \\\"value\\\": \\\"2.2.3\\\"\\n-    },\\n-    {\\n-      \\\"@type\\\": \\\"entity\\\",\\n-      \\\"label\\\": \\\"python_version\\\",\\n-      \\\"value\\\": \\\"3.11.5\\\"\\n-    },\\n-    {\\n-      \\\"@type\\\": \\\"entity\\\",\\n-      \\\"label\\\": \\\"random_state\\\",\\n-      \\\"value\\\": \\\"42\\\"\\n-    },\\n-    {\\n-      \\\"@type\\\": \\\"entity\\\",\\n-      \\\"label\\\": \\\"retrieval_time\\\",\\n-      \\\"value\\\": \\\"2025-04-23T21:04:22.410093\\\"\\n-    },\\n-    {\\n-      \\\"@type\\\": \\\"entity\\\",\\n-      \\\"label\\\": \\\"seaborn_version\\\",\\n-      \\\"value\\\": \\\"0.12.2\\\"\\n-    },\\n-    {\\n-      \\\"@type\\\": \\\"entity\\\",\\n-      \\\"label\\\": \\\"shap_version\\\",\\n-      \\\"value\\\": \\\"0.47.1\\\"\\n-    },\\n-    {\\n-      \\\"@type\\\": \\\"entity\\\",\\n-      \\\"label\\\": \\\"sklearn_version\\\",\\n-      \\\"value\\\": \\\"1.3.0\\\"\\n-    },\\n-    {\\n-      \\\"@type\\\": \\\"entity\\\",\\n-      \\\"label\\\": \\\"test_size\\\",\\n-      \\\"value\\\": \\\"0.2\\\"\\n-    },\\n-    {\\n-      \\\"@type\\\": \\\"entity\\\",\\n-      \\\"label\\\": \\\"verbose\\\",\\n-      \\\"value\\\": \\\"1\\\"\\n-    },\\n-    {\\n-      \\\"@type\\\": \\\"entity\\\",\\n-      \\\"label\\\": \\\"warm_start\\\",\\n-      \\\"value\\\": \\\"False\\\"\\n-    }\\n-  ],\\n-  \\\"metric\\\": [\\n-    {\\n-      \\\"@type\\\": \\\"entity\\\",\\n-      \\\"label\\\": \\\"accuracy\\\",\\n-      \\\"value\\\": {\\n-        \\\"@type\\\": \\\"xsd:decimal\\\",\\n-        \\\"@value\\\": 1.0\\n-      }\\n-    },\\n-    {\\n-      \\\"@type\\\": \\\"entity\\\",\\n-      \\\"label\\\": \\\"accuracy_score_X_test\\\",\\n-      \\\"value\\\": {\\n-        \\\"@type\\\": \\\"xsd:decimal\\\",\\n-        \\\"@value\\\": 1.0\\n-      }\\n-    },\\n-    {\\n-      \\\"@type\\\": \\\"entity\\\",\\n-      \\\"label\\\": \\\"dbrepo.num_deletes\\\",\\n-      \\\"value\\\": {\\n-        \\\"@type\\\": \\\"xsd:decimal\\\",\\n-        \\\"@value\\\": 0.0\\n-      }\\n-    },\\n-    {\\n-      \\\"@type\\\": \\\"entity\\\",\\n-      \\\"label\\\": \\\"dbrepo.num_inserts\\\",\\n-      \\\"value\\\": {\\n-        \\\"@type\\\": \\\"xsd:decimal\\\",\\n-        \\\"@value\\\": 1.0\\n-      }\\n-    },\\n-    {\\n-      \\\"@type\\\": \\\"entity\\\",\\n-      \\\"label\\\": \\\"dbrepo.row_count_end\\\",\\n-      \\\"value\\\": {\\n-        \\\"@type\\\": \\\"xsd:decimal\\\",\\n-        \\\"@value\\\": 150.0\\n-      }\\n-    },\\n-    {\\n-      \\\"@type\\\": \\\"entity\\\",\\n-      \\\"label\\\": \\\"dbrepo.row_count_start\\\",\\n-      \\\"value\\\": {\\n-        \\\"@type\\\": \\\"xsd:decimal\\\",\\n-        \\\"@value\\\": 150.0\\n-      }\\n-    },\\n-    {\\n-      \\\"@type\\\": \\\"entity\\\",\\n-      \\\"label\\\": \\\"f1_macro\\\",\\n-      \\\"value\\\": {\\n-        \\\"@type\\\": \\\"xsd:decimal\\\",\\n-        \\\"@value\\\": 1.0\\n-      }\\n-    },\\n-    {\\n-      \\\"@type\\\": \\\"entity\\\",\\n-      \\\"label\\\": \\\"f1_score_X_test\\\",\\n-      \\\"value\\\": {\\n-        \\\"@type\\\": \\\"xsd:decimal\\\",\\n-        \\\"@value\\\": 1.0\\n-      }\\n-    },\\n-    {\\n-      \\\"@type\\\": \\\"entity\\\",\\n-      \\\"label\\\": \\\"precision_macro\\\",\\n-      \\\"value\\\": {\\n-        \\\"@type\\\": \\\"xsd:decimal\\\",\\n-        \\\"@value\\\": 1.0\\n-      }\\n-    },\\n-    {\\n-      \\\"@type\\\": \\\"entity\\\",\\n-      \\\"label\\\": \\\"precision_score_X_test\\\",\\n-      \\\"value\\\": {\\n-        \\\"@type\\\": \\\"xsd:decimal\\\",\\n-        \\\"@value\\\": 1.0\\n-      }\\n-    },\\n-    {\\n-      \\\"@type\\\": \\\"entity\\\",\\n-      \\\"label\\\": \\\"recall_macro\\\",\\n-      \\\"value\\\": {\\n-        \\\"@type\\\": \\\"xsd:decimal\\\",\\n-        \\\"@value\\\": 1.0\\n-      }\\n-    },\\n-    {\\n-      \\\"@type\\\": \\\"entity\\\",\\n-      \\\"label\\\": \\\"recall_score_X_test\\\",\\n-      \\\"value\\\": {\\n-        \\\"@type\\\": \\\"xsd:decimal\\\",\\n-        \\\"@value\\\": 1.0\\n-      }\\n-    },\\n-    {\\n-      \\\"@type\\\": \\\"entity\\\",\\n-      \\\"label\\\": \\\"roc_auc\\\",\\n-      \\\"value\\\": {\\n-        \\\"@type\\\": \\\"xsd:decimal\\\",\\n-        \\\"@value\\\": 1.0\\n-      }\\n-    },\\n-    {\\n-      \\\"@type\\\": \\\"entity\\\",\\n-      \\\"label\\\": \\\"roc_auc_score_X_test\\\",\\n-      \\\"value\\\": {\\n-        \\\"@type\\\": \\\"xsd:decimal\\\",\\n-        \\\"@value\\\": 1.0\\n-      }\\n-    },\\n-    {\\n-      \\\"@type\\\": \\\"entity\\\",\\n-      \\\"label\\\": \\\"training_accuracy_score\\\",\\n-      \\\"value\\\": {\\n-        \\\"@type\\\": \\\"xsd:decimal\\\",\\n-        \\\"@value\\\": 0.9666666666666667\\n-      }\\n-    },\\n-    {\\n-      \\\"@type\\\": \\\"entity\\\",\\n-      \\\"label\\\": \\\"training_f1_score\\\",\\n-      \\\"value\\\": {\\n-        \\\"@type\\\": \\\"xsd:decimal\\\",\\n-        \\\"@value\\\": 0.9666666666666667\\n-      }\\n-    },\\n-    {\\n-      \\\"@type\\\": \\\"entity\\\",\\n-      \\\"label\\\": \\\"training_log_loss\\\",\\n-      \\\"value\\\": {\\n-        \\\"@type\\\": \\\"xsd:decimal\\\",\\n-        \\\"@value\\\": 0.0653522301195834\\n-      }\\n-    },\\n-    {\\n-      \\\"@type\\\": \\\"entity\\\",\\n-      \\\"label\\\": \\\"training_precision_score\\\",\\n-      \\\"value\\\": {\\n-        \\\"@type\\\": \\\"xsd:decimal\\\",\\n-        \\\"@value\\\": 0.9674588284344383\\n-      }\\n-    },\\n-    {\\n-      \\\"@type\\\": \\\"entity\\\",\\n-      \\\"label\\\": \\\"training_recall_score\\\",\\n-      \\\"value\\\": {\\n-        \\\"@type\\\": \\\"xsd:decimal\\\",\\n-        \\\"@value\\\": 0.9666666666666667\\n-      }\\n-    },\\n-    {\\n-      \\\"@type\\\": \\\"entity\\\",\\n-      \\\"label\\\": \\\"training_roc_auc\\\",\\n-      \\\"value\\\": {\\n-        \\\"@type\\\": \\\"xsd:decimal\\\",\\n-        \\\"@value\\\": 0.9987492182614135\\n-      }\\n-    },\\n-    {\\n-      \\\"@type\\\": \\\"entity\\\",\\n-      \\\"label\\\": \\\"training_score\\\",\\n-      \\\"value\\\": {\\n-        \\\"@type\\\": \\\"xsd:decimal\\\",\\n-        \\\"@value\\\": 0.9666666666666667\\n-      }\\n-    }\\n-  ],\\n-  \\\"gen\\\": [\\n-    {\\n-      \\\"@type\\\": \\\"entity\\\",\\n-      \\\"label\\\": \\\"RandomForest_Iris_v20250423_230422/RandomForest_Iris_v20250423_230422.pkl\\\",\\n-      \\\"prov:location\\\": \\\"\\\"\\n-    },\\n-    {\\n-      \\\"@type\\\": \\\"entity\\\",\\n-      \\\"label\\\": \\\"commit_diff.json\\\",\\n-      \\\"prov:location\\\": \\\"{\\\\n  \\\\\\\"previous_commit\\\\\\\": \\\\\\\"a07434\\\\u2026\\\"\\n-    },\\n-    {\\n-      \\\"@type\\\": \\\"entity\\\",\\n-      \\\"label\\\": \\\"confusion_matrix.png\\\",\\n-      \\\"prov:location\\\": \\\"\\\"\\n-    },\\n-    {\\n-      \\\"@type\\\": \\\"entity\\\",\\n-      \\\"label\\\": \\\"estimator.html\\\",\\n-      \\\"prov:location\\\": \\\"\\\"\\n-    },\\n-    {\\n-      \\\"@type\\\": \\\"entity\\\",\\n-      \\\"label\\\": \\\"feature_importances.png\\\",\\n-      \\\"prov:location\\\": \\\"\\\"\\n-    },\\n-    {\\n-      \\\"@type\\\": \\\"entity\\\",\\n-      \\\"label\\\": \\\"label_mapping.json\\\",\\n-      \\\"prov:location\\\": \\\"{\\\\n  \\\\\\\"0\\\\\\\": \\\\\\\"Iris-setosa\\\\\\\",\\\\n  \\\\\\\"1\\\\\\\":\\\\u2026\\\"\\n-    },\\n-    {\\n-      \\\"@type\\\": \\\"entity\\\",\\n-      \\\"label\\\": \\\"metric_info.json\\\",\\n-      \\\"prov:location\\\": \\\"{\\\\n  \\\\\\\"accuracy_score_X_test\\\\\\\": \\\\\\\"\\\\u2026\\\"\\n-    },\\n-    {\\n-      \\\"@type\\\": \\\"entity\\\",\\n-      \\\"label\\\": \\\"model/MLmodel\\\",\\n-      \\\"prov:location\\\": \\\"\\\"\\n-    },\\n-    {\\n-      \\\"@type\\\": \\\"entity\\\",\\n-      \\\"label\\\": \\\"model/conda.yaml\\\",\\n-      \\\"prov:location\\\": \\\"\\\"\\n-    },\\n-    {\\n-      \\\"@type\\\": \\\"entity\\\",\\n-      \\\"label\\\": \\\"model/input_example.json\\\",\\n-      \\\"prov:location\\\": \\\"{\\\\\\\"columns\\\\\\\": [\\\\\\\"sepallengthcm\\\\\\\", \\\\u2026\\\"\\n-    },\\n-    {\\n-      \\\"@type\\\": \\\"entity\\\",\\n-      \\\"label\\\": \\\"model/model.pkl\\\",\\n-      \\\"prov:location\\\": \\\"\\\"\\n-    },\\n-    {\\n-      \\\"@type\\\": \\\"entity\\\",\\n-      \\\"label\\\": \\\"model/python_env.yaml\\\",\\n-      \\\"prov:location\\\": \\\"\\\"\\n-    },\\n-    {\\n-      \\\"@type\\\": \\\"entity\\\",\\n-      \\\"label\\\": \\\"model/requirements.txt\\\",\\n-      \\\"prov:location\\\": \\\"mlflow==2.21.2\\\\nbackports-funct\\\\u2026\\\"\\n-    },\\n-    {\\n-      \\\"@type\\\": \\\"entity\\\",\\n-      \\\"label\\\": \\\"model/serving_input_example.json\\\",\\n-      \\\"prov:location\\\": \\\"{\\\\n  \\\\\\\"dataframe_split\\\\\\\": {\\\\n    \\\\\\\"\\\\u2026\\\"\\n-    },\\n-    {\\n-      \\\"@type\\\": \\\"entity\\\",\\n-      \\\"label\\\": \\\"pr_curve_cls_0.png\\\",\\n-      \\\"prov:location\\\": \\\"\\\"\\n-    },\\n-    {\\n-      \\\"@type\\\": \\\"entity\\\",\\n-      \\\"label\\\": \\\"pr_curve_cls_1.png\\\",\\n-      \\\"prov:location\\\": \\\"\\\"\\n-    },\\n-    {\\n-      \\\"@type\\\": \\\"entity\\\",\\n-      \\\"label\\\": \\\"pr_curve_cls_2.png\\\",\\n-      \\\"prov:location\\\": \\\"\\\"\\n-    },\\n-    {\\n-      \\\"@type\\\": \\\"entity\\\",\\n-      \\\"label\\\": \\\"public_datasetRepository_metadata.json\\\",\\n-      \\\"prov:location\\\": \\\"{\\\\n  \\\\\\\"zenodo\\\\\\\": {\\\\n    \\\\\\\"title\\\\\\\": \\\\\\\"\\\\u2026\\\"\\n-    },\\n-    {\\n-      \\\"@type\\\": \\\"entity\\\",\\n-      \\\"label\\\": \\\"roc_curve_cls_0.png\\\",\\n-      \\\"prov:location\\\": \\\"\\\"\\n-    },\\n-    {\\n-      \\\"@type\\\": \\\"entity\\\",\\n-      \\\"label\\\": \\\"roc_curve_cls_1.png\\\",\\n-      \\\"prov:location\\\": \\\"\\\"\\n-    },\\n-    {\\n-      \\\"@type\\\": \\\"entity\\\",\\n-      \\\"label\\\": \\\"roc_curve_cls_2.png\\\",\\n-      \\\"prov:location\\\": \\\"\\\"\\n-    },\\n-    {\\n-      \\\"@type\\\": \\\"entity\\\",\\n-      \\\"label\\\": \\\"shap_summary.png\\\",\\n-      \\\"prov:location\\\": \\\"\\\"\\n-    },\\n-    {\\n-      \\\"@type\\\": \\\"entity\\\",\\n-      \\\"label\\\": \\\"training_confusion_matrix.png\\\",\\n-      \\\"prov:location\\\": \\\"\\\"\\n-    }\\n-  ],\\n-  \\\"used\\\": {\\n-    \\\"@type\\\": \\\"entity\\\",\\n-    \\\"label\\\": \\\"Iris\\\",\\n-    \\\"version\\\": \\\"1.0.0\\\"\\n-  }\\n-}\\n\\\\ No newline at end of file\\ndiff --git a/notebooks/RQ_notebooks/MODEL_PROVENANCE/RandomForest_Iris_v20250423_230422.ttl b/notebooks/RQ_notebooks/MODEL_PROVENANCE/RandomForest_Iris_v20250423_230422.ttl\\ndeleted file mode 100644\\nindex 2f002b3..0000000\\n--- a/notebooks/RQ_notebooks/MODEL_PROVENANCE/RandomForest_Iris_v20250423_230422.ttl\\n+++ /dev/null\\n@@ -1,285 +0,0 @@\\n-@prefix prov: <http://www.w3.org/ns/prov#> .\\n-@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .\\n-\\n-<urn:run:361daa12f99f4129a06cd20b78dd6fa7> a prov:Activity ;\\n-    prov:generated [ a prov:Entity ;\\n-            prov:label \\\"model/model.pkl\\\" ;\\n-            prov:location \\\"\\\" ],\\n-        [ a prov:Entity ;\\n-            prov:label \\\"model/python_env.yaml\\\" ;\\n-            prov:location \\\"\\\" ],\\n-        [ a prov:Entity ;\\n-            prov:label \\\"metric_info.json\\\" ;\\n-            prov:location \\\"\\\"\\\"{\\n-  \\\"accuracy_score_X_test\\\": \\\"\\u2026\\\"\\\"\\\" ],\\n-        [ a prov:Entity ;\\n-            prov:label \\\"model/requirements.txt\\\" ;\\n-            prov:location \\\"\\\"\\\"mlflow==2.21.2\\n-backports-funct\\u2026\\\"\\\"\\\" ],\\n-        [ a prov:Entity ;\\n-            prov:label \\\"commit_diff.json\\\" ;\\n-            prov:location \\\"\\\"\\\"{\\n-  \\\"previous_commit\\\": \\\"a07434\\u2026\\\"\\\"\\\" ],\\n-        [ a prov:Entity ;\\n-            prov:label \\\"label_mapping.json\\\" ;\\n-            prov:location \\\"\\\"\\\"{\\n-  \\\"0\\\": \\\"Iris-setosa\\\",\\n-  \\\"1\\\":\\u2026\\\"\\\"\\\" ],\\n-        [ a prov:Entity ;\\n-            prov:label \\\"roc_curve_cls_0.png\\\" ;\\n-            prov:location \\\"\\\" ],\\n-        [ a prov:Entity ;\\n-            prov:label \\\"model/conda.yaml\\\" ;\\n-            prov:location \\\"\\\" ],\\n-        [ a prov:Entity ;\\n-            prov:label \\\"pr_curve_cls_1.png\\\" ;\\n-            prov:location \\\"\\\" ],\\n-        [ a prov:Entity ;\\n-            prov:label \\\"public_datasetRepository_metadata.json\\\" ;\\n-            prov:location \\\"\\\"\\\"{\\n-  \\\"zenodo\\\": {\\n-    \\\"title\\\": \\\"\\u2026\\\"\\\"\\\" ],\\n-        [ a prov:Entity ;\\n-            prov:label \\\"training_confusion_matrix.png\\\" ;\\n-            prov:location \\\"\\\" ],\\n-        [ a prov:Entity ;\\n-            prov:label \\\"roc_curve_cls_1.png\\\" ;\\n-            prov:location \\\"\\\" ],\\n-        [ a prov:Entity ;\\n-            prov:label \\\"model/input_example.json\\\" ;\\n-            prov:location \\\"{\\\\\\\"columns\\\\\\\": [\\\\\\\"sepallengthcm\\\\\\\", \\u2026\\\" ],\\n-        [ a prov:Entity ;\\n-            prov:label \\\"RandomForest_Iris_v20250423_230422/RandomForest_Iris_v20250423_230422.pkl\\\" ;\\n-            prov:location \\\"\\\" ],\\n-        [ a prov:Entity ;\\n-            prov:label \\\"roc_curve_cls_2.png\\\" ;\\n-            prov:location \\\"\\\" ],\\n-        [ a prov:Entity ;\\n-            prov:label \\\"estimator.html\\\" ;\\n-            prov:location \\\"\\\" ],\\n-        [ a prov:Entity ;\\n-            prov:label \\\"model/serving_input_example.json\\\" ;\\n-            prov:location \\\"\\\"\\\"{\\n-  \\\"dataframe_split\\\": {\\n-    \\\"\\u2026\\\"\\\"\\\" ],\\n-        [ a prov:Entity ;\\n-            prov:label \\\"pr_curve_cls_2.png\\\" ;\\n-            prov:location \\\"\\\" ],\\n-        [ a prov:Entity ;\\n-            prov:label \\\"feature_importances.png\\\" ;\\n-            prov:location \\\"\\\" ],\\n-        [ a prov:Entity ;\\n-            prov:label \\\"shap_summary.png\\\" ;\\n-            prov:location \\\"\\\" ],\\n-        [ a prov:Entity ;\\n-            prov:label \\\"pr_curve_cls_0.png\\\" ;\\n-            prov:location \\\"\\\" ],\\n-        [ a prov:Entity ;\\n-            prov:label \\\"model/MLmodel\\\" ;\\n-            prov:location \\\"\\\" ],\\n-        [ a prov:Entity ;\\n-            prov:label \\\"confusion_matrix.png\\\" ;\\n-            prov:location \\\"\\\" ] ;\\n-    prov:hadParameter [ a prov:Entity ;\\n-            prov:label \\\"database.id\\\" ;\\n-            prov:value \\\"c3a42d17-42b7-43c9-a504-2363fb4c9c8d\\\" ],\\n-        [ a prov:Entity ;\\n-            prov:label \\\"pandas_version\\\" ;\\n-            prov:value \\\"2.2.3\\\" ],\\n-        [ a prov:Entity ;\\n-            prov:label \\\"dataset.title\\\" ;\\n-            prov:value \\\"Scikit-Learn Iris\\\" ],\\n-        [ a prov:Entity ;\\n-            prov:label \\\"python_version\\\" ;\\n-            prov:value \\\"3.11.5\\\" ],\\n-        [ a prov:Entity ;\\n-            prov:label \\\"n_test_samples\\\" ;\\n-            prov:value \\\"30\\\" ],\\n-        [ a prov:Entity ;\\n-            prov:label \\\"dataset.published\\\" ;\\n-            prov:value \\\"2018-8-27\\\" ],\\n-        [ a prov:Entity ;\\n-            prov:label \\\"matplotlib_version\\\" ;\\n-            prov:value \\\"3.7.2\\\" ],\\n-        [ a prov:Entity ;\\n-            prov:label \\\"sklearn_version\\\" ;\\n-            prov:value \\\"1.3.0\\\" ],\\n-        [ a prov:Entity ;\\n-            prov:label \\\"verbose\\\" ;\\n-            prov:value \\\"1\\\" ],\\n-        [ a prov:Entity ;\\n-            prov:label \\\"bootstrap\\\" ;\\n-            prov:value \\\"True\\\" ],\\n-        [ a prov:Entity ;\\n-            prov:label \\\"oob_score\\\" ;\\n-            prov:value \\\"False\\\" ],\\n-        [ a prov:Entity ;\\n-            prov:label \\\"min_impurity_decrease\\\" ;\\n-            prov:value \\\"0.0\\\" ],\\n-        [ a prov:Entity ;\\n-            prov:label \\\"n_features_final\\\" ;\\n-            prov:value \\\"4\\\" ],\\n-        [ a prov:Entity ;\\n-            prov:label \\\"max_depth\\\" ;\\n-            prov:value \\\"12\\\" ],\\n-        [ a prov:Entity ;\\n-            prov:label \\\"n_records\\\" ;\\n-            prov:value \\\"150\\\" ],\\n-        [ a prov:Entity ;\\n-            prov:label \\\"dataset.authors\\\" ;\\n-            prov:value \\\"[\\\\\\\"Marshall Michael\\\\\\\"]\\\" ],\\n-        [ a prov:Entity ;\\n-            prov:label \\\"dropped_columns\\\" ;\\n-            prov:value \\\"[]\\\" ],\\n-        [ a prov:Entity ;\\n-            prov:label \\\"n_features\\\" ;\\n-            prov:value \\\"4\\\" ],\\n-        [ a prov:Entity ;\\n-            prov:label \\\"max_features\\\" ;\\n-            prov:value \\\"sqrt\\\" ],\\n-        [ a prov:Entity ;\\n-            prov:label \\\"n_estimators\\\" ;\\n-            prov:value \\\"200\\\" ],\\n-        [ a prov:Entity ;\\n-            prov:label \\\"shap_version\\\" ;\\n-            prov:value \\\"0.47.1\\\" ],\\n-        [ a prov:Entity ;\\n-            prov:label \\\"seaborn_version\\\" ;\\n-            prov:value \\\"0.12.2\\\" ],\\n-        [ a prov:Entity ;\\n-            prov:label \\\"dataset.doi\\\" ;\\n-            prov:value \\\"10.5281/ZENODO.1404173\\\" ],\\n-        [ a prov:Entity ;\\n-            prov:label \\\"n_jobs\\\" ;\\n-            prov:value \\\"-1\\\" ],\\n-        [ a prov:Entity ;\\n-            prov:label \\\"n_train_samples\\\" ;\\n-            prov:value \\\"120\\\" ],\\n-        [ a prov:Entity ;\\n-            prov:label \\\"dataset.publisher\\\" ;\\n-            prov:value \\\"Zenodo\\\" ],\\n-        [ a prov:Entity ;\\n-            prov:label \\\"os_platform\\\" ;\\n-            prov:value \\\"Windows 10\\\" ],\\n-        [ a prov:Entity ;\\n-            prov:label \\\"min_samples_split\\\" ;\\n-            prov:value \\\"5\\\" ],\\n-        [ a prov:Entity ;\\n-            prov:label \\\"max_leaf_nodes\\\" ;\\n-            prov:value \\\"None\\\" ],\\n-        [ a prov:Entity ;\\n-            prov:label \\\"columns_raw\\\" ;\\n-            prov:value \\\"['id', 'sepallengthcm', 'sepalwidthcm', 'petallengthcm', 'petalwidthcm', 'species']\\\" ],\\n-        [ a prov:Entity ;\\n-            prov:label \\\"min_samples_leaf\\\" ;\\n-            prov:value \\\"2\\\" ],\\n-        [ a prov:Entity ;\\n-            prov:label \\\"feature_names\\\" ;\\n-            prov:value \\\"['sepallengthcm', 'sepalwidthcm', 'petallengthcm', 'petalwidthcm']\\\" ],\\n-        [ a prov:Entity ;\\n-            prov:label \\\"criterion\\\" ;\\n-            prov:value \\\"entropy\\\" ],\\n-        [ a prov:Entity ;\\n-            prov:label \\\"database.owner\\\" ;\\n-            prov:value \\\"reema\\\" ],\\n-        [ a prov:Entity ;\\n-            prov:label \\\"database.description\\\" ;\\n-            prov:value \\\"None\\\" ],\\n-        [ a prov:Entity ;\\n-            prov:label \\\"random_state\\\" ;\\n-            prov:value \\\"42\\\" ],\\n-        [ a prov:Entity ;\\n-            prov:label \\\"warm_start\\\" ;\\n-            prov:value \\\"False\\\" ],\\n-        [ a prov:Entity ;\\n-            prov:label \\\"max_samples\\\" ;\\n-            prov:value \\\"None\\\" ],\\n-        [ a prov:Entity ;\\n-            prov:label \\\"test_size\\\" ;\\n-            prov:value \\\"0.2\\\" ],\\n-        [ a prov:Entity ;\\n-            prov:label \\\"numpy_version\\\" ;\\n-            prov:value \\\"1.24.4\\\" ],\\n-        [ a prov:Entity ;\\n-            prov:label \\\"ccp_alpha\\\" ;\\n-            prov:value \\\"0.0\\\" ],\\n-        [ a prov:Entity ;\\n-            prov:label \\\"retrieval_time\\\" ;\\n-            prov:value \\\"2025-04-23T21:04:22.410093\\\" ],\\n-        [ a prov:Entity ;\\n-            prov:label \\\"database.name\\\" ;\\n-            prov:value \\\"Iris\\\" ],\\n-        [ a prov:Entity ;\\n-            prov:label \\\"min_weight_fraction_leaf\\\" ;\\n-            prov:value \\\"0.0\\\" ],\\n-        [ a prov:Entity ;\\n-            prov:label \\\"class_weight\\\" ;\\n-            prov:value \\\"None\\\" ] ;\\n-    prov:hadQuality [ a prov:Entity ;\\n-            prov:label \\\"training_f1_score\\\" ;\\n-            prov:value 0.9666666666666667 ],\\n-        [ a prov:Entity ;\\n-            prov:label \\\"training_recall_score\\\" ;\\n-            prov:value 0.9666666666666667 ],\\n-        [ a prov:Entity ;\\n-            prov:label \\\"dbrepo.row_count_end\\\" ;\\n-            prov:value 150.0 ],\\n-        [ a prov:Entity ;\\n-            prov:label \\\"f1_macro\\\" ;\\n-            prov:value 1.0 ],\\n-        [ a prov:Entity ;\\n-            prov:label \\\"accuracy\\\" ;\\n-            prov:value 1.0 ],\\n-        [ a prov:Entity ;\\n-            prov:label \\\"accuracy_score_X_test\\\" ;\\n-            prov:value 1.0 ],\\n-        [ a prov:Entity ;\\n-            prov:label \\\"f1_score_X_test\\\" ;\\n-            prov:value 1.0 ],\\n-        [ a prov:Entity ;\\n-            prov:label \\\"training_roc_auc\\\" ;\\n-            prov:value 0.9987492182614135 ],\\n-        [ a prov:Entity ;\\n-            prov:label \\\"dbrepo.row_count_start\\\" ;\\n-            prov:value 150.0 ],\\n-        [ a prov:Entity ;\\n-            prov:label \\\"training_accuracy_score\\\" ;\\n-            prov:value 0.9666666666666667 ],\\n-        [ a prov:Entity ;\\n-            prov:label \\\"recall_macro\\\" ;\\n-            prov:value 1.0 ],\\n-        [ a prov:Entity ;\\n-            prov:label \\\"roc_auc\\\" ;\\n-            prov:value 1.0 ],\\n-        [ a prov:Entity ;\\n-            prov:label \\\"roc_auc_score_X_test\\\" ;\\n-            prov:value 1.0 ],\\n-        [ a prov:Entity ;\\n-            prov:label \\\"dbrepo.num_inserts\\\" ;\\n-            prov:value 1.0 ],\\n-        [ a prov:Entity ;\\n-            prov:label \\\"dbrepo.num_deletes\\\" ;\\n-            prov:value 0.0 ],\\n-        [ a prov:Entity ;\\n-            prov:label \\\"training_precision_score\\\" ;\\n-            prov:value 0.9674588284344383 ],\\n-        [ a prov:Entity ;\\n-            prov:label \\\"precision_score_X_test\\\" ;\\n-            prov:value 1.0 ],\\n-        [ a prov:Entity ;\\n-            prov:label \\\"recall_score_X_test\\\" ;\\n-            prov:value 1.0 ],\\n-        [ a prov:Entity ;\\n-            prov:label \\\"precision_macro\\\" ;\\n-            prov:value 1.0 ],\\n-        [ a prov:Entity ;\\n-            prov:label \\\"training_log_loss\\\" ;\\n-            prov:value 0.0653522301195834 ],\\n-        [ a prov:Entity ;\\n-            prov:label \\\"training_score\\\" ;\\n-            prov:value 0.9666666666666667 ] ;\\n-    prov:startedAtTime \\\"2025-04-23T21:04:21.262000+00:00\\\"^^xsd:dateTime ;\\n-    prov:used [ a prov:Entity ;\\n-            prov:hadRevision \\\"1.0.0\\\" ;\\n-            prov:label \\\"Iris\\\" ] .\\n-\\ndiff --git a/notebooks/RQ_notebooks/MODEL_PROVENANCE/RandomForest_Iris_v20250425_121328/RandomForest_Iris_v20250425_121328.jsonld b/notebooks/RQ_notebooks/MODEL_PROVENANCE/RandomForest_Iris_v20250425_121328/RandomForest_Iris_v20250425_121328.jsonld\\nnew file mode 100644\\nindex 0000000..c0b6d06\\n--- /dev/null\\n+++ b/notebooks/RQ_notebooks/MODEL_PROVENANCE/RandomForest_Iris_v20250425_121328/RandomForest_Iris_v20250425_121328.jsonld\\n@@ -0,0 +1,289 @@\\n+{\\n+  \\\"@context\\\": {\\n+    \\\"run_id\\\": {\\n+      \\\"@id\\\": \\\"run_id\\\"\\n+    },\\n+    \\\"run_name\\\": {\\n+      \\\"@id\\\": \\\"run_name\\\"\\n+    },\\n+    \\\"experiment_id\\\": {\\n+      \\\"@id\\\": \\\"experiment_id\\\"\\n+    },\\n+    \\\"params\\\": {\\n+      \\\"@id\\\": \\\"params\\\"\\n+    },\\n+    \\\"metrics\\\": {\\n+      \\\"@id\\\": \\\"metrics\\\"\\n+    },\\n+    \\\"artifacts\\\": {\\n+      \\\"@id\\\": \\\"artifacts\\\"\\n+    },\\n+    \\\"tags\\\": {\\n+      \\\"@id\\\": \\\"tags\\\"\\n+    },\\n+    \\\"prov\\\": \\\"http://www.w3.org/ns/prov#\\\",\\n+    \\\"xsd\\\": \\\"http://www.w3.org/2001/XMLSchema#\\\",\\n+    \\\"start_time\\\": {\\n+      \\\"@id\\\": \\\"prov:startedAtTime\\\",\\n+      \\\"@type\\\": \\\"xsd:dateTime\\\"\\n+    },\\n+    \\\"end_time\\\": {\\n+      \\\"@id\\\": \\\"prov:endedAtTime\\\",\\n+      \\\"@type\\\": \\\"xsd:dateTime\\\"\\n+    },\\n+    \\\"used\\\": {\\n+      \\\"@id\\\": \\\"prov:used\\\",\\n+      \\\"@type\\\": \\\"@id\\\"\\n+    },\\n+    \\\"generated\\\": {\\n+      \\\"@id\\\": \\\"prov:generated\\\",\\n+      \\\"@type\\\": \\\"@id\\\"\\n+    },\\n+    \\\"@id\\\": \\\"@id\\\",\\n+    \\\"@type\\\": \\\"@type\\\"\\n+  },\\n+  \\\"run_id\\\": \\\"28f01e38b7f04d2f948fe21f57f41d0c\\\",\\n+  \\\"run_name\\\": \\\"amazing-sponge-952\\\",\\n+  \\\"experiment_id\\\": \\\"615223710259862608\\\",\\n+  \\\"params\\\": {\\n+    \\\"bootstrap\\\": \\\"True\\\",\\n+    \\\"ccp_alpha\\\": \\\"0.0\\\",\\n+    \\\"class_weight\\\": \\\"None\\\",\\n+    \\\"columns_raw\\\": \\\"['id', 'sepallengthcm', 'sepalwidthcm', 'petallengthcm', 'petalwidthcm', 'species']\\\",\\n+    \\\"criterion\\\": \\\"entropy\\\",\\n+    \\\"database.description\\\": \\\"None\\\",\\n+    \\\"database.id\\\": \\\"c3a42d17-42b7-43c9-a504-2363fb4c9c8d\\\",\\n+    \\\"database.name\\\": \\\"Iris\\\",\\n+    \\\"database.owner\\\": \\\"reema\\\",\\n+    \\\"dataset.authors\\\": \\\"[\\\\\\\"Marshall Michael\\\\\\\"]\\\",\\n+    \\\"dataset.doi\\\": \\\"10.5281/ZENODO.1404173\\\",\\n+    \\\"dataset.published\\\": \\\"2018-8-27\\\",\\n+    \\\"dataset.publisher\\\": \\\"Zenodo\\\",\\n+    \\\"dataset.title\\\": \\\"Scikit-Learn Iris\\\",\\n+    \\\"dropped_columns\\\": \\\"['id']\\\",\\n+    \\\"feature_names\\\": \\\"['sepallengthcm', 'sepalwidthcm', 'petallengthcm', 'petalwidthcm']\\\",\\n+    \\\"matplotlib_version\\\": \\\"3.7.2\\\",\\n+    \\\"max_depth\\\": \\\"12\\\",\\n+    \\\"max_features\\\": \\\"sqrt\\\",\\n+    \\\"max_leaf_nodes\\\": \\\"None\\\",\\n+    \\\"max_samples\\\": \\\"None\\\",\\n+    \\\"min_impurity_decrease\\\": \\\"0.0\\\",\\n+    \\\"min_samples_leaf\\\": \\\"2\\\",\\n+    \\\"min_samples_split\\\": \\\"5\\\",\\n+    \\\"min_weight_fraction_leaf\\\": \\\"0.0\\\",\\n+    \\\"numpy_version\\\": \\\"1.24.4\\\",\\n+    \\\"n_estimators\\\": \\\"200\\\",\\n+    \\\"n_features\\\": \\\"4\\\",\\n+    \\\"n_features_final\\\": \\\"4\\\",\\n+    \\\"n_jobs\\\": \\\"-1\\\",\\n+    \\\"n_records\\\": \\\"150\\\",\\n+    \\\"n_test_samples\\\": \\\"30\\\",\\n+    \\\"n_train_samples\\\": \\\"120\\\",\\n+    \\\"oob_score\\\": \\\"False\\\",\\n+    \\\"os_platform\\\": \\\"Windows 10\\\",\\n+    \\\"pandas_version\\\": \\\"2.2.3\\\",\\n+    \\\"python_version\\\": \\\"3.11.5\\\",\\n+    \\\"random_state\\\": \\\"42\\\",\\n+    \\\"retrieval_time\\\": \\\"2025-04-25T10:13:28.463814\\\",\\n+    \\\"seaborn_version\\\": \\\"0.12.2\\\",\\n+    \\\"shap_version\\\": \\\"0.47.1\\\",\\n+    \\\"sklearn_version\\\": \\\"1.3.0\\\",\\n+    \\\"test_size\\\": \\\"0.2\\\",\\n+    \\\"verbose\\\": \\\"1\\\",\\n+    \\\"warm_start\\\": \\\"False\\\"\\n+  },\\n+  \\\"metrics\\\": {\\n+    \\\"accuracy\\\": 1.0,\\n+    \\\"accuracy_score_X_test\\\": 1.0,\\n+    \\\"dbrepo.num_deletes\\\": 0.0,\\n+    \\\"dbrepo.num_inserts\\\": 1.0,\\n+    \\\"dbrepo.row_count_end\\\": 150.0,\\n+    \\\"dbrepo.row_count_start\\\": 150.0,\\n+    \\\"f1_macro\\\": 1.0,\\n+    \\\"f1_score_X_test\\\": 1.0,\\n+    \\\"precision_macro\\\": 1.0,\\n+    \\\"precision_score_X_test\\\": 1.0,\\n+    \\\"recall_macro\\\": 1.0,\\n+    \\\"recall_score_X_test\\\": 1.0,\\n+    \\\"roc_auc\\\": 1.0,\\n+    \\\"roc_auc_score_X_test\\\": 1.0,\\n+    \\\"training_accuracy_score\\\": 0.9666666666666667,\\n+    \\\"training_f1_score\\\": 0.9666666666666667,\\n+    \\\"training_log_loss\\\": 0.0653522301195834,\\n+    \\\"training_precision_score\\\": 0.9674588284344383,\\n+    \\\"training_recall_score\\\": 0.9666666666666667,\\n+    \\\"training_roc_auc\\\": 0.9987492182614135,\\n+    \\\"training_score\\\": 0.9666666666666667\\n+  },\\n+  \\\"artifacts\\\": [\\n+    {\\n+      \\\"path\\\": \\\"RandomForest_Iris_v20250425_121328/RandomForest_Iris_v20250425_121328.pkl\\\",\\n+      \\\"type\\\": \\\"other\\\",\\n+      \\\"uri\\\": \\\"file:///C:/Users/reema/REPO/notebooks/RQ_notebooks/mlrunlogs/mlflow.db/615223710259862608/28f01e38b7f04d2f948fe21f57f41d0c/artifacts/RandomForest_Iris_v20250425_121328/RandomForest_Iris_v20250425_121328.pkl\\\"\\n+    },\\n+    {\\n+      \\\"path\\\": \\\"commit_diff.json\\\",\\n+      \\\"type\\\": \\\"text\\\",\\n+      \\\"content\\\": \\\"{\\\\n  \\\\\\\"previous_commit\\\\\\\": \\\\\\\"8c5c1cb1d6a5e4a1d63b6ffdef1f78328209301a\\\\\\\",\\\\n  \\\\\\\"previous_commit_url\\\\\\\": \\\\\\\"https://github.com/reema-dass26/REPO/commit/8c5c1cb1d6a5e4a1d63b6ffdef1f78328209301a\\\\\\\",\\\\n  \\\\\\\"current_commit_url\\\\\\\": \\\\\\\"https://github.com/reema-dass26/REPO/commit/b88aa7eddfb150c58ed3dee766f1c62d3107975a\\\\\\\",\\\\n  \\\\\\\"current_commit\\\\\\\": \\\\\\\"b88aa7eddfb150c58ed3dee766f1c62d3107975a\\\\\\\",\\\\n  \\\\\\\"diff\\\\\\\": \\\\\\\"diff --git a/notebooks/RQ_notebooks/MODEL_PROVENANCE/RandomForest_Iris_v20250423_230422.jsonld b/notebooks/RQ_notebooks/MODEL_PROVENANCE/RandomForest_Iris_v20250423_230422.jsonld\\\\\\\\ndeleted file mode 100644\\\\\\\\nindex 9a18980..0000000\\\\\\\\n--- a/notebooks/RQ_notebooks/MODEL_PROVENANCE/RandomForest_Iris_v20250423_230422.jsonld\\\\\\\\n+++ /dev/null\\\\\\\\n@@ -1,544 +0,0 @@\\\\\\\\n-{\\\\\\\\n-  \\\\\\\\\\\\\\\"@context\\\\\\\\\\\\\\\": {\\\\\\\\n-    \\\\\\\\\\\\\\\"prov\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"http://www.w3.org/ns/prov#\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"xsd\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"http://www.w3.org/2001/XMLSchema#\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"run\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"prov:Activity\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"start\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"prov:startedAtTime\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"end\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"prov:endedAtTime\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"used\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"prov:used\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"gen\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"prov:generated\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"param\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"prov:hadParameter\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"metric\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"prov:hadQuality\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"entity\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"prov:Entity\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"prov:label\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"value\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"prov:value\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"version\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"prov:hadRevision\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"@id\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\"\\\\\\\\n-  },\\\\\\\\n-  \\\\\\\\\\\\\\\"@id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"urn:run:361daa12f99f4129a06cd20b78dd6fa7\\\\\\\\\\\\\\\",\\\\\\\\n-  \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"run\\\\\\\\\\\\\\\",\\\\\\\\n-  \\\\\\\\\\\\\\\"start\\\\\\\\\\\\\\\": {\\\\\\\\n-    \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"xsd:dateTime\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"@value\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"2025-04-23T21:04:21.262000+00:00\\\\\\\\\\\\\\\"\\\\\\\\n-  },\\\\\\\\n-  \\\\\\\\\\\\\\\"param\\\\\\\\\\\\\\\": [\\\\\\\\n-    {\\\\\\\\n-      \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"entity\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"bootstrap\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"value\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"True\\\\\\\\\\\\\\\"\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-      \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"entity\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"ccp_alpha\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"value\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"0.0\\\\\\\\\\\\\\\"\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-      \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"entity\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"class_weight\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"value\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"None\\\\\\\\\\\\\\\"\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-      \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"entity\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"columns_raw\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"value\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"['id', 'sepallengthcm', 'sepalwidthcm', 'petallengthcm', 'petalwidthcm', 'species']\\\\\\\\\\\\\\\"\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-      \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"entity\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"criterion\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"value\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"entropy\\\\\\\\\\\\\\\"\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-      \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"entity\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"database.description\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"value\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"None\\\\\\\\\\\\\\\"\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-      \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"entity\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"database.id\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"value\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"c3a42d17-42b7-43c9-a504-2363fb4c9c8d\\\\\\\\\\\\\\\"\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-      \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"entity\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"database.name\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"value\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Iris\\\\\\\\\\\\\\\"\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-      \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"entity\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"database.owner\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"value\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"reema\\\\\\\\\\\\\\\"\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-      \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"entity\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"dataset.authors\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"value\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Marshall Michael\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"]\\\\\\\\\\\\\\\"\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-      \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"entity\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"dataset.doi\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"value\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"10.5281/ZENODO.1404173\\\\\\\\\\\\\\\"\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-      \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"entity\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"dataset.published\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"value\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"2018-8-27\\\\\\\\\\\\\\\"\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-      \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"entity\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"dataset.publisher\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"value\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Zenodo\\\\\\\\\\\\\\\"\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-      \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"entity\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"dataset.title\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"value\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Scikit-Learn Iris\\\\\\\\\\\\\\\"\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-      \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"entity\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"dropped_columns\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"value\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"[]\\\\\\\\\\\\\\\"\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-      \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"entity\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"feature_names\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"value\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"['sepallengthcm', 'sepalwidthcm', 'petallengthcm', 'petalwidthcm']\\\\\\\\\\\\\\\"\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-      \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"entity\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"matplotlib_version\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"value\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"3.7.2\\\\\\\\\\\\\\\"\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-      \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"entity\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"max_depth\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"value\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"12\\\\\\\\\\\\\\\"\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-      \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"entity\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"max_features\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"value\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"sqrt\\\\\\\\\\\\\\\"\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-      \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"entity\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"max_leaf_nodes\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"value\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"None\\\\\\\\\\\\\\\"\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-      \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"entity\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"max_samples\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"value\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"None\\\\\\\\\\\\\\\"\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-      \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"entity\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"min_impurity_decrease\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"value\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"0.0\\\\\\\\\\\\\\\"\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-      \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"entity\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"min_samples_leaf\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"value\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"2\\\\\\\\\\\\\\\"\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-      \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"entity\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"min_samples_split\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"value\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"5\\\\\\\\\\\\\\\"\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-      \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"entity\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"min_weight_fraction_leaf\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"value\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"0.0\\\\\\\\\\\\\\\"\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-      \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"entity\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"numpy_version\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"value\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"1.24.4\\\\\\\\\\\\\\\"\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-      \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"entity\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"n_estimators\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"value\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"200\\\\\\\\\\\\\\\"\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-      \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"entity\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"n_features\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"value\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"4\\\\\\\\\\\\\\\"\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-      \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"entity\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"n_features_final\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"value\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"4\\\\\\\\\\\\\\\"\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-      \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"entity\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"n_jobs\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"value\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"-1\\\\\\\\\\\\\\\"\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-      \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"entity\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"n_records\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"value\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"150\\\\\\\\\\\\\\\"\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-      \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"entity\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"n_test_samples\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"value\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"30\\\\\\\\\\\\\\\"\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-      \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"entity\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"n_train_samples\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"value\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"120\\\\\\\\\\\\\\\"\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-      \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"entity\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"oob_score\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"value\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"False\\\\\\\\\\\\\\\"\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-      \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"entity\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"os_platform\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"value\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Windows 10\\\\\\\\\\\\\\\"\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-      \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"entity\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"pandas_version\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"value\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"2.2.3\\\\\\\\\\\\\\\"\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-      \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"entity\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"python_version\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"value\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"3.11.5\\\\\\\\\\\\\\\"\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-      \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"entity\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"random_state\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"value\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"42\\\\\\\\\\\\\\\"\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-      \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"entity\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"retrieval_time\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"value\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"2025-04-23T21:04:22.410093\\\\\\\\\\\\\\\"\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-      \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"entity\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"seaborn_version\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"value\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"0.12.2\\\\\\\\\\\\\\\"\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-      \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"entity\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"shap_version\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"value\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"0.47.1\\\\\\\\\\\\\\\"\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-      \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"entity\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"sklearn_version\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"value\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"1.3.0\\\\\\\\\\\\\\\"\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-      \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"entity\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"test_size\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"value\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"0.2\\\\\\\\\\\\\\\"\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-      \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"entity\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"verbose\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"value\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"1\\\\\\\\\\\\\\\"\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-      \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"entity\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"warm_start\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"value\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"False\\\\\\\\\\\\\\\"\\\\\\\\n-    }\\\\\\\\n-  ],\\\\\\\\n-  \\\\\\\\\\\\\\\"metric\\\\\\\\\\\\\\\": [\\\\\\\\n-    {\\\\\\\\n-      \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"entity\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"accuracy\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"value\\\\\\\\\\\\\\\": {\\\\\\\\n-        \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"xsd:decimal\\\\\\\\\\\\\\\",\\\\\\\\n-        \\\\\\\\\\\\\\\"@value\\\\\\\\\\\\\\\": 1.0\\\\\\\\n-      }\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-      \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"entity\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"accuracy_score_X_test\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"value\\\\\\\\\\\\\\\": {\\\\\\\\n-        \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"xsd:decimal\\\\\\\\\\\\\\\",\\\\\\\\n-        \\\\\\\\\\\\\\\"@value\\\\\\\\\\\\\\\": 1.0\\\\\\\\n-      }\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-      \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"entity\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"dbrepo.num_deletes\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"value\\\\\\\\\\\\\\\": {\\\\\\\\n-        \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"xsd:decimal\\\\\\\\\\\\\\\",\\\\\\\\n-        \\\\\\\\\\\\\\\"@value\\\\\\\\\\\\\\\": 0.0\\\\\\\\n-      }\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-      \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"entity\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"dbrepo.num_inserts\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"value\\\\\\\\\\\\\\\": {\\\\\\\\n-        \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"xsd:decimal\\\\\\\\\\\\\\\",\\\\\\\\n-        \\\\\\\\\\\\\\\"@value\\\\\\\\\\\\\\\": 1.0\\\\\\\\n-      }\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-      \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"entity\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"dbrepo.row_count_end\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"value\\\\\\\\\\\\\\\": {\\\\\\\\n-        \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"xsd:decimal\\\\\\\\\\\\\\\",\\\\\\\\n-        \\\\\\\\\\\\\\\"@value\\\\\\\\\\\\\\\": 150.0\\\\\\\\n-      }\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-      \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"entity\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"dbrepo.row_count_start\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"value\\\\\\\\\\\\\\\": {\\\\\\\\n-        \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"xsd:decimal\\\\\\\\\\\\\\\",\\\\\\\\n-        \\\\\\\\\\\\\\\"@value\\\\\\\\\\\\\\\": 150.0\\\\\\\\n-      }\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-      \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"entity\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"f1_macro\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"value\\\\\\\\\\\\\\\": {\\\\\\\\n-        \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"xsd:decimal\\\\\\\\\\\\\\\",\\\\\\\\n-        \\\\\\\\\\\\\\\"@value\\\\\\\\\\\\\\\": 1.0\\\\\\\\n-      }\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-      \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"entity\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"f1_score_X_test\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"value\\\\\\\\\\\\\\\": {\\\\\\\\n-        \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"xsd:decimal\\\\\\\\\\\\\\\",\\\\\\\\n-        \\\\\\\\\\\\\\\"@value\\\\\\\\\\\\\\\": 1.0\\\\\\\\n-      }\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-      \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"entity\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"precision_macro\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"value\\\\\\\\\\\\\\\": {\\\\\\\\n-        \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"xsd:decimal\\\\\\\\\\\\\\\",\\\\\\\\n-        \\\\\\\\\\\\\\\"@value\\\\\\\\\\\\\\\": 1.0\\\\\\\\n-      }\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-      \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"entity\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"precision_score_X_test\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"value\\\\\\\\\\\\\\\": {\\\\\\\\n-        \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"xsd:decimal\\\\\\\\\\\\\\\",\\\\\\\\n-        \\\\\\\\\\\\\\\"@value\\\\\\\\\\\\\\\": 1.0\\\\\\\\n-      }\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-      \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"entity\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"recall_macro\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"value\\\\\\\\\\\\\\\": {\\\\\\\\n-        \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"xsd:decimal\\\\\\\\\\\\\\\",\\\\\\\\n-        \\\\\\\\\\\\\\\"@value\\\\\\\\\\\\\\\": 1.0\\\\\\\\n-      }\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-      \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"entity\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"recall_score_X_test\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"value\\\\\\\\\\\\\\\": {\\\\\\\\n-        \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"xsd:decimal\\\\\\\\\\\\\\\",\\\\\\\\n-        \\\\\\\\\\\\\\\"@value\\\\\\\\\\\\\\\": 1.0\\\\\\\\n-      }\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-      \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"entity\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"roc_auc\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"value\\\\\\\\\\\\\\\": {\\\\\\\\n-        \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"xsd:decimal\\\\\\\\\\\\\\\",\\\\\\\\n-        \\\\\\\\\\\\\\\"@value\\\\\\\\\\\\\\\": 1.0\\\\\\\\n-      }\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-      \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"entity\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"roc_auc_score_X_test\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"value\\\\\\\\\\\\\\\": {\\\\\\\\n-        \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"xsd:decimal\\\\\\\\\\\\\\\",\\\\\\\\n-        \\\\\\\\\\\\\\\"@value\\\\\\\\\\\\\\\": 1.0\\\\\\\\n-      }\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-      \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"entity\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"training_accuracy_score\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"value\\\\\\\\\\\\\\\": {\\\\\\\\n-        \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"xsd:decimal\\\\\\\\\\\\\\\",\\\\\\\\n-        \\\\\\\\\\\\\\\"@value\\\\\\\\\\\\\\\": 0.9666666666666667\\\\\\\\n-      }\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-      \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"entity\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"training_f1_score\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"value\\\\\\\\\\\\\\\": {\\\\\\\\n-        \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"xsd:decimal\\\\\\\\\\\\\\\",\\\\\\\\n-        \\\\\\\\\\\\\\\"@value\\\\\\\\\\\\\\\": 0.9666666666666667\\\\\\\\n-      }\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-      \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"entity\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"training_log_loss\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"value\\\\\\\\\\\\\\\": {\\\\\\\\n-        \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"xsd:decimal\\\\\\\\\\\\\\\",\\\\\\\\n-        \\\\\\\\\\\\\\\"@value\\\\\\\\\\\\\\\": 0.0653522301195834\\\\\\\\n-      }\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-      \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"entity\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"training_precision_score\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"value\\\\\\\\\\\\\\\": {\\\\\\\\n-        \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"xsd:decimal\\\\\\\\\\\\\\\",\\\\\\\\n-        \\\\\\\\\\\\\\\"@value\\\\\\\\\\\\\\\": 0.9674588284344383\\\\\\\\n-      }\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-      \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"entity\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"training_recall_score\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"value\\\\\\\\\\\\\\\": {\\\\\\\\n-        \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"xsd:decimal\\\\\\\\\\\\\\\",\\\\\\\\n-        \\\\\\\\\\\\\\\"@value\\\\\\\\\\\\\\\": 0.9666666666666667\\\\\\\\n-      }\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-      \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"entity\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"training_roc_auc\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"value\\\\\\\\\\\\\\\": {\\\\\\\\n-        \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"xsd:decimal\\\\\\\\\\\\\\\",\\\\\\\\n-        \\\\\\\\\\\\\\\"@value\\\\\\\\\\\\\\\": 0.9987492182614135\\\\\\\\n-      }\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-      \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"entity\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"training_score\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"value\\\\\\\\\\\\\\\": {\\\\\\\\n-        \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"xsd:decimal\\\\\\\\\\\\\\\",\\\\\\\\n-        \\\\\\\\\\\\\\\"@value\\\\\\\\\\\\\\\": 0.9666666666666667\\\\\\\\n-      }\\\\\\\\n-    }\\\\\\\\n-  ],\\\\\\\\n-  \\\\\\\\\\\\\\\"gen\\\\\\\\\\\\\\\": [\\\\\\\\n-    {\\\\\\\\n-      \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"entity\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"RandomForest_Iris_v20250423_230422/RandomForest_Iris_v20250423_230422.pkl\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"prov:location\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-      \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"entity\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"commit_diff.json\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"prov:location\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"{\\\\\\\\\\\\\\\\n  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"previous_commit\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"a07434\\\\\\\\\\\\\\\\u2026\\\\\\\\\\\\\\\"\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-      \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"entity\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"confusion_matrix.png\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"prov:location\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-      \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"entity\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"estimator.html\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"prov:location\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-      \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"entity\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"feature_importances.png\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"prov:location\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-      \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"entity\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"label_mapping.json\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"prov:location\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"{\\\\\\\\\\\\\\\\n  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Iris-setosa\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\u2026\\\\\\\\\\\\\\\"\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-      \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"entity\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"metric_info.json\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"prov:location\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"{\\\\\\\\\\\\\\\\n  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"accuracy_score_X_test\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\u2026\\\\\\\\\\\\\\\"\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-      \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"entity\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"model/MLmodel\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"prov:location\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-      \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"entity\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"model/conda.yaml\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"prov:location\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-      \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"entity\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"model/input_example.json\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"prov:location\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"columns\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": [\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sepallengthcm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\u2026\\\\\\\\\\\\\\\"\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-      \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"entity\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"model/model.pkl\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"prov:location\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-      \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"entity\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"model/python_env.yaml\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"prov:location\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-      \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"entity\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"model/requirements.txt\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"prov:location\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"mlflow==2.21.2\\\\\\\\\\\\\\\\nbackports-funct\\\\\\\\\\\\\\\\u2026\\\\\\\\\\\\\\\"\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-      \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"entity\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"model/serving_input_example.json\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"prov:location\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"{\\\\\\\\\\\\\\\\n  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"dataframe_split\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\u2026\\\\\\\\\\\\\\\"\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-      \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"entity\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"pr_curve_cls_0.png\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"prov:location\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-      \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"entity\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"pr_curve_cls_1.png\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"prov:location\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-      \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"entity\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"pr_curve_cls_2.png\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"prov:location\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-      \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"entity\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"public_datasetRepository_metadata.json\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"prov:location\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"{\\\\\\\\\\\\\\\\n  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"zenodo\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"title\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\u2026\\\\\\\\\\\\\\\"\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-      \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"entity\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"roc_curve_cls_0.png\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"prov:location\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-      \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"entity\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"roc_curve_cls_1.png\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"prov:location\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-      \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"entity\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"roc_curve_cls_2.png\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"prov:location\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-      \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"entity\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"shap_summary.png\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"prov:location\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-      \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"entity\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"training_confusion_matrix.png\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"prov:location\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n-    }\\\\\\\\n-  ],\\\\\\\\n-  \\\\\\\\\\\\\\\"used\\\\\\\\\\\\\\\": {\\\\\\\\n-    \\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"entity\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Iris\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"version\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"1.0.0\\\\\\\\\\\\\\\"\\\\\\\\n-  }\\\\\\\\n-}\\\\\\\\n\\\\\\\\\\\\\\\\ No newline at end of file\\\\\\\\ndiff --git a/notebooks/RQ_notebooks/MODEL_PROVENANCE/RandomForest_Iris_v20250423_230422.ttl b/notebooks/RQ_notebooks/MODEL_PROVENANCE/RandomForest_Iris_v20250423_230422.ttl\\\\\\\\ndeleted file mode 100644\\\\\\\\nindex 2f002b3..0000000\\\\\\\\n--- a/notebooks/RQ_notebooks/MODEL_PROVENANCE/RandomForest_Iris_v20250423_230422.ttl\\\\\\\\n+++ /dev/null\\\\\\\\n@@ -1,285 +0,0 @@\\\\\\\\n-@prefix prov: <http://www.w3.org/ns/prov#> .\\\\\\\\n-@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .\\\\\\\\n-\\\\\\\\n-<urn:run:361daa12f99f4129a06cd20b78dd6fa7> a prov:Activity ;\\\\\\\\n-    prov:generated [ a prov:Entity ;\\\\\\\\n-            prov:label \\\\\\\\\\\\\\\"model/model.pkl\\\\\\\\\\\\\\\" ;\\\\\\\\n-            prov:location \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\" ],\\\\\\\\n-        [ a prov:Entity ;\\\\\\\\n-            prov:label \\\\\\\\\\\\\\\"model/python_env.yaml\\\\\\\\\\\\\\\" ;\\\\\\\\n-            prov:location \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\" ],\\\\\\\\n-        [ a prov:Entity ;\\\\\\\\n-            prov:label \\\\\\\\\\\\\\\"metric_info.json\\\\\\\\\\\\\\\" ;\\\\\\\\n-            prov:location \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"{\\\\\\\\n-  \\\\\\\\\\\\\\\"accuracy_score_X_test\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"\\\\\\\\u2026\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\" ],\\\\\\\\n-        [ a prov:Entity ;\\\\\\\\n-            prov:label \\\\\\\\\\\\\\\"model/requirements.txt\\\\\\\\\\\\\\\" ;\\\\\\\\n-            prov:location \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"mlflow==2.21.2\\\\\\\\n-backports-funct\\\\\\\\u2026\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\" ],\\\\\\\\n-        [ a prov:Entity ;\\\\\\\\n-            prov:label \\\\\\\\\\\\\\\"commit_diff.json\\\\\\\\\\\\\\\" ;\\\\\\\\n-            prov:location \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"{\\\\\\\\n-  \\\\\\\\\\\\\\\"previous_commit\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"a07434\\\\\\\\u2026\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\" ],\\\\\\\\n-        [ a prov:Entity ;\\\\\\\\n-            prov:label \\\\\\\\\\\\\\\"label_mapping.json\\\\\\\\\\\\\\\" ;\\\\\\\\n-            prov:location \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"{\\\\\\\\n-  \\\\\\\\\\\\\\\"0\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Iris-setosa\\\\\\\\\\\\\\\",\\\\\\\\n-  \\\\\\\\\\\\\\\"1\\\\\\\\\\\\\\\":\\\\\\\\u2026\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\" ],\\\\\\\\n-        [ a prov:Entity ;\\\\\\\\n-            prov:label \\\\\\\\\\\\\\\"roc_curve_cls_0.png\\\\\\\\\\\\\\\" ;\\\\\\\\n-            prov:location \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\" ],\\\\\\\\n-        [ a prov:Entity ;\\\\\\\\n-            prov:label \\\\\\\\\\\\\\\"model/conda.yaml\\\\\\\\\\\\\\\" ;\\\\\\\\n-            prov:location \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\" ],\\\\\\\\n-        [ a prov:Entity ;\\\\\\\\n-            prov:label \\\\\\\\\\\\\\\"pr_curve_cls_1.png\\\\\\\\\\\\\\\" ;\\\\\\\\n-            prov:location \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\" ],\\\\\\\\n-        [ a prov:Entity ;\\\\\\\\n-            prov:label \\\\\\\\\\\\\\\"public_datasetRepository_metadata.json\\\\\\\\\\\\\\\" ;\\\\\\\\n-            prov:location \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"{\\\\\\\\n-  \\\\\\\\\\\\\\\"zenodo\\\\\\\\\\\\\\\": {\\\\\\\\n-    \\\\\\\\\\\\\\\"title\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"\\\\\\\\u2026\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\" ],\\\\\\\\n-        [ a prov:Entity ;\\\\\\\\n-            prov:label \\\\\\\\\\\\\\\"training_confusion_matrix.png\\\\\\\\\\\\\\\" ;\\\\\\\\n-            prov:location \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\" ],\\\\\\\\n-        [ a prov:Entity ;\\\\\\\\n-            prov:label \\\\\\\\\\\\\\\"roc_curve_cls_1.png\\\\\\\\\\\\\\\" ;\\\\\\\\n-            prov:location \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\" ],\\\\\\\\n-        [ a prov:Entity ;\\\\\\\\n-            prov:label \\\\\\\\\\\\\\\"model/input_example.json\\\\\\\\\\\\\\\" ;\\\\\\\\n-            prov:location \\\\\\\\\\\\\\\"{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"columns\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": [\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sepallengthcm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\u2026\\\\\\\\\\\\\\\" ],\\\\\\\\n-        [ a prov:Entity ;\\\\\\\\n-            prov:label \\\\\\\\\\\\\\\"RandomForest_Iris_v20250423_230422/RandomForest_Iris_v20250423_230422.pkl\\\\\\\\\\\\\\\" ;\\\\\\\\n-            prov:location \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\" ],\\\\\\\\n-        [ a prov:Entity ;\\\\\\\\n-            prov:label \\\\\\\\\\\\\\\"roc_curve_cls_2.png\\\\\\\\\\\\\\\" ;\\\\\\\\n-            prov:location \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\" ],\\\\\\\\n-        [ a prov:Entity ;\\\\\\\\n-            prov:label \\\\\\\\\\\\\\\"estimator.html\\\\\\\\\\\\\\\" ;\\\\\\\\n-            prov:location \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\" ],\\\\\\\\n-        [ a prov:Entity ;\\\\\\\\n-            prov:label \\\\\\\\\\\\\\\"model/serving_input_example.json\\\\\\\\\\\\\\\" ;\\\\\\\\n-            prov:location \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"{\\\\\\\\n-  \\\\\\\\\\\\\\\"dataframe_split\\\\\\\\\\\\\\\": {\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\u2026\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\" ],\\\\\\\\n-        [ a prov:Entity ;\\\\\\\\n-            prov:label \\\\\\\\\\\\\\\"pr_curve_cls_2.png\\\\\\\\\\\\\\\" ;\\\\\\\\n-            prov:location \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\" ],\\\\\\\\n-        [ a prov:Entity ;\\\\\\\\n-            prov:label \\\\\\\\\\\\\\\"feature_importances.png\\\\\\\\\\\\\\\" ;\\\\\\\\n-            prov:location \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\" ],\\\\\\\\n-        [ a prov:Entity ;\\\\\\\\n-            prov:label \\\\\\\\\\\\\\\"shap_summary.png\\\\\\\\\\\\\\\" ;\\\\\\\\n-            prov:location \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\" ],\\\\\\\\n-        [ a prov:Entity ;\\\\\\\\n-            prov:label \\\\\\\\\\\\\\\"pr_curve_cls_0.png\\\\\\\\\\\\\\\" ;\\\\\\\\n-            prov:location \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\" ],\\\\\\\\n-        [ a prov:Entity ;\\\\\\\\n-            prov:label \\\\\\\\\\\\\\\"model/MLmodel\\\\\\\\\\\\\\\" ;\\\\\\\\n-            prov:location \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\" ],\\\\\\\\n-        [ a prov:Entity ;\\\\\\\\n-            prov:label \\\\\\\\\\\\\\\"confusion_matrix.png\\\\\\\\\\\\\\\" ;\\\\\\\\n-            prov:location \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\" ] ;\\\\\\\\n-    prov:hadParameter [ a prov:Entity ;\\\\\\\\n-            prov:label \\\\\\\\\\\\\\\"database.id\\\\\\\\\\\\\\\" ;\\\\\\\\n-            prov:value \\\\\\\\\\\\\\\"c3a42d17-42b7-43c9-a504-2363fb4c9c8d\\\\\\\\\\\\\\\" ],\\\\\\\\n-        [ a prov:Entity ;\\\\\\\\n-            prov:label \\\\\\\\\\\\\\\"pandas_version\\\\\\\\\\\\\\\" ;\\\\\\\\n-            prov:value \\\\\\\\\\\\\\\"2.2.3\\\\\\\\\\\\\\\" ],\\\\\\\\n-        [ a prov:Entity ;\\\\\\\\n-            prov:label \\\\\\\\\\\\\\\"dataset.title\\\\\\\\\\\\\\\" ;\\\\\\\\n-            prov:value \\\\\\\\\\\\\\\"Scikit-Learn Iris\\\\\\\\\\\\\\\" ],\\\\\\\\n-        [ a prov:Entity ;\\\\\\\\n-            prov:label \\\\\\\\\\\\\\\"python_version\\\\\\\\\\\\\\\" ;\\\\\\\\n-            prov:value \\\\\\\\\\\\\\\"3.11.5\\\\\\\\\\\\\\\" ],\\\\\\\\n-        [ a prov:Entity ;\\\\\\\\n-            prov:label \\\\\\\\\\\\\\\"n_test_samples\\\\\\\\\\\\\\\" ;\\\\\\\\n-            prov:value \\\\\\\\\\\\\\\"30\\\\\\\\\\\\\\\" ],\\\\\\\\n-        [ a prov:Entity ;\\\\\\\\n-            prov:label \\\\\\\\\\\\\\\"dataset.published\\\\\\\\\\\\\\\" ;\\\\\\\\n-            prov:value \\\\\\\\\\\\\\\"2018-8-27\\\\\\\\\\\\\\\" ],\\\\\\\\n-        [ a prov:Entity ;\\\\\\\\n-            prov:label \\\\\\\\\\\\\\\"matplotlib_version\\\\\\\\\\\\\\\" ;\\\\\\\\n-            prov:value \\\\\\\\\\\\\\\"3.7.2\\\\\\\\\\\\\\\" ],\\\\\\\\n-        [ a prov:Entity ;\\\\\\\\n-            prov:label \\\\\\\\\\\\\\\"sklearn_version\\\\\\\\\\\\\\\" ;\\\\\\\\n-            prov:value \\\\\\\\\\\\\\\"1.3.0\\\\\\\\\\\\\\\" ],\\\\\\\\n-        [ a prov:Entity ;\\\\\\\\n-            prov:label \\\\\\\\\\\\\\\"verbose\\\\\\\\\\\\\\\" ;\\\\\\\\n-            prov:value \\\\\\\\\\\\\\\"1\\\\\\\\\\\\\\\" ],\\\\\\\\n-        [ a prov:Entity ;\\\\\\\\n-            prov:label \\\\\\\\\\\\\\\"bootstrap\\\\\\\\\\\\\\\" ;\\\\\\\\n-            prov:value \\\\\\\\\\\\\\\"True\\\\\\\\\\\\\\\" ],\\\\\\\\n-        [ a prov:Entity ;\\\\\\\\n-            prov:label \\\\\\\\\\\\\\\"oob_score\\\\\\\\\\\\\\\" ;\\\\\\\\n-            prov:value \\\\\\\\\\\\\\\"False\\\\\\\\\\\\\\\" ],\\\\\\\\n-        [ a prov:Entity ;\\\\\\\\n-            prov:label \\\\\\\\\\\\\\\"min_impurity_decrease\\\\\\\\\\\\\\\" ;\\\\\\\\n-            prov:value \\\\\\\\\\\\\\\"0.0\\\\\\\\\\\\\\\" ],\\\\\\\\n-        [ a prov:Entity ;\\\\\\\\n-            prov:label \\\\\\\\\\\\\\\"n_features_final\\\\\\\\\\\\\\\" ;\\\\\\\\n-            prov:value \\\\\\\\\\\\\\\"4\\\\\\\\\\\\\\\" ],\\\\\\\\n-        [ a prov:Entity ;\\\\\\\\n-            prov:label \\\\\\\\\\\\\\\"max_depth\\\\\\\\\\\\\\\" ;\\\\\\\\n-            prov:value \\\\\\\\\\\\\\\"12\\\\\\\\\\\\\\\" ],\\\\\\\\n-        [ a prov:Entity ;\\\\\\\\n-            prov:label \\\\\\\\\\\\\\\"n_records\\\\\\\\\\\\\\\" ;\\\\\\\\n-            prov:value \\\\\\\\\\\\\\\"150\\\\\\\\\\\\\\\" ],\\\\\\\\n-        [ a prov:Entity ;\\\\\\\\n-            prov:label \\\\\\\\\\\\\\\"dataset.authors\\\\\\\\\\\\\\\" ;\\\\\\\\n-            prov:value \\\\\\\\\\\\\\\"[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Marshall Michael\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"]\\\\\\\\\\\\\\\" ],\\\\\\\\n-        [ a prov:Entity ;\\\\\\\\n-            prov:label \\\\\\\\\\\\\\\"dropped_columns\\\\\\\\\\\\\\\" ;\\\\\\\\n-            prov:value \\\\\\\\\\\\\\\"[]\\\\\\\\\\\\\\\" ],\\\\\\\\n-        [ a prov:Entity ;\\\\\\\\n-            prov:label \\\\\\\\\\\\\\\"n_features\\\\\\\\\\\\\\\" ;\\\\\\\\n-            prov:value \\\\\\\\\\\\\\\"4\\\\\\\\\\\\\\\" ],\\\\\\\\n-        [ a prov:Entity ;\\\\\\\\n-            prov:label \\\\\\\\\\\\\\\"max_features\\\\\\\\\\\\\\\" ;\\\\\\\\n-            prov:value \\\\\\\\\\\\\\\"sqrt\\\\\\\\\\\\\\\" ],\\\\\\\\n-        [ a prov:Entity ;\\\\\\\\n-            prov:label \\\\\\\\\\\\\\\"n_estimators\\\\\\\\\\\\\\\" ;\\\\\\\\n-            prov:value \\\\\\\\\\\\\\\"200\\\\\\\\\\\\\\\" ],\\\\\\\\n-        [ a prov:Entity ;\\\\\\\\n-            prov:label \\\\\\\\\\\\\\\"shap_version\\\\\\\\\\\\\\\" ;\\\\\\\\n-            prov:value \\\\\\\\\\\\\\\"0.47.1\\\\\\\\\\\\\\\" ],\\\\\\\\n-        [ a prov:Entity ;\\\\\\\\n-            prov:label \\\\\\\\\\\\\\\"seaborn_version\\\\\\\\\\\\\\\" ;\\\\\\\\n-            prov:value \\\\\\\\\\\\\\\"0.12.2\\\\\\\\\\\\\\\" ],\\\\\\\\n-        [ a prov:Entity ;\\\\\\\\n-            prov:label \\\\\\\\\\\\\\\"dataset.doi\\\\\\\\\\\\\\\" ;\\\\\\\\n-            prov:value \\\\\\\\\\\\\\\"10.5281/ZENODO.1404173\\\\\\\\\\\\\\\" ],\\\\\\\\n-        [ a prov:Entity ;\\\\\\\\n-            prov:label \\\\\\\\\\\\\\\"n_jobs\\\\\\\\\\\\\\\" ;\\\\\\\\n-            prov:value \\\\\\\\\\\\\\\"-1\\\\\\\\\\\\\\\" ],\\\\\\\\n-        [ a prov:Entity ;\\\\\\\\n-            prov:label \\\\\\\\\\\\\\\"n_train_samples\\\\\\\\\\\\\\\" ;\\\\\\\\n-            prov:value \\\\\\\\\\\\\\\"120\\\\\\\\\\\\\\\" ],\\\\\\\\n-        [ a prov:Entity ;\\\\\\\\n-            prov:label \\\\\\\\\\\\\\\"dataset.publisher\\\\\\\\\\\\\\\" ;\\\\\\\\n-            prov:value \\\\\\\\\\\\\\\"Zenodo\\\\\\\\\\\\\\\" ],\\\\\\\\n-        [ a prov:Entity ;\\\\\\\\n-            prov:label \\\\\\\\\\\\\\\"os_platform\\\\\\\\\\\\\\\" ;\\\\\\\\n-            prov:value \\\\\\\\\\\\\\\"Windows 10\\\\\\\\\\\\\\\" ],\\\\\\\\n-        [ a prov:Entity ;\\\\\\\\n-            prov:label \\\\\\\\\\\\\\\"min_samples_split\\\\\\\\\\\\\\\" ;\\\\\\\\n-            prov:value \\\\\\\\\\\\\\\"5\\\\\\\\\\\\\\\" ],\\\\\\\\n-        [ a prov:Entity ;\\\\\\\\n-            prov:label \\\\\\\\\\\\\\\"max_leaf_nodes\\\\\\\\\\\\\\\" ;\\\\\\\\n-            prov:value \\\\\\\\\\\\\\\"None\\\\\\\\\\\\\\\" ],\\\\\\\\n-        [ a prov:Entity ;\\\\\\\\n-            prov:label \\\\\\\\\\\\\\\"columns_raw\\\\\\\\\\\\\\\" ;\\\\\\\\n-            prov:value \\\\\\\\\\\\\\\"['id', 'sepallengthcm', 'sepalwidthcm', 'petallengthcm', 'petalwidthcm', 'species']\\\\\\\\\\\\\\\" ],\\\\\\\\n-        [ a prov:Entity ;\\\\\\\\n-            prov:label \\\\\\\\\\\\\\\"min_samples_leaf\\\\\\\\\\\\\\\" ;\\\\\\\\n-            prov:value \\\\\\\\\\\\\\\"2\\\\\\\\\\\\\\\" ],\\\\\\\\n-        [ a prov:Entity ;\\\\\\\\n-            prov:label \\\\\\\\\\\\\\\"feature_names\\\\\\\\\\\\\\\" ;\\\\\\\\n-            prov:value \\\\\\\\\\\\\\\"['sepallengthcm', 'sepalwidthcm', 'petallengthcm', 'petalwidthcm']\\\\\\\\\\\\\\\" ],\\\\\\\\n-        [ a prov:Entity ;\\\\\\\\n-            prov:label \\\\\\\\\\\\\\\"criterion\\\\\\\\\\\\\\\" ;\\\\\\\\n-            prov:value \\\\\\\\\\\\\\\"entropy\\\\\\\\\\\\\\\" ],\\\\\\\\n-        [ a prov:Entity ;\\\\\\\\n-            prov:label \\\\\\\\\\\\\\\"database.owner\\\\\\\\\\\\\\\" ;\\\\\\\\n-            prov:value \\\\\\\\\\\\\\\"reema\\\\\\\\\\\\\\\" ],\\\\\\\\n-        [ a prov:Entity ;\\\\\\\\n-            prov:label \\\\\\\\\\\\\\\"database.description\\\\\\\\\\\\\\\" ;\\\\\\\\n-            prov:value \\\\\\\\\\\\\\\"None\\\\\\\\\\\\\\\" ],\\\\\\\\n-        [ a prov:Entity ;\\\\\\\\n-            prov:label \\\\\\\\\\\\\\\"random_state\\\\\\\\\\\\\\\" ;\\\\\\\\n-            prov:value \\\\\\\\\\\\\\\"42\\\\\\\\\\\\\\\" ],\\\\\\\\n-        [ a prov:Entity ;\\\\\\\\n-            prov:label \\\\\\\\\\\\\\\"warm_start\\\\\\\\\\\\\\\" ;\\\\\\\\n-            prov:value \\\\\\\\\\\\\\\"False\\\\\\\\\\\\\\\" ],\\\\\\\\n-        [ a prov:Entity ;\\\\\\\\n-            prov:label \\\\\\\\\\\\\\\"max_samples\\\\\\\\\\\\\\\" ;\\\\\\\\n-            prov:value \\\\\\\\\\\\\\\"None\\\\\\\\\\\\\\\" ],\\\\\\\\n-        [ a prov:Entity ;\\\\\\\\n-            prov:label \\\\\\\\\\\\\\\"test_size\\\\\\\\\\\\\\\" ;\\\\\\\\n-            prov:value \\\\\\\\\\\\\\\"0.2\\\\\\\\\\\\\\\" ],\\\\\\\\n-        [ a prov:Entity ;\\\\\\\\n-            prov:label \\\\\\\\\\\\\\\"numpy_version\\\\\\\\\\\\\\\" ;\\\\\\\\n-            prov:value \\\\\\\\\\\\\\\"1.24.4\\\\\\\\\\\\\\\" ],\\\\\\\\n-        [ a prov:Entity ;\\\\\\\\n-            prov:label \\\\\\\\\\\\\\\"ccp_alpha\\\\\\\\\\\\\\\" ;\\\\\\\\n-            prov:value \\\\\\\\\\\\\\\"0.0\\\\\\\\\\\\\\\" ],\\\\\\\\n-        [ a prov:Entity ;\\\\\\\\n-            prov:label \\\\\\\\\\\\\\\"retrieval_time\\\\\\\\\\\\\\\" ;\\\\\\\\n-            prov:value \\\\\\\\\\\\\\\"2025-04-23T21:04:22.410093\\\\\\\\\\\\\\\" ],\\\\\\\\n-        [ a prov:Entity ;\\\\\\\\n-            prov:label \\\\\\\\\\\\\\\"database.name\\\\\\\\\\\\\\\" ;\\\\\\\\n-            prov:value \\\\\\\\\\\\\\\"Iris\\\\\\\\\\\\\\\" ],\\\\\\\\n-        [ a prov:Entity ;\\\\\\\\n-            prov:label \\\\\\\\\\\\\\\"min_weight_fraction_leaf\\\\\\\\\\\\\\\" ;\\\\\\\\n-            prov:value \\\\\\\\\\\\\\\"0.0\\\\\\\\\\\\\\\" ],\\\\\\\\n-        [ a prov:Entity ;\\\\\\\\n-            prov:label \\\\\\\\\\\\\\\"class_weight\\\\\\\\\\\\\\\" ;\\\\\\\\n-            prov:value \\\\\\\\\\\\\\\"None\\\\\\\\\\\\\\\" ] ;\\\\\\\\n-    prov:hadQuality [ a prov:Entity ;\\\\\\\\n-            prov:label \\\\\\\\\\\\\\\"training_f1_score\\\\\\\\\\\\\\\" ;\\\\\\\\n-            prov:value 0.9666666666666667 ],\\\\\\\\n-        [ a prov:Entity ;\\\\\\\\n-            prov:label \\\\\\\\\\\\\\\"training_recall_score\\\\\\\\\\\\\\\" ;\\\\\\\\n-            prov:value 0.9666666666666667 ],\\\\\\\\n-        [ a prov:Entity ;\\\\\\\\n-            prov:label \\\\\\\\\\\\\\\"dbrepo.row_count_end\\\\\\\\\\\\\\\" ;\\\\\\\\n-            prov:value 150.0 ],\\\\\\\\n-        [ a prov:Entity ;\\\\\\\\n-            prov:label \\\\\\\\\\\\\\\"f1_macro\\\\\\\\\\\\\\\" ;\\\\\\\\n-            prov:value 1.0 ],\\\\\\\\n-        [ a prov:Entity ;\\\\\\\\n-            prov:label \\\\\\\\\\\\\\\"accuracy\\\\\\\\\\\\\\\" ;\\\\\\\\n-            prov:value 1.0 ],\\\\\\\\n-        [ a prov:Entity ;\\\\\\\\n-            prov:label \\\\\\\\\\\\\\\"accuracy_score_X_test\\\\\\\\\\\\\\\" ;\\\\\\\\n-            prov:value 1.0 ],\\\\\\\\n-        [ a prov:Entity ;\\\\\\\\n-            prov:label \\\\\\\\\\\\\\\"f1_score_X_test\\\\\\\\\\\\\\\" ;\\\\\\\\n-            prov:value 1.0 ],\\\\\\\\n-        [ a prov:Entity ;\\\\\\\\n-            prov:label \\\\\\\\\\\\\\\"training_roc_auc\\\\\\\\\\\\\\\" ;\\\\\\\\n-            prov:value 0.9987492182614135 ],\\\\\\\\n-        [ a prov:Entity ;\\\\\\\\n-            prov:label \\\\\\\\\\\\\\\"dbrepo.row_count_start\\\\\\\\\\\\\\\" ;\\\\\\\\n-            prov:value 150.0 ],\\\\\\\\n-        [ a prov:Entity ;\\\\\\\\n-            prov:label \\\\\\\\\\\\\\\"training_accuracy_score\\\\\\\\\\\\\\\" ;\\\\\\\\n-            prov:value 0.9666666666666667 ],\\\\\\\\n-        [ a prov:Entity ;\\\\\\\\n-            prov:label \\\\\\\\\\\\\\\"recall_macro\\\\\\\\\\\\\\\" ;\\\\\\\\n-            prov:value 1.0 ],\\\\\\\\n-        [ a prov:Entity ;\\\\\\\\n-            prov:label \\\\\\\\\\\\\\\"roc_auc\\\\\\\\\\\\\\\" ;\\\\\\\\n-            prov:value 1.0 ],\\\\\\\\n-        [ a prov:Entity ;\\\\\\\\n-            prov:label \\\\\\\\\\\\\\\"roc_auc_score_X_test\\\\\\\\\\\\\\\" ;\\\\\\\\n-            prov:value 1.0 ],\\\\\\\\n-        [ a prov:Entity ;\\\\\\\\n-            prov:label \\\\\\\\\\\\\\\"dbrepo.num_inserts\\\\\\\\\\\\\\\" ;\\\\\\\\n-            prov:value 1.0 ],\\\\\\\\n-        [ a prov:Entity ;\\\\\\\\n-            prov:label \\\\\\\\\\\\\\\"dbrepo.num_deletes\\\\\\\\\\\\\\\" ;\\\\\\\\n-            prov:value 0.0 ],\\\\\\\\n-        [ a prov:Entity ;\\\\\\\\n-            prov:label \\\\\\\\\\\\\\\"training_precision_score\\\\\\\\\\\\\\\" ;\\\\\\\\n-            prov:value 0.9674588284344383 ],\\\\\\\\n-        [ a prov:Entity ;\\\\\\\\n-            prov:label \\\\\\\\\\\\\\\"precision_score_X_test\\\\\\\\\\\\\\\" ;\\\\\\\\n-            prov:value 1.0 ],\\\\\\\\n-        [ a prov:Entity ;\\\\\\\\n-            prov:label \\\\\\\\\\\\\\\"recall_score_X_test\\\\\\\\\\\\\\\" ;\\\\\\\\n-            prov:value 1.0 ],\\\\\\\\n-        [ a prov:Entity ;\\\\\\\\n-            prov:label \\\\\\\\\\\\\\\"precision_macro\\\\\\\\\\\\\\\" ;\\\\\\\\n-            prov:value 1.0 ],\\\\\\\\n-        [ a prov:Entity ;\\\\\\\\n-            prov:label \\\\\\\\\\\\\\\"training_log_loss\\\\\\\\\\\\\\\" ;\\\\\\\\n-            prov:value 0.0653522301195834 ],\\\\\\\\n-        [ a prov:Entity ;\\\\\\\\n-            prov:label \\\\\\\\\\\\\\\"training_score\\\\\\\\\\\\\\\" ;\\\\\\\\n-            prov:value 0.9666666666666667 ] ;\\\\\\\\n-    prov:startedAtTime \\\\\\\\\\\\\\\"2025-04-23T21:04:21.262000+00:00\\\\\\\\\\\\\\\"^^xsd:dateTime ;\\\\\\\\n-    prov:used [ a prov:Entity ;\\\\\\\\n-            prov:hadRevision \\\\\\\\\\\\\\\"1.0.0\\\\\\\\\\\\\\\" ;\\\\\\\\n-            prov:label \\\\\\\\\\\\\\\"Iris\\\\\\\\\\\\\\\" ] .\\\\\\\\n-\\\\\\\\ndiff --git a/notebooks/RQ_notebooks/RQ1.ipynb b/notebooks/RQ_notebooks/RQ1.ipynb\\\\\\\\ndeleted file mode 100644\\\\\\\\nindex 468a62a..0000000\\\\\\\\n--- a/notebooks/RQ_notebooks/RQ1.ipynb\\\\\\\\n+++ /dev/null\\\\\\\\n@@ -1,1093 +0,0 @@\\\\\\\\n-{\\\\\\\\n- \\\\\\\\\\\\\\\"cells\\\\\\\\\\\\\\\": [\\\\\\\\n-  {\\\\\\\\n-   \\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"markdown\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"d55b8ff1-b8ac-4dbf-861f-458e234526f3\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {},\\\\\\\\n-   \\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\": [\\\\\\\\n-    \\\\\\\\\\\\\\\"TODO\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"create venv to wrap up all installation programatically\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"set the experiment name in mlflow dynamically\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"update teh target name dynamic after db repo integration\\\\\\\\\\\\\\\"\\\\\\\\n-   ]\\\\\\\\n-  },\\\\\\\\n-  {\\\\\\\\n-   \\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"code\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\\\": null,\\\\\\\\n-   \\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"387a312e-e0db-4522-b4b2-4a346fd008ba\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {\\\\\\\\n-    \\\\\\\\\\\\\\\"editable\\\\\\\\\\\\\\\": true,\\\\\\\\n-    \\\\\\\\\\\\\\\"scrolled\\\\\\\\\\\\\\\": true,\\\\\\\\n-    \\\\\\\\\\\\\\\"slideshow\\\\\\\\\\\\\\\": {\\\\\\\\n-     \\\\\\\\\\\\\\\"slide_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n-    },\\\\\\\\n-    \\\\\\\\\\\\\\\"tags\\\\\\\\\\\\\\\": []\\\\\\\\n-   },\\\\\\\\n-   \\\\\\\\\\\\\\\"outputs\\\\\\\\\\\\\\\": [],\\\\\\\\n-   \\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\": [\\\\\\\\n-    \\\\\\\\\\\\\\\"# \\\\\\\\u2699\\\\\\\\ufe0f Install required packages in the notebook itself\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# !pip install --quiet --upgrade pip\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"!pip install mlflow scikit-learn\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"!pip install pandas\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"!pip install numpy\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"!pip install jupyter\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"!pip install shap\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n-   ]\\\\\\\\n-  },\\\\\\\\n-  {\\\\\\\\n-   \\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"code\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\\\": null,\\\\\\\\n-   \\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"1d52b769-2727-457d-ba78-29726ebf4fe3\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {},\\\\\\\\n-   \\\\\\\\\\\\\\\"outputs\\\\\\\\\\\\\\\": [],\\\\\\\\n-   \\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\": [\\\\\\\\n-    \\\\\\\\\\\\\\\"!pip install scikit-learn\\\\\\\\\\\\\\\"\\\\\\\\n-   ]\\\\\\\\n-  },\\\\\\\\n-  {\\\\\\\\n-   \\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"code\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\\\": null,\\\\\\\\n-   \\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"3e42e4c3-ab59-40dd-ac48-aef4bbecd4b6\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {\\\\\\\\n-    \\\\\\\\\\\\\\\"scrolled\\\\\\\\\\\\\\\": true\\\\\\\\n-   },\\\\\\\\n-   \\\\\\\\\\\\\\\"outputs\\\\\\\\\\\\\\\": [],\\\\\\\\n-   \\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\": [\\\\\\\\n-    \\\\\\\\\\\\\\\"!pip uninstall numpy\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"!pip install numpy --force-reinstall --upgrade\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"!pip uninstall shap\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"!pip install shap --upgrade\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"!pip install mkl\\\\\\\\\\\\\\\"\\\\\\\\n-   ]\\\\\\\\n-  },\\\\\\\\n-  {\\\\\\\\n-   \\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"code\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\\\": 69,\\\\\\\\n-   \\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"8e95a3c5-c669-421f-891a-a58799d81de1\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {\\\\\\\\n-    \\\\\\\\\\\\\\\"editable\\\\\\\\\\\\\\\": true,\\\\\\\\n-    \\\\\\\\\\\\\\\"scrolled\\\\\\\\\\\\\\\": true,\\\\\\\\n-    \\\\\\\\\\\\\\\"slideshow\\\\\\\\\\\\\\\": {\\\\\\\\n-     \\\\\\\\\\\\\\\"slide_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n-    },\\\\\\\\n-    \\\\\\\\\\\\\\\"tags\\\\\\\\\\\\\\\": []\\\\\\\\n-   },\\\\\\\\n-   \\\\\\\\\\\\\\\"outputs\\\\\\\\\\\\\\\": [],\\\\\\\\n-   \\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\": [\\\\\\\\n-    \\\\\\\\\\\\\\\"import git  \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"import mlflow\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"from mlflow import MlflowClient\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"import time\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"import psutil\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"import platform\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"import sklearn\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"import pandas as pd\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"import numpy as np\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"import matplotlib\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"import seaborn\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"import json\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"import os\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"import sys\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"from sklearn.ensemble import RandomForestClassifier\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"from sklearn.model_selection import train_test_split\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"from sklearn.metrics import (\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    accuracy_score, roc_auc_score, confusion_matrix,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    precision_score, recall_score, f1_score, roc_curve\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"import shap\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"import seaborn as sns\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"import matplotlib.pyplot as plt\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"os.environ[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"MLFLOW_SYSTEM_METRICS_ENABLED\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"] = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"true\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n-   ]\\\\\\\\n-  },\\\\\\\\n-  {\\\\\\\\n-   \\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"code\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\\\": 70,\\\\\\\\n-   \\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"b5930009-6cf8-4258-9375-0ee20f290bc3\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {},\\\\\\\\n-   \\\\\\\\\\\\\\\"outputs\\\\\\\\\\\\\\\": [\\\\\\\\n-    {\\\\\\\\n-     \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"stdout\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"output_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"stream\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\": [\\\\\\\\n-      \\\\\\\\\\\\\\\"Tracking URI set to: mlrunlogs/mlflow.db\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n-     ]\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-     \\\\\\\\\\\\\\\"data\\\\\\\\\\\\\\\": {\\\\\\\\n-      \\\\\\\\\\\\\\\"text/plain\\\\\\\\\\\\\\\": [\\\\\\\\n-       \\\\\\\\\\\\\\\"<Experiment: artifact_location='file:///C:/Users/reema/OneDrive/Dokumente/Provenance_tracking_thesis/Provenence-Tracking-Thesis-Research/notebooks/RQ_notebooks/mlrunlogs/mlflow.db/350083769514222255', creation_time=1744653654888, experiment_id='350083769514222255', last_update_time=1744653654888, lifecycle_stage='active', name='RandomForest-Iris-CSV', tags={}>\\\\\\\\\\\\\\\"\\\\\\\\n-      ]\\\\\\\\n-     },\\\\\\\\n-     \\\\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\\\": 70,\\\\\\\\n-     \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {},\\\\\\\\n-     \\\\\\\\\\\\\\\"output_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"execute_result\\\\\\\\\\\\\\\"\\\\\\\\n-    }\\\\\\\\n-   ],\\\\\\\\n-   \\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\": [\\\\\\\\n-    \\\\\\\\\\\\\\\"# Set experiment name\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# ============================\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# \\\\\\\\ud83d\\\\\\\\udd27 Configuration\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# ============================\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"pproject_dir = os.getcwd()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"tracking_dir = os.path.join(project_dir, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"mlruns\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"mlflow.set_tracking_uri(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"mlrunlogs/mlflow.db\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")  # Setting the MLflow tracking URI\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Tracking URI set to:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", mlflow.get_tracking_uri())\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"mlflow.set_experiment(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"RandomForest-Iris-CSV\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\"\\\\\\\\n-   ]\\\\\\\\n-  },\\\\\\\\n-  {\\\\\\\\n-   \\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"code\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\\\": 71,\\\\\\\\n-   \\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"055a90d6-b671-46bc-8daf-b1b442347915\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {},\\\\\\\\n-   \\\\\\\\\\\\\\\"outputs\\\\\\\\\\\\\\\": [],\\\\\\\\n-   \\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\": [\\\\\\\\n-    \\\\\\\\\\\\\\\"# ============================\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# \\\\\\\\ud83d\\\\\\\\udce5 Load Data from CSV\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# ============================\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# Read data from CSV file\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"df = pd.read_csv(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"C:/Users/reema/OneDrive/Dokumente/Provenance_tracking_thesis/Provenence-Tracking-Thesis-Research/data/Iris.csv\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# Use the last column as the target variable\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"X = df.iloc[:, :-1]  # All columns except the last one are features\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"y = df.iloc[:, -1]   # The last column is the target\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# Create a dataset object with mlflow.data\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"dataset = mlflow.data.from_pandas(df, name=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Iris Dataset\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\"\\\\\\\\n-   ]\\\\\\\\n-  },\\\\\\\\n-  {\\\\\\\\n-   \\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"code\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\\\": 72,\\\\\\\\n-   \\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"91732c7f-362c-4557-8b8e-71ed640ae8d4\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {},\\\\\\\\n-   \\\\\\\\\\\\\\\"outputs\\\\\\\\\\\\\\\": [],\\\\\\\\n-   \\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\": [\\\\\\\\n-    \\\\\\\\\\\\\\\"# Dataset Metadata to be logged 'TODO_update based on DBREPO LOG\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"dataset_metadata = {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"dataset_name\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Iris Dataset\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"dataset_version\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"1.0.0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",  # or use a Git commit hash or timestamp\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"dataset_source_url_or_path\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"C:/Users/reema/OneDrive/Dokumente/Provenance_tracking_thesis/Provenence-Tracking-Thesis-Research/data/Iris.csv\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"dataset_size_bytes\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": os.path.getsize(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"C:/Users/reema/OneDrive/Dokumente/Provenance_tracking_thesis/Provenence-Tracking-Thesis-Research/data/Iris.csv\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"),\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"dataset_shape\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{df.shape[0]} x {df.shape[1]}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"dataset_format\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"CSV\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"feature_names\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": list(X.columns),\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"feature_types\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": [str(X[col].dtype) for col in X.columns],\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"target_column\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": y.name,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"class_distribution\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": y.value_counts().to_dict(),\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"missing_value_strategy\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"None\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",  # Update based on your strategy (e.g., imputation or dropping missing values)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"scaling_encoding_steps\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"None\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",  # Update if any scaling or encoding is performed\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"data_split_method\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Train-test split (80-20)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"data_random_seed\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 42,  # Random state for reproducibility\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"preprocessing_pipeline\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"None\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",  # Or provide a path or summary of preprocessing steps\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"}\\\\\\\\\\\\\\\"\\\\\\\\n-   ]\\\\\\\\n-  },\\\\\\\\n-  {\\\\\\\\n-   \\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"code\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\\\": 73,\\\\\\\\n-   \\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"f47aa487-ab46-4032-b00f-4b8067a12066\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {},\\\\\\\\n-   \\\\\\\\\\\\\\\"outputs\\\\\\\\\\\\\\\": [\\\\\\\\n-    {\\\\\\\\n-     \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"stderr\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"output_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"stream\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\": [\\\\\\\\n-      \\\\\\\\\\\\\\\"2025/04/14 22:10:03 INFO mlflow.tracking.fluent: Autologging successfully enabled for statsmodels.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n-     ]\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-     \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"stdout\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"output_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"stream\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\": [\\\\\\\\n-      \\\\\\\\\\\\\\\"Git commit: 8f07816bad4ec2acee3ef8dbb7370db46c6d172b\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Git commit: 8f07816bad4ec2acee3ef8dbb7370db46c6d172b\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Python version: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Platform: Windows\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n-     ]\\\\\\\\n-    }\\\\\\\\n-   ],\\\\\\\\n-   \\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\": [\\\\\\\\n-    \\\\\\\\\\\\\\\"# Capture Git commit hash\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"repo_dir = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"C:/Users/reema/OneDrive/Dokumente/Provenance_tracking_thesis/Provenence-Tracking-Thesis-Research\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"repo = git.Repo(repo_dir)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"commit_hash = repo.head.object.hexsha\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Git commit: {commit_hash}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# Log system information\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"python_version = sys.version\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"platform_info = platform.system()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Git commit: {commit_hash}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Python version: {python_version}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Platform: {platform_info}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# \\\\\\\\ud83e\\\\\\\\udde0 MLflow Autologging\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"mlflow.autolog(log_input_examples=True, log_model_signatures=True)\\\\\\\\\\\\\\\"\\\\\\\\n-   ]\\\\\\\\n-  },\\\\\\\\n-  {\\\\\\\\n-   \\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"code\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\\\": 74,\\\\\\\\n-   \\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"b469604a-0b98-45ae-a52a-5a97a14a0657\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {},\\\\\\\\n-   \\\\\\\\\\\\\\\"outputs\\\\\\\\\\\\\\\": [\\\\\\\\n-    {\\\\\\\\n-     \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"stderr\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"output_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"stream\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\": [\\\\\\\\n-      \\\\\\\\\\\\\\\"2025/04/14 22:10:03 INFO mlflow.tracking.fluent: Autologging successfully enabled for statsmodels.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"2025/04/14 22:10:05 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n-     ]\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-     \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"stdout\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"output_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"stream\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\": [\\\\\\\\n-      \\\\\\\\\\\\\\\"Model 'RandomForest_IrisDataset_v1.0.0' already exists. Registering a new version...\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n-     ]\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-     \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"stderr\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"output_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"stream\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\": [\\\\\\\\n-      \\\\\\\\\\\\\\\"2025/04/14 22:10:11 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Registered model 'RandomForest_IrisDataset_v1.0.0' already exists. Creating a new version of this model...\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Created version '7' of model 'RandomForest_IrisDataset_v1.0.0'.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\reema\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\AppData\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Local\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Temp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ipykernel_14504\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\2059064886.py:38: FutureWarning: ``mlflow.tracking.client.MlflowClient.get_latest_versions`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"  model_versions = client.get_latest_versions(model_name)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n-     ]\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-     \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"stdout\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"output_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"stream\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\": [\\\\\\\\n-      \\\\\\\\\\\\\\\"\\\\\\\\u2705 Model logged and registered as: RandomForest_IrisDataset_v1.0.0, Version: 7\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n-     ]\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-     \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"stderr\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"output_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"stream\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\": [\\\\\\\\n-      \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\reema\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\sklearn\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\metrics\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\_ranking.py:1132: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"  warnings.warn(\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\reema\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\shap\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\plots\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\_beeswarm.py:1153: UserWarning: The figure layout has changed to tight\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"  pl.tight_layout()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\reema\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\shap\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\plots\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\_beeswarm.py:761: UserWarning: The figure layout has changed to tight\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"  pl.tight_layout(pad=0, w_pad=0, h_pad=0.0)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n-     ]\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-     \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"stdout\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"output_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"stream\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\": [\\\\\\\\n-      \\\\\\\\\\\\\\\"Run logged with ID: 21017b4179494ef49706508240ab526e\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n-     ]\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-     \\\\\\\\\\\\\\\"data\\\\\\\\\\\\\\\": {\\\\\\\\n-      \\\\\\\\\\\\\\\"image/png\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"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\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"text/plain\\\\\\\\\\\\\\\": [\\\\\\\\n-       \\\\\\\\\\\\\\\"<Figure size 600x600 with 2 Axes>\\\\\\\\\\\\\\\"\\\\\\\\n-      ]\\\\\\\\n-     },\\\\\\\\n-     \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {},\\\\\\\\n-     \\\\\\\\\\\\\\\"output_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"display_data\\\\\\\\\\\\\\\"\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-     \\\\\\\\\\\\\\\"data\\\\\\\\\\\\\\\": {\\\\\\\\n-      \\\\\\\\\\\\\\\"text/plain\\\\\\\\\\\\\\\": [\\\\\\\\n-       \\\\\\\\\\\\\\\"<Figure size 640x480 with 0 Axes>\\\\\\\\\\\\\\\"\\\\\\\\n-      ]\\\\\\\\n-     },\\\\\\\\n-     \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {},\\\\\\\\n-     \\\\\\\\\\\\\\\"output_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"display_data\\\\\\\\\\\\\\\"\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-     \\\\\\\\\\\\\\\"data\\\\\\\\\\\\\\\": {\\\\\\\\n-      \\\\\\\\\\\\\\\"image/png\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"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\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"text/plain\\\\\\\\\\\\\\\": [\\\\\\\\n-       \\\\\\\\\\\\\\\"<Figure size 1150x660 with 1 Axes>\\\\\\\\\\\\\\\"\\\\\\\\n-      ]\\\\\\\\n-     },\\\\\\\\n-     \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {},\\\\\\\\n-     \\\\\\\\\\\\\\\"output_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"display_data\\\\\\\\\\\\\\\"\\\\\\\\n-    }\\\\\\\\n-   ],\\\\\\\\n-   \\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\": [\\\\\\\\n-    \\\\\\\\\\\\\\\"# \\\\\\\\ud83e\\\\\\\\udde0 MLflow Autologging Enabled\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"mlflow.autolog(log_input_examples=True, log_model_signatures=True)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# ============================\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# \\\\\\\\ud83d\\\\\\\\ude80 Start MLflow Run\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# ============================\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# \\\\\\\\u2705 Logging Dataset Metadata\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"with mlflow.start_run() as run:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # Track system metrics manually\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    cpu_before = psutil.cpu_percent(interval=1)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    mem_before = psutil.virtual_memory().percent\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    training_time_start = time.time()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # Log dataset metadata\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    mlflow.log_params(dataset_metadata)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # Define dynamic model name\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    model_name = f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"RandomForest_{dataset_metadata['dataset_name'].replace(' ', '')}_v{dataset_metadata['dataset_version']}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # Use the MLflow client to check if the model already exists\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    client = MlflowClient()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    model_registered = False\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    for model in client.search_registered_models():\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        if model.name == model_name:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            model_registered = True\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            break\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # Register the model or update with a new version\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    if model_registered:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Model '{model_name}' already exists. Registering a new version...\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        mlflow.sklearn.log_model(model, artifact_path=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"model\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", registered_model_name=model_name)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    else:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Registering new model '{model_name}'...\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        mlflow.sklearn.log_model(model, artifact_path=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"model\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", registered_model_name=model_name)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # Fetch the model version\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    model_versions = client.get_latest_versions(model_name)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    latest_version = model_versions[0].version if model_versions else None\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # Log the model version and other details\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    mlflow.log_param(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"model_name\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", model_name)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    mlflow.log_param(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"model_version\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", latest_version)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    mlflow.log_param(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"all_model_version\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", model_versions)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\u2705 Model logged and registered as: {model_name}, Version: {latest_version}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # Save input data as CSV and log it\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    Xy = X.copy()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    Xy[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"target\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"] = y\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    data_path = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"iris_dataset.csv\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    Xy.to_csv(data_path, index=False)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    mlflow.log_artifact(data_path, artifact_path=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"input_data\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # Model training\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    try:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        model = RandomForestClassifier(n_estimators=100, random_state=42)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        model.fit(X_train, y_train)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    except ValueError as e:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        error_code = 1001  # Example error code\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        mlflow.log_param(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"error_code\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", error_code)  # Log the error code\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        error_message = str(e)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        mlflow.log_param(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"error_message\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", error_message)  # Log the specific error message\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        with open(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"error_log.txt\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"w\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\") as error_file:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            error_file.write(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Error Code: {error_code}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nError Message: {error_message}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        mlflow.log_artifact(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"error_log.txt\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")  # Log the error log file\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Error Code: {error_code}, Message: {error_message}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    training_time_end = time.time()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    training_time = training_time_end - training_time_start\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    cpu_after = psutil.cpu_percent(interval=1)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    mem_after = psutil.virtual_memory().percent\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # Log base params\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    mlflow.log_params({\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"model_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": type(model).__name__,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"model_library\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"scikit-learn\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"dataset_source\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"DBrepo\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"training_time_start\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": training_time_start,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"training_time_end\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": training_time_end\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    })\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # Save model metadata\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    model_metadata = {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"model_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"RandomForestClassifier\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"commit_hash\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": commit_hash,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"experiment_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": mlflow.active_run().info.experiment_id,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"training_timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": time.strftime(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"%Y-%m-%d %H:%M:%S\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"),\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"training_error\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"None\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"training_dataset_version\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"1.0.0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"testing_dataset_version\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"1.0.0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"python_version\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": python_version,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"platform\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": platform_info\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # Evaluation\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    y_pred = model.predict(X_test)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    y_proba = model.predict_proba(X_test)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    acc = accuracy_score(y_test, y_pred)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    auc = roc_auc_score(y_test, y_proba, multi_class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"ovr\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    mlflow.log_metrics({\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"accuracy\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": acc,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"roc_auc\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": auc,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"precision\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": precision_score(y_test, y_pred, average='macro'),\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"recall\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": recall_score(y_test, y_pred, average='macro'),\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"f1_score\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": f1_score(y_test, y_pred, average='macro')\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    })\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # Log full model hyperparameters\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    mlflow.log_params(model.get_params())\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # Log metrics\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    mlflow.log_metrics({\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"cpu_before\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": cpu_before,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"cpu_after\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": cpu_after,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"mem_before\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": mem_before,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"mem_after\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": mem_after,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"training_duration_seconds\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": training_time\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    })\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    mlflow.log_param(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"python_version\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", python_version)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    mlflow.log_param(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"platform\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", platform_info)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    mlflow.log_param(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"commit_hash\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", commit_hash)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    mlflow.log_param(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"training_timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", time.strftime(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"%Y-%m-%d %H:%M:%S\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"))\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    mlflow.log_param(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"training_error\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"None\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    mlflow.log_params({\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"model\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"RandomForestClassifier\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"n_estimators\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 100,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"dataset_source\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"DBrepo\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    })\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # Confusion Matrix\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    confusion = confusion_matrix(y_test, y_pred)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    plt.figure(figsize=(6, 6))\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    sns.heatmap(confusion, annot=True, fmt=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"d\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", cmap=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Blues\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    plt.title(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Confusion Matrix\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    plt.xlabel(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Predicted\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    plt.ylabel(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Actual\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    cm_path = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"confusion_matrix.png\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    plt.savefig(cm_path)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    mlflow.log_artifact(cm_path)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # ROC Curve\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    fpr, tpr, _ = roc_curve(y_test, y_proba[:, 1], pos_label=1)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    plt.figure()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    plt.plot(fpr, tpr, label=f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"ROC AUC = {auc:.2f}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    plt.plot([0, 1], [0, 1], \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"k--\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    plt.xlabel(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"False Positive Rate\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    plt.ylabel(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"True Positive Rate\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    plt.title(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"ROC Curve\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    roc_path = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"roc_curve.png\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    plt.savefig(roc_path)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    mlflow.log_artifact(roc_path)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # SHAP values\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    explainer = shap.TreeExplainer(model)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    shap_values = explainer.shap_values(X_test)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    shap.summary_plot(shap_values, X_test, show=False)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    shap_path = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"shap_summary.png\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    plt.savefig(shap_path)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    mlflow.log_artifact(shap_path)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # Feature importance\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    feat_imp = pd.DataFrame({\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Feature\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": X.columns,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Importance\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": model.feature_importances_\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    }).sort_values(by=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Importance\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", ascending=False)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    feat_path = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"feature_importance.csv\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    feat_imp.to_csv(feat_path, index=False)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    mlflow.log_artifact(feat_path)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # Save and log dataset as artifact\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    Xy = X.copy()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    Xy[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"target\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"] = y\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    data_path = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"iris_dataset.csv\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    Xy.to_csv(data_path, index=False)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    mlflow.log_artifact(data_path, artifact_path=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"input_data\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # Log input and output schema\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    input_schema = X.dtypes.astype(str).to_dict()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    with open(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"input_schema.json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"w\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\") as f:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        json.dump(input_schema, f)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    mlflow.log_artifact(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"input_schema.json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    output_schema = {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"output_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": str(type(y_pred[0])),\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"classes\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": model.classes_.tolist()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    with open(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"output_schema.json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"w\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\") as f:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        json.dump(output_schema, f)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    mlflow.log_artifact(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"output_schema.json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # Git commit and push after successful run\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    repo.git.add(A=True)  # Add all changes to git\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    repo.index.commit(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Model training and logging complete: {commit_hash}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    repo.remotes.origin.push()  # Push to the remote repository\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # Log model version and Git commit after successful run\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    model_uri = f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"runs:/{run.info.run_id}/random_forest_model\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Run logged with ID: {run.info.run_id}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    mlflow.end_run()\\\\\\\\\\\\\\\"\\\\\\\\n-   ]\\\\\\\\n-  },\\\\\\\\n-  {\\\\\\\\n-   \\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"code\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\\\": 78,\\\\\\\\n-   \\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"2526ebe3-18f0-4951-a553-05a21d96db12\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {},\\\\\\\\n-   \\\\\\\\\\\\\\\"outputs\\\\\\\\\\\\\\\": [\\\\\\\\n-    {\\\\\\\\n-     \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"stdout\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"output_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"stream\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\": [\\\\\\\\n-      \\\\\\\\\\\\\\\"Forked by: reemagdass - https://github.com/reemagdass/Provenence-Tracking-Thesis-Research\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n-     ]\\\\\\\\n-    }\\\\\\\\n-   ],\\\\\\\\n-   \\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\": [\\\\\\\\n-    \\\\\\\\\\\\\\\"import requests\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# GitHub repository details\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"owner = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"reema-dass26\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"repo = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Provenence-Tracking-Thesis-Research\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"token = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"REMOVED_SECRET\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"  # A GitHub token with read access to public repositories\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# GitHub API URL to get forks\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"url = f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"https://api.github.com/repos/{owner}/{repo}/forks\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# Set headers with authorization token\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"headers = {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Authorization\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"token {token}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# Make the GET request to fetch the forks\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"response = requests.get(url, headers=headers)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# Check if the request was successful\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"if response.status_code == 200:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    forks = response.json()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    for fork in forks:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Forked by: {fork['owner']['login']} - {fork['html_url']}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"else:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Failed to fetch forks: {response.status_code}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n-   ]\\\\\\\\n-  },\\\\\\\\n-  {\\\\\\\\n-   \\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"code\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\\\": 82,\\\\\\\\n-   \\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"d4623d09-6e7f-4246-a6e5-18ba9ef387ed\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {},\\\\\\\\n-   \\\\\\\\\\\\\\\"outputs\\\\\\\\\\\\\\\": [\\\\\\\\n-    {\\\\\\\\n-     \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"stdout\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"output_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"stream\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\": [\\\\\\\\n-      \\\\\\\\\\\\\\\"Forked by: reemagdass - https://github.com/reemagdass/Provenence-Tracking-Thesis-Research\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"\\\\\\\\u274c Failed to create issue for @reemagdass: 404 - {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Not Found\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"documentation_url\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"https://docs.github.com/rest/issues/issues#create-an-issue\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"status\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"404\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n-     ]\\\\\\\\n-    }\\\\\\\\n-   ],\\\\\\\\n-   \\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\": [\\\\\\\\n-    \\\\\\\\\\\\\\\"# import requests\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# # GitHub repository details\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# owner = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"reema-dass26\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# repo = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Provenence-Tracking-Thesis-Research\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# token = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"REMOVED_SECRET\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"  # GitHub token with 'repo' or 'public_repo' scope\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# # Headers for authentication\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# headers = {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Authorization\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"token {token}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Accept\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"application/vnd.github.v3+json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# # Step 1: Get all forks of the repo\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# forks_url = f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"https://api.github.com/repos/{owner}/{repo}/forks\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# response = requests.get(forks_url, headers=headers)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# if response.status_code == 200:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     forks = response.json()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     for fork in forks:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         forked_by = fork['owner']['login']\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         fork_url = fork['html_url']\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Forked by: {forked_by} - {fork_url}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         # Step 2: Create an issue in the original repo to notify the forker\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         issue_url = f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"https://api.github.com/repos/{owner}/{repo}/issues\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         issue_data = {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#             \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"title\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Repository Update Notification for @{forked_by}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#             \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"body\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": (\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#                 f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Hi @{forked_by},\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#                 \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"We noticed you have forked this repository. \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#                 \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Just wanted to notify you that there have been recent updates. \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#                 \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Please pull the latest changes to stay up to date.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#                 \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Let us know if you face any issues! \\\\\\\\ud83d\\\\\\\\ude0a\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#             )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         issue_response = requests.post(issue_url, headers=headers, json=issue_data)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         if issue_response.status_code == 201:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#             print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\u2705 Issue successfully created to notify @{forked_by}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         else:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#             print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\u274c Failed to create issue for @{forked_by}: {issue_response.status_code} - {issue_response.text}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# else:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\u274c Failed to fetch forks: {response.status_code} - {response.text}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n-   ]\\\\\\\\n-  },\\\\\\\\n-  {\\\\\\\\n-   \\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"code\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\\\": 84,\\\\\\\\n-   \\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"c1732bfb-b3b3-4ce7-b793-981046700624\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {},\\\\\\\\n-   \\\\\\\\\\\\\\\"outputs\\\\\\\\\\\\\\\": [\\\\\\\\n-    {\\\\\\\\n-     \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"stdout\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"output_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"stream\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\": [\\\\\\\\n-      \\\\\\\\\\\\\\\"404\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"{'message': 'Not Found', 'documentation_url': 'https://docs.github.com/rest/issues/issues#create-an-issue', 'status': '404'}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n-     ]\\\\\\\\n-    }\\\\\\\\n-   ],\\\\\\\\n-   \\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\": [\\\\\\\\n-    \\\\\\\\\\\\\\\"# import requests\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# # Basic test issue creation\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# owner = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"reema-dass26\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# repo = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Provenence-Tracking-Thesis-Research\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# token = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"REMOVED_SECRET\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# headers = {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Authorization\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"token {token}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Accept\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"application/vnd.github.v3+json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# url = f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"https://api.github.com/repos/{owner}/{repo}/issues\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# data = {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"title\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test Issue from Script\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"body\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"This is a test issue to check access permissions.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# response = requests.post(url, headers=headers, json=data)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# print(response.status_code)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# print(response.json())\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n-   ]\\\\\\\\n-  },\\\\\\\\n-  {\\\\\\\\n-   \\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"code\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\\\": 92,\\\\\\\\n-   \\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"98db1e21-5646-4aed-b686-7c57e6b709fa\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {},\\\\\\\\n-   \\\\\\\\\\\\\\\"outputs\\\\\\\\\\\\\\\": [\\\\\\\\n-    {\\\\\\\\n-     \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"stdout\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"output_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"stream\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\": [\\\\\\\\n-      \\\\\\\\\\\\\\\"\\\\\\\\u274c Failed to create issue: 404 - {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Not Found\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"documentation_url\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"https://docs.github.com/rest/issues/issues#create-an-issue\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"status\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"404\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n-     ]\\\\\\\\n-    }\\\\\\\\n-   ],\\\\\\\\n-   \\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\": [\\\\\\\\n-    \\\\\\\\\\\\\\\"# import requests\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# # GitHub authentication\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# token = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"REMOVED_SECRET\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# owner = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"reema-dass26\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# repo = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Provenence-Tracking-Thesis-Research\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# # Headers for authentication\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# headers = {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Authorization\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"token {token}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Accept\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"application/vnd.github+json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# # Step 1: Fetch all forks\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# forks_url = f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"https://api.github.com/repos/{owner}/{repo}/forks\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# response = requests.get(forks_url, headers=headers)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# if response.status_code == 200:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     forks = response.json()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     usernames = [f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"@{fork['owner']['login']}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" for fork in forks]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     if not usernames:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"No forks found.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     else:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         mention_line = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".join(usernames)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         title = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\ud83d\\\\\\\\udd14 Repository Update Notification\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         body = f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Hi {mention_line},\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nThere have been some updates or changes to the main repository. Please pull the latest changes or check if any part is broken.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nThanks for contributing! \\\\\\\\u2764\\\\\\\\ufe0f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         # Step 2: Create an issue on your repo with mentions\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         issues_url = f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"https://api.github.com/repos/{owner}/{repo}/issues\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         issue_data = {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#             \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"title\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": title,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#             \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"body\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": body,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         create_issue = requests.post(issues_url, headers=headers, json=issue_data)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         if create_issue.status_code == 201:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#             print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\u2705 Issue created successfully and users notified!\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         else:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#             print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\u274c Failed to create issue: {create_issue.status_code} - {create_issue.text}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# else:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\u274c Failed to fetch forks: {response.status_code} - {response.text}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n-   ]\\\\\\\\n-  },\\\\\\\\n-  {\\\\\\\\n-   \\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"code\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\\\": 97,\\\\\\\\n-   \\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"782b6dee-7d02-46bc-a092-0c75d854572e\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {},\\\\\\\\n-   \\\\\\\\\\\\\\\"outputs\\\\\\\\\\\\\\\": [\\\\\\\\n-    {\\\\\\\\n-     \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"stdout\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"output_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"stream\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\": [\\\\\\\\n-      \\\\\\\\\\\\\\\"Could not create Issue \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Issue Title\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Response: b'{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Not Found\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"documentation_url\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"https://docs.github.com/rest/issues/issues#create-an-issue\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"status\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"404\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"}'\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n-     ]\\\\\\\\n-    }\\\\\\\\n-   ],\\\\\\\\n-   \\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\": [\\\\\\\\n-    \\\\\\\\\\\\\\\"# import requests\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# # Authentication for user filing issue (must have read/write access to\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# # repository to add issue to)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# TOKEN = 'REMOVED_SECRET'  # Use your GitHub Personal Access Token\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# USERNAME = 'reema-dass26'\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# # The repository to add this issue to\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# REPO_OWNER = 'reema-dass26'  # Your GitHub username or organization\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# REPO_NAME = 'Provenence-Tracking-Thesis-Research'  # Your repository name\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# def make_github_issue(title, body=None, assignee=None, milestone=None, labels=None):\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     '''Create an issue on github.com using the given parameters.'''\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     # URL to create issues via POST\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     url = f'https://api.github.com/repos/{REPO_OWNER}/{REPO_NAME}/issues'\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     # Create the headers including the token for authentication\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     headers = {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         'Authorization': f'token {TOKEN}',\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         'Accept': 'application/vnd.github+json'\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     # Create our issue\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     issue = {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         'title': title,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         'body': body,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         'assignee': assignee,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         'milestone': milestone,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         'labels': labels\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     # Add the issue to our repository\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     r = requests.post(url, headers=headers, json=issue)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     # Check if the request was successful\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     if r.status_code == 201:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         print(f'Successfully created Issue \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{title}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"')\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     else:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         print(f'Could not create Issue \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{title}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"')\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         print('Response:', r.content)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# # Example usage\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# make_github_issue('Issue Title', 'Body text', 'assigned_user', 3, ['bug'])\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n-   ]\\\\\\\\n-  },\\\\\\\\n-  {\\\\\\\\n-   \\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"code\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\\\": null,\\\\\\\\n-   \\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"43d84ba7-bf8a-4a8a-a797-de01d1aec67a\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {},\\\\\\\\n-   \\\\\\\\\\\\\\\"outputs\\\\\\\\\\\\\\\": [],\\\\\\\\n-   \\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\": [\\\\\\\\n-    \\\\\\\\\\\\\\\"#     # Track system metrics manually\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     cpu_before = psutil.cpu_percent(interval=1)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     mem_before = psutil.virtual_memory().percent\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     training_time_start  = time.time()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     # Log dataset metadata\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     mlflow.log_params(dataset_metadata)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#      # Define dynamic model name\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     model_name = f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"RandomForest_{dataset_metadata['dataset_name'].replace(' ', '')}_v{dataset_metadata['dataset_version']}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     # Use the MLflow client to check if the model already exists\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     client = MlflowClient()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#      # Check if model already exists\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     existing_models = client.search_registered_models()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     model_registered = False\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     for model in existing_models:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         if model.name == model_name:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#             model_registered = True\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#             break\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     # Register the model or update with a new version\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     if model_registered:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Model '{model_name}' already exists. Registering a new version...\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         mlflow.sklearn.log_model(\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#             sk_model=model,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#             artifact_path=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"model\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#             registered_model_name=model_name\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     else:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Registering new model '{model_name}'...\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         mlflow.sklearn.log_model(\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#             sk_model=model,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#             artifact_path=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"model\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#             registered_model_name=model_name\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#          # Fetch the model version after logging it\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     model_versions = client.get_latest_versions(model_name)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     latest_version = model_versions[0].version if model_versions else None\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     mlflow.log_param(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"model_name\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", model_name)  \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     mlflow.log_param(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"model_version\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", latest_version)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     mlflow.log_param(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"all_model_version\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", model_versions)  \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\u2705 Model logged and registered as: {model_name}, Version: {latest_version}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\u2705 Model logged and registered as: {model_name}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     # Save input data as CSV and log it\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     Xy = X.copy()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     Xy[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"target\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"] = y\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     data_path = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"iris_dataset.csv\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     Xy.to_csv(data_path, index=False)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     mlflow.log_artifact(data_path, artifact_path=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"input_data\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#    # Model training\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     model = RandomForestClassifier(n_estimators=100, random_state=42)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     model.fit(X_train, y_train)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     training_time_end = time.time()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     training_time = training_time_end - training_time_start\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     cpu_after = psutil.cpu_percent(interval=1)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     mem_after = psutil.virtual_memory().percent\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#      # Log base params\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     mlflow.log_params({\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"model_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": type(model).__name__,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"model_library\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"scikit-learn\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"dataset_source\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"DBrepo\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"training_time_start\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": training_time_start,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"training_time_end\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": training_time_end\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     })\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#       # Save the model metadata \\\\\\\\ud83d\\\\\\\\udc48 **New**\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     model_metadata = {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"model_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"RandomForestClassifier\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"commit_hash\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": commit_hash,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"experiment_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": mlflow.active_run().info.experiment_id,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"training_timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": time.strftime(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"%Y-%m-%d %H:%M:%S\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"),\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"training_error\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"None\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"training_dataset_version\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"1.0.0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"testing_dataset_version\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"1.0.0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"python_version\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": python_version,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"platform\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": platform_info\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#      # Log full model hyperparameters\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     mlflow.log_params(model.get_params())\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     # Log metrics\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     mlflow.log_metrics({\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"cpu_before\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": cpu_before,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"cpu_after\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": cpu_after,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"mem_before\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": mem_before,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"mem_after\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": mem_after,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"training_duration_seconds\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": training_time\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     })\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     # Log environment details \\\\\\\\ud83d\\\\\\\\udc48 **New**\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     mlflow.log_param(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"python_version\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", python_version)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     mlflow.log_param(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"platform\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", platform_info)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     mlflow.log_param(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"commit_hash\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", commit_hash)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     # Log the training timestamp \\\\\\\\ud83d\\\\\\\\udc48 **New**\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     mlflow.log_param(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"training_timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", time.strftime(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"%Y-%m-%d %H:%M:%S\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"))\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     # Log error tracking (e.g., error messages during training, testing, or inference) \\\\\\\\ud83d\\\\\\\\udc48 **New**\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     mlflow.log_param(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"training_error\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"None\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")  # Update if any errors are caught during training or inference\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     # Notify about deprecated dataset versions (implement a notification system if needed) \\\\\\\\ud83d\\\\\\\\udc48 **New**\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     if \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"deprecated_version\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in mlflow.params:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         mlflow.log_param(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"deprecated_version\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"1.0.0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")  # This could be dynamically checked\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     # Log input features\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     mlflow.log_param(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"model_input_features\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", list(X.columns))\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     # Log script path\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     mlflow.log_param(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"training_script_path\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"RQ1.ipynb\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")  # or use __file__ if script\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#       # Log Python, OS, and libraries\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     mlflow.log_params({\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"python_version\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": platform.python_version(),\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"os_platform\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{platform.system()} {platform.release()}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sklearn_version\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": sklearn.__version__,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"pandas_version\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": pd.__version__,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"numpy_version\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": np.__version__,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"matplotlib_version\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": matplotlib.__version__,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"seaborn_version\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": seaborn.__version__,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"virtual_env\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": os.environ.get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"VIRTUAL_ENV\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\") or os.environ.get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"CONDA_DEFAULT_ENV\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"not_detected\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     })\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#      # Log model\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     mlflow.sklearn.log_model(model, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"random_forest_model\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     # Evaluation\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     y_pred = model.predict(X_test)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     y_proba = model.predict_proba(X_test)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     acc = accuracy_score(y_test, y_pred)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     auc = roc_auc_score(y_test, y_proba, multi_class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"ovr\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     mlflow.log_metrics({\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"accuracy\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": acc,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"roc_auc\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": auc,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"precision\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": precision_score(y_test, y_pred, average='macro'),\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"recall\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": recall_score(y_test, y_pred, average='macro'),\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"f1_score\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": f1_score(y_test, y_pred, average='macro')\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     })\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"   \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     # Optionally log the model metadata as a JSON file or another structure\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     mlflow.log_dict(model_metadata, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"model_metadata.json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     # Log parameters and metrics\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     mlflow.log_params({\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"model\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"RandomForestClassifier\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"n_estimators\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 100,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"dataset_source\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"DBrepo\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     })\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\" \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"  \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#    # Confusion Matrix\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     confusion = confusion_matrix(y_test, y_pred)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     plt.figure(figsize=(6, 6))\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     sns.heatmap(confusion, annot=True, fmt=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"d\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", cmap=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Blues\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     plt.title(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Confusion Matrix\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     plt.xlabel(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Predicted\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     plt.ylabel(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Actual\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     cm_path = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"confusion_matrix.png\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     plt.savefig(cm_path)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     mlflow.log_artifact(cm_path)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     # ROC Curve\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     fpr, tpr, _ = roc_curve(y_test, y_proba[:, 1], pos_label=1)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     plt.figure()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     plt.plot(fpr, tpr, label=f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"ROC AUC = {auc:.2f}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     plt.plot([0, 1], [0, 1], \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"k--\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     plt.xlabel(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"False Positive Rate\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     plt.ylabel(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"True Positive Rate\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     plt.title(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"ROC Curve\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     roc_path = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"roc_curve.png\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     plt.savefig(roc_path)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     mlflow.log_artifact(roc_path)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     # SHAP\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     explainer = shap.TreeExplainer(model)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     shap_values = explainer.shap_values(X_test)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     shap.summary_plot(shap_values, X_test, show=False)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     shap_path = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"shap_summary.png\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     plt.savefig(shap_path)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     mlflow.log_artifact(shap_path)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     # Feature importance\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     feat_imp = pd.DataFrame({\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Feature\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": X.columns,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Importance\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": model.feature_importances_\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     }).sort_values(by=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Importance\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", ascending=False)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     feat_path = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"feature_importance.csv\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     feat_imp.to_csv(feat_path, index=False)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     mlflow.log_artifact(feat_path)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     # \\\\\\\\ud83d\\\\\\\\uddc3\\\\\\\\ufe0f Save and log dataset as artifact\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     Xy = X.copy()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     Xy[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"target\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"] = y\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     data_path = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"iris_dataset.csv\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     Xy.to_csv(data_path, index=False)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     mlflow.log_artifact(data_path, artifact_path=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"input_data\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#   # Input schema\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     input_schema = X.dtypes.astype(str).to_dict()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     with open(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"input_schema.json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"w\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\") as f:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         json.dump(input_schema, f)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     mlflow.log_artifact(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"input_schema.json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     # Output schema\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     output_schema = {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"output_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": str(type(y_pred[0])),\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"classes\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": model.classes_.tolist()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     with open(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"output_schema.json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"w\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\") as f:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         json.dump(output_schema, f)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     mlflow.log_artifact(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"output_schema.json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     # Register model\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     model_uri = f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"runs:/{run.info.run_id}/random_forest_model\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     # mlflow.register_model(model_uri, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"RandomForest_Iris_CSV_Model\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Run logged with ID: {run.info.run_id}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     mlflow.end_run()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# mlflow.set_experiment(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"RandomForest-Iris-CSV\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# client = MlflowClient()\\\\\\\\\\\\\\\"\\\\\\\\n-   ]\\\\\\\\n-  },\\\\\\\\n-  {\\\\\\\\n-   \\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"code\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\\\": null,\\\\\\\\n-   \\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"389db24b-0578-40a0-8731-2c2f9d58d0ef\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {},\\\\\\\\n-   \\\\\\\\\\\\\\\"outputs\\\\\\\\\\\\\\\": [],\\\\\\\\n-   \\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\": []\\\\\\\\n-  },\\\\\\\\n-  {\\\\\\\\n-   \\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"code\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\\\": null,\\\\\\\\n-   \\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"cc4f0725-805c-44ce-9926-d0d849fce621\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {},\\\\\\\\n-   \\\\\\\\\\\\\\\"outputs\\\\\\\\\\\\\\\": [],\\\\\\\\n-   \\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\": []\\\\\\\\n-  },\\\\\\\\n-  {\\\\\\\\n-   \\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"code\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\\\": null,\\\\\\\\n-   \\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"9202135f-8c33-4f97-9458-173183b92111\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {},\\\\\\\\n-   \\\\\\\\\\\\\\\"outputs\\\\\\\\\\\\\\\": [],\\\\\\\\n-   \\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\": []\\\\\\\\n-  },\\\\\\\\n-  {\\\\\\\\n-   \\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"code\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\\\": null,\\\\\\\\n-   \\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"a4703d1d-9cf2-4416-b627-74ef93e009e4\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {},\\\\\\\\n-   \\\\\\\\\\\\\\\"outputs\\\\\\\\\\\\\\\": [],\\\\\\\\n-   \\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\": []\\\\\\\\n-  },\\\\\\\\n-  {\\\\\\\\n-   \\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"code\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\\\": null,\\\\\\\\n-   \\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"e39da051-b6cc-4d52-bc9b-ada392d4de47\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {},\\\\\\\\n-   \\\\\\\\\\\\\\\"outputs\\\\\\\\\\\\\\\": [],\\\\\\\\n-   \\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\": []\\\\\\\\n-  }\\\\\\\\n- ],\\\\\\\\n- \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {\\\\\\\\n-  \\\\\\\\\\\\\\\"kernelspec\\\\\\\\\\\\\\\": {\\\\\\\\n-   \\\\\\\\\\\\\\\"display_name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Python 3 (ipykernel)\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"language\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"python\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"python3\\\\\\\\\\\\\\\"\\\\\\\\n-  },\\\\\\\\n-  \\\\\\\\\\\\\\\"language_info\\\\\\\\\\\\\\\": {\\\\\\\\n-   \\\\\\\\\\\\\\\"codemirror_mode\\\\\\\\\\\\\\\": {\\\\\\\\n-    \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"ipython\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"version\\\\\\\\\\\\\\\": 3\\\\\\\\n-   },\\\\\\\\n-   \\\\\\\\\\\\\\\"file_extension\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\".py\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"mimetype\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"text/x-python\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"python\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"nbconvert_exporter\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"python\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"pygments_lexer\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"ipython3\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"version\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"3.11.5\\\\\\\\\\\\\\\"\\\\\\\\n-  }\\\\\\\\n- },\\\\\\\\n- \\\\\\\\\\\\\\\"nbformat\\\\\\\\\\\\\\\": 4,\\\\\\\\n- \\\\\\\\\\\\\\\"nbformat_minor\\\\\\\\\\\\\\\": 5\\\\\\\\n-}\\\\\\\\ndiff --git a/notebooks/RQ_notebooks/RQ1_updated-Copy1.ipynb b/notebooks/RQ_notebooks/RQ1_updated-Copy1.ipynb\\\\\\\\ndeleted file mode 100644\\\\\\\\nindex 3a07d0e..0000000\\\\\\\\n--- a/notebooks/RQ_notebooks/RQ1_updated-Copy1.ipynb\\\\\\\\n+++ /dev/null\\\\\\\\n@@ -1,4255 +0,0 @@\\\\\\\\n-{\\\\\\\\n- \\\\\\\\\\\\\\\"cells\\\\\\\\\\\\\\\": [\\\\\\\\n-  {\\\\\\\\n-   \\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"code\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\\\": 1,\\\\\\\\n-   \\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"12fa6f59-927c-4003-964f-83e53793fd36\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {\\\\\\\\n-    \\\\\\\\\\\\\\\"scrolled\\\\\\\\\\\\\\\": true\\\\\\\\n-   },\\\\\\\\n-   \\\\\\\\\\\\\\\"outputs\\\\\\\\\\\\\\\": [],\\\\\\\\n-   \\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\": [\\\\\\\\n-    \\\\\\\\\\\\\\\"# TODO: atm the mlflow autolog isnt capturing metrics n params\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# and sklearn.autolog throws error( posted the issue on github)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# Ideally, I should be able to fetch most of the imp detail via MLFLOW AUTOLOG. will check that later in time\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#============================\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# \\\\\\\\ud83e\\\\\\\\udde0 MLflow Autologging\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# ============================\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# mlflow.autolog(log_input_examples=True, log_model_signatures=True)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# mlflow.sklearn.autolog() \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# mlflow.sklearn.autolog(\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     log_input_examples=True,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     log_model_signatures=True,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     log_post_training_metrics=True,        # calls model.score() \\\\\\\\u2192 accuracy\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     disable_for_unsupported_versions=True,  # skips if versions still wonky\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     exclusive=True                          # only patch the sklearn integration\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# )\\\\\\\\\\\\\\\"\\\\\\\\n-   ]\\\\\\\\n-  },\\\\\\\\n-  {\\\\\\\\n-   \\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"markdown\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"61d4d6b8-34a9-47b5-974d-5927c0ee2256\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {},\\\\\\\\n-   \\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\": [\\\\\\\\n-    \\\\\\\\\\\\\\\"DBREPO INTEGRETION\\\\\\\\\\\\\\\"\\\\\\\\n-   ]\\\\\\\\n-  },\\\\\\\\n-  {\\\\\\\\n-   \\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"code\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\\\": 88,\\\\\\\\n-   \\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"8e3570e2-9a60-45b4-8653-28060071e728\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {\\\\\\\\n-    \\\\\\\\\\\\\\\"scrolled\\\\\\\\\\\\\\\": true\\\\\\\\n-   },\\\\\\\\n-   \\\\\\\\\\\\\\\"outputs\\\\\\\\\\\\\\\": [\\\\\\\\n-    {\\\\\\\\n-     \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"stdout\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"output_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"stream\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\": [\\\\\\\\n-      \\\\\\\\\\\\\\\"API Response: [{'id': '1', 'sepallengthcm': '5.100000000000000000', 'sepalwidthcm': '3.500000000000000000', 'petallengthcm': '1.400000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '2', 'sepallengthcm': '4.900000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '1.400000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '3', 'sepallengthcm': '4.700000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '1.300000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '4', 'sepallengthcm': '4.600000000000000000', 'sepalwidthcm': '3.100000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '5', 'sepallengthcm': '5.000000000000000000', 'sepalwidthcm': '3.600000000000000000', 'petallengthcm': '1.400000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '6', 'sepallengthcm': '5.400000000000000000', 'sepalwidthcm': '3.900000000000000000', 'petallengthcm': '1.700000000000000000', 'petalwidthcm': '0.400000000000000000', 'species': 'Iris-setosa'}, {'id': '7', 'sepallengthcm': '4.600000000000000000', 'sepalwidthcm': '3.400000000000000000', 'petallengthcm': '1.400000000000000000', 'petalwidthcm': '0.300000000000000000', 'species': 'Iris-setosa'}, {'id': '8', 'sepallengthcm': '5.000000000000000000', 'sepalwidthcm': '3.400000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '9', 'sepallengthcm': '4.400000000000000000', 'sepalwidthcm': '2.900000000000000000', 'petallengthcm': '1.400000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '10', 'sepallengthcm': '4.900000000000000000', 'sepalwidthcm': '3.100000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.100000000000000000', 'species': 'Iris-setosa'}, {'id': '11', 'sepallengthcm': '5.400000000000000000', 'sepalwidthcm': '3.700000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '12', 'sepallengthcm': '4.800000000000000000', 'sepalwidthcm': '3.400000000000000000', 'petallengthcm': '1.600000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '13', 'sepallengthcm': '4.800000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '1.400000000000000000', 'petalwidthcm': '0.100000000000000000', 'species': 'Iris-setosa'}, {'id': '14', 'sepallengthcm': '4.300000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '1.100000000000000000', 'petalwidthcm': '0.100000000000000000', 'species': 'Iris-setosa'}, {'id': '15', 'sepallengthcm': '5.800000000000000000', 'sepalwidthcm': '4.000000000000000000', 'petallengthcm': '1.200000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '16', 'sepallengthcm': '5.700000000000000000', 'sepalwidthcm': '4.400000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.400000000000000000', 'species': 'Iris-setosa'}, {'id': '17', 'sepallengthcm': '5.400000000000000000', 'sepalwidthcm': '3.900000000000000000', 'petallengthcm': '1.300000000000000000', 'petalwidthcm': '0.400000000000000000', 'species': 'Iris-setosa'}, {'id': '18', 'sepallengthcm': '5.100000000000000000', 'sepalwidthcm': '3.500000000000000000', 'petallengthcm': '1.400000000000000000', 'petalwidthcm': '0.300000000000000000', 'species': 'Iris-setosa'}, {'id': '19', 'sepallengthcm': '5.700000000000000000', 'sepalwidthcm': '3.800000000000000000', 'petallengthcm': '1.700000000000000000', 'petalwidthcm': '0.300000000000000000', 'species': 'Iris-setosa'}, {'id': '20', 'sepallengthcm': '5.100000000000000000', 'sepalwidthcm': '3.800000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.300000000000000000', 'species': 'Iris-setosa'}, {'id': '21', 'sepallengthcm': '5.400000000000000000', 'sepalwidthcm': '3.400000000000000000', 'petallengthcm': '1.700000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '22', 'sepallengthcm': '5.100000000000000000', 'sepalwidthcm': '3.700000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.400000000000000000', 'species': 'Iris-setosa'}, {'id': '23', 'sepallengthcm': '4.600000000000000000', 'sepalwidthcm': '3.600000000000000000', 'petallengthcm': '1.000000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '24', 'sepallengthcm': '5.100000000000000000', 'sepalwidthcm': '3.300000000000000000', 'petallengthcm': '1.700000000000000000', 'petalwidthcm': '0.500000000000000000', 'species': 'Iris-setosa'}, {'id': '25', 'sepallengthcm': '4.800000000000000000', 'sepalwidthcm': '3.400000000000000000', 'petallengthcm': '1.900000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '26', 'sepallengthcm': '5.000000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '1.600000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '27', 'sepallengthcm': '5.000000000000000000', 'sepalwidthcm': '3.400000000000000000', 'petallengthcm': '1.600000000000000000', 'petalwidthcm': '0.400000000000000000', 'species': 'Iris-setosa'}, {'id': '28', 'sepallengthcm': '5.200000000000000000', 'sepalwidthcm': '3.500000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '29', 'sepallengthcm': '5.200000000000000000', 'sepalwidthcm': '3.400000000000000000', 'petallengthcm': '1.400000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '30', 'sepallengthcm': '4.700000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '1.600000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '31', 'sepallengthcm': '4.800000000000000000', 'sepalwidthcm': '3.100000000000000000', 'petallengthcm': '1.600000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '32', 'sepallengthcm': '5.400000000000000000', 'sepalwidthcm': '3.400000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.400000000000000000', 'species': 'Iris-setosa'}, {'id': '33', 'sepallengthcm': '5.200000000000000000', 'sepalwidthcm': '4.100000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.100000000000000000', 'species': 'Iris-setosa'}, {'id': '34', 'sepallengthcm': '5.500000000000000000', 'sepalwidthcm': '4.200000000000000000', 'petallengthcm': '1.400000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '35', 'sepallengthcm': '4.900000000000000000', 'sepalwidthcm': '3.100000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.100000000000000000', 'species': 'Iris-setosa'}, {'id': '36', 'sepallengthcm': '5.000000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '1.200000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '37', 'sepallengthcm': '5.500000000000000000', 'sepalwidthcm': '3.500000000000000000', 'petallengthcm': '1.300000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '38', 'sepallengthcm': '4.900000000000000000', 'sepalwidthcm': '3.100000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.100000000000000000', 'species': 'Iris-setosa'}, {'id': '39', 'sepallengthcm': '4.400000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '1.300000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '40', 'sepallengthcm': '5.100000000000000000', 'sepalwidthcm': '3.400000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '41', 'sepallengthcm': '5.000000000000000000', 'sepalwidthcm': '3.500000000000000000', 'petallengthcm': '1.300000000000000000', 'petalwidthcm': '0.300000000000000000', 'species': 'Iris-setosa'}, {'id': '42', 'sepallengthcm': '4.500000000000000000', 'sepalwidthcm': '2.300000000000000000', 'petallengthcm': '1.300000000000000000', 'petalwidthcm': '0.300000000000000000', 'species': 'Iris-setosa'}, {'id': '43', 'sepallengthcm': '4.400000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '1.300000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '44', 'sepallengthcm': '5.000000000000000000', 'sepalwidthcm': '3.500000000000000000', 'petallengthcm': '1.600000000000000000', 'petalwidthcm': '0.600000000000000000', 'species': 'Iris-setosa'}, {'id': '45', 'sepallengthcm': '5.100000000000000000', 'sepalwidthcm': '3.800000000000000000', 'petallengthcm': '1.900000000000000000', 'petalwidthcm': '0.400000000000000000', 'species': 'Iris-setosa'}, {'id': '46', 'sepallengthcm': '4.800000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '1.400000000000000000', 'petalwidthcm': '0.300000000000000000', 'species': 'Iris-setosa'}, {'id': '47', 'sepallengthcm': '5.100000000000000000', 'sepalwidthcm': '3.800000000000000000', 'petallengthcm': '1.600000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '48', 'sepallengthcm': '4.600000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '1.400000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '49', 'sepallengthcm': '5.300000000000000000', 'sepalwidthcm': '3.700000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '50', 'sepallengthcm': '5.000000000000000000', 'sepalwidthcm': '3.300000000000000000', 'petallengthcm': '1.400000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '51', 'sepallengthcm': '7.000000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '4.700000000000000000', 'petalwidthcm': '1.400000000000000000', 'species': 'Iris-versicolor'}, {'id': '52', 'sepallengthcm': '6.400000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '4.500000000000000000', 'petalwidthcm': '1.500000000000000000', 'species': 'Iris-versicolor'}, {'id': '53', 'sepallengthcm': '6.900000000000000000', 'sepalwidthcm': '3.100000000000000000', 'petallengthcm': '4.900000000000000000', 'petalwidthcm': '1.500000000000000000', 'species': 'Iris-versicolor'}, {'id': '54', 'sepallengthcm': '5.500000000000000000', 'sepalwidthcm': '2.300000000000000000', 'petallengthcm': '4.000000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '55', 'sepallengthcm': '6.500000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '4.600000000000000000', 'petalwidthcm': '1.500000000000000000', 'species': 'Iris-versicolor'}, {'id': '56', 'sepallengthcm': '5.700000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '4.500000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '57', 'sepallengthcm': '6.300000000000000000', 'sepalwidthcm': '3.300000000000000000', 'petallengthcm': '4.700000000000000000', 'petalwidthcm': '1.600000000000000000', 'species': 'Iris-versicolor'}, {'id': '58', 'sepallengthcm': '4.900000000000000000', 'sepalwidthcm': '2.400000000000000000', 'petallengthcm': '3.300000000000000000', 'petalwidthcm': '1.000000000000000000', 'species': 'Iris-versicolor'}, {'id': '59', 'sepallengthcm': '6.600000000000000000', 'sepalwidthcm': '2.900000000000000000', 'petallengthcm': '4.600000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '60', 'sepallengthcm': '5.200000000000000000', 'sepalwidthcm': '2.700000000000000000', 'petallengthcm': '3.900000000000000000', 'petalwidthcm': '1.400000000000000000', 'species': 'Iris-versicolor'}, {'id': '61', 'sepallengthcm': '5.000000000000000000', 'sepalwidthcm': '2.000000000000000000', 'petallengthcm': '3.500000000000000000', 'petalwidthcm': '1.000000000000000000', 'species': 'Iris-versicolor'}, {'id': '62', 'sepallengthcm': '5.900000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '4.200000000000000000', 'petalwidthcm': '1.500000000000000000', 'species': 'Iris-versicolor'}, {'id': '63', 'sepallengthcm': '6.000000000000000000', 'sepalwidthcm': '2.200000000000000000', 'petallengthcm': '4.000000000000000000', 'petalwidthcm': '1.000000000000000000', 'species': 'Iris-versicolor'}, {'id': '64', 'sepallengthcm': '6.100000000000000000', 'sepalwidthcm': '2.900000000000000000', 'petallengthcm': '4.700000000000000000', 'petalwidthcm': '1.400000000000000000', 'species': 'Iris-versicolor'}, {'id': '65', 'sepallengthcm': '5.600000000000000000', 'sepalwidthcm': '2.900000000000000000', 'petallengthcm': '3.600000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '66', 'sepallengthcm': '6.700000000000000000', 'sepalwidthcm': '3.100000000000000000', 'petallengthcm': '4.400000000000000000', 'petalwidthcm': '1.400000000000000000', 'species': 'Iris-versicolor'}, {'id': '67', 'sepallengthcm': '5.600000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '4.500000000000000000', 'petalwidthcm': '1.500000000000000000', 'species': 'Iris-versicolor'}, {'id': '68', 'sepallengthcm': '5.800000000000000000', 'sepalwidthcm': '2.700000000000000000', 'petallengthcm': '4.100000000000000000', 'petalwidthcm': '1.000000000000000000', 'species': 'Iris-versicolor'}, {'id': '69', 'sepallengthcm': '6.200000000000000000', 'sepalwidthcm': '2.200000000000000000', 'petallengthcm': '4.500000000000000000', 'petalwidthcm': '1.500000000000000000', 'species': 'Iris-versicolor'}, {'id': '70', 'sepallengthcm': '5.600000000000000000', 'sepalwidthcm': '2.500000000000000000', 'petallengthcm': '3.900000000000000000', 'petalwidthcm': '1.100000000000000000', 'species': 'Iris-versicolor'}, {'id': '71', 'sepallengthcm': '5.900000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '4.800000000000000000', 'petalwidthcm': '1.800000000000000000', 'species': 'Iris-versicolor'}, {'id': '72', 'sepallengthcm': '6.100000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '4.000000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '73', 'sepallengthcm': '6.300000000000000000', 'sepalwidthcm': '2.500000000000000000', 'petallengthcm': '4.900000000000000000', 'petalwidthcm': '1.500000000000000000', 'species': 'Iris-versicolor'}, {'id': '74', 'sepallengthcm': '6.100000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '4.700000000000000000', 'petalwidthcm': '1.200000000000000000', 'species': 'Iris-versicolor'}, {'id': '75', 'sepallengthcm': '6.400000000000000000', 'sepalwidthcm': '2.900000000000000000', 'petallengthcm': '4.300000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '76', 'sepallengthcm': '6.600000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '4.400000000000000000', 'petalwidthcm': '1.400000000000000000', 'species': 'Iris-versicolor'}, {'id': '77', 'sepallengthcm': '6.800000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '4.800000000000000000', 'petalwidthcm': '1.400000000000000000', 'species': 'Iris-versicolor'}, {'id': '78', 'sepallengthcm': '6.700000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '5.000000000000000000', 'petalwidthcm': '1.700000000000000000', 'species': 'Iris-versicolor'}, {'id': '79', 'sepallengthcm': '6.000000000000000000', 'sepalwidthcm': '2.900000000000000000', 'petallengthcm': '4.500000000000000000', 'petalwidthcm': '1.500000000000000000', 'species': 'Iris-versicolor'}, {'id': '80', 'sepallengthcm': '5.700000000000000000', 'sepalwidthcm': '2.600000000000000000', 'petallengthcm': '3.500000000000000000', 'petalwidthcm': '1.000000000000000000', 'species': 'Iris-versicolor'}, {'id': '81', 'sepallengthcm': '5.500000000000000000', 'sepalwidthcm': '2.400000000000000000', 'petallengthcm': '3.800000000000000000', 'petalwidthcm': '1.100000000000000000', 'species': 'Iris-versicolor'}, {'id': '82', 'sepallengthcm': '5.500000000000000000', 'sepalwidthcm': '2.400000000000000000', 'petallengthcm': '3.700000000000000000', 'petalwidthcm': '1.000000000000000000', 'species': 'Iris-versicolor'}, {'id': '83', 'sepallengthcm': '5.800000000000000000', 'sepalwidthcm': '2.700000000000000000', 'petallengthcm': '3.900000000000000000', 'petalwidthcm': '1.200000000000000000', 'species': 'Iris-versicolor'}, {'id': '84', 'sepallengthcm': '6.000000000000000000', 'sepalwidthcm': '2.700000000000000000', 'petallengthcm': '5.100000000000000000', 'petalwidthcm': '1.600000000000000000', 'species': 'Iris-versicolor'}, {'id': '85', 'sepallengthcm': '5.400000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '4.500000000000000000', 'petalwidthcm': '1.500000000000000000', 'species': 'Iris-versicolor'}, {'id': '86', 'sepallengthcm': '6.000000000000000000', 'sepalwidthcm': '3.400000000000000000', 'petallengthcm': '4.500000000000000000', 'petalwidthcm': '1.600000000000000000', 'species': 'Iris-versicolor'}, {'id': '87', 'sepallengthcm': '6.700000000000000000', 'sepalwidthcm': '3.100000000000000000', 'petallengthcm': '4.700000000000000000', 'petalwidthcm': '1.500000000000000000', 'species': 'Iris-versicolor'}, {'id': '88', 'sepallengthcm': '6.300000000000000000', 'sepalwidthcm': '2.300000000000000000', 'petallengthcm': '4.400000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '89', 'sepallengthcm': '5.600000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '4.100000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '90', 'sepallengthcm': '5.500000000000000000', 'sepalwidthcm': '2.500000000000000000', 'petallengthcm': '4.000000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '91', 'sepallengthcm': '5.500000000000000000', 'sepalwidthcm': '2.600000000000000000', 'petallengthcm': '4.400000000000000000', 'petalwidthcm': '1.200000000000000000', 'species': 'Iris-versicolor'}, {'id': '92', 'sepallengthcm': '6.100000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '4.600000000000000000', 'petalwidthcm': '1.400000000000000000', 'species': 'Iris-versicolor'}, {'id': '93', 'sepallengthcm': '5.800000000000000000', 'sepalwidthcm': '2.600000000000000000', 'petallengthcm': '4.000000000000000000', 'petalwidthcm': '1.200000000000000000', 'species': 'Iris-versicolor'}, {'id': '94', 'sepallengthcm': '5.000000000000000000', 'sepalwidthcm': '2.300000000000000000', 'petallengthcm': '3.300000000000000000', 'petalwidthcm': '1.000000000000000000', 'species': 'Iris-versicolor'}, {'id': '95', 'sepallengthcm': '5.600000000000000000', 'sepalwidthcm': '2.700000000000000000', 'petallengthcm': '4.200000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '96', 'sepallengthcm': '5.700000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '4.200000000000000000', 'petalwidthcm': '1.200000000000000000', 'species': 'Iris-versicolor'}, {'id': '97', 'sepallengthcm': '5.700000000000000000', 'sepalwidthcm': '2.900000000000000000', 'petallengthcm': '4.200000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '98', 'sepallengthcm': '6.200000000000000000', 'sepalwidthcm': '2.900000000000000000', 'petallengthcm': '4.300000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '99', 'sepallengthcm': '5.100000000000000000', 'sepalwidthcm': '2.500000000000000000', 'petallengthcm': '3.000000000000000000', 'petalwidthcm': '1.100000000000000000', 'species': 'Iris-versicolor'}, {'id': '100', 'sepallengthcm': '5.700000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '4.100000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '101', 'sepallengthcm': '6.300000000000000000', 'sepalwidthcm': '3.300000000000000000', 'petallengthcm': '6.000000000000000000', 'petalwidthcm': '2.500000000000000000', 'species': 'Iris-virginica'}, {'id': '102', 'sepallengthcm': '5.800000000000000000', 'sepalwidthcm': '2.700000000000000000', 'petallengthcm': '5.100000000000000000', 'petalwidthcm': '1.900000000000000000', 'species': 'Iris-virginica'}, {'id': '103', 'sepallengthcm': '7.100000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '5.900000000000000000', 'petalwidthcm': '2.100000000000000000', 'species': 'Iris-virginica'}, {'id': '104', 'sepallengthcm': '6.300000000000000000', 'sepalwidthcm': '2.900000000000000000', 'petallengthcm': '5.600000000000000000', 'petalwidthcm': '1.800000000000000000', 'species': 'Iris-virginica'}, {'id': '105', 'sepallengthcm': '6.500000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '5.800000000000000000', 'petalwidthcm': '2.200000000000000000', 'species': 'Iris-virginica'}, {'id': '106', 'sepallengthcm': '7.600000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '6.600000000000000000', 'petalwidthcm': '2.100000000000000000', 'species': 'Iris-virginica'}, {'id': '107', 'sepallengthcm': '4.900000000000000000', 'sepalwidthcm': '2.500000000000000000', 'petallengthcm': '4.500000000000000000', 'petalwidthcm': '1.700000000000000000', 'species': 'Iris-virginica'}, {'id': '108', 'sepallengthcm': '7.300000000000000000', 'sepalwidthcm': '2.900000000000000000', 'petallengthcm': '6.300000000000000000', 'petalwidthcm': '1.800000000000000000', 'species': 'Iris-virginica'}, {'id': '109', 'sepallengthcm': '6.700000000000000000', 'sepalwidthcm': '2.500000000000000000', 'petallengthcm': '5.800000000000000000', 'petalwidthcm': '1.800000000000000000', 'species': 'Iris-virginica'}, {'id': '110', 'sepallengthcm': '7.200000000000000000', 'sepalwidthcm': '3.600000000000000000', 'petallengthcm': '6.100000000000000000', 'petalwidthcm': '2.500000000000000000', 'species': 'Iris-virginica'}, {'id': '111', 'sepallengthcm': '6.500000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '5.100000000000000000', 'petalwidthcm': '2.000000000000000000', 'species': 'Iris-virginica'}, {'id': '112', 'sepallengthcm': '6.400000000000000000', 'sepalwidthcm': '2.700000000000000000', 'petallengthcm': '5.300000000000000000', 'petalwidthcm': '1.900000000000000000', 'species': 'Iris-virginica'}, {'id': '113', 'sepallengthcm': '6.800000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '5.500000000000000000', 'petalwidthcm': '2.100000000000000000', 'species': 'Iris-virginica'}, {'id': '114', 'sepallengthcm': '5.700000000000000000', 'sepalwidthcm': '2.500000000000000000', 'petallengthcm': '5.000000000000000000', 'petalwidthcm': '2.000000000000000000', 'species': 'Iris-virginica'}, {'id': '115', 'sepallengthcm': '5.800000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '5.100000000000000000', 'petalwidthcm': '2.400000000000000000', 'species': 'Iris-virginica'}, {'id': '116', 'sepallengthcm': '6.400000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '5.300000000000000000', 'petalwidthcm': '2.300000000000000000', 'species': 'Iris-virginica'}, {'id': '117', 'sepallengthcm': '6.500000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '5.500000000000000000', 'petalwidthcm': '1.800000000000000000', 'species': 'Iris-virginica'}, {'id': '118', 'sepallengthcm': '7.700000000000000000', 'sepalwidthcm': '3.800000000000000000', 'petallengthcm': '6.700000000000000000', 'petalwidthcm': '2.200000000000000000', 'species': 'Iris-virginica'}, {'id': '119', 'sepallengthcm': '7.700000000000000000', 'sepalwidthcm': '2.600000000000000000', 'petallengthcm': '6.900000000000000000', 'petalwidthcm': '2.300000000000000000', 'species': 'Iris-virginica'}, {'id': '120', 'sepallengthcm': '6.000000000000000000', 'sepalwidthcm': '2.200000000000000000', 'petallengthcm': '5.000000000000000000', 'petalwidthcm': '1.500000000000000000', 'species': 'Iris-virginica'}, {'id': '121', 'sepallengthcm': '6.900000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '5.700000000000000000', 'petalwidthcm': '2.300000000000000000', 'species': 'Iris-virginica'}, {'id': '122', 'sepallengthcm': '5.600000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '4.900000000000000000', 'petalwidthcm': '2.000000000000000000', 'species': 'Iris-virginica'}, {'id': '123', 'sepallengthcm': '7.700000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '6.700000000000000000', 'petalwidthcm': '2.000000000000000000', 'species': 'Iris-virginica'}, {'id': '124', 'sepallengthcm': '6.300000000000000000', 'sepalwidthcm': '2.700000000000000000', 'petallengthcm': '4.900000000000000000', 'petalwidthcm': '1.800000000000000000', 'species': 'Iris-virginica'}, {'id': '125', 'sepallengthcm': '6.700000000000000000', 'sepalwidthcm': '3.300000000000000000', 'petallengthcm': '5.700000000000000000', 'petalwidthcm': '2.100000000000000000', 'species': 'Iris-virginica'}, {'id': '126', 'sepallengthcm': '7.200000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '6.000000000000000000', 'petalwidthcm': '1.800000000000000000', 'species': 'Iris-virginica'}, {'id': '127', 'sepallengthcm': '6.200000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '4.800000000000000000', 'petalwidthcm': '1.800000000000000000', 'species': 'Iris-virginica'}, {'id': '128', 'sepallengthcm': '6.100000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '4.900000000000000000', 'petalwidthcm': '1.800000000000000000', 'species': 'Iris-virginica'}, {'id': '129', 'sepallengthcm': '6.400000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '5.600000000000000000', 'petalwidthcm': '2.100000000000000000', 'species': 'Iris-virginica'}, {'id': '130', 'sepallengthcm': '7.200000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '5.800000000000000000', 'petalwidthcm': '1.600000000000000000', 'species': 'Iris-virginica'}, {'id': '131', 'sepallengthcm': '7.400000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '6.100000000000000000', 'petalwidthcm': '1.900000000000000000', 'species': 'Iris-virginica'}, {'id': '132', 'sepallengthcm': '7.900000000000000000', 'sepalwidthcm': '3.800000000000000000', 'petallengthcm': '6.400000000000000000', 'petalwidthcm': '2.000000000000000000', 'species': 'Iris-virginica'}, {'id': '133', 'sepallengthcm': '6.400000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '5.600000000000000000', 'petalwidthcm': '2.200000000000000000', 'species': 'Iris-virginica'}, {'id': '134', 'sepallengthcm': '6.300000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '5.100000000000000000', 'petalwidthcm': '1.500000000000000000', 'species': 'Iris-virginica'}, {'id': '135', 'sepallengthcm': '6.100000000000000000', 'sepalwidthcm': '2.600000000000000000', 'petallengthcm': '5.600000000000000000', 'petalwidthcm': '1.400000000000000000', 'species': 'Iris-virginica'}, {'id': '136', 'sepallengthcm': '7.700000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '6.100000000000000000', 'petalwidthcm': '2.300000000000000000', 'species': 'Iris-virginica'}, {'id': '137', 'sepallengthcm': '6.300000000000000000', 'sepalwidthcm': '3.400000000000000000', 'petallengthcm': '5.600000000000000000', 'petalwidthcm': '2.400000000000000000', 'species': 'Iris-virginica'}, {'id': '138', 'sepallengthcm': '6.400000000000000000', 'sepalwidthcm': '3.100000000000000000', 'petallengthcm': '5.500000000000000000', 'petalwidthcm': '1.800000000000000000', 'species': 'Iris-virginica'}, {'id': '139', 'sepallengthcm': '6.000000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '4.800000000000000000', 'petalwidthcm': '1.800000000000000000', 'species': 'Iris-virginica'}, {'id': '140', 'sepallengthcm': '6.900000000000000000', 'sepalwidthcm': '3.100000000000000000', 'petallengthcm': '5.400000000000000000', 'petalwidthcm': '2.100000000000000000', 'species': 'Iris-virginica'}, {'id': '141', 'sepallengthcm': '6.700000000000000000', 'sepalwidthcm': '3.100000000000000000', 'petallengthcm': '5.600000000000000000', 'petalwidthcm': '2.400000000000000000', 'species': 'Iris-virginica'}, {'id': '142', 'sepallengthcm': '6.900000000000000000', 'sepalwidthcm': '3.100000000000000000', 'petallengthcm': '5.100000000000000000', 'petalwidthcm': '2.300000000000000000', 'species': 'Iris-virginica'}, {'id': '143', 'sepallengthcm': '5.800000000000000000', 'sepalwidthcm': '2.700000000000000000', 'petallengthcm': '5.100000000000000000', 'petalwidthcm': '1.900000000000000000', 'species': 'Iris-virginica'}, {'id': '144', 'sepallengthcm': '6.800000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '5.900000000000000000', 'petalwidthcm': '2.300000000000000000', 'species': 'Iris-virginica'}, {'id': '145', 'sepallengthcm': '6.700000000000000000', 'sepalwidthcm': '3.300000000000000000', 'petallengthcm': '5.700000000000000000', 'petalwidthcm': '2.500000000000000000', 'species': 'Iris-virginica'}, {'id': '146', 'sepallengthcm': '6.700000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '5.200000000000000000', 'petalwidthcm': '2.300000000000000000', 'species': 'Iris-virginica'}, {'id': '147', 'sepallengthcm': '6.300000000000000000', 'sepalwidthcm': '2.500000000000000000', 'petallengthcm': '5.000000000000000000', 'petalwidthcm': '1.900000000000000000', 'species': 'Iris-virginica'}, {'id': '148', 'sepallengthcm': '6.500000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '5.200000000000000000', 'petalwidthcm': '2.000000000000000000', 'species': 'Iris-virginica'}, {'id': '149', 'sepallengthcm': '6.200000000000000000', 'sepalwidthcm': '3.400000000000000000', 'petallengthcm': '5.400000000000000000', 'petalwidthcm': '2.300000000000000000', 'species': 'Iris-virginica'}, {'id': '150', 'sepallengthcm': '5.900000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '5.100000000000000000', 'petalwidthcm': '1.800000000000000000', 'species': 'Iris-virginica'}]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"<built-in method count of list object at 0x000001EF7FA4E400>\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n-     ]\\\\\\\\n-    }\\\\\\\\n-   ],\\\\\\\\n-   \\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\": [\\\\\\\\n-    \\\\\\\\\\\\\\\"import requests\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# API endpoint URL\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"API_URL = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"http://localhost/api/database/c3a42d17-42b7-43c9-a504-2363fb4c9c8d/table/5315e7da-64fb-4fdb-b493-95b4138c765f/data?size=100000&page=0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# Define the headers\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"headers = {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Accept\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"application/json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"  # Specify the expected response format\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"try:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # Send a GET request to the API with the Accept header\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    response = requests.get(API_URL, headers=headers)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # Check if the request was successful\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    if response.status_code == 200:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        # Parse the JSON response\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        dataset = response.json()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"API Response:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", dataset)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        print( dataset.count)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    else:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Error: Received status code {response.status_code}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Response content:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", response.text)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"       \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"except requests.exceptions.RequestException as e:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Request failed: {e}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n-   ]\\\\\\\\n-  },\\\\\\\\n-  {\\\\\\\\n-   \\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"markdown\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"09557f94-325c-4bd6-882a-069a9e3c5ecd\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {},\\\\\\\\n-   \\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\": [\\\\\\\\n-    \\\\\\\\\\\\\\\"replacing dynamic fetching of data while i integrete invenio\\\\\\\\\\\\\\\"\\\\\\\\n-   ]\\\\\\\\n-  },\\\\\\\\n-  {\\\\\\\\n-   \\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"code\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\\\": 90,\\\\\\\\n-   \\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"ce6e020d-cb80-49ec-8bcc-687b1e08885c\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {},\\\\\\\\n-   \\\\\\\\\\\\\\\"outputs\\\\\\\\\\\\\\\": [],\\\\\\\\n-   \\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\": [\\\\\\\\n-    \\\\\\\\\\\\\\\"# 2a. Save raw JSON\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# with open(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"iris_data.json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"w\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\") as f:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     json.dump(dataset, f, indent=2)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# 1. Read the JSON file\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"with open(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"iris_data.json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"r\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\") as f:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    dataset = json.load(f)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n-   ]\\\\\\\\n-  },\\\\\\\\n-  {\\\\\\\\n-   \\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"markdown\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"a6c6007a-2126-4b1a-90ee-3326eb39a362\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {},\\\\\\\\n-   \\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\": [\\\\\\\\n-    \\\\\\\\\\\\\\\"Metadata fetching from db repo\\\\\\\\\\\\\\\"\\\\\\\\n-   ]\\\\\\\\n-  },\\\\\\\\n-  {\\\\\\\\n-   \\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"code\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\\\": 3,\\\\\\\\n-   \\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"abe912e7-bf9b-4bbd-8e43-6046745ade3f\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {\\\\\\\\n-    \\\\\\\\\\\\\\\"scrolled\\\\\\\\\\\\\\\": true\\\\\\\\n-   },\\\\\\\\n-   \\\\\\\\\\\\\\\"outputs\\\\\\\\\\\\\\\": [],\\\\\\\\n-   \\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\": [\\\\\\\\n-    \\\\\\\\\\\\\\\"import requests\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"import mlflow\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"DB_API = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"http://localhost/api/database/{db_id}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"def fetch_db_metadata(db_id: str) -> dict:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    url = DB_API.format(db_id=db_id)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    resp = requests.get(url)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    resp.raise_for_status()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    return resp.json()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"def log_db_metadata(db_meta: dict):\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # 1) core DB fields as params\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    mlflow.log_param(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"database.id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",          db_meta[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"])\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    mlflow.log_param(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"database.name\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",        db_meta[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"])\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    mlflow.log_param(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"database.description\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", db_meta.get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"description\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"))\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    owner = db_meta[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"tables\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"][0][\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"owner\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"][\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"username\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    mlflow.log_param(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"database.owner\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",       owner)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n-   ]\\\\\\\\n-  },\\\\\\\\n-  {\\\\\\\\n-   \\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"code\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\\\": 4,\\\\\\\\n-   \\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"296f307e-e01b-477a-9406-92cab9f2d7bf\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {},\\\\\\\\n-   \\\\\\\\\\\\\\\"outputs\\\\\\\\\\\\\\\": [\\\\\\\\n-    {\\\\\\\\n-     \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"stdout\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"output_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"stream\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\": [\\\\\\\\n-      \\\\\\\\\\\\\\\"<ns0:OAI-PMH xmlns:ns0=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"http://www.openarchives.org/OAI/2.0/\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" xmlns:xsi=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"http://www.w3.org/2001/XMLSchema-instance\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" xsi:schemaLocation=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"    <ns0:responseDate>2025-04-23T20:56:28Z</ns0:responseDate>\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"    <ns0:request verb=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Identify\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">https://localhost/api/oai</ns0:request>\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"    <ns0:Identify>\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"    <ns0:repositoryName>Database Repository</ns0:repositoryName>\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"    <ns0:baseURL>http://localhost</ns0:baseURL>\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"    <ns0:protocolVersion>2.0</ns0:protocolVersion>\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"    <ns0:adminEmail>noreply@localhost</ns0:adminEmail>\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"    <ns0:earliestDatestamp />\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"    <ns0:deletedRecord>persistent</ns0:deletedRecord>\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"    <ns0:granularity>YYYY-MM-DDThh:mm:ssZ</ns0:granularity>\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"</ns0:Identify>\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"</ns0:OAI-PMH>\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n-     ]\\\\\\\\n-    }\\\\\\\\n-   ],\\\\\\\\n-   \\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\": [\\\\\\\\n-    \\\\\\\\\\\\\\\"import requests\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"import xml.etree.ElementTree as ET\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"import urllib.parse\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"import mlflow, requests, json\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"import pandas as pd\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# 1) Fetch your database metadata\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"db_url = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"http://localhost/api/database/c3a42d17-42b7-43c9-a504-2363fb4c9c8d\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"db_resp = requests.get(db_url)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"db_resp.raise_for_status()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"db_data = db_resp.json()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"db_id  = db_data[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"tbl_id = db_data[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"tables\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"][0][\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# 2) Build the OAI-PMH URL, URL-encoding the `set` param\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"set_param   = f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Databases/{db_id}/Tables/{tbl_id}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"encoded_set = urllib.parse.quote(set_param, safe=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"oai_url = (\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"http://localhost/api/oai\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"?metadataPrefix=oai_dc\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"&from=2025-03-01\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"&until=2025-03-07\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"&set={encoded_set}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"&resumptionToken=string\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"&fromDate=2025-03-07T19%3A35%3A51.476Z\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"&untilDate=2025-03-07T19%3A35%3A51.476Z\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"&parametersString=string\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# 3) Call and parse\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"try:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    resp = requests.get(oai_url)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    resp.raise_for_status()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    if \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"xml\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in resp.headers.get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Content-Type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"):\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        root = ET.fromstring(resp.text)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        print(ET.tostring(root, encoding=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"utf-8\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\").decode())\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    else:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Non-XML response:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", resp.headers.get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Content-Type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"), resp.text)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"except requests.exceptions.RequestException as e:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Request failed:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", e)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n-   ]\\\\\\\\n-  },\\\\\\\\n-  {\\\\\\\\n-   \\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"code\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\\\": 5,\\\\\\\\n-   \\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"61cc99ab-4a5c-4142-8725-e7c940673ffd\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {},\\\\\\\\n-   \\\\\\\\\\\\\\\"outputs\\\\\\\\\\\\\\\": [],\\\\\\\\n-   \\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\": [\\\\\\\\n-    \\\\\\\\\\\\\\\"import xml.etree.ElementTree as ET\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# \\\\\\\\u2026after you fetch & parse your XML into `root`\\\\\\\\u2026\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"ns = {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"oai\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"http://www.openarchives.org/OAI/2.0/\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"repo_name   = root.findtext(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"oai:Identify/oai:repositoryName\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",   namespaces=ns)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"base_url    = root.findtext(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"oai:Identify/oai:baseURL\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",          namespaces=ns)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"protocol    = root.findtext(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"oai:Identify/oai:protocolVersion\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",  namespaces=ns)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"admin_email = root.findtext(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"oai:Identify/oai:adminEmail\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",       namespaces=ns)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"gran        = root.findtext(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"oai:Identify/oai:granularity\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",      namespaces=ns)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n-   ]\\\\\\\\n-  },\\\\\\\\n-  {\\\\\\\\n-   \\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"markdown\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"74214aa7-c12f-414e-9feb-094a366b855b\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {},\\\\\\\\n-   \\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\": [\\\\\\\\n-    \\\\\\\\\\\\\\\"History Logging\\\\\\\\\\\\\\\"\\\\\\\\n-   ]\\\\\\\\n-  },\\\\\\\\n-  {\\\\\\\\n-   \\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"code\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\\\": 6,\\\\\\\\n-   \\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"e9c74e9b-c9b0-4b4a-82eb-2a6e56456508\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {},\\\\\\\\n-   \\\\\\\\\\\\\\\"outputs\\\\\\\\\\\\\\\": [\\\\\\\\n-    {\\\\\\\\n-     \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"stdout\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"output_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"stream\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\": [\\\\\\\\n-      \\\\\\\\\\\\\\\"API Response: [{'timestamp': '2025-04-23T20:42:29.501Z', 'event': 'insert', 'total': 150}]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n-     ]\\\\\\\\n-    }\\\\\\\\n-   ],\\\\\\\\n-   \\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\": [\\\\\\\\n-    \\\\\\\\\\\\\\\"url = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"http://localhost/api/database/c3a42d17-42b7-43c9-a504-2363fb4c9c8d/table/5315e7da-64fb-4fdb-b493-95b4138c765f/history\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"try:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # Send a GET request to the API\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    response = requests.get(url)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # Check if the request was successful\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    if response.status_code == 200:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        # Parse the JSON response\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        data = response.json()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"API Response:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", data)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    else:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Error: Received status code {response.status_code}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Response content:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", response.text)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"except requests.exceptions.RequestException as e:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Request failed: {e}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\"\\\\\\\\n-   ]\\\\\\\\n-  },\\\\\\\\n-  {\\\\\\\\n-   \\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"code\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\\\": 7,\\\\\\\\n-   \\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"3630c954-5ad2-4759-b9a0-fa6e20e184ef\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {},\\\\\\\\n-   \\\\\\\\\\\\\\\"outputs\\\\\\\\\\\\\\\": [],\\\\\\\\n-   \\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\": [\\\\\\\\n-    \\\\\\\\\\\\\\\"first   = data[0]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"last    = data[-1]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"count_0 = first[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"total\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"]    # e.g. 149\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"count_N = last[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"total\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"]     # e.g. 149 again, or changed\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"ts_last = last[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"]  # e.g. \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"2025-03-28T17:42:38.058Z\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"n_insert = sum(1 for ev in data if ev[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"event\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"]==\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"insert\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"n_delete = sum(1 for ev in data if ev[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"event\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"]==\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"delete\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"history = response.json()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"first, last = history[0], history[-1]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# summary stats\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"count_start = first[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"total\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"count_end   = last[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"total\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"ts_last     = last[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"n_insert    = sum(1 for ev in history if ev[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"event\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"]==\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"insert\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"n_delete    = sum(1 for ev in history if ev[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"event\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"]==\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"delete\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\"\\\\\\\\n-   ]\\\\\\\\n-  },\\\\\\\\n-  {\\\\\\\\n-   \\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"markdown\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"1afd5dad-72d5-42e1-a0fa-b7bd3455937b\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {},\\\\\\\\n-   \\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\": [\\\\\\\\n-    \\\\\\\\\\\\\\\"Dataset metadata fetching from ZONEDO or any public dataset repositories to gain more details\\\\\\\\\\\\\\\"\\\\\\\\n-   ]\\\\\\\\n-  },\\\\\\\\n-  {\\\\\\\\n-   \\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"code\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\\\": 40,\\\\\\\\n-   \\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"a7fa122a-c6e5-4b38-842a-dc81590a1f46\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {},\\\\\\\\n-   \\\\\\\\\\\\\\\"outputs\\\\\\\\\\\\\\\": [],\\\\\\\\n-   \\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\": [\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"def fetch_and_log_dataset_metadata_nested(doi_url: str):\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # 1) fetch the CSL+JSON\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    headers = {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Accept\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"application/vnd.citationstyles.csl+json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    r = requests.get(doi_url, headers=headers); r.raise_for_status()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    meta = r.json()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # 2) pull out what you care about\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    authors = [f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{a.get('family','')} {a.get('given','')}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".strip()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"               for a in meta.get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"author\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", [])]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    pubdate = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"-\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".join(str(x) for x in meta.get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"issued\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",{}).get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"date-parts\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",[[]])[0])\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # 3) assemble one nested dict\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    public_datasetRepository_metadata = {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"zenodo\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"title\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":     meta.get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"title\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"),\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"doi\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":       meta.get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"DOI\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"),\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"authors\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":   authors,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"published\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": pubdate,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"publisher\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": meta.get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"publisher\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"),\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"      },\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"   \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"      # 4) log it as a single JSON artifact\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    mlflow.log_dict(public_datasetRepository_metadata,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"public_datasetRepository_metadata.json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # 2) Flatten and log the important bits as params:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    z = public_datasetRepository_metadata[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"zenodo\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    mlflow.log_param(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"dataset.title\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",     z[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"title\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"])\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    mlflow.log_param(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"dataset.doi\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",       z[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"doi\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"])\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    mlflow.log_param(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"dataset.authors\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",   json.dumps(z[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"authors\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"]))\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    mlflow.log_param(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"dataset.published\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", z[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"published\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"])\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    mlflow.log_param(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"dataset.publisher\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", z[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"publisher\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"])\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"   \\\\\\\\\\\\\\\"\\\\\\\\n-   ]\\\\\\\\n-  },\\\\\\\\n-  {\\\\\\\\n-   \\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"markdown\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"9832d0df-af0a-4eee-90d0-fab926e03e85\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {},\\\\\\\\n-   \\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\": [\\\\\\\\n-    \\\\\\\\\\\\\\\"DATA PREPROCESSING\\\\\\\\\\\\\\\"\\\\\\\\n-   ]\\\\\\\\n-  },\\\\\\\\n-  {\\\\\\\\n-   \\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"code\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\\\": 91,\\\\\\\\n-   \\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"77402d80-22d1-4bed-9489-768958c3e9fa\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {},\\\\\\\\n-   \\\\\\\\\\\\\\\"outputs\\\\\\\\\\\\\\\": [],\\\\\\\\n-   \\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\": [\\\\\\\\n-    \\\\\\\\\\\\\\\"# \\\\\\\\u2500\\\\\\\\u2500 2) Load into a DataFrame \\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"df = pd.DataFrame(dataset)\\\\\\\\\\\\\\\"\\\\\\\\n-   ]\\\\\\\\n-  },\\\\\\\\n-  {\\\\\\\\n-   \\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"code\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\\\": 92,\\\\\\\\n-   \\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"01309a7b-53d2-4df4-b334-0f0db8b03333\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {},\\\\\\\\n-   \\\\\\\\\\\\\\\"outputs\\\\\\\\\\\\\\\": [\\\\\\\\n-    {\\\\\\\\n-     \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"stdout\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"output_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"stream\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\": [\\\\\\\\n-      \\\\\\\\\\\\\\\"Shapes: (150, 4) (150,)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n-     ]\\\\\\\\n-    }\\\\\\\\n-   ],\\\\\\\\n-   \\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\": [\\\\\\\\n-    \\\\\\\\\\\\\\\"target_col = df.columns[-1]      # e.g. \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"species\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# 2) extract y as the Series of labels\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"y = df[target_col]               # length == n_samples\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# 3) build X by dropping just that one column\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"X = df.drop(columns=[target_col])\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# 4) drop any ID column (case-insensitive)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"id_cols = [c for c in X.columns if c.lower() == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"if id_cols:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    X = X.drop(columns=id_cols)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# 5) coerce numeric where possible\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"for c in X.columns:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    try:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        X[c] = pd.to_numeric(X[c])\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    except Exception:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        pass\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Shapes:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", X.shape, y.shape)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# \\\\\\\\u2192 (150, 4) (150,)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n-   ]\\\\\\\\n-  },\\\\\\\\n-  {\\\\\\\\n-   \\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"code\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\\\": 93,\\\\\\\\n-   \\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"11f5126d-6a03-48c6-9ecf-39ed0d43688c\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {},\\\\\\\\n-   \\\\\\\\\\\\\\\"outputs\\\\\\\\\\\\\\\": [\\\\\\\\n-    {\\\\\\\\n-     \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"stdout\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"output_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"stream\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\": [\\\\\\\\n-      \\\\\\\\\\\\\\\"Classes: ['Iris-setosa' 'Iris-versicolor' 'Iris-virginica']\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n-     ]\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-     \\\\\\\\\\\\\\\"data\\\\\\\\\\\\\\\": {\\\\\\\\n-      \\\\\\\\\\\\\\\"text/plain\\\\\\\\\\\\\\\": [\\\\\\\\n-       \\\\\\\\\\\\\\\"array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-       \\\\\\\\\\\\\\\"       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-       \\\\\\\\\\\\\\\"       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-       \\\\\\\\\\\\\\\"       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-       \\\\\\\\\\\\\\\"       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-       \\\\\\\\\\\\\\\"       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-       \\\\\\\\\\\\\\\"       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\\\\\\\\\\\\\\\"\\\\\\\\n-      ]\\\\\\\\n-     },\\\\\\\\n-     \\\\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\\\": 93,\\\\\\\\n-     \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {},\\\\\\\\n-     \\\\\\\\\\\\\\\"output_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"execute_result\\\\\\\\\\\\\\\"\\\\\\\\n-    }\\\\\\\\n-   ],\\\\\\\\n-   \\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\": [\\\\\\\\n-    \\\\\\\\\\\\\\\"from sklearn.preprocessing import LabelEncoder\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"le = LabelEncoder()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"y = le.fit_transform(y)  \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# now y_enc is a 1d numpy array of ints 0,1,2\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Classes:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", le.classes_)  \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"y\\\\\\\\\\\\\\\"\\\\\\\\n-   ]\\\\\\\\n-  },\\\\\\\\n-  {\\\\\\\\n-   \\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"code\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\\\": 103,\\\\\\\\n-   \\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"68d0a924-c65f-4a44-a5cc-bbb32d17e96f\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {},\\\\\\\\n-   \\\\\\\\\\\\\\\"outputs\\\\\\\\\\\\\\\": [],\\\\\\\\n-   \\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\": [\\\\\\\\n-    \\\\\\\\\\\\\\\"# \\\\\\\\u2500\\\\\\\\u2500 4) Cast feature columns to numeric where possible \\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"for col in X.columns:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    try:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        X[col] = pd.to_numeric(X[col])   # no errors=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"ignore\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    except ValueError:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        # if it can\\\\\\\\u2019t be cast, just leave it as-is\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        pass\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n-   ]\\\\\\\\n-  },\\\\\\\\n-  {\\\\\\\\n-   \\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"code\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\\\": 104,\\\\\\\\n-   \\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"e17f39ce-3322-4626-83a6-079d304bbc04\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {},\\\\\\\\n-   \\\\\\\\\\\\\\\"outputs\\\\\\\\\\\\\\\": [],\\\\\\\\n-   \\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\": [\\\\\\\\n-    \\\\\\\\\\\\\\\"# \\\\\\\\u2500\\\\\\\\u2500 5) Drop any \\\\\\\\u201cid\\\\\\\\u201d column (case-insensitive) \\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"dropped = [c for c in X.columns if c.lower() == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"X = X.drop(columns=dropped, errors=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"ignore\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\"\\\\\\\\n-   ]\\\\\\\\n-  },\\\\\\\\n-  {\\\\\\\\n-   \\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"code\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\\\": 55,\\\\\\\\n-   \\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"46f00853-206c-4fd1-b627-38115ae95a0f\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {\\\\\\\\n-    \\\\\\\\\\\\\\\"scrolled\\\\\\\\\\\\\\\": true\\\\\\\\n-   },\\\\\\\\n-   \\\\\\\\\\\\\\\"outputs\\\\\\\\\\\\\\\": [],\\\\\\\\n-   \\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\": [\\\\\\\\n-    \\\\\\\\\\\\\\\"# RQ1.2: Model Provenance Tracking in Jupyter Notebook using MLflow\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# Updated with automatic logging of environment, Git, model config, and FAIR-aligned metadata\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# ============================\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# \\\\\\\\u2699\\\\\\\\ufe0f Install Dependencies (if needed in Colab)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# ============================\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# !pip install mlflow scikit-learn pandas numpy matplotlib seaborn shap requests GitPython\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n-   ]\\\\\\\\n-  },\\\\\\\\n-  {\\\\\\\\n-   \\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"code\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\\\": 56,\\\\\\\\n-   \\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"3475b9b8-173d-4b5b-8913-de384dc60e67\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {},\\\\\\\\n-   \\\\\\\\\\\\\\\"outputs\\\\\\\\\\\\\\\": [],\\\\\\\\n-   \\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\": [\\\\\\\\n-    \\\\\\\\\\\\\\\"# !pip install --upgrade threadpoolctl\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# !pip install setuptools\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# !pip install ace_tools \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n-   ]\\\\\\\\n-  },\\\\\\\\n-  {\\\\\\\\n-   \\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"code\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\\\": 57,\\\\\\\\n-   \\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"64674a5d-93d3-4557-8f5a-2c1babfcfb2a\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {},\\\\\\\\n-   \\\\\\\\\\\\\\\"outputs\\\\\\\\\\\\\\\": [],\\\\\\\\n-   \\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\": [\\\\\\\\n-    \\\\\\\\\\\\\\\"# ============================\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# \\\\\\\\ud83d\\\\\\\\udce6 Imports\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# ============================\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"import os\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"import time\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"import json\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"import psutil\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"import platform\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"import git\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"from git import Repo\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"from git import Repo, GitCommandError\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"import mlflow\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"import requests\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"import shap\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"import pandas as pd\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"import numpy as np\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"import sklearn\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"import subprocess\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"import seaborn as sns\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"from git import Repo, GitCommandError\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"import matplotlib\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"import matplotlib.pyplot as plt\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"import mlflow.sklearn\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"from dotenv import load_dotenv\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"from datetime import datetime\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# import setuptools\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"from sklearn.ensemble import RandomForestClassifier\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"from sklearn.model_selection import train_test_split\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"from sklearn.metrics import (\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    accuracy_score, roc_auc_score, confusion_matrix,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    precision_score, recall_score, f1_score, roc_curve\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"from mlflow import MlflowClient\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"from sklearn.metrics import (\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    accuracy_score,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    roc_auc_score,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    precision_score,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    recall_score,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    f1_score,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    RocCurveDisplay,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    PrecisionRecallDisplay,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"from sklearn.preprocessing import label_binarize\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"import numpy as np\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"import pickle\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n-   ]\\\\\\\\n-  },\\\\\\\\n-  {\\\\\\\\n-   \\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"code\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\\\": 205,\\\\\\\\n-   \\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"cbe91ec0-6447-4586-b7cc-2c1f74d4218f\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {},\\\\\\\\n-   \\\\\\\\\\\\\\\"outputs\\\\\\\\\\\\\\\": [],\\\\\\\\n-   \\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\": [\\\\\\\\n-    \\\\\\\\\\\\\\\"# ============================\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# \\\\\\\\ud83d\\\\\\\\udcc2 Setup MLflow\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# ============================\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"project_dir = os.getcwd()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"mlflow.set_tracking_uri(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"mlrunlogs/mlflow.db\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"mlflow.set_experiment(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"RandomForest-Iris-CSV\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# mlflow.sklearn.autolog()\\\\\\\\\\\\\\\"\\\\\\\\n-   ]\\\\\\\\n-  },\\\\\\\\n-  {\\\\\\\\n-   \\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"code\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\\\": 59,\\\\\\\\n-   \\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"838dd233-25dc-4725-974d-4da89c257782\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {},\\\\\\\\n-   \\\\\\\\\\\\\\\"outputs\\\\\\\\\\\\\\\": [],\\\\\\\\n-   \\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\": [\\\\\\\\n-    \\\\\\\\\\\\\\\"# ============================\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# \\\\\\\\ud83d\\\\\\\\udd04 Git Commit Hash\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# ============================\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"repo_dir = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"C:/Users/reema/REPO\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"previous_commit_repo = git.Repo(repo_dir)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"previous_commit_hash = previous_commit_repo.head.object.hexsha\\\\\\\\\\\\\\\"\\\\\\\\n-   ]\\\\\\\\n-  },\\\\\\\\n-  {\\\\\\\\n-   \\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"code\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\\\": 60,\\\\\\\\n-   \\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"9668451f-4352-4bdc-8b6b-bbe49074212a\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {},\\\\\\\\n-   \\\\\\\\\\\\\\\"outputs\\\\\\\\\\\\\\\": [\\\\\\\\n-    {\\\\\\\\n-     \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"stderr\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"output_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"stream\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\": [\\\\\\\\n-      \\\\\\\\\\\\\\\"2025/04/23 23:01:41 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"2025/04/23 23:01:41 INFO mlflow.tracking.fluent: Autologging successfully enabled for statsmodels.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n-     ]\\\\\\\\n-    }\\\\\\\\n-   ],\\\\\\\\n-   \\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\": [\\\\\\\\n-    \\\\\\\\\\\\\\\"# \\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500 0) Make threadpoolctl safe so MLflow\\\\\\\\u2019s autologger won\\\\\\\\u2019t crash \\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"try:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    import threadpoolctl\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    _orig = threadpoolctl.threadpool_info\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    def _safe_threadpool_info(*args, **kwargs):\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        try:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            return _orig(*args, **kwargs)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        except Exception:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            return []\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    threadpoolctl.threadpool_info = _safe_threadpool_info\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"except ImportError:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    pass  # if threadpoolctl isn\\\\\\\\u2019t installed, autolog will skip unsupported versions\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# \\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500 1) Enable generic autolog (will auto-patch sklearn under the hood) \\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"import mlflow\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"mlflow.autolog(\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    log_input_examples=True,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    log_model_signatures=True\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\"\\\\\\\\n-   ]\\\\\\\\n-  },\\\\\\\\n-  {\\\\\\\\n-   \\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"code\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\\\": 206,\\\\\\\\n-   \\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"14c62f08-a116-4060-9689-f69968e9f240\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {\\\\\\\\n-    \\\\\\\\\\\\\\\"scrolled\\\\\\\\\\\\\\\": true\\\\\\\\n-   },\\\\\\\\n-   \\\\\\\\\\\\\\\"outputs\\\\\\\\\\\\\\\": [\\\\\\\\n-    {\\\\\\\\n-     \\\\\\\\\\\\\\\"ename\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"ConnectionError\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"evalue\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"HTTPConnectionPool(host='localhost', port=80): Max retries exceeded with url: /api/database/c3a42d17-42b7-43c9-a504-2363fb4c9c8d (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001EF2D576A10>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"output_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"error\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"traceback\\\\\\\\\\\\\\\": [\\\\\\\\n-      \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\u001b[1;31m---------------------------------------------------------------------------\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\u001b[1;31mConnectionRefusedError\\\\\\\\\\\\\\\\u001b[0m                    Traceback (most recent call last)\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"File \\\\\\\\\\\\\\\\u001b[1;32m~\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\urllib3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\connection.py:174\\\\\\\\\\\\\\\\u001b[0m, in \\\\\\\\\\\\\\\\u001b[0;36mHTTPConnection._new_conn\\\\\\\\\\\\\\\\u001b[1;34m(self)\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m    173\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[38;5;28;01mtry\\\\\\\\\\\\\\\\u001b[39;00m:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[1;32m--> 174\\\\\\\\\\\\\\\\u001b[0m     conn \\\\\\\\\\\\\\\\u001b[38;5;241m=\\\\\\\\\\\\\\\\u001b[39m \\\\\\\\\\\\\\\\u001b[43mconnection\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[38;5;241;43m.\\\\\\\\\\\\\\\\u001b[39;49m\\\\\\\\\\\\\\\\u001b[43mcreate_connection\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m(\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m    175\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[43m        \\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m(\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[38;5;28;43mself\\\\\\\\\\\\\\\\u001b[39;49m\\\\\\\\\\\\\\\\u001b[38;5;241;43m.\\\\\\\\\\\\\\\\u001b[39;49m\\\\\\\\\\\\\\\\u001b[43m_dns_host\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m,\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m \\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[38;5;28;43mself\\\\\\\\\\\\\\\\u001b[39;49m\\\\\\\\\\\\\\\\u001b[38;5;241;43m.\\\\\\\\\\\\\\\\u001b[39;49m\\\\\\\\\\\\\\\\u001b[43mport\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m)\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m,\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m \\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[38;5;28;43mself\\\\\\\\\\\\\\\\u001b[39;49m\\\\\\\\\\\\\\\\u001b[38;5;241;43m.\\\\\\\\\\\\\\\\u001b[39;49m\\\\\\\\\\\\\\\\u001b[43mtimeout\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m,\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m \\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[38;5;241;43m*\\\\\\\\\\\\\\\\u001b[39;49m\\\\\\\\\\\\\\\\u001b[38;5;241;43m*\\\\\\\\\\\\\\\\u001b[39;49m\\\\\\\\\\\\\\\\u001b[43mextra_kw\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m    176\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[43m    \\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m)\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m    178\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[38;5;28;01mexcept\\\\\\\\\\\\\\\\u001b[39;00m SocketTimeout:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"File \\\\\\\\\\\\\\\\u001b[1;32m~\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\urllib3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\util\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\connection.py:95\\\\\\\\\\\\\\\\u001b[0m, in \\\\\\\\\\\\\\\\u001b[0;36mcreate_connection\\\\\\\\\\\\\\\\u001b[1;34m(address, timeout, source_address, socket_options)\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m     94\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[38;5;28;01mif\\\\\\\\\\\\\\\\u001b[39;00m err \\\\\\\\\\\\\\\\u001b[38;5;129;01mis\\\\\\\\\\\\\\\\u001b[39;00m \\\\\\\\\\\\\\\\u001b[38;5;129;01mnot\\\\\\\\\\\\\\\\u001b[39;00m \\\\\\\\\\\\\\\\u001b[38;5;28;01mNone\\\\\\\\\\\\\\\\u001b[39;00m:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[1;32m---> 95\\\\\\\\\\\\\\\\u001b[0m     \\\\\\\\\\\\\\\\u001b[38;5;28;01mraise\\\\\\\\\\\\\\\\u001b[39;00m err\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m     97\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[38;5;28;01mraise\\\\\\\\\\\\\\\\u001b[39;00m socket\\\\\\\\\\\\\\\\u001b[38;5;241m.\\\\\\\\\\\\\\\\u001b[39merror(\\\\\\\\\\\\\\\\u001b[38;5;124m\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\u001b[39m\\\\\\\\\\\\\\\\u001b[38;5;124mgetaddrinfo returns an empty list\\\\\\\\\\\\\\\\u001b[39m\\\\\\\\\\\\\\\\u001b[38;5;124m\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\u001b[39m)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"File \\\\\\\\\\\\\\\\u001b[1;32m~\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\urllib3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\util\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\connection.py:85\\\\\\\\\\\\\\\\u001b[0m, in \\\\\\\\\\\\\\\\u001b[0;36mcreate_connection\\\\\\\\\\\\\\\\u001b[1;34m(address, timeout, source_address, socket_options)\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m     84\\\\\\\\\\\\\\\\u001b[0m     sock\\\\\\\\\\\\\\\\u001b[38;5;241m.\\\\\\\\\\\\\\\\u001b[39mbind(source_address)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[1;32m---> 85\\\\\\\\\\\\\\\\u001b[0m sock\\\\\\\\\\\\\\\\u001b[38;5;241m.\\\\\\\\\\\\\\\\u001b[39mconnect(sa)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m     86\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[38;5;28;01mreturn\\\\\\\\\\\\\\\\u001b[39;00m sock\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\u001b[1;31mConnectionRefusedError\\\\\\\\\\\\\\\\u001b[0m: [WinError 10061] No connection could be made because the target machine actively refused it\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nDuring handling of the above exception, another exception occurred:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\u001b[1;31mNewConnectionError\\\\\\\\\\\\\\\\u001b[0m                        Traceback (most recent call last)\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"File \\\\\\\\\\\\\\\\u001b[1;32m~\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\urllib3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\connectionpool.py:714\\\\\\\\\\\\\\\\u001b[0m, in \\\\\\\\\\\\\\\\u001b[0;36mHTTPConnectionPool.urlopen\\\\\\\\\\\\\\\\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m    713\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[38;5;66;03m# Make the request on the httplib connection object.\\\\\\\\\\\\\\\\u001b[39;00m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[1;32m--> 714\\\\\\\\\\\\\\\\u001b[0m httplib_response \\\\\\\\\\\\\\\\u001b[38;5;241m=\\\\\\\\\\\\\\\\u001b[39m \\\\\\\\\\\\\\\\u001b[38;5;28;43mself\\\\\\\\\\\\\\\\u001b[39;49m\\\\\\\\\\\\\\\\u001b[38;5;241;43m.\\\\\\\\\\\\\\\\u001b[39;49m\\\\\\\\\\\\\\\\u001b[43m_make_request\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m(\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m    715\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[43m    \\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43mconn\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m,\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m    716\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[43m    \\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43mmethod\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m,\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m    717\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[43m    \\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43murl\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m,\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m    718\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[43m    \\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43mtimeout\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[38;5;241;43m=\\\\\\\\\\\\\\\\u001b[39;49m\\\\\\\\\\\\\\\\u001b[43mtimeout_obj\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m,\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m    719\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[43m    \\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43mbody\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[38;5;241;43m=\\\\\\\\\\\\\\\\u001b[39;49m\\\\\\\\\\\\\\\\u001b[43mbody\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m,\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m    720\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[43m    \\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43mheaders\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[38;5;241;43m=\\\\\\\\\\\\\\\\u001b[39;49m\\\\\\\\\\\\\\\\u001b[43mheaders\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m,\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m    721\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[43m    \\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43mchunked\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[38;5;241;43m=\\\\\\\\\\\\\\\\u001b[39;49m\\\\\\\\\\\\\\\\u001b[43mchunked\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m,\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m    722\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[43m\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m)\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m    724\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\\\\\\\\\\\\\\\\u001b[39;00m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m    725\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\\\\\\\\\\\\\\\\u001b[39;00m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m    726\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\\\\\\\\\\\\\\\\u001b[39;00m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m    727\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[38;5;66;03m# mess.\\\\\\\\\\\\\\\\u001b[39;00m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"File \\\\\\\\\\\\\\\\u001b[1;32m~\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\urllib3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\connectionpool.py:415\\\\\\\\\\\\\\\\u001b[0m, in \\\\\\\\\\\\\\\\u001b[0;36mHTTPConnectionPool._make_request\\\\\\\\\\\\\\\\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m    414\\\\\\\\\\\\\\\\u001b[0m     \\\\\\\\\\\\\\\\u001b[38;5;28;01melse\\\\\\\\\\\\\\\\u001b[39;00m:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[1;32m--> 415\\\\\\\\\\\\\\\\u001b[0m         \\\\\\\\\\\\\\\\u001b[43mconn\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[38;5;241;43m.\\\\\\\\\\\\\\\\u001b[39;49m\\\\\\\\\\\\\\\\u001b[43mrequest\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m(\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43mmethod\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m,\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m \\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43murl\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m,\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m \\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[38;5;241;43m*\\\\\\\\\\\\\\\\u001b[39;49m\\\\\\\\\\\\\\\\u001b[38;5;241;43m*\\\\\\\\\\\\\\\\u001b[39;49m\\\\\\\\\\\\\\\\u001b[43mhttplib_request_kw\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m)\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m    417\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[38;5;66;03m# We are swallowing BrokenPipeError (errno.EPIPE) since the server is\\\\\\\\\\\\\\\\u001b[39;00m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m    418\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[38;5;66;03m# legitimately able to close the connection after sending a valid response.\\\\\\\\\\\\\\\\u001b[39;00m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m    419\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[38;5;66;03m# With this behaviour, the received response is still readable.\\\\\\\\\\\\\\\\u001b[39;00m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"File \\\\\\\\\\\\\\\\u001b[1;32m~\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\urllib3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\connection.py:244\\\\\\\\\\\\\\\\u001b[0m, in \\\\\\\\\\\\\\\\u001b[0;36mHTTPConnection.request\\\\\\\\\\\\\\\\u001b[1;34m(self, method, url, body, headers)\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m    243\\\\\\\\\\\\\\\\u001b[0m     headers[\\\\\\\\\\\\\\\\u001b[38;5;124m\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\u001b[39m\\\\\\\\\\\\\\\\u001b[38;5;124mUser-Agent\\\\\\\\\\\\\\\\u001b[39m\\\\\\\\\\\\\\\\u001b[38;5;124m\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\u001b[39m] \\\\\\\\\\\\\\\\u001b[38;5;241m=\\\\\\\\\\\\\\\\u001b[39m _get_default_user_agent()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[1;32m--> 244\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[38;5;28;43msuper\\\\\\\\\\\\\\\\u001b[39;49m\\\\\\\\\\\\\\\\u001b[43m(\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43mHTTPConnection\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m,\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m \\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[38;5;28;43mself\\\\\\\\\\\\\\\\u001b[39;49m\\\\\\\\\\\\\\\\u001b[43m)\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[38;5;241;43m.\\\\\\\\\\\\\\\\u001b[39;49m\\\\\\\\\\\\\\\\u001b[43mrequest\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m(\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43mmethod\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m,\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m \\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43murl\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m,\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m \\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43mbody\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[38;5;241;43m=\\\\\\\\\\\\\\\\u001b[39;49m\\\\\\\\\\\\\\\\u001b[43mbody\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m,\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m \\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43mheaders\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[38;5;241;43m=\\\\\\\\\\\\\\\\u001b[39;49m\\\\\\\\\\\\\\\\u001b[43mheaders\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m)\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"File \\\\\\\\\\\\\\\\u001b[1;32m~\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\http\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\client.py:1286\\\\\\\\\\\\\\\\u001b[0m, in \\\\\\\\\\\\\\\\u001b[0;36mHTTPConnection.request\\\\\\\\\\\\\\\\u001b[1;34m(self, method, url, body, headers, encode_chunked)\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m   1285\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[38;5;250m\\\\\\\\\\\\\\\\u001b[39m\\\\\\\\\\\\\\\\u001b[38;5;124;03m\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Send a complete request to the server.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\u001b[39;00m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[1;32m-> 1286\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[38;5;28;43mself\\\\\\\\\\\\\\\\u001b[39;49m\\\\\\\\\\\\\\\\u001b[38;5;241;43m.\\\\\\\\\\\\\\\\u001b[39;49m\\\\\\\\\\\\\\\\u001b[43m_send_request\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m(\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43mmethod\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m,\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m \\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43murl\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m,\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m \\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43mbody\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m,\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m \\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43mheaders\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m,\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m \\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43mencode_chunked\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m)\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"File \\\\\\\\\\\\\\\\u001b[1;32m~\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\http\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\client.py:1332\\\\\\\\\\\\\\\\u001b[0m, in \\\\\\\\\\\\\\\\u001b[0;36mHTTPConnection._send_request\\\\\\\\\\\\\\\\u001b[1;34m(self, method, url, body, headers, encode_chunked)\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m   1331\\\\\\\\\\\\\\\\u001b[0m     body \\\\\\\\\\\\\\\\u001b[38;5;241m=\\\\\\\\\\\\\\\\u001b[39m _encode(body, \\\\\\\\\\\\\\\\u001b[38;5;124m'\\\\\\\\\\\\\\\\u001b[39m\\\\\\\\\\\\\\\\u001b[38;5;124mbody\\\\\\\\\\\\\\\\u001b[39m\\\\\\\\\\\\\\\\u001b[38;5;124m'\\\\\\\\\\\\\\\\u001b[39m)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[1;32m-> 1332\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[38;5;28;43mself\\\\\\\\\\\\\\\\u001b[39;49m\\\\\\\\\\\\\\\\u001b[38;5;241;43m.\\\\\\\\\\\\\\\\u001b[39;49m\\\\\\\\\\\\\\\\u001b[43mendheaders\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m(\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43mbody\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m,\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m \\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43mencode_chunked\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[38;5;241;43m=\\\\\\\\\\\\\\\\u001b[39;49m\\\\\\\\\\\\\\\\u001b[43mencode_chunked\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m)\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"File \\\\\\\\\\\\\\\\u001b[1;32m~\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\http\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\client.py:1281\\\\\\\\\\\\\\\\u001b[0m, in \\\\\\\\\\\\\\\\u001b[0;36mHTTPConnection.endheaders\\\\\\\\\\\\\\\\u001b[1;34m(self, message_body, encode_chunked)\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m   1280\\\\\\\\\\\\\\\\u001b[0m     \\\\\\\\\\\\\\\\u001b[38;5;28;01mraise\\\\\\\\\\\\\\\\u001b[39;00m CannotSendHeader()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[1;32m-> 1281\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[38;5;28;43mself\\\\\\\\\\\\\\\\u001b[39;49m\\\\\\\\\\\\\\\\u001b[38;5;241;43m.\\\\\\\\\\\\\\\\u001b[39;49m\\\\\\\\\\\\\\\\u001b[43m_send_output\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m(\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43mmessage_body\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m,\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m \\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43mencode_chunked\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[38;5;241;43m=\\\\\\\\\\\\\\\\u001b[39;49m\\\\\\\\\\\\\\\\u001b[43mencode_chunked\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m)\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"File \\\\\\\\\\\\\\\\u001b[1;32m~\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\http\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\client.py:1041\\\\\\\\\\\\\\\\u001b[0m, in \\\\\\\\\\\\\\\\u001b[0;36mHTTPConnection._send_output\\\\\\\\\\\\\\\\u001b[1;34m(self, message_body, encode_chunked)\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m   1040\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[38;5;28;01mdel\\\\\\\\\\\\\\\\u001b[39;00m \\\\\\\\\\\\\\\\u001b[38;5;28mself\\\\\\\\\\\\\\\\u001b[39m\\\\\\\\\\\\\\\\u001b[38;5;241m.\\\\\\\\\\\\\\\\u001b[39m_buffer[:]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[1;32m-> 1041\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[38;5;28;43mself\\\\\\\\\\\\\\\\u001b[39;49m\\\\\\\\\\\\\\\\u001b[38;5;241;43m.\\\\\\\\\\\\\\\\u001b[39;49m\\\\\\\\\\\\\\\\u001b[43msend\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m(\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43mmsg\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m)\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m   1043\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[38;5;28;01mif\\\\\\\\\\\\\\\\u001b[39;00m message_body \\\\\\\\\\\\\\\\u001b[38;5;129;01mis\\\\\\\\\\\\\\\\u001b[39;00m \\\\\\\\\\\\\\\\u001b[38;5;129;01mnot\\\\\\\\\\\\\\\\u001b[39;00m \\\\\\\\\\\\\\\\u001b[38;5;28;01mNone\\\\\\\\\\\\\\\\u001b[39;00m:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m   1044\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m   1045\\\\\\\\\\\\\\\\u001b[0m     \\\\\\\\\\\\\\\\u001b[38;5;66;03m# create a consistent interface to message_body\\\\\\\\\\\\\\\\u001b[39;00m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"File \\\\\\\\\\\\\\\\u001b[1;32m~\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\http\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\client.py:979\\\\\\\\\\\\\\\\u001b[0m, in \\\\\\\\\\\\\\\\u001b[0;36mHTTPConnection.send\\\\\\\\\\\\\\\\u001b[1;34m(self, data)\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m    978\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[38;5;28;01mif\\\\\\\\\\\\\\\\u001b[39;00m \\\\\\\\\\\\\\\\u001b[38;5;28mself\\\\\\\\\\\\\\\\u001b[39m\\\\\\\\\\\\\\\\u001b[38;5;241m.\\\\\\\\\\\\\\\\u001b[39mauto_open:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[1;32m--> 979\\\\\\\\\\\\\\\\u001b[0m     \\\\\\\\\\\\\\\\u001b[38;5;28;43mself\\\\\\\\\\\\\\\\u001b[39;49m\\\\\\\\\\\\\\\\u001b[38;5;241;43m.\\\\\\\\\\\\\\\\u001b[39;49m\\\\\\\\\\\\\\\\u001b[43mconnect\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m(\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m)\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m    980\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[38;5;28;01melse\\\\\\\\\\\\\\\\u001b[39;00m:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"File \\\\\\\\\\\\\\\\u001b[1;32m~\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\urllib3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\connection.py:205\\\\\\\\\\\\\\\\u001b[0m, in \\\\\\\\\\\\\\\\u001b[0;36mHTTPConnection.connect\\\\\\\\\\\\\\\\u001b[1;34m(self)\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m    204\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[38;5;28;01mdef\\\\\\\\\\\\\\\\u001b[39;00m \\\\\\\\\\\\\\\\u001b[38;5;21mconnect\\\\\\\\\\\\\\\\u001b[39m(\\\\\\\\\\\\\\\\u001b[38;5;28mself\\\\\\\\\\\\\\\\u001b[39m):\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[1;32m--> 205\\\\\\\\\\\\\\\\u001b[0m     conn \\\\\\\\\\\\\\\\u001b[38;5;241m=\\\\\\\\\\\\\\\\u001b[39m \\\\\\\\\\\\\\\\u001b[38;5;28;43mself\\\\\\\\\\\\\\\\u001b[39;49m\\\\\\\\\\\\\\\\u001b[38;5;241;43m.\\\\\\\\\\\\\\\\u001b[39;49m\\\\\\\\\\\\\\\\u001b[43m_new_conn\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m(\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m)\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m    206\\\\\\\\\\\\\\\\u001b[0m     \\\\\\\\\\\\\\\\u001b[38;5;28mself\\\\\\\\\\\\\\\\u001b[39m\\\\\\\\\\\\\\\\u001b[38;5;241m.\\\\\\\\\\\\\\\\u001b[39m_prepare_conn(conn)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"File \\\\\\\\\\\\\\\\u001b[1;32m~\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\urllib3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\connection.py:186\\\\\\\\\\\\\\\\u001b[0m, in \\\\\\\\\\\\\\\\u001b[0;36mHTTPConnection._new_conn\\\\\\\\\\\\\\\\u001b[1;34m(self)\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m    185\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[38;5;28;01mexcept\\\\\\\\\\\\\\\\u001b[39;00m SocketError \\\\\\\\\\\\\\\\u001b[38;5;28;01mas\\\\\\\\\\\\\\\\u001b[39;00m e:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[1;32m--> 186\\\\\\\\\\\\\\\\u001b[0m     \\\\\\\\\\\\\\\\u001b[38;5;28;01mraise\\\\\\\\\\\\\\\\u001b[39;00m NewConnectionError(\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m    187\\\\\\\\\\\\\\\\u001b[0m         \\\\\\\\\\\\\\\\u001b[38;5;28mself\\\\\\\\\\\\\\\\u001b[39m, \\\\\\\\\\\\\\\\u001b[38;5;124m\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\u001b[39m\\\\\\\\\\\\\\\\u001b[38;5;124mFailed to establish a new connection: \\\\\\\\\\\\\\\\u001b[39m\\\\\\\\\\\\\\\\u001b[38;5;132;01m%s\\\\\\\\\\\\\\\\u001b[39;00m\\\\\\\\\\\\\\\\u001b[38;5;124m\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\u001b[39m \\\\\\\\\\\\\\\\u001b[38;5;241m%\\\\\\\\\\\\\\\\u001b[39m e\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m    188\\\\\\\\\\\\\\\\u001b[0m     )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m    190\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[38;5;28;01mreturn\\\\\\\\\\\\\\\\u001b[39;00m conn\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\u001b[1;31mNewConnectionError\\\\\\\\\\\\\\\\u001b[0m: <urllib3.connection.HTTPConnection object at 0x000001EF2D576A10>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nDuring handling of the above exception, another exception occurred:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\u001b[1;31mMaxRetryError\\\\\\\\\\\\\\\\u001b[0m                             Traceback (most recent call last)\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"File \\\\\\\\\\\\\\\\u001b[1;32m~\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\requests\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\adapters.py:486\\\\\\\\\\\\\\\\u001b[0m, in \\\\\\\\\\\\\\\\u001b[0;36mHTTPAdapter.send\\\\\\\\\\\\\\\\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m    485\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[38;5;28;01mtry\\\\\\\\\\\\\\\\u001b[39;00m:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[1;32m--> 486\\\\\\\\\\\\\\\\u001b[0m     resp \\\\\\\\\\\\\\\\u001b[38;5;241m=\\\\\\\\\\\\\\\\u001b[39m \\\\\\\\\\\\\\\\u001b[43mconn\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[38;5;241;43m.\\\\\\\\\\\\\\\\u001b[39;49m\\\\\\\\\\\\\\\\u001b[43murlopen\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m(\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m    487\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[43m        \\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43mmethod\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[38;5;241;43m=\\\\\\\\\\\\\\\\u001b[39;49m\\\\\\\\\\\\\\\\u001b[43mrequest\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[38;5;241;43m.\\\\\\\\\\\\\\\\u001b[39;49m\\\\\\\\\\\\\\\\u001b[43mmethod\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m,\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m    488\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[43m        \\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43murl\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[38;5;241;43m=\\\\\\\\\\\\\\\\u001b[39;49m\\\\\\\\\\\\\\\\u001b[43murl\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m,\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m    489\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[43m        \\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43mbody\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[38;5;241;43m=\\\\\\\\\\\\\\\\u001b[39;49m\\\\\\\\\\\\\\\\u001b[43mrequest\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[38;5;241;43m.\\\\\\\\\\\\\\\\u001b[39;49m\\\\\\\\\\\\\\\\u001b[43mbody\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m,\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m    490\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[43m        \\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43mheaders\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[38;5;241;43m=\\\\\\\\\\\\\\\\u001b[39;49m\\\\\\\\\\\\\\\\u001b[43mrequest\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[38;5;241;43m.\\\\\\\\\\\\\\\\u001b[39;49m\\\\\\\\\\\\\\\\u001b[43mheaders\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m,\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m    491\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[43m        \\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43mredirect\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[38;5;241;43m=\\\\\\\\\\\\\\\\u001b[39;49m\\\\\\\\\\\\\\\\u001b[38;5;28;43;01mFalse\\\\\\\\\\\\\\\\u001b[39;49;00m\\\\\\\\\\\\\\\\u001b[43m,\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m    492\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[43m        \\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43massert_same_host\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[38;5;241;43m=\\\\\\\\\\\\\\\\u001b[39;49m\\\\\\\\\\\\\\\\u001b[38;5;28;43;01mFalse\\\\\\\\\\\\\\\\u001b[39;49;00m\\\\\\\\\\\\\\\\u001b[43m,\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m    493\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[43m        \\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43mpreload_content\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[38;5;241;43m=\\\\\\\\\\\\\\\\u001b[39;49m\\\\\\\\\\\\\\\\u001b[38;5;28;43;01mFalse\\\\\\\\\\\\\\\\u001b[39;49;00m\\\\\\\\\\\\\\\\u001b[43m,\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m    494\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[43m        \\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43mdecode_content\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[38;5;241;43m=\\\\\\\\\\\\\\\\u001b[39;49m\\\\\\\\\\\\\\\\u001b[38;5;28;43;01mFalse\\\\\\\\\\\\\\\\u001b[39;49;00m\\\\\\\\\\\\\\\\u001b[43m,\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m    495\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[43m        \\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43mretries\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[38;5;241;43m=\\\\\\\\\\\\\\\\u001b[39;49m\\\\\\\\\\\\\\\\u001b[38;5;28;43mself\\\\\\\\\\\\\\\\u001b[39;49m\\\\\\\\\\\\\\\\u001b[38;5;241;43m.\\\\\\\\\\\\\\\\u001b[39;49m\\\\\\\\\\\\\\\\u001b[43mmax_retries\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m,\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m    496\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[43m        \\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43mtimeout\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[38;5;241;43m=\\\\\\\\\\\\\\\\u001b[39;49m\\\\\\\\\\\\\\\\u001b[43mtimeout\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m,\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m    497\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[43m        \\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43mchunked\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[38;5;241;43m=\\\\\\\\\\\\\\\\u001b[39;49m\\\\\\\\\\\\\\\\u001b[43mchunked\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m,\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m    498\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[43m    \\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m)\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m    500\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[38;5;28;01mexcept\\\\\\\\\\\\\\\\u001b[39;00m (ProtocolError, \\\\\\\\\\\\\\\\u001b[38;5;167;01mOSError\\\\\\\\\\\\\\\\u001b[39;00m) \\\\\\\\\\\\\\\\u001b[38;5;28;01mas\\\\\\\\\\\\\\\\u001b[39;00m err:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"File \\\\\\\\\\\\\\\\u001b[1;32m~\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\urllib3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\connectionpool.py:798\\\\\\\\\\\\\\\\u001b[0m, in \\\\\\\\\\\\\\\\u001b[0;36mHTTPConnectionPool.urlopen\\\\\\\\\\\\\\\\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m    796\\\\\\\\\\\\\\\\u001b[0m     e \\\\\\\\\\\\\\\\u001b[38;5;241m=\\\\\\\\\\\\\\\\u001b[39m ProtocolError(\\\\\\\\\\\\\\\\u001b[38;5;124m\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\u001b[39m\\\\\\\\\\\\\\\\u001b[38;5;124mConnection aborted.\\\\\\\\\\\\\\\\u001b[39m\\\\\\\\\\\\\\\\u001b[38;5;124m\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\u001b[39m, e)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[1;32m--> 798\\\\\\\\\\\\\\\\u001b[0m retries \\\\\\\\\\\\\\\\u001b[38;5;241m=\\\\\\\\\\\\\\\\u001b[39m \\\\\\\\\\\\\\\\u001b[43mretries\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[38;5;241;43m.\\\\\\\\\\\\\\\\u001b[39;49m\\\\\\\\\\\\\\\\u001b[43mincrement\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m(\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m    799\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[43m    \\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43mmethod\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m,\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m \\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43murl\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m,\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m \\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43merror\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[38;5;241;43m=\\\\\\\\\\\\\\\\u001b[39;49m\\\\\\\\\\\\\\\\u001b[43me\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m,\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m \\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m_pool\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[38;5;241;43m=\\\\\\\\\\\\\\\\u001b[39;49m\\\\\\\\\\\\\\\\u001b[38;5;28;43mself\\\\\\\\\\\\\\\\u001b[39;49m\\\\\\\\\\\\\\\\u001b[43m,\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m \\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m_stacktrace\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[38;5;241;43m=\\\\\\\\\\\\\\\\u001b[39;49m\\\\\\\\\\\\\\\\u001b[43msys\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[38;5;241;43m.\\\\\\\\\\\\\\\\u001b[39;49m\\\\\\\\\\\\\\\\u001b[43mexc_info\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m(\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m)\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m[\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[38;5;241;43m2\\\\\\\\\\\\\\\\u001b[39;49m\\\\\\\\\\\\\\\\u001b[43m]\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m    800\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[43m\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m)\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m    801\\\\\\\\\\\\\\\\u001b[0m retries\\\\\\\\\\\\\\\\u001b[38;5;241m.\\\\\\\\\\\\\\\\u001b[39msleep()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"File \\\\\\\\\\\\\\\\u001b[1;32m~\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\urllib3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\util\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\retry.py:592\\\\\\\\\\\\\\\\u001b[0m, in \\\\\\\\\\\\\\\\u001b[0;36mRetry.increment\\\\\\\\\\\\\\\\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m    591\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[38;5;28;01mif\\\\\\\\\\\\\\\\u001b[39;00m new_retry\\\\\\\\\\\\\\\\u001b[38;5;241m.\\\\\\\\\\\\\\\\u001b[39mis_exhausted():\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[1;32m--> 592\\\\\\\\\\\\\\\\u001b[0m     \\\\\\\\\\\\\\\\u001b[38;5;28;01mraise\\\\\\\\\\\\\\\\u001b[39;00m MaxRetryError(_pool, url, error \\\\\\\\\\\\\\\\u001b[38;5;129;01mor\\\\\\\\\\\\\\\\u001b[39;00m ResponseError(cause))\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m    594\\\\\\\\\\\\\\\\u001b[0m log\\\\\\\\\\\\\\\\u001b[38;5;241m.\\\\\\\\\\\\\\\\u001b[39mdebug(\\\\\\\\\\\\\\\\u001b[38;5;124m\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\u001b[39m\\\\\\\\\\\\\\\\u001b[38;5;124mIncremented Retry for (url=\\\\\\\\\\\\\\\\u001b[39m\\\\\\\\\\\\\\\\u001b[38;5;124m'\\\\\\\\\\\\\\\\u001b[39m\\\\\\\\\\\\\\\\u001b[38;5;132;01m%s\\\\\\\\\\\\\\\\u001b[39;00m\\\\\\\\\\\\\\\\u001b[38;5;124m'\\\\\\\\\\\\\\\\u001b[39m\\\\\\\\\\\\\\\\u001b[38;5;124m): \\\\\\\\\\\\\\\\u001b[39m\\\\\\\\\\\\\\\\u001b[38;5;132;01m%r\\\\\\\\\\\\\\\\u001b[39;00m\\\\\\\\\\\\\\\\u001b[38;5;124m\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\u001b[39m, url, new_retry)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\u001b[1;31mMaxRetryError\\\\\\\\\\\\\\\\u001b[0m: HTTPConnectionPool(host='localhost', port=80): Max retries exceeded with url: /api/database/c3a42d17-42b7-43c9-a504-2363fb4c9c8d (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001EF2D576A10>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nDuring handling of the above exception, another exception occurred:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\u001b[1;31mConnectionError\\\\\\\\\\\\\\\\u001b[0m                           Traceback (most recent call last)\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Cell \\\\\\\\\\\\\\\\u001b[1;32mIn[206], line 16\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m     11\\\\\\\\\\\\\\\\u001b[0m   \\\\\\\\\\\\\\\\u001b[38;5;66;03m# 4) log it as a single JSON artifact\\\\\\\\\\\\\\\\u001b[39;00m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m     12\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[38;5;66;03m# mlflow.log_dict(public_datasetRepository_metadata, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"public_datasetRepository_metadata.json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\u001b[39;00m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m     13\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m     14\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[38;5;66;03m#Datasbase info logging\\\\\\\\\\\\\\\\u001b[39;00m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m     15\\\\\\\\\\\\\\\\u001b[0m db_id \\\\\\\\\\\\\\\\u001b[38;5;241m=\\\\\\\\\\\\\\\\u001b[39m \\\\\\\\\\\\\\\\u001b[38;5;124m\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\u001b[39m\\\\\\\\\\\\\\\\u001b[38;5;124mc3a42d17-42b7-43c9-a504-2363fb4c9c8d\\\\\\\\\\\\\\\\u001b[39m\\\\\\\\\\\\\\\\u001b[38;5;124m\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\u001b[39m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[1;32m---> 16\\\\\\\\\\\\\\\\u001b[0m db_meta \\\\\\\\\\\\\\\\u001b[38;5;241m=\\\\\\\\\\\\\\\\u001b[39m \\\\\\\\\\\\\\\\u001b[43mfetch_db_metadata\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m(\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43mdb_id\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m)\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m     17\\\\\\\\\\\\\\\\u001b[0m log_db_metadata(db_meta)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m     19\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[38;5;66;03m#OAI metadata logging from api endpoint\\\\\\\\\\\\\\\\u001b[39;00m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m     20\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[38;5;66;03m# log as tags\\\\\\\\\\\\\\\\u001b[39;00m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Cell \\\\\\\\\\\\\\\\u001b[1;32mIn[3], line 8\\\\\\\\\\\\\\\\u001b[0m, in \\\\\\\\\\\\\\\\u001b[0;36mfetch_db_metadata\\\\\\\\\\\\\\\\u001b[1;34m(db_id)\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m      6\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[38;5;28;01mdef\\\\\\\\\\\\\\\\u001b[39;00m \\\\\\\\\\\\\\\\u001b[38;5;21mfetch_db_metadata\\\\\\\\\\\\\\\\u001b[39m(db_id: \\\\\\\\\\\\\\\\u001b[38;5;28mstr\\\\\\\\\\\\\\\\u001b[39m) \\\\\\\\\\\\\\\\u001b[38;5;241m-\\\\\\\\\\\\\\\\u001b[39m\\\\\\\\\\\\\\\\u001b[38;5;241m>\\\\\\\\\\\\\\\\u001b[39m \\\\\\\\\\\\\\\\u001b[38;5;28mdict\\\\\\\\\\\\\\\\u001b[39m:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m      7\\\\\\\\\\\\\\\\u001b[0m     url \\\\\\\\\\\\\\\\u001b[38;5;241m=\\\\\\\\\\\\\\\\u001b[39m DB_API\\\\\\\\\\\\\\\\u001b[38;5;241m.\\\\\\\\\\\\\\\\u001b[39mformat(db_id\\\\\\\\\\\\\\\\u001b[38;5;241m=\\\\\\\\\\\\\\\\u001b[39mdb_id)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[1;32m----> 8\\\\\\\\\\\\\\\\u001b[0m     resp \\\\\\\\\\\\\\\\u001b[38;5;241m=\\\\\\\\\\\\\\\\u001b[39m \\\\\\\\\\\\\\\\u001b[43mrequests\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[38;5;241;43m.\\\\\\\\\\\\\\\\u001b[39;49m\\\\\\\\\\\\\\\\u001b[43mget\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m(\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43murl\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m)\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m      9\\\\\\\\\\\\\\\\u001b[0m     resp\\\\\\\\\\\\\\\\u001b[38;5;241m.\\\\\\\\\\\\\\\\u001b[39mraise_for_status()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m     10\\\\\\\\\\\\\\\\u001b[0m     \\\\\\\\\\\\\\\\u001b[38;5;28;01mreturn\\\\\\\\\\\\\\\\u001b[39;00m resp\\\\\\\\\\\\\\\\u001b[38;5;241m.\\\\\\\\\\\\\\\\u001b[39mjson()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"File \\\\\\\\\\\\\\\\u001b[1;32m~\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\requests\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\api.py:73\\\\\\\\\\\\\\\\u001b[0m, in \\\\\\\\\\\\\\\\u001b[0;36mget\\\\\\\\\\\\\\\\u001b[1;34m(url, params, **kwargs)\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m     62\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[38;5;28;01mdef\\\\\\\\\\\\\\\\u001b[39;00m \\\\\\\\\\\\\\\\u001b[38;5;21mget\\\\\\\\\\\\\\\\u001b[39m(url, params\\\\\\\\\\\\\\\\u001b[38;5;241m=\\\\\\\\\\\\\\\\u001b[39m\\\\\\\\\\\\\\\\u001b[38;5;28;01mNone\\\\\\\\\\\\\\\\u001b[39;00m, \\\\\\\\\\\\\\\\u001b[38;5;241m*\\\\\\\\\\\\\\\\u001b[39m\\\\\\\\\\\\\\\\u001b[38;5;241m*\\\\\\\\\\\\\\\\u001b[39mkwargs):\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m     63\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[38;5;250m    \\\\\\\\\\\\\\\\u001b[39m\\\\\\\\\\\\\\\\u001b[38;5;124mr\\\\\\\\\\\\\\\\u001b[39m\\\\\\\\\\\\\\\\u001b[38;5;124;03m\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Sends a GET request.\\\\\\\\\\\\\\\\u001b[39;00m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m     64\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m     65\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\\\\\\\\\\\\\\\\u001b[39;00m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[1;32m   (...)\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m     70\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[38;5;124;03m    :rtype: requests.Response\\\\\\\\\\\\\\\\u001b[39;00m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m     71\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[38;5;124;03m    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\u001b[39;00m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[1;32m---> 73\\\\\\\\\\\\\\\\u001b[0m     \\\\\\\\\\\\\\\\u001b[38;5;28;01mreturn\\\\\\\\\\\\\\\\u001b[39;00m \\\\\\\\\\\\\\\\u001b[43mrequest\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m(\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[38;5;124;43m\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\u001b[39;49m\\\\\\\\\\\\\\\\u001b[38;5;124;43mget\\\\\\\\\\\\\\\\u001b[39;49m\\\\\\\\\\\\\\\\u001b[38;5;124;43m\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\u001b[39;49m\\\\\\\\\\\\\\\\u001b[43m,\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m \\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43murl\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m,\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m \\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43mparams\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[38;5;241;43m=\\\\\\\\\\\\\\\\u001b[39;49m\\\\\\\\\\\\\\\\u001b[43mparams\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m,\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m \\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[38;5;241;43m*\\\\\\\\\\\\\\\\u001b[39;49m\\\\\\\\\\\\\\\\u001b[38;5;241;43m*\\\\\\\\\\\\\\\\u001b[39;49m\\\\\\\\\\\\\\\\u001b[43mkwargs\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m)\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"File \\\\\\\\\\\\\\\\u001b[1;32m~\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\requests\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\api.py:59\\\\\\\\\\\\\\\\u001b[0m, in \\\\\\\\\\\\\\\\u001b[0;36mrequest\\\\\\\\\\\\\\\\u001b[1;34m(method, url, **kwargs)\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m     55\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\\\\\\\\\\\\\\\\u001b[39;00m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m     56\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\\\\\\\\\\\\\\\\u001b[39;00m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m     57\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[38;5;66;03m# cases, and look like a memory leak in others.\\\\\\\\\\\\\\\\u001b[39;00m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m     58\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[38;5;28;01mwith\\\\\\\\\\\\\\\\u001b[39;00m sessions\\\\\\\\\\\\\\\\u001b[38;5;241m.\\\\\\\\\\\\\\\\u001b[39mSession() \\\\\\\\\\\\\\\\u001b[38;5;28;01mas\\\\\\\\\\\\\\\\u001b[39;00m session:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[1;32m---> 59\\\\\\\\\\\\\\\\u001b[0m     \\\\\\\\\\\\\\\\u001b[38;5;28;01mreturn\\\\\\\\\\\\\\\\u001b[39;00m \\\\\\\\\\\\\\\\u001b[43msession\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[38;5;241;43m.\\\\\\\\\\\\\\\\u001b[39;49m\\\\\\\\\\\\\\\\u001b[43mrequest\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m(\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43mmethod\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[38;5;241;43m=\\\\\\\\\\\\\\\\u001b[39;49m\\\\\\\\\\\\\\\\u001b[43mmethod\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m,\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m \\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43murl\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[38;5;241;43m=\\\\\\\\\\\\\\\\u001b[39;49m\\\\\\\\\\\\\\\\u001b[43murl\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m,\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m \\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[38;5;241;43m*\\\\\\\\\\\\\\\\u001b[39;49m\\\\\\\\\\\\\\\\u001b[38;5;241;43m*\\\\\\\\\\\\\\\\u001b[39;49m\\\\\\\\\\\\\\\\u001b[43mkwargs\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m)\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"File \\\\\\\\\\\\\\\\u001b[1;32m~\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\requests\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\sessions.py:589\\\\\\\\\\\\\\\\u001b[0m, in \\\\\\\\\\\\\\\\u001b[0;36mSession.request\\\\\\\\\\\\\\\\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m    584\\\\\\\\\\\\\\\\u001b[0m send_kwargs \\\\\\\\\\\\\\\\u001b[38;5;241m=\\\\\\\\\\\\\\\\u001b[39m {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m    585\\\\\\\\\\\\\\\\u001b[0m     \\\\\\\\\\\\\\\\u001b[38;5;124m\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\u001b[39m\\\\\\\\\\\\\\\\u001b[38;5;124mtimeout\\\\\\\\\\\\\\\\u001b[39m\\\\\\\\\\\\\\\\u001b[38;5;124m\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\u001b[39m: timeout,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m    586\\\\\\\\\\\\\\\\u001b[0m     \\\\\\\\\\\\\\\\u001b[38;5;124m\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\u001b[39m\\\\\\\\\\\\\\\\u001b[38;5;124mallow_redirects\\\\\\\\\\\\\\\\u001b[39m\\\\\\\\\\\\\\\\u001b[38;5;124m\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\u001b[39m: allow_redirects,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m    587\\\\\\\\\\\\\\\\u001b[0m }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m    588\\\\\\\\\\\\\\\\u001b[0m send_kwargs\\\\\\\\\\\\\\\\u001b[38;5;241m.\\\\\\\\\\\\\\\\u001b[39mupdate(settings)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[1;32m--> 589\\\\\\\\\\\\\\\\u001b[0m resp \\\\\\\\\\\\\\\\u001b[38;5;241m=\\\\\\\\\\\\\\\\u001b[39m \\\\\\\\\\\\\\\\u001b[38;5;28;43mself\\\\\\\\\\\\\\\\u001b[39;49m\\\\\\\\\\\\\\\\u001b[38;5;241;43m.\\\\\\\\\\\\\\\\u001b[39;49m\\\\\\\\\\\\\\\\u001b[43msend\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m(\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43mprep\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m,\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m \\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[38;5;241;43m*\\\\\\\\\\\\\\\\u001b[39;49m\\\\\\\\\\\\\\\\u001b[38;5;241;43m*\\\\\\\\\\\\\\\\u001b[39;49m\\\\\\\\\\\\\\\\u001b[43msend_kwargs\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m)\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m    591\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[38;5;28;01mreturn\\\\\\\\\\\\\\\\u001b[39;00m resp\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"File \\\\\\\\\\\\\\\\u001b[1;32m~\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\requests\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\sessions.py:703\\\\\\\\\\\\\\\\u001b[0m, in \\\\\\\\\\\\\\\\u001b[0;36mSession.send\\\\\\\\\\\\\\\\u001b[1;34m(self, request, **kwargs)\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m    700\\\\\\\\\\\\\\\\u001b[0m start \\\\\\\\\\\\\\\\u001b[38;5;241m=\\\\\\\\\\\\\\\\u001b[39m preferred_clock()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m    702\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[38;5;66;03m# Send the request\\\\\\\\\\\\\\\\u001b[39;00m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[1;32m--> 703\\\\\\\\\\\\\\\\u001b[0m r \\\\\\\\\\\\\\\\u001b[38;5;241m=\\\\\\\\\\\\\\\\u001b[39m \\\\\\\\\\\\\\\\u001b[43madapter\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[38;5;241;43m.\\\\\\\\\\\\\\\\u001b[39;49m\\\\\\\\\\\\\\\\u001b[43msend\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m(\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43mrequest\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m,\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m \\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[38;5;241;43m*\\\\\\\\\\\\\\\\u001b[39;49m\\\\\\\\\\\\\\\\u001b[38;5;241;43m*\\\\\\\\\\\\\\\\u001b[39;49m\\\\\\\\\\\\\\\\u001b[43mkwargs\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m)\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m    705\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[38;5;66;03m# Total elapsed time of the request (approximately)\\\\\\\\\\\\\\\\u001b[39;00m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m    706\\\\\\\\\\\\\\\\u001b[0m elapsed \\\\\\\\\\\\\\\\u001b[38;5;241m=\\\\\\\\\\\\\\\\u001b[39m preferred_clock() \\\\\\\\\\\\\\\\u001b[38;5;241m-\\\\\\\\\\\\\\\\u001b[39m start\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"File \\\\\\\\\\\\\\\\u001b[1;32m~\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\requests\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\adapters.py:519\\\\\\\\\\\\\\\\u001b[0m, in \\\\\\\\\\\\\\\\u001b[0;36mHTTPAdapter.send\\\\\\\\\\\\\\\\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m    515\\\\\\\\\\\\\\\\u001b[0m     \\\\\\\\\\\\\\\\u001b[38;5;28;01mif\\\\\\\\\\\\\\\\u001b[39;00m \\\\\\\\\\\\\\\\u001b[38;5;28misinstance\\\\\\\\\\\\\\\\u001b[39m(e\\\\\\\\\\\\\\\\u001b[38;5;241m.\\\\\\\\\\\\\\\\u001b[39mreason, _SSLError):\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m    516\\\\\\\\\\\\\\\\u001b[0m         \\\\\\\\\\\\\\\\u001b[38;5;66;03m# This branch is for urllib3 v1.22 and later.\\\\\\\\\\\\\\\\u001b[39;00m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m    517\\\\\\\\\\\\\\\\u001b[0m         \\\\\\\\\\\\\\\\u001b[38;5;28;01mraise\\\\\\\\\\\\\\\\u001b[39;00m SSLError(e, request\\\\\\\\\\\\\\\\u001b[38;5;241m=\\\\\\\\\\\\\\\\u001b[39mrequest)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[1;32m--> 519\\\\\\\\\\\\\\\\u001b[0m     \\\\\\\\\\\\\\\\u001b[38;5;28;01mraise\\\\\\\\\\\\\\\\u001b[39;00m \\\\\\\\\\\\\\\\u001b[38;5;167;01mConnectionError\\\\\\\\\\\\\\\\u001b[39;00m(e, request\\\\\\\\\\\\\\\\u001b[38;5;241m=\\\\\\\\\\\\\\\\u001b[39mrequest)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m    521\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[38;5;28;01mexcept\\\\\\\\\\\\\\\\u001b[39;00m ClosedPoolError \\\\\\\\\\\\\\\\u001b[38;5;28;01mas\\\\\\\\\\\\\\\\u001b[39;00m e:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m    522\\\\\\\\\\\\\\\\u001b[0m     \\\\\\\\\\\\\\\\u001b[38;5;28;01mraise\\\\\\\\\\\\\\\\u001b[39;00m \\\\\\\\\\\\\\\\u001b[38;5;167;01mConnectionError\\\\\\\\\\\\\\\\u001b[39;00m(e, request\\\\\\\\\\\\\\\\u001b[38;5;241m=\\\\\\\\\\\\\\\\u001b[39mrequest)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\u001b[1;31mConnectionError\\\\\\\\\\\\\\\\u001b[0m: HTTPConnectionPool(host='localhost', port=80): Max retries exceeded with url: /api/database/c3a42d17-42b7-43c9-a504-2363fb4c9c8d (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001EF2D576A10>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))\\\\\\\\\\\\\\\"\\\\\\\\n-     ]\\\\\\\\n-    }\\\\\\\\n-   ],\\\\\\\\n-   \\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\": [\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# ============================\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# \\\\\\\\ud83d\\\\\\\\ude80 Start MLflow Run CURRENT BACKUP\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# ============================\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"with mlflow.start_run() as run:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    ##########################\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    meta = fetch_and_log_dataset_metadata_nested(\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"https://doi.org/10.5281/zenodo.1404173\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"           \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"      # 4) log it as a single JSON artifact\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # mlflow.log_dict(public_datasetRepository_metadata, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"public_datasetRepository_metadata.json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    #Datasbase info logging\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    db_id = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"c3a42d17-42b7-43c9-a504-2363fb4c9c8d\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    db_meta = fetch_db_metadata(db_id)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    log_db_metadata(db_meta)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    #OAI metadata logging from api endpoint\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # log as tags\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    mlflow.set_tag(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"dbrepo.repository_name\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", repo_name)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    mlflow.set_tag(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"dbrepo.base_url\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",       base_url)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    mlflow.set_tag(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"dbrepo.protocol_version\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", protocol)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    mlflow.set_tag(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"dbrepo.admin_email\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",     admin_email)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    mlflow.set_tag(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"dbrepo.granularity\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",     gran)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    #From history API logging\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # provenance tags\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    mlflow.set_tag(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"dbrepo.table_last_modified\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", ts_last)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # row-count metrics\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    mlflow.log_metric(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"dbrepo.row_count_start\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", count_start)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    mlflow.log_metric(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"dbrepo.row_count_end\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",   count_end)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # change-event metrics\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    mlflow.log_metric(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"dbrepo.num_inserts\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", n_insert)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    mlflow.log_metric(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"dbrepo.num_deletes\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", n_delete)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # 2) Capture raw metadata\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    mlflow.set_tag(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"data_source\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", API_URL)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    mlflow.log_param(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"retrieval_time\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", datetime.utcnow().isoformat())\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    mlflow.log_param(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"n_records\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", len(df))\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    mlflow.log_param(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"columns_raw\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", df.columns.tolist())\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    mlflow.log_param(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"dropped_columns\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", id_cols)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # 4) Post\\\\\\\\u2010processing metadata\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    mlflow.log_param(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"n_features_final\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", X.shape[1])\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    mlflow.log_param(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"feature_names\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", X.columns.tolist())\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    mlflow.set_tag(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"target_name\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", y)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    #Lable encoding\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    label_map = { int(idx): cls for idx, cls in enumerate(le.classes_) }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    with open(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"label_mapping.json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"w\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\") as fp:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        json.dump(label_map, fp, indent=2)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    mlflow.log_artifact(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"label_mapping.json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"   \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    ts = datetime.now().strftime(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"%Y%m%d_%H%M%S\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    model_name = f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"RandomForest_Iris_v{ts}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    mlflow.set_tag(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"model_name\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",model_name)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    train_start_ts = datetime.now().isoformat()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    mlflow.set_tag(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"training_start_time\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", train_start_ts)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    test_size    = 0.2\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    random_state = 42\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # \\\\\\\\ud83d\\\\\\\\udcc8 Model Training\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # \\\\\\\\u2500\\\\\\\\u2500 2) Log dataset split params \\\\\\\\u2500\\\\\\\\u2500\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    mlflow.log_param(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"test_size\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", test_size)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    mlflow.log_param(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"random_state\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", random_state)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    mlflow.log_param(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"n_train_samples\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", X_train.shape[0])\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    mlflow.log_param(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"n_test_samples\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",  X_test.shape[0])\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    mlflow.log_param(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"n_features\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",      X_train.shape[1])\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"     # 1) Define a more complex hyperparameter dict\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    hyperparams = {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"n_estimators\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":       200,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"criterion\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":          \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"entropy\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"max_depth\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":          12,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"min_samples_split\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":  5,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"min_samples_leaf\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":   2,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"max_features\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":       \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sqrt\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bootstrap\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":          True,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"oob_score\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":          False,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"class_weight\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":       None,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"random_state\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":       42,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"verbose\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":            1,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"n_jobs\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":             -1\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # 2) Log them ALL at once\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    mlflow.log_params(hyperparams)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    model = RandomForestClassifier(**hyperparams)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    model.fit(X_train, y_train)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    train_end_ts = datetime.now().isoformat()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    mlflow.set_tag(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"training_end_time\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", train_end_ts)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"     # \\\\\\\\u2500\\\\\\\\u2500 6) Predict & log metrics \\\\\\\\u2500\\\\\\\\u2500\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    y_pred = model.predict(X_test)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    y_proba = model.predict_proba(X_test)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    acc = accuracy_score(y_test, y_pred)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    auc = roc_auc_score(y_test, y_proba, multi_class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"ovr\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    prec = precision_score(y_test, y_pred, average=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"macro\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    rec  = recall_score(y_test,    y_pred, average=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"macro\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    f1   = f1_score(y_test,      y_pred, average=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"macro\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    mlflow.log_metric(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"precision_macro\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", prec)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    mlflow.log_metric(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"recall_macro\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",    rec)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    mlflow.log_metric(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"f1_macro\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",        f1)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    mlflow.log_metric(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"accuracy\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", acc)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    mlflow.log_metric(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"roc_auc\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",   auc)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # \\\\\\\\u2705 Log Environment Automatically\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    mlflow.log_params({\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"python_version\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": platform.python_version(),\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"os_platform\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{platform.system()} {platform.release()}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sklearn_version\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": sklearn.__version__,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"pandas_version\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": pd.__version__,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"numpy_version\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": np.__version__,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"matplotlib_version\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": matplotlib.__version__,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"seaborn_version\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": sns.__version__,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"shap_version\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": shap.__version__,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    })\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # \\\\\\\\u2705 Git and Notebook Metadata\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    mlflow.set_tag(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"notebook_name\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"RQ1.ipynb\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # \\\\\\\\u2705 Dataset Metadata Tags\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    mlflow.set_tag(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"dataset_name\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Iris\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\") #TODO\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    mlflow.set_tag(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"dataset_version\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"1.0.0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\") #TODO\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    mlflow.set_tag(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"dataset_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"iris_local\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\") #TODO\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # \\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500 2) Create a folder for this run\\\\\\\\u2019s plots \\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    plot_dir = os.path.join(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"plots\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", model_name)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    os.makedirs(plot_dir, exist_ok=True)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # 1) Feature Importance Bar Chart\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    importances = model.feature_importances_\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # if X_train is a DataFrame, grab column names; otherwise auto-name them f0,f1,...\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    try:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        feature_names = X_train.columns\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    except AttributeError:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        feature_names = [f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"f{i}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" for i in range(X_train.shape[1])]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    fi_path = os.path.join(plot_dir, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"feature_importances.png\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    plt.figure(figsize=(8, 6))\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    sns.barplot(x=importances, y=feature_names)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    plt.title(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Feature Importances\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    plt.xlabel(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Importance\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    plt.ylabel(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Feature\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    plt.tight_layout()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    plt.savefig(fi_path)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    mlflow.log_artifact(fi_path)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    plt.close()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# 2) Multi-class ROC Curves\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# Binarize labels for one-vs-rest\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    classes = np.unique(y_test)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    y_test_bin = label_binarize(y_test, classes=classes)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    for idx, cls in enumerate(classes):\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        disp = RocCurveDisplay.from_predictions(\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            y_test_bin[:, idx], \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            y_proba[:, idx],\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            name=f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"ROC for class {cls}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        roc_path = os.path.join(plot_dir, f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"roc_curve_cls_{cls}.png\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        disp.figure_.savefig(roc_path)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        mlflow.log_artifact(roc_path)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        plt.close(disp.figure_)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # 3) Multi-class Precision-Recall Curves\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    for idx, cls in enumerate(classes):\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        disp = PrecisionRecallDisplay.from_predictions(\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            y_test_bin[:, idx], \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            y_proba[:, idx],\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            name=f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"PR curve for class {cls}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        pr_path = os.path.join(plot_dir, f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"pr_curve_cls_{cls}.png\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        disp.figure_.savefig(pr_path)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        mlflow.log_artifact(pr_path)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        plt.close(disp.figure_)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # \\\\\\\\u2705 Confusion Matrix Plot\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    cm_path = os.path.join(plot_dir, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"confusion_matrix.png\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    cm = confusion_matrix(y_test, y_pred)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    plt.figure(figsize=(6, 6))\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    sns.heatmap(cm, annot=True, fmt=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"d\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", cmap=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Blues\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    plt.title(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Confusion Matrix\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    plt.xlabel(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Predicted\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    plt.ylabel(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Actual\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    plt.savefig(cm_path)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    mlflow.log_artifact(cm_path)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # \\\\\\\\u2705 SHAP Summary\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    shap_path = os.path.join(plot_dir, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"shap_summary.png\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    explainer = shap.TreeExplainer(model)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    shap_values = explainer.shap_values(X_test)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    shap.summary_plot(shap_values, X_test, show=False)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    plt.savefig(shap_path)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    mlflow.log_artifact(shap_path)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # \\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500 1) Build a .pkl filename (you can include your model_name for clarity)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    pkl_path = f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{model_name}.pkl\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # \\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500 2) Serialize your trained model to disk\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    with open(pkl_path, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"wb\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\") as f:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        pickle.dump(model, f)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # \\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500 3) Log that pickle file as an MLflow artifact\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    #     It will appear under Artifacts \\\\\\\\u2192 models/RandomForest_Iris_vYYYYMMDD_HHMMSS.pkl\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    mlflow.log_artifact(pkl_path, artifact_path=model_name)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    def get_latest_commit_hash(repo_path=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"):\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        # returns the full SHA of HEAD\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        res = subprocess.run(\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            [\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"git\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"-C\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", repo_path, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"rev-parse\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"HEAD\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"],\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            capture_output=True, text=True, check=True)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        return res.stdout.strip()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    def get_remote_url(repo_path=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", remote=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"origin\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"):\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        # returns something like git@github.com:user/repo.git or https://...\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        res = subprocess.run(\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            [\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"git\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"-C\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", repo_path, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"config\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"--get\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"remote.{remote}.url\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"],\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            capture_output=True, text=True, check=True\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        return res.stdout.strip()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    def make_commit_link(remote_url, commit_hash):\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        # handle GitHub/GitLab convention; strip \\\\\\\\u201c.git\\\\\\\\u201d if present\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        base = remote_url.rstrip(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".git\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        # if SSH form (git@github.com:owner/repo), convert to https\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        if base.startswith(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"git@\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"):\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            base = base.replace(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"/\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\").replace(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"git@\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"https://\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        return f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{base}/commit/{commit_hash}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    def simple_commit_and_push_and_log(repo_path=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", message=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Auto commit\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", remote=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"origin\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", branch=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"main\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"):\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # 1) Check for changes\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        status = subprocess.run(\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            [\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"git\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"-C\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", repo_path, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"status\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"--porcelain\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"],\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            capture_output=True, text=True\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        if not status.stdout.strip():\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\ud83d\\\\\\\\udfe1 No changes to commit.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            return None, None\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        # 2) Stage everything\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        add = subprocess.run(\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            [\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"git\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"-C\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", repo_path, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"add\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"--all\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"],\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            capture_output=True, text=True\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        if add.returncode:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\u274c git add failed:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", add.stderr)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            return None, None\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        # 3) Commit\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        commit = subprocess.run(\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            [\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"git\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"-C\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", repo_path, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"commit\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"-m\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", message],\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            capture_output=True, text=True\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        if commit.returncode:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\u274c git commit failed:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", commit.stderr)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            return None, None\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\u2705 Commit successful.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        # 4) Push\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        push = subprocess.run(\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            [\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"git\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"-C\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", repo_path, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"push\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"-u\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", remote, branch],\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            capture_output=True, text=True\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        if push.returncode:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\u274c git push failed:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", push.stderr)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        else:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\ud83d\\\\\\\\ude80 Push successful.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        # 5) Retrieve hash & remote URL\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        sha = get_latest_commit_hash(repo_path)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        url = get_remote_url(repo_path, remote)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        link = make_commit_link(url, sha)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        return sha, link\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"      \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    sha, link = simple_commit_and_push_and_log(\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        repo_path=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        message=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Auto commit after successful training\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    if sha and link:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        diff_text = subprocess.check_output(\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            [\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"git\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"-C\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"diff\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", previous_commit_hash, sha],\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            encoding=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"utf-8\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            errors=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"ignore\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"    # or \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"replace\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        # 1) Get your repo\\\\\\\\u2019s remote URL and normalize to HTTPS\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        remote_url = subprocess.check_output(\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            [\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"git\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"config\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"--get\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"remote.origin.url\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"],\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            text=True\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        ).strip().rstrip(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".git\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        if remote_url.startswith(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"git@\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"):\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            # git@github.com:owner/repo.git \\\\\\\\u2192 https://github.com/owner/repo\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            remote_url = remote_url.replace(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"/\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\").replace(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"git@\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"https://\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        # 2) Build commit URLs\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        previous_commit_url  = f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{remote_url}/commit/{previous_commit_hash}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        current_commit_url = f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{remote_url}/commit/{sha}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        diff_data = {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"previous_commit\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":  previous_commit_hash,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"previous_commit_url\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":previous_commit_url,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"current_commit_url\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":current_commit_url,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"current_commit\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": sha,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"diff\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": diff_text\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        mlflow.log_dict(\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            diff_data,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            artifact_file=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"commit_diff.json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        mlflow.set_tag(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"git_previous_commit_hash\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", previous_commit_hash)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        mlflow.set_tag(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"git_current_commit_hash\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", sha)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        mlflow.set_tag(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"git__current_commit_url\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", link) \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    client   = MlflowClient()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    run_id    = run.info.run_id\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    run_info  = client.get_run(run_id).info\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    run_data  = client.get_run(run_id).data\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # 1) params, metrics, tags\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    params  = dict(run_data.params)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    metrics = dict(run_data.metrics)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    tags    = dict(run_data.tags)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # (4) List artifacts under a specific subfolder\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # artifact_paths = [af.path for af in client.list_artifacts(run_id)]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    run_meta     = client.get_run(run_id).info\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    artifact_uri = run_meta.artifact_uri  # base URI for all artifacts\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    artifact_meta = []\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    def _gather(path=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"):\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        for af in client.list_artifacts(run_id, path):\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            # If it\\\\\\\\u2019s a directory, recurse\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            if af.is_dir:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"                _gather(af.path)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"                continue\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            rel_path = af.path\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            uri      = f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{artifact_uri}/{rel_path}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            lower    = rel_path.lower()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            # 1) Text files \\\\\\\\u2192 download & embed contents\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            if lower.endswith((\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".txt\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".patch\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")):\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"                local = client.download_artifacts(run_id, rel_path)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"                with open(local, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"r\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", encoding=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"utf-8\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\") as f:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"                    content = f.read()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"                artifact_meta.append({\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"                    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"path\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":    rel_path,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"                    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"                    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": content\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"                })\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            # 2) Images \\\\\\\\u2192 surface a clickable URI\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            elif lower.endswith((\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".png\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".jpg\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".jpeg\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".svg\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")):\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"                artifact_meta.append({\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"                    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"path\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": rel_path,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"                    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"image\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"                    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"uri\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":  uri\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"                })\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            # 3) Everything else \\\\\\\\u2192 just link\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            else:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"                artifact_meta.append({\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"                    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"path\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": rel_path,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"                    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"other\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"                    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"uri\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":  uri\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"                })\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # Run the gather\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    _gather()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"     \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    summary = {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"run_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":         run_id,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"run_name\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": run_info.run_name,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"experiment_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":  run_info.experiment_id,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"start_time\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":     run_info.start_time,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"end_time\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":       run_info.end_time,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"params\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":         params,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metrics\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":        metrics,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"tags\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":           tags,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"artifacts\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":      artifact_meta\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # 1) Create (or reuse) a base folder for run summaries\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    base_dir = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"run_summaries\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    os.makedirs(base_dir, exist_ok=True)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"   # 2) Pick next numeric folder\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    existing = [\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        d for d in os.listdir(base_dir)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        if os.path.isdir(os.path.join(base_dir, d)) and d.isdigit()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    ]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    next_num = max(map(int, existing), default=0) + 1\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # 1) Determine notebook directory (where your .ipynb lives)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    notebook_dir = os.getcwd()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # 2) Create a subfolder for this model\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    summary_dir = os.path.join(os.getcwd(), \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"MODEL_PROVENANCE\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    os.makedirs(summary_dir, exist_ok=True)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"   # 2) Pick a filename based on your model_name\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    summary_filename   = f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{model_name}_run_summary.json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    summary_local_path = os.path.join(summary_dir, summary_filename)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"   # 3) Write the JSON locally\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    with open(summary_local_path, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"w\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", encoding=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"utf-8\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\") as f:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        json.dump(summary, f, indent=2)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # 4) (Optional) Mirror it into MLflow artifacts under a single folder\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    mlflow.log_artifact(summary_local_path, artifact_path=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"run_summaries\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    mlflow.end_run()\\\\\\\\\\\\\\\"\\\\\\\\n-   ]\\\\\\\\n-  },\\\\\\\\n-  {\\\\\\\\n-   \\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"code\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\\\": null,\\\\\\\\n-   \\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"461eca1d-e33c-4398-835a-64f9ea850469\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {},\\\\\\\\n-   \\\\\\\\\\\\\\\"outputs\\\\\\\\\\\\\\\": [],\\\\\\\\n-   \\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\": [\\\\\\\\n-    \\\\\\\\\\\\\\\"# !pip install rdflib\\\\\\\\\\\\\\\"\\\\\\\\n-   ]\\\\\\\\n-  },\\\\\\\\n-  {\\\\\\\\n-   \\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"markdown\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"7a5e3bbb-0288-47d0-9dc4-2855d7e4801a\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {},\\\\\\\\n-   \\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\": [\\\\\\\\n-    \\\\\\\\\\\\\\\"1. Standards-compliant export (JSON-LD + Turtle)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"I already have your plain run_summary.json , wrap it in a JSON-LD context that maps your fields into PROV-O terms, then use rdflib to emit Turtle:\\\\\\\\\\\\\\\"\\\\\\\\n-   ]\\\\\\\\n-  },\\\\\\\\n-  {\\\\\\\\n-   \\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"code\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\\\": 66,\\\\\\\\n-   \\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"5cf88da4-69f8-4982-a594-28cf25e4f79a\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {},\\\\\\\\n-   \\\\\\\\\\\\\\\"outputs\\\\\\\\\\\\\\\": [\\\\\\\\n-    {\\\\\\\\n-     \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"stdout\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"output_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"stream\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\": [\\\\\\\\n-      \\\\\\\\\\\\\\\"Converted RandomForest_Iris_v20250423_230422_run_summary.json \\\\\\\\u2192 RandomForest_Iris_v20250423_230422.jsonld, RandomForest_Iris_v20250423_230422.ttl\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n-     ]\\\\\\\\n-    }\\\\\\\\n-   ],\\\\\\\\n-   \\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\": [\\\\\\\\n-    \\\\\\\\\\\\\\\"import os\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"import json\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"import glob\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"from datetime import datetime, timezone\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"from rdflib import Graph\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"def iso8601(ms):\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Convert milliseconds since epoch to ISO8601 UTC.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    return datetime.fromtimestamp(ms / 1000, tz=timezone.utc).isoformat()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"for json_path in glob.glob(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"MODEL_PROVENANCE/*_run_summary.json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"):\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    basename   = os.path.basename(json_path)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    model_name = basename.rsplit(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"_run_summary.json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", 1)[0]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    with open(json_path, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"r\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", encoding=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"utf-8\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\") as f:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        summary = json.load(f)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    #\\\\\\\\u2013\\\\\\\\u2013 Minimal override context: keep all your flat fields as-is,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    #\\\\\\\\u2013\\\\\\\\u2013 and only map the actual PROV terms to their IRIs.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    ctx = {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        # keep these flat\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"run_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":       { \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"@id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"run_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" },\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"run_name\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":     { \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"@id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"run_name\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" },\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"experiment_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":{ \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"@id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"experiment_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" },\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"params\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":       { \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"@id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"params\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" },\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metrics\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":      { \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"@id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metrics\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" },\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"artifacts\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":    { \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"@id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"artifacts\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" },\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"tags\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":         { \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"@id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"tags\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" },\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        # provenance namespace\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"prov\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"http://www.w3.org/ns/prov#\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"xsd\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"http://www.w3.org/2001/XMLSchema#\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        # map your timestamp fields into PROV\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"start_time\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": { \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"@id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"prov:startedAtTime\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"xsd:dateTime\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" },\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"end_time\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":   { \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"@id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"prov:endedAtTime\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",   \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"xsd:dateTime\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" },\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        # PROV-used/generated\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"used\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":      { \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"@id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"prov:used\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"@id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" },\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"generated\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": { \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"@id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"prov:generated\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"@id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" },\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        # JSON-LD boilerplate\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"@id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":   \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"@id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    #\\\\\\\\u2013\\\\\\\\u2013 Build JSON-LD document, re-using your original keys verbatim\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    doc = {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"@context\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":      ctx,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"run_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":        summary[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"run_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"],\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"run_name\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":      summary.get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"run_name\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"),\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"experiment_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": summary.get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"experiment_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"),\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"params\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":        summary.get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"params\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", {}),\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metrics\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":       summary.get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metrics\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", {}),\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"artifacts\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":     summary.get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"artifacts\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", []),\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"tags\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":          summary.get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"tags\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", {}),\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        # PROV fields:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"start_time\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": iso8601(summary[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"start_time\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"])\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    if summary.get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"end_time\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\") is not None:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        doc[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"end_time\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"] = iso8601(summary[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"end_time\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"])\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # for used/generated, just point at your dataset/model URIs\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # (or blank-node them if you prefer richer structure)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    doc[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"used\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"] = summary.get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"tags\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", {}).get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"dataset_uri\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\") or []\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    doc[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"generated\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"] = [\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        art.get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"uri\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\") or art.get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"path\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        for art in summary.get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"artifacts\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", [])\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    ]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    #\\\\\\\\u2013\\\\\\\\u2013 write JSON-LD\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    out_jsonld = os.path.join(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"MODEL_PROVENANCE\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{model_name}.jsonld\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    with open(out_jsonld, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"w\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", encoding=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"utf-8\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\") as f:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        json.dump(doc, f, indent=2)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    #\\\\\\\\u2013\\\\\\\\u2013 parse & serialize to Turtle\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    g = Graph().parse(data=json.dumps(doc), format=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"json-ld\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    out_ttl = os.path.join(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"MODEL_PROVENANCE\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{model_name}.ttl\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    g.serialize(destination=out_ttl, format=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"turtle\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Converted {basename} \\\\\\\\u2192 {os.path.basename(out_jsonld)}, {os.path.basename(out_ttl)}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n-   ]\\\\\\\\n-  },\\\\\\\\n-  {\\\\\\\\n-   \\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"markdown\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"83d6d524-01da-4f20-8131-0d4a3ac005e2\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {},\\\\\\\\n-   \\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\": [\\\\\\\\n-    \\\\\\\\\\\\\\\"This code programatically, finds diff between generated Json file and created JsonLD and .TTL file to make it easier to understand if there is any discrepency\\\\\\\\\\\\\\\"\\\\\\\\n-   ]\\\\\\\\n-  },\\\\\\\\n-  {\\\\\\\\n-   \\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"code\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\\\": 68,\\\\\\\\n-   \\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"77a420c0-230d-41c0-9b63-f3dbbca1e670\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {},\\\\\\\\n-   \\\\\\\\\\\\\\\"outputs\\\\\\\\\\\\\\\": [\\\\\\\\n-    {\\\\\\\\n-     \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"stdout\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"output_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"stream\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\": [\\\\\\\\n-      \\\\\\\\\\\\\\\"== JSON-LD vs TTL ==\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Change summary:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"changed    1 \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"First 10 \\\\\\\\u2018changed\\\\\\\\u2019 entries:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Top-level adds/removes:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Empty DataFrame\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Columns: [path, type, a, b]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Index: []\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"== JSON vs JSON-LD ==\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Change summary:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"added      3\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"changed    1\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"removed    1 \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"First 10 \\\\\\\\u2018changed\\\\\\\\u2019 entries:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Top-level adds/removes:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Empty DataFrame\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Columns: [path, type, a, b]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Index: []\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n-     ]\\\\\\\\n-    }\\\\\\\\n-   ],\\\\\\\\n-   \\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\": [\\\\\\\\n-    \\\\\\\\\\\\\\\"import json\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"from rdflib import Graph\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"import pandas as pd\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"def load_as_dict(path):\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    if path.endswith((\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".ttl\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".turtle\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")):\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        g = Graph()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        g.parse(path, format=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"turtle\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        # normalize to JSON-LD dict\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        return json.loads(g.serialize(format=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"json-ld\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", indent=2))\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    else:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        with open(path, encoding=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"utf-8\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\") as f:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            return json.load(f)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"def compare_json(a, b, path=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"):\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    diffs = []\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    if isinstance(a, dict) and isinstance(b, dict):\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        all_keys = set(a) | set(b)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        for k in all_keys:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            new_path = f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{path}/{k}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" if path else k\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            if k not in a:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"                diffs.append({\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"path\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": new_path, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"added\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",   \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"a\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": None,    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"b\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": b[k]})\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            elif k not in b:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"                diffs.append({\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"path\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": new_path, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"removed\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"a\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": a[k],   \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"b\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": None})\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            else:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"                diffs.extend(compare_json(a[k], b[k], new_path))\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    elif isinstance(a, list) and isinstance(b, list):\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        for i, (ia, ib) in enumerate(zip(a, b)):\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            diffs.extend(compare_json(ia, ib, f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{path}[{i}]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"))\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        # handle length mismatches\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        if len(a) < len(b):\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            for i in range(len(a), len(b)):\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"                diffs.append({\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"path\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{path}[{i}]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"added\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",   \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"a\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": None,  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"b\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": b[i]})\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        elif len(a) > len(b):\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            for i in range(len(b), len(a)):\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"                diffs.append({\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"path\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{path}[{i}]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"removed\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"a\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": a[i],  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"b\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": None})\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    else:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        if a != b:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            diffs.append({\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"path\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": path, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"changed\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"a\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": a, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"b\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": b})\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    return diffs\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# --- Usage example -----------------------------------------------\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# Compare JSON-LD vs Turtle:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"a = load_as_dict(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"MODEL_PROVENANCE/RandomForest_Iris_v20250423_230422_run_summary.json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"b = load_as_dict(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"MODEL_PROVENANCE/RandomForest_Iris_v20250423_230422.ttl\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"diffs_jsonld_vs_ttl = compare_json(a, b)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# Compare JSON vs JSON-LD:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"c = load_as_dict(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"MODEL_PROVENANCE/RandomForest_Iris_v20250423_230422_run_summary.json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"d = load_as_dict(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"MODEL_PROVENANCE/RandomForest_Iris_v20250423_230422.jsonld\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"diffs_json_vs_jsonld = compare_json(c, d)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# Build DataFrames for interactive inspection\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"df1 = pd.DataFrame(diffs_jsonld_vs_ttl)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"df2 = pd.DataFrame(diffs_json_vs_jsonld)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# --- Summaries & Filtering ---------------------------------------\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"def summarize_and_preview(df, preview_n=10):\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Change summary:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    print(df['type'].value_counts().to_string(), \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"First {preview_n} \\\\\\\\u2018changed\\\\\\\\u2019 entries:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # print(df[df['type']==\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"changed\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"].head(preview_n).to_string(index=False), \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # Top\\\\\\\\u2010level (one slash) adds/removes\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    top = df[df['path'].str.count(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"/\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\") == 1]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Top-level adds/removes:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    print(top[top['type'].isin(['added','removed'])].to_string(index=False))\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"== JSON-LD vs TTL ==\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"summarize_and_preview(df1)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n== JSON vs JSON-LD ==\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"summarize_and_preview(df2)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n-   ]\\\\\\\\n-  },\\\\\\\\n-  {\\\\\\\\n-   \\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"code\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\\\": 69,\\\\\\\\n-   \\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"41af9d6e-c683-45f9-bac1-296611b4d0b9\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {},\\\\\\\\n-   \\\\\\\\\\\\\\\"outputs\\\\\\\\\\\\\\\": [\\\\\\\\n-    {\\\\\\\\n-     \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"stdout\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"output_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"stream\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\": [\\\\\\\\n-      \\\\\\\\\\\\\\\"Removed in JSON-LD comparison:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"    path\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"end_time\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Added in JSON-LD comparison:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"     path\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\" @context\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"generated\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"     used\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n-     ]\\\\\\\\n-    }\\\\\\\\n-   ],\\\\\\\\n-   \\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\": [\\\\\\\\n-    \\\\\\\\\\\\\\\"# show all the removed paths (in JSON but not in JSON-LD)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Removed in JSON-LD comparison:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"print(df2[df2['type']==\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"removed\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"][['path']].to_string(index=False))\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# show all the added paths (in JSON-LD but not in JSON)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nAdded in JSON-LD comparison:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"print(df2[df2['type']==\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"added\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"][['path']].to_string(index=False))\\\\\\\\\\\\\\\"\\\\\\\\n-   ]\\\\\\\\n-  },\\\\\\\\n-  {\\\\\\\\n-   \\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"code\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\\\": 70,\\\\\\\\n-   \\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"f0d6f92a-5cd9-4c78-9c2a-0cd3247137c6\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {},\\\\\\\\n-   \\\\\\\\\\\\\\\"outputs\\\\\\\\\\\\\\\": [\\\\\\\\n-    {\\\\\\\\n-     \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"stdout\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"output_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"stream\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\": [\\\\\\\\n-      \\\\\\\\\\\\\\\"Removed in .ttl comparison:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Empty DataFrame\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Columns: [path]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Index: []\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Added in .ttl comparison:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Empty DataFrame\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Columns: [path]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Index: []\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n-     ]\\\\\\\\n-    }\\\\\\\\n-   ],\\\\\\\\n-   \\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\": [\\\\\\\\n-    \\\\\\\\\\\\\\\"# show all the removed paths (in JSON but not in JSON-LD)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Removed in .ttl comparison:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"print(df1[df1['type']==\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"removed\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"][['path']].to_string(index=False))\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# show all the added paths (in JSON-LD but not in JSON)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nAdded in .ttl comparison:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"print(df1[df1['type']==\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"added\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"][['path']].to_string(index=False))\\\\\\\\\\\\\\\"\\\\\\\\n-   ]\\\\\\\\n-  },\\\\\\\\n-  {\\\\\\\\n-   \\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"markdown\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"69efd0d0-9277-4efa-88cf-d2fd1b90d74c\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {},\\\\\\\\n-   \\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\": [\\\\\\\\n-    \\\\\\\\\\\\\\\"Checks for completeness and mapping and time taken, needs work #TODO\\\\\\\\\\\\\\\"\\\\\\\\n-   ]\\\\\\\\n-  },\\\\\\\\n-  {\\\\\\\\n-   \\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"code\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\\\": 71,\\\\\\\\n-   \\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"165a13eb-7679-4f4c-b346-24f25da72cce\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {},\\\\\\\\n-   \\\\\\\\\\\\\\\"outputs\\\\\\\\\\\\\\\": [\\\\\\\\n-    {\\\\\\\\n-     \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"stdout\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"output_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"stream\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\": [\\\\\\\\n-      \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"\\\\\\\\u2500\\\\\\\\u2500 RandomForest_Iris_v20250423_230422 diffs \\\\\\\\u2500\\\\\\\\u2500\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"  \\\\\\\\u2022 JSON \\\\\\\\u2192 JSON-LD: 17 differences\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"  \\\\\\\\u2022 JSON-LD \\\\\\\\u2192 TTL \\\\\\\\u2192 JSON-LD: 1 differences\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"1/1 runs passed completeness checks (100.0%).\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Mapping integrity: 0/1 runs have zero diffs \\\\\\\\u2014 0.0%\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Overall quality score: 50.0%\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Benchmarking train_and_log() overhead:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"  \\\\\\\\u2022 No MLflow : 0.501s\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"  \\\\\\\\u2022 With MLflow: 0.601s\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n-     ]\\\\\\\\n-    }\\\\\\\\n-   ],\\\\\\\\n-   \\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\": [\\\\\\\\n-    \\\\\\\\\\\\\\\"import os\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"import glob\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"import json\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"import time\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"from datetime import datetime, timezone\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"from rdflib import Graph\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# from your_compare_module import compare_json  # \\\\\\\\u2190 your existing compare_json()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# \\\\\\\\u2500\\\\\\\\u2500 User configuration \\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# Which keys must appear in every run_summary.json?\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"REQUIRED_TOPLEVEL = {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"run_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"start_time\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"end_time\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"params\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metrics\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"tags\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"artifacts\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# A couple of sub-fields we also want to spot-check:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"REQUIRED_PARAMS  = {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"random_state\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"REQUIRED_METRICS = {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"accuracy\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"JSON_SUMMARIES = glob.glob(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"MODEL_PROVENANCE/*_run_summary.json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# \\\\\\\\u2500\\\\\\\\u2500 Helpers \\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"def iso8601(ms):\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    return datetime.fromtimestamp(ms/1000, tz=timezone.utc).isoformat()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"def load_json(path):\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    with open(path, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"r\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", encoding=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"utf-8\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\") as f:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        return json.load(f)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"def write_json(path, obj):\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    with open(path, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"w\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", encoding=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"utf-8\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\") as f:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        json.dump(obj, f, indent=2)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"def convert_to_jsonld_and_ttl(summary, basename):\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # build @context\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    ctx = {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"prov\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"http://www.w3.org/ns/prov#\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"xsd\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":     \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"http://www.w3.org/2001/XMLSchema#\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"run\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":     \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"prov:Activity\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"start\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":   \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"prov:startedAtTime\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"end\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":     \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"prov:endedAtTime\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"used\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"prov:used\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"gen\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":     \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"prov:generated\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"param\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":   \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"prov:hadParameter\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metric\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"prov:hadQuality\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"entity\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"prov:Entity\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":   \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"prov:label\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"value\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":   \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"prov:value\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"version\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"prov:hadRevision\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"@id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    jsonld = {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"@context\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": ctx,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"@id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":      f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"urn:run:{summary['run_id']}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"run\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"start\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"xsd:dateTime\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"@value\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": iso8601(summary[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"start_time\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"])\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    if summary.get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"end_time\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\") is not None:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        jsonld[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"end\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"] = {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"xsd:dateTime\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"@value\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": iso8601(summary[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"end_time\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"])\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # params\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    jsonld[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"param\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"] = [\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"entity\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":k,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"value\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":str(v)}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        for k,v in summary.get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"params\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",{}).items()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    ]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # metrics\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    jsonld[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metric\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"] = [\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"entity\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":k,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"         \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"value\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"xsd:decimal\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"@value\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":v}}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        for k,v in summary.get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metrics\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",{}).items()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    ]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # artifacts\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    jsonld[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"gen\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"] = [\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"entity\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": art.get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"path\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\") or art.get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"),\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"prov:location\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": (\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"                art.get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"uri\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"                or (art.get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")[:30]+\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\u2026\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"                if isinstance(art.get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"),str)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"                else \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        for art in summary.get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"artifacts\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",[])\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    ]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # dataset used\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    jsonld[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"used\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"] = {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"entity\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": summary[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"tags\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"].get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"dataset_name\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"),\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"version\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": summary[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"tags\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"].get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"dataset_version\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # write JSON-LD\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    out_jsonld = f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"MODEL_PROVENANCE/{basename}.jsonld\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    write_json(out_jsonld, jsonld)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # serialize TTL\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    g = Graph().parse(data=json.dumps(jsonld), format=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"json-ld\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    out_ttl = f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"MODEL_PROVENANCE/{basename}.ttl\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    g.serialize(destination=out_ttl, format=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"turtle\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    return out_jsonld, out_ttl\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"def normalize_jsonld(js):\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Simple deep-sort so compare_json doesn\\\\\\\\u2019t trip over ordering.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    if isinstance(js, dict):\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        return {k: normalize_jsonld(js[k]) for k in sorted(js)}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    if isinstance(js, list):\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        return sorted((normalize_jsonld(el) for el in js),\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"                      key=lambda x: json.dumps(x, sort_keys=True))\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    return js\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"def diff_roundtrip(orig_json, jsonld_path, ttl_path):\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    orig = load_json(orig_json)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    ld   = load_json(jsonld_path)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # parse TTL back to JSON-LD\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    g = Graph().parse(ttl_path, format=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"turtle\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    ttl_as_ld = json.loads(g.serialize(format=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"json-ld\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"))\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # normalize\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    nl = normalize_jsonld(ld)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    nt = normalize_jsonld(ttl_as_ld)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    return {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"orig_vs_jsonld\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":   compare_json(orig, ld),\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"jsonld_vs_ttl_ld\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": compare_json(nl, nt)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# \\\\\\\\u2500\\\\\\\\u2500 Main flow \\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"def main():\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    ok = 0\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    total = len(JSON_SUMMARIES)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    missing_reports = []\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    cases = {}  # store diff results per run\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    for js_path in JSON_SUMMARIES:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        summary = load_json(js_path)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        base    = os.path.basename(js_path).split(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"_run_summary.json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")[0]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        # 1) completeness check\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        if not REQUIRED_TOPLEVEL.issubset(summary):\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            missing = REQUIRED_TOPLEVEL - set(summary)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            missing_reports.append((js_path, f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"missing fields {missing}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"))\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            continue\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        if not (REQUIRED_PARAMS <= summary[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"params\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"].keys()):\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            missing_reports.append((js_path, f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"params missing {REQUIRED_PARAMS - summary['params'].keys()}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"))\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            continue\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        if not (REQUIRED_METRICS <= summary[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metrics\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"].keys()):\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            missing_reports.append((js_path, f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metrics missing {REQUIRED_METRICS - summary['metrics'].keys()}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"))\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            continue\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        ok += 1\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        # 2) convert\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        jsonld_path, ttl_path = convert_to_jsonld_and_ttl(summary, base)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        # 3) diff\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        diffs = diff_roundtrip(js_path, jsonld_path, ttl_path)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        cases[base] = diffs\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\u2500\\\\\\\\u2500 {base} diffs \\\\\\\\u2500\\\\\\\\u2500\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"  \\\\\\\\u2022 JSON \\\\\\\\u2192 JSON-LD:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", len(diffs[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"orig_vs_jsonld\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"]), \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"differences\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"  \\\\\\\\u2022 JSON-LD \\\\\\\\u2192 TTL \\\\\\\\u2192 JSON-LD:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", len(diffs[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"jsonld_vs_ttl_ld\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"]), \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"differences\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # 4) completeness summary\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    completeness_pct = (100 * ok / total) if total else 0\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n{ok}/{total} runs passed completeness checks ({completeness_pct:.1f}%).\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    if missing_reports:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nFailures:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        for path, reason in missing_reports:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" \\\\\\\\u2022 {path}: {reason}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # 5) integrity check\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    total_runs = len(cases)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    zero_diff_runs = sum(\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        1\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        for diffs in cases.values()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        if not diffs[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"orig_vs_jsonld\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"] and not diffs[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"jsonld_vs_ttl_ld\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    integrity_pct = (100 * zero_diff_runs / total_runs) if total_runs else 0\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nMapping integrity: {zero_diff_runs}/{total_runs} runs have zero diffs \\\\\\\\u2014 {integrity_pct:.1f}%\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # 6) overall quality score\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    overall_score = (completeness_pct + integrity_pct) / 2\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Overall quality score: {overall_score:.1f}%\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # 7) Benchmark your training fn\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nBenchmarking train_and_log() overhead:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    def train_and_log(use_mlflow=False):\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        # \\\\\\\\u2190 your real instrumentation + fit logic here\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        time.sleep(0.5 + (0.1 if use_mlflow else 0))  # stub\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        return\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    for flag in (False, True):\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        start = time.time()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        train_and_log(use_mlflow=flag)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        elapsed = time.time() - start\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        label = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"With MLflow\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" if flag else \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"No MLflow\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"  \\\\\\\\u2022 {label:10s}: {elapsed:.3f}s\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"if __name__ == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"__main__\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    main()\\\\\\\\\\\\\\\"\\\\\\\\n-   ]\\\\\\\\n-  },\\\\\\\\n-  {\\\\\\\\n-   \\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"markdown\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"5883f673-371e-415e-a73e-5c9c88b56fb1\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {},\\\\\\\\n-   \\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\": [\\\\\\\\n-    \\\\\\\\\\\\\\\"RQ2  implementation\\\\\\\\\\\\\\\"\\\\\\\\n-   ]\\\\\\\\n-  },\\\\\\\\n-  {\\\\\\\\n-   \\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"code\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\\\": 96,\\\\\\\\n-   \\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"57c1f653-ff09-494a-9c11-4433936f1824\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {},\\\\\\\\n-   \\\\\\\\\\\\\\\"outputs\\\\\\\\\\\\\\\": [\\\\\\\\n-    {\\\\\\\\n-     \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"stdout\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"output_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"stream\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\": [\\\\\\\\n-      \\\\\\\\\\\\\\\"Requirement already satisfied: ace_tools in c:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\reema\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages (0.0)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n-     ]\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-     \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"stderr\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"output_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"stream\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\": [\\\\\\\\n-      \\\\\\\\\\\\\\\"WARNING: There was an error checking the latest version of pip.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n-     ]\\\\\\\\n-    }\\\\\\\\n-   ],\\\\\\\\n-   \\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\": []\\\\\\\\n-  },\\\\\\\\n-  {\\\\\\\\n-   \\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"code\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\\\": 148,\\\\\\\\n-   \\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"6d07ac1c-ea80-4787-bcb9-da047d12167d\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {},\\\\\\\\n-   \\\\\\\\\\\\\\\"outputs\\\\\\\\\\\\\\\": [\\\\\\\\n-    {\\\\\\\\n-     \\\\\\\\\\\\\\\"data\\\\\\\\\\\\\\\": {\\\\\\\\n-      \\\\\\\\\\\\\\\"text/plain\\\\\\\\\\\\\\\": [\\\\\\\\n-       \\\\\\\\\\\\\\\"Index(['run_id', 'param_bootstrap', 'param_ccp_alpha', 'param_class_weight',\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-       \\\\\\\\\\\\\\\"       'param_columns_raw', 'param_criterion', 'param_database.description',\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-       \\\\\\\\\\\\\\\"       'param_database.id', 'param_database.name', 'param_database.owner',\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-       \\\\\\\\\\\\\\\"       'param_dataset.authors', 'param_dataset.doi', 'param_dataset.published',\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-       \\\\\\\\\\\\\\\"       'param_dataset.publisher', 'param_dataset.title',\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-       \\\\\\\\\\\\\\\"       'param_dropped_columns', 'param_feature_names',\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-       \\\\\\\\\\\\\\\"       'param_matplotlib_version', 'param_max_depth', 'param_max_features',\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-       \\\\\\\\\\\\\\\"       'param_max_leaf_nodes', 'param_max_samples',\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-       \\\\\\\\\\\\\\\"       'param_min_impurity_decrease', 'param_min_samples_leaf',\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-       \\\\\\\\\\\\\\\"       'param_min_samples_split', 'param_min_weight_fraction_leaf',\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-       \\\\\\\\\\\\\\\"       'param_numpy_version', 'param_n_estimators', 'param_n_features',\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-       \\\\\\\\\\\\\\\"       'param_n_features_final', 'param_n_jobs', 'param_n_records',\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-       \\\\\\\\\\\\\\\"       'param_n_test_samples', 'param_n_train_samples', 'param_oob_score',\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-       \\\\\\\\\\\\\\\"       'param_os_platform', 'param_pandas_version', 'param_python_version',\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-       \\\\\\\\\\\\\\\"       'param_random_state', 'param_retrieval_time', 'param_seaborn_version',\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-       \\\\\\\\\\\\\\\"       'param_shap_version', 'param_sklearn_version', 'param_test_size',\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-       \\\\\\\\\\\\\\\"       'param_verbose', 'param_warm_start', 'metric_accuracy',\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-       \\\\\\\\\\\\\\\"       'metric_accuracy_score_X_test', 'metric_dbrepo.num_deletes',\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-       \\\\\\\\\\\\\\\"       'metric_dbrepo.num_inserts', 'metric_dbrepo.row_count_end',\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-       \\\\\\\\\\\\\\\"       'metric_dbrepo.row_count_start', 'metric_f1_macro',\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-       \\\\\\\\\\\\\\\"       'metric_f1_score_X_test', 'metric_precision_macro',\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-       \\\\\\\\\\\\\\\"       'metric_precision_score_X_test', 'metric_recall_macro',\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-       \\\\\\\\\\\\\\\"       'metric_recall_score_X_test', 'metric_roc_auc',\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-       \\\\\\\\\\\\\\\"       'metric_roc_auc_score_X_test', 'metric_training_accuracy_score',\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-       \\\\\\\\\\\\\\\"       'metric_training_f1_score', 'metric_training_log_loss',\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-       \\\\\\\\\\\\\\\"       'metric_training_precision_score', 'metric_training_recall_score',\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-       \\\\\\\\\\\\\\\"       'metric_training_roc_auc', 'metric_training_score', 'tag_dataset_id',\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-       \\\\\\\\\\\\\\\"       'tag_dataset_name', 'tag_dataset_version', 'tag_data_source',\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-       \\\\\\\\\\\\\\\"       'tag_dbrepo.admin_email', 'tag_dbrepo.base_url',\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-       \\\\\\\\\\\\\\\"       'tag_dbrepo.granularity', 'tag_dbrepo.protocol_version',\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-       \\\\\\\\\\\\\\\"       'tag_dbrepo.repository_name', 'tag_dbrepo.table_last_modified',\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-       \\\\\\\\\\\\\\\"       'tag_estimator_class', 'tag_estimator_name',\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-       \\\\\\\\\\\\\\\"       'tag_git_current_commit_hash', 'tag_git_previous_commit_hash',\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-       \\\\\\\\\\\\\\\"       'tag_git__current_commit_url', 'tag_mlflow.log-model.history',\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-       \\\\\\\\\\\\\\\"       'tag_mlflow.runName', 'tag_mlflow.source.name',\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-       \\\\\\\\\\\\\\\"       'tag_mlflow.source.type', 'tag_mlflow.user', 'tag_model_name',\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-       \\\\\\\\\\\\\\\"       'tag_notebook_name', 'tag_target_name', 'tag_training_end_time',\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-       \\\\\\\\\\\\\\\"       'tag_training_start_time'],\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-       \\\\\\\\\\\\\\\"      dtype='object')\\\\\\\\\\\\\\\"\\\\\\\\n-      ]\\\\\\\\n-     },\\\\\\\\n-     \\\\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\\\": 148,\\\\\\\\n-     \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {},\\\\\\\\n-     \\\\\\\\\\\\\\\"output_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"execute_result\\\\\\\\\\\\\\\"\\\\\\\\n-    }\\\\\\\\n-   ],\\\\\\\\n-   \\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\": [\\\\\\\\n-    \\\\\\\\\\\\\\\"import pandas as pd\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"import glob\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"import json\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# Load all run summary JSON files\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"files = glob.glob(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"MODEL_PROVENANCE/*_run_summary.json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"rows = []\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"for f in files:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    with open(f) as fh:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        summary = json.load(fh)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # Flatten parameters and metrics\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    row = {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"run_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": summary[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"run_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"]}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    row.update({f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"param_{k}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": v for k, v in summary.get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"params\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", {}).items()})\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    row.update({f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metric_{k}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": v for k, v in summary.get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metrics\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", {}).items()})\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    row.update({f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"tag_{k}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": v for k, v in summary.get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"tags\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", {}).items()})\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    rows.append(row)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# Create DataFrame\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"df = pd.DataFrame(rows)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# Display the DataFrame\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"df.columns\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n-   ]\\\\\\\\n-  },\\\\\\\\n-  {\\\\\\\\n-   \\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"markdown\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"ba148da6-6ce5-45cf-a985-f164a53c969b\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {},\\\\\\\\n-   \\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\": [\\\\\\\\n-    \\\\\\\\\\\\\\\"1) Tracing preprocessing steps\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"Here are the top 4 Iris\\\\\\\\u2010focused preprocessing\\\\\\\\u2010tracing use cases I\\\\\\\\u2019d tackle first:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"Reconstruct a run\\\\\\\\u2019s exact preprocessing\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"Fetch a run\\\\\\\\u2019s run_id, columns_raw, dropped_columns, feature_names and test_size so you can replay the exact data pull & split.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"Feature\\\\\\\\u2010drop impact analysis\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"Identify runs where one or more measurements (e.g. petalwidthcm) were dropped and compare their test accuracies.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"Best feature subset discovery\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"Group runs by which features they used (sepals only vs petals only vs both) and rank them by test F1 or accuracy.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"Common steps in high-accuracy runs\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"Filter for runs with accuracy_score_X_test \\\\\\\\u2265 0.95 and list the shared preprocessing settings (dropped columns, test_size, etc.).\\\\\\\\\\\\\\\"\\\\\\\\n-   ]\\\\\\\\n-  },\\\\\\\\n-  {\\\\\\\\n-   \\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"code\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\\\": 145,\\\\\\\\n-   \\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"6e147555-afbf-4bba-b6da-7e90ff391920\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {},\\\\\\\\n-   \\\\\\\\\\\\\\\"outputs\\\\\\\\\\\\\\\": [\\\\\\\\n-    {\\\\\\\\n-     \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"stderr\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"output_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"stream\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\": [\\\\\\\\n-      \\\\\\\\\\\\\\\"2025/04/24 12:07:41 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'de1ce9f489f949cc8121489b43ce6ea0', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n-     ]\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-     \\\\\\\\\\\\\\\"data\\\\\\\\\\\\\\\": {\\\\\\\\n-      \\\\\\\\\\\\\\\"application/vnd.jupyter.widget-view+json\\\\\\\\\\\\\\\": {\\\\\\\\n-       \\\\\\\\\\\\\\\"model_id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"0dfb26a56b7a498982e572a07bb00f76\\\\\\\\\\\\\\\",\\\\\\\\n-       \\\\\\\\\\\\\\\"version_major\\\\\\\\\\\\\\\": 2,\\\\\\\\n-       \\\\\\\\\\\\\\\"version_minor\\\\\\\\\\\\\\\": 0\\\\\\\\n-      },\\\\\\\\n-      \\\\\\\\\\\\\\\"text/plain\\\\\\\\\\\\\\\": [\\\\\\\\n-       \\\\\\\\\\\\\\\"Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]\\\\\\\\\\\\\\\"\\\\\\\\n-      ]\\\\\\\\n-     },\\\\\\\\n-     \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {},\\\\\\\\n-     \\\\\\\\\\\\\\\"output_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"display_data\\\\\\\\\\\\\\\"\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-     \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"stderr\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"output_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"stream\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\": [\\\\\\\\n-      \\\\\\\\\\\\\\\"2025/04/24 12:07:47 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '138898a600114e3d9ab06790184b5356', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n-     ]\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-     \\\\\\\\\\\\\\\"data\\\\\\\\\\\\\\\": {\\\\\\\\n-      \\\\\\\\\\\\\\\"application/vnd.jupyter.widget-view+json\\\\\\\\\\\\\\\": {\\\\\\\\n-       \\\\\\\\\\\\\\\"model_id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"ed955ab5fb7246d0aa6f829e1f0062cf\\\\\\\\\\\\\\\",\\\\\\\\n-       \\\\\\\\\\\\\\\"version_major\\\\\\\\\\\\\\\": 2,\\\\\\\\n-       \\\\\\\\\\\\\\\"version_minor\\\\\\\\\\\\\\\": 0\\\\\\\\n-      },\\\\\\\\n-      \\\\\\\\\\\\\\\"text/plain\\\\\\\\\\\\\\\": [\\\\\\\\n-       \\\\\\\\\\\\\\\"Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]\\\\\\\\\\\\\\\"\\\\\\\\n-      ]\\\\\\\\n-     },\\\\\\\\n-     \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {},\\\\\\\\n-     \\\\\\\\\\\\\\\"output_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"display_data\\\\\\\\\\\\\\\"\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-     \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"stderr\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"output_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"stream\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\": [\\\\\\\\n-      \\\\\\\\\\\\\\\"2025/04/24 12:07:53 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '54d74e4b53e148fb94fa7338ab205c64', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n-     ]\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-     \\\\\\\\\\\\\\\"data\\\\\\\\\\\\\\\": {\\\\\\\\n-      \\\\\\\\\\\\\\\"application/vnd.jupyter.widget-view+json\\\\\\\\\\\\\\\": {\\\\\\\\n-       \\\\\\\\\\\\\\\"model_id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"0afb20462ac648bcb6b9d84e4953ae37\\\\\\\\\\\\\\\",\\\\\\\\n-       \\\\\\\\\\\\\\\"version_major\\\\\\\\\\\\\\\": 2,\\\\\\\\n-       \\\\\\\\\\\\\\\"version_minor\\\\\\\\\\\\\\\": 0\\\\\\\\n-      },\\\\\\\\n-      \\\\\\\\\\\\\\\"text/plain\\\\\\\\\\\\\\\": [\\\\\\\\n-       \\\\\\\\\\\\\\\"Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]\\\\\\\\\\\\\\\"\\\\\\\\n-      ]\\\\\\\\n-     },\\\\\\\\n-     \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {},\\\\\\\\n-     \\\\\\\\\\\\\\\"output_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"display_data\\\\\\\\\\\\\\\"\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-     \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"stderr\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"output_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"stream\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\": [\\\\\\\\n-      \\\\\\\\\\\\\\\"2025/04/24 12:07:59 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '3aaa56d6cd9f4f99917238af626c09e8', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n-     ]\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-     \\\\\\\\\\\\\\\"data\\\\\\\\\\\\\\\": {\\\\\\\\n-      \\\\\\\\\\\\\\\"application/vnd.jupyter.widget-view+json\\\\\\\\\\\\\\\": {\\\\\\\\n-       \\\\\\\\\\\\\\\"model_id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"76d774e068fd42a19c1c85f664375d00\\\\\\\\\\\\\\\",\\\\\\\\n-       \\\\\\\\\\\\\\\"version_major\\\\\\\\\\\\\\\": 2,\\\\\\\\n-       \\\\\\\\\\\\\\\"version_minor\\\\\\\\\\\\\\\": 0\\\\\\\\n-      },\\\\\\\\n-      \\\\\\\\\\\\\\\"text/plain\\\\\\\\\\\\\\\": [\\\\\\\\n-       \\\\\\\\\\\\\\\"Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]\\\\\\\\\\\\\\\"\\\\\\\\n-      ]\\\\\\\\n-     },\\\\\\\\n-     \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {},\\\\\\\\n-     \\\\\\\\\\\\\\\"output_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"display_data\\\\\\\\\\\\\\\"\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-     \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"stderr\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"output_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"stream\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\": [\\\\\\\\n-      \\\\\\\\\\\\\\\"2025/04/24 12:08:05 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '28c0256f7c314fb3a85beee8b915b84f', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n-     ]\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-     \\\\\\\\\\\\\\\"data\\\\\\\\\\\\\\\": {\\\\\\\\n-      \\\\\\\\\\\\\\\"application/vnd.jupyter.widget-view+json\\\\\\\\\\\\\\\": {\\\\\\\\n-       \\\\\\\\\\\\\\\"model_id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"da728bc463814a9b9ab9b03226e7d758\\\\\\\\\\\\\\\",\\\\\\\\n-       \\\\\\\\\\\\\\\"version_major\\\\\\\\\\\\\\\": 2,\\\\\\\\n-       \\\\\\\\\\\\\\\"version_minor\\\\\\\\\\\\\\\": 0\\\\\\\\n-      },\\\\\\\\n-      \\\\\\\\\\\\\\\"text/plain\\\\\\\\\\\\\\\": [\\\\\\\\n-       \\\\\\\\\\\\\\\"Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]\\\\\\\\\\\\\\\"\\\\\\\\n-      ]\\\\\\\\n-     },\\\\\\\\n-     \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {},\\\\\\\\n-     \\\\\\\\\\\\\\\"output_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"display_data\\\\\\\\\\\\\\\"\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-     \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"stdout\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"output_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"stream\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\": [\\\\\\\\n-      \\\\\\\\\\\\\\\"[{'dropped_feature': 'sepallengthcm', 'baseline_acc': 1.0, 'dropped_acc': 1.0, 'impact': 0.0}, {'dropped_feature': 'sepalwidthcm', 'baseline_acc': 1.0, 'dropped_acc': 1.0, 'impact': 0.0}, {'dropped_feature': 'petallengthcm', 'baseline_acc': 1.0, 'dropped_acc': 0.9666666666666667, 'impact': 0.0333}, {'dropped_feature': 'petalwidthcm', 'baseline_acc': 1.0, 'dropped_acc': 0.9666666666666667, 'impact': 0.0333}]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n-     ]\\\\\\\\n-    }\\\\\\\\n-   ],\\\\\\\\n-   \\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\": [\\\\\\\\n-    \\\\\\\\\\\\\\\"import pandas as pd\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"import glob\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"import json\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"from typing import List, Dict, Any\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# --------------------------------------------\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# Query functions for Iris provenance exploration\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# --------------------------------------------\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"import ast\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"import pandas as pd\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"from sklearn.datasets import load_iris\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"from sklearn.ensemble import RandomForestClassifier\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"from sklearn.model_selection import train_test_split\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"from sklearn.metrics import accuracy_score\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# Helper to get the \\\\\\\\u201cofficial\\\\\\\\u201d feature_names from your summary DF\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"def _get_all_features(df):\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # assumes every row has the same param_feature_names\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    raw = df.loc[0, 'param_feature_names']\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    return ast.literal_eval(raw)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# Train & eval RF on just these columns of Iris\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"def evaluate_subset(features, test_size=0.2, random_state=42, n_estimators=200):\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    iris = load_iris()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    X = pd.DataFrame(iris.data, columns=iris.feature_names)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # map sklearn\\\\\\\\u2019s names to your param names, e.g. \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sepal length (cm)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" \\\\\\\\u2192 \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sepallengthcm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    canon = _get_all_features(df)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    mapping = dict(zip(iris.feature_names, canon))\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    X = X.rename(columns=mapping)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    X_sub = X[features]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    y = iris.target\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    Xtr, Xte, ytr, yte = train_test_split(X_sub, y, test_size=test_size, random_state=random_state)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    m = RandomForestClassifier(n_estimators=n_estimators, random_state=random_state)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    m.fit(Xtr, ytr)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    return accuracy_score(yte, m.predict(Xte))\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"def trace_preprocessing(df, run_id=None):\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    cols = ['run_id',\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            'param_dataset.title',\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            'param_columns_raw',\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            'param_dropped_columns',\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            'param_feature_names',\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            'param_dataset.authors', 'param_dataset.doi', 'param_dataset.published',\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            'param_test_size',\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            'param_criterion',\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            'param_max_depth','param_max_leaf_nodes', 'param_max_samples',\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"           'metric_accuracy','metric_f1_macro','metric_roc_auc']\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    if run_id is None:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        subset = df.loc[:, cols]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    else:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        subset = df.loc[df['run_id'] == run_id, cols]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    return subset.to_dict(orient='records')\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"def drop_impact(df, feature, **_):\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    all_feats = _get_all_features(df)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    baseline = evaluate_subset(all_feats)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    without = [f for f in all_feats if f!=feature]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    dropped = evaluate_subset(without)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    return {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"      'dropped_feature': feature,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"      'baseline_acc': baseline,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"      'dropped_acc': dropped,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"      'impact': baseline - dropped\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"def drop_impact_all(df: pd.DataFrame) -> List[Dict[str, Any]]:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    Compute drop-impact for every feature in the dataset.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    Returns list of dicts with dropped_feature, baseline_acc, dropped_acc, impact.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    feats = _get_all_features(df)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    baseline = evaluate_subset(feats)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    summary = []\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    for feat in feats:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        without = [f for f in feats if f != feat]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        acc = evaluate_subset(without)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        summary.append({\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            'dropped_feature': feat,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            'baseline_acc': baseline,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            'dropped_acc': acc,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            'impact': round(baseline - acc, 4)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        })\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    return summary\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"def best_feature_subset(df, features, **_):\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    acc = evaluate_subset(features)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    return {'features': features, 'accuracy': acc}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"def common_high_accuracy(df: pd.DataFrame, threshold: float = 0.95) -> List[Dict[str, Any]]:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    Filter runs with test accuracy >= threshold and list unique shared preprocessing settings.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    high = df[df['metric_accuracy_score_X_test'] >= threshold]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    cols = ['param_dropped_columns', 'param_test_size', 'param_feature_names']\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    return high[cols].drop_duplicates().to_dict(orient='records')\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# --------------------------------------------\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# Use Case Registry with parameter order for minimal input\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# --------------------------------------------\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"USE_CASES = {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    'trace_preprocessing': {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        'func': trace_preprocessing,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        'required_params': [],            # none strictly required\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        'optional_params': ['run_id'],    # run_id can be supplied or not\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    },\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    'drop_impact': {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        'func': drop_impact,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        'required_params': ['feature'],\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        'optional_params': [],\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    },\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"     'drop_impact_all': {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        'func': drop_impact_all,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        'required_params': [],\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        'optional_params': [],\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    },\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    'best_feature_subset': {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        'func': best_feature_subset,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        'required_params': ['features'],\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        'optional_params': [],\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    },\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    'common_high_accuracy': {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        'func': common_high_accuracy,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        'required_params': ['threshold'],\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        'optional_params': [],\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    },\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"def call_use_case(df, use_case_name, **kwargs):\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    if use_case_name not in USE_CASES:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        raise ValueError(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Unknown use case: {use_case_name}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    case = USE_CASES[use_case_name]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    func = case['func']\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # check required\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    missing = [p for p in case['required_params'] if p not in kwargs]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    if missing:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        raise ValueError(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{use_case_name} missing required params: {missing}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # build args\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    args = {p: kwargs[p] for p in case['required_params']}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    for p in case['optional_params']:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        args[p] = kwargs.get(p)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    return func(df, **args)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# --------------------------------------------\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# Example Usage\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# --------------------------------------------\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"if __name__ == '__main__':\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"   # # 1) trace_preprocessing for all runs\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # print(call_use_case(df, 'trace_preprocessing'))\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # 2) trace_preprocessing for a single run_id\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # print(call_use_case(df, 'trace_preprocessing', run_id='361daa12f99f4129a06cd20b78dd6fa7'))\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # 5) common_high_accuracy\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # print(call_use_case(df, 'common_high_accuracy', threshold=0.99))\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # 4) Best\\\\\\\\u2010subset on just sepals:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # print(call_use_case(df, 'best_feature_subset', features=['sepallengthcm','sepalwidthcm']))\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # 3) Drop\\\\\\\\u2010impact for \\\\\\\\u201cpetallengthcm\\\\\\\\u201d:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # print(call_use_case(df, 'drop_impact', feature='petallengthcm'))\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    print(call_use_case(df, 'drop_impact_all'))  # summary for all features\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n-   ]\\\\\\\\n-  },\\\\\\\\n-  {\\\\\\\\n-   \\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"markdown\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"96f912d6-0e84-4155-858a-9668bef63f6e\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {},\\\\\\\\n-   \\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\": [\\\\\\\\n-    \\\\\\\\\\\\\\\" \\\\\\\\u2022 Detecting models trained with deprecated code versions\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\" \\\\\\\\u2022 Mapping models to specific datasets used during training\\\\\\\\\\\\\\\"\\\\\\\\n-   ]\\\\\\\\n-  },\\\\\\\\n-  {\\\\\\\\n-   \\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"code\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\\\": 150,\\\\\\\\n-   \\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"34a02c9a-5459-478f-a3c5-7f7a58ff22b0\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {},\\\\\\\\n-   \\\\\\\\\\\\\\\"outputs\\\\\\\\\\\\\\\": [\\\\\\\\n-    {\\\\\\\\n-     \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"stdout\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"output_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"stream\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\": [\\\\\\\\n-      \\\\\\\\\\\\\\\"[{'param_dataset.doi': '10.5281/ZENODO.1404173',\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"  'param_dataset.published': '2018-8-27',\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"  'param_dataset.publisher': 'Zenodo',\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"  'param_dataset.title': 'Scikit-Learn Iris',\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"  'run_id': '361daa12f99f4129a06cd20b78dd6fa7',\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"  'tag_model_name': 'RandomForest_Iris_v20250423_230422'},\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\" {'param_dataset.doi': '10.5281/ZENODO.1404173',\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"  'param_dataset.published': '2018-8-27',\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"  'param_dataset.publisher': 'Zenodo',\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"  'param_dataset.title': 'Scikit-Learn Iris',\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"  'run_id': 'dcb65d2337a047fdac192b7fe9c8e3d6',\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"  'tag_model_name': 'RandomForest_Iris_v20250424_110923'},\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\" {'param_dataset.doi': '10.5281/ZENODO.1404173',\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"  'param_dataset.published': '2018-8-27',\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"  'param_dataset.publisher': 'Zenodo',\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"  'param_dataset.title': 'Scikit-Learn Iris',\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"  'run_id': 'e519450da74a4abbb11e6d00901bd435',\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"  'tag_model_name': 'RandomForest_Iris_v20250424_111946'}]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n-     ]\\\\\\\\n-    }\\\\\\\\n-   ],\\\\\\\\n-   \\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\": [\\\\\\\\n-    \\\\\\\\\\\\\\\"# --------------------------------------------\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# New Query Functions\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# --------------------------------------------\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"from typing import List, Dict, Any\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"from pprint import pprint\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"def detect_deprecated_code(df: pd.DataFrame, deprecated_commits: List[str], **_) -> List[Dict[str, Any]]:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # we know the column is called tag_git_current_commit_hash\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    commit_col = 'tag_git_current_commit_hash'\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    if commit_col not in df.columns:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        raise KeyError(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Missing {commit_col} in DataFrame\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    out = df[df[commit_col].isin(deprecated_commits)]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # include run_id and notebook/runName for context\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    cols = ['run_id', commit_col, 'tag_notebook_name', 'tag_mlflow.runName']\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # drop any that don\\\\\\\\u2019t exist\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    cols = [c for c in cols if c in df.columns]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    return out[cols].to_dict(orient='records')\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"def map_model_dataset(df: pd.DataFrame, **_) -> List[Dict[str, Any]]:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    For each run, return its model name (or run_id) alongside the dataset\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    title, DOI, published date and publisher.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # pick whichever model-name column you have\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    model_col = 'tag_model_name' if 'tag_model_name' in df.columns else 'param_model_name'\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    cols = [\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        'run_id',\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        model_col,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        'param_dataset.title',\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        'param_dataset.doi',\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        'param_dataset.published',\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        'param_dataset.publisher'\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    ]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # filter out any columns that don\\\\\\\\u2019t actually exist\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    cols = [c for c in cols if c in df.columns]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    return df[cols].to_dict(orient='records')\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# --------------------------------------------\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# Extend Use-Case Registry\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# --------------------------------------------\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"USE_CASES.update({\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    'detect_deprecated_code': {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        'func': detect_deprecated_code,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        'required_params': ['deprecated_commits'],\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        'optional_params': []\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    },\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    'map_model_dataset': {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        'func': map_model_dataset,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        'required_params': [],\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        'optional_params': []\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    },\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"})\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# 1) Detect runs on deprecated commits:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"deprecated = [\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"a07434af4f547af2daab044d6873eb7081162293\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"d329c92495e196ec0f39fbb19dfdd367131a77d9\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# print(call_use_case(df, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"detect_deprecated_code\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", deprecated_commits=deprecated))\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"pprint(call_use_case(df, 'map_model_dataset'))\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n-   ]\\\\\\\\n-  },\\\\\\\\n-  {\\\\\\\\n-   \\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"code\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\\\": null,\\\\\\\\n-   \\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"da6f16e7-4086-4867-b326-5d6eecab2439\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {},\\\\\\\\n-   \\\\\\\\\\\\\\\"outputs\\\\\\\\\\\\\\\": [],\\\\\\\\n-   \\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\": []\\\\\\\\n-  },\\\\\\\\n-  {\\\\\\\\n-   \\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"markdown\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"c52607ad-5849-4a2d-97ef-e8fc1ca16dc7\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {},\\\\\\\\n-   \\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\": [\\\\\\\\n-    \\\\\\\\\\\\\\\"Goal: Notify collaborators who have forked the GitHub repo if their fork is outdated (i.e., behind the current commit used to train a model).\\\\\\\\\\\\\\\"\\\\\\\\n-   ]\\\\\\\\n-  },\\\\\\\\n-  {\\\\\\\\n-   \\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"markdown\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"f29c8ad9-00bb-4c1e-ac3b-ee6861991acd\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {},\\\\\\\\n-   \\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\": [\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\ud83e\\\\\\\\udde0 What We Need\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"Current training run\\\\\\\\u2019s Git commit hash\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"GitHub API to fetch all forks of your repo\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"Compare each fork\\\\\\\\u2019s main or master branch head commit\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"Create an issue on their fork or on your repo tagging them if they\\\\\\\\u2019re behind\\\\\\\\\\\\\\\"\\\\\\\\n-   ]\\\\\\\\n-  },\\\\\\\\n-  {\\\\\\\\n-   \\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"markdown\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"c72bed50-fb56-442d-a21e-bb7991892d07\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {},\\\\\\\\n-   \\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\": [\\\\\\\\n-    \\\\\\\\\\\\\\\"Option 1 (Practical): Notify via issues on your own repo\\\\\\\\\\\\\\\"\\\\\\\\n-   ]\\\\\\\\n-  },\\\\\\\\n-  {\\\\\\\\n-   \\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"code\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\\\": 72,\\\\\\\\n-   \\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"852f147c-9d0a-4d7f-a4ab-545d1e2375fb\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {\\\\\\\\n-    \\\\\\\\\\\\\\\"scrolled\\\\\\\\\\\\\\\": true\\\\\\\\n-   },\\\\\\\\n-   \\\\\\\\\\\\\\\"outputs\\\\\\\\\\\\\\\": [\\\\\\\\n-    {\\\\\\\\n-     \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"stdin\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"output_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"stream\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\": [\\\\\\\\n-      \\\\\\\\\\\\\\\"Do you want to notify collaborators whose forks are behind? (y/N):  y\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n-     ]\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-     \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"stdout\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"output_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"stream\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\": [\\\\\\\\n-      \\\\\\\\\\\\\\\"Latest upstream commit: d329c92495e196ec0f39fbb19dfdd367131a77d9\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"\\\\\\\\u2192 POST https://api.github.com/repos/reema-dass26/REPO/issues\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"\\\\\\\\u2192 Status code: 201\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"\\\\\\\\u2192 Response headers: {'Date': 'Wed, 23 Apr 2025 21:06:22 GMT', 'Content-Type': 'application/json; charset=utf-8', 'Content-Length': '2383', 'Cache-Control': 'private, max-age=60, s-maxage=60', 'Vary': 'Accept, Authorization, Cookie, X-GitHub-OTP,Accept-Encoding, Accept, X-Requested-With', 'ETag': '\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"7c97cb7c44baea87eb39ae010093b566d7f13db1ddd45bd81e7d8a302d330834\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"', 'X-OAuth-Scopes': 'admin:enterprise, admin:gpg_key, admin:org, admin:org_hook, admin:public_key, admin:repo_hook, admin:ssh_signing_key, audit_log, codespace, copilot, delete:packages, delete_repo, gist, notifications, project, repo, user, workflow, write:discussion, write:network_configurations, write:packages', 'X-Accepted-OAuth-Scopes': '', 'Location': 'https://api.github.com/repos/reema-dass26/REPO/issues/3', 'X-GitHub-Media-Type': 'github.v3; format=json', 'x-github-api-version-selected': '2022-11-28', 'X-RateLimit-Limit': '5000', 'X-RateLimit-Remaining': '4996', 'X-RateLimit-Reset': '1745445980', 'X-RateLimit-Used': '4', 'X-RateLimit-Resource': 'core', 'Access-Control-Expose-Headers': 'ETag, Link, Location, Retry-After, X-GitHub-OTP, X-RateLimit-Limit, X-RateLimit-Remaining, X-RateLimit-Used, X-RateLimit-Resource, X-RateLimit-Reset, X-OAuth-Scopes, X-Accepted-OAuth-Scopes, X-Poll-Interval, X-GitHub-Media-Type, X-GitHub-SSO, X-GitHub-Request-Id, Deprecation, Sunset', 'Access-Control-Allow-Origin': '*', 'Strict-Transport-Security': 'max-age=31536000; includeSubdomains; preload', 'X-Frame-Options': 'deny', 'X-Content-Type-Options': 'nosniff', 'X-XSS-Protection': '0', 'Referrer-Policy': 'origin-when-cross-origin, strict-origin-when-cross-origin', 'Content-Security-Policy': \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"default-src 'none'\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", 'Server': 'github.com', 'X-GitHub-Request-Id': 'FF27:37CDC4:28E48A1:29EB238:6809564E'}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"\\\\\\\\u2192 Response JSON: {'url': 'https://api.github.com/repos/reema-dass26/REPO/issues/3', 'repository_url': 'https://api.github.com/repos/reema-dass26/REPO', 'labels_url': 'https://api.github.com/repos/reema-dass26/REPO/issues/3/labels{/name}', 'comments_url': 'https://api.github.com/repos/reema-dass26/REPO/issues/3/comments', 'events_url': 'https://api.github.com/repos/reema-dass26/REPO/issues/3/events', 'html_url': 'https://github.com/reema-dass26/REPO/issues/3', 'id': 3015254398, 'node_id': 'I_kwDOOdxdk86zuSF-', 'number': 3, 'title': '\\\\\\\\ud83d\\\\\\\\udd14 Notification: Your fork is behind the latest commit', 'user': {'login': 'reema-dass26', 'id': 106236154, 'node_id': 'U_kgDOBlUI-g', 'avatar_url': 'https://avatars.githubusercontent.com/u/106236154?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/reema-dass26', 'html_url': 'https://github.com/reema-dass26', 'followers_url': 'https://api.github.com/users/reema-dass26/followers', 'following_url': 'https://api.github.com/users/reema-dass26/following{/other_user}', 'gists_url': 'https://api.github.com/users/reema-dass26/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/reema-dass26/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/reema-dass26/subscriptions', 'organizations_url': 'https://api.github.com/users/reema-dass26/orgs', 'repos_url': 'https://api.github.com/users/reema-dass26/repos', 'events_url': 'https://api.github.com/users/reema-dass26/events{/privacy}', 'received_events_url': 'https://api.github.com/users/reema-dass26/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}, 'labels': [], 'state': 'open', 'locked': False, 'assignee': None, 'assignees': [], 'milestone': None, 'comments': 0, 'created_at': '2025-04-23T21:06:22Z', 'updated_at': '2025-04-23T21:06:22Z', 'closed_at': None, 'author_association': 'OWNER', 'sub_issues_summary': {'total': 0, 'completed': 0, 'percent_completed': 0}, 'active_lock_reason': None, 'body': 'Hi @reemagdass,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nThe main repository has been updated to commit `d329c92495e196ec0f39fbb19dfdd367131a77d9`.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nPlease consider pulling the latest changes to stay in sync.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nThanks!', 'closed_by': None, 'reactions': {'url': 'https://api.github.com/repos/reema-dass26/REPO/issues/3/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}, 'timeline_url': 'https://api.github.com/repos/reema-dass26/REPO/issues/3/timeline', 'performed_via_github_app': None, 'state_reason': None}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"\\\\\\\\u2192 html_url field: https://github.com/reema-dass26/REPO/issues/3\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n-     ]\\\\\\\\n-    }\\\\\\\\n-   ],\\\\\\\\n-   \\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\": [\\\\\\\\n-    \\\\\\\\\\\\\\\"import requests\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"import os\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"from dotenv import load_dotenv\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"def notify_outdated_forks():\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    load_dotenv()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    token     = os.getenv(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"THESIS_TOKEN\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    owner     = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"reema-dass26\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    repo      = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"REPO\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    if not token:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\u26a0\\\\\\\\ufe0f GITHUB_TOKEN not set.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        return\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    headers = {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Authorization\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"token {token}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Accept\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"application/vnd.github.v3+json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # 1) Get latest upstream commit\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    main_commits = requests.get(\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"https://api.github.com/repos/{owner}/{repo}/commits\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        headers=headers,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        params={\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"per_page\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    main_commits.raise_for_status()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    new_commit_hash = main_commits.json()[0][\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sha\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Latest upstream commit: {new_commit_hash}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # 2) List forks\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    forks_resp = requests.get(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"https://api.github.com/repos/{owner}/{repo}/forks\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", headers=headers)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    forks_resp.raise_for_status()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    forks = forks_resp.json()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # 3) Compare each fork\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    outdated = []\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    for fork in forks:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        fork_owner = fork[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"owner\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"][\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"login\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        fork_comm = requests.get(\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            fork[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"url\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"] + \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"/commits\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            headers=headers,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            params={\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"per_page\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        if fork_comm.status_code != 200:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\u00a0\\\\\\\\u00a0\\\\\\\\u2013 could not fetch commits for {fork_owner}, skipping.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            continue\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        fork_sha = fork_comm.json()[0][\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sha\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        if fork_sha != new_commit_hash:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            outdated.append(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"@{fork_owner}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # 4) Open an issue if any are behind\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    if outdated:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        title = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\ud83d\\\\\\\\udd14 Notification: Your fork is behind the latest commit\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        body  = (\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Hi {' '.join(outdated)},\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"The main repository has been updated to commit `{new_commit_hash}`.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Please consider pulling the latest changes to stay in sync.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Thanks!\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        issues_url = f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"https://api.github.com/repos/{owner}/{repo}/issues\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        resp = requests.post(\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        issues_url,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        headers=headers,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        json={\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"title\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": title, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"body\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": body}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # DEBUGGING OUTPUT\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\u2192 POST {issues_url}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\u2192 Status code:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", resp.status_code)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\u2192 Response headers:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", resp.headers)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    try:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        data = resp.json()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\u2192 Response JSON:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", data)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\u2192 html_url field:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", data.get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"html_url\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"))\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    except ValueError:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\u2192 No JSON response body; raw text:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", resp.text)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"if __name__ == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"__main__\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    answer = input(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Do you want to notify collaborators whose forks are behind? (y/N): \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\").strip().lower()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    if answer in (\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"y\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"yes\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"):\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        notify_outdated_forks()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    else:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"No action taken.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n-   ]\\\\\\\\n-  },\\\\\\\\n-  {\\\\\\\\n-   \\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"markdown\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"cda31f16-fbe9-40ce-ac1b-9ebc898c8820\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {},\\\\\\\\n-   \\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\": [\\\\\\\\n-    \\\\\\\\\\\\\\\"INVENIO INTEGRETION\\\\\\\\\\\\\\\"\\\\\\\\n-   ]\\\\\\\\n-  },\\\\\\\\n-  {\\\\\\\\n-   \\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"code\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\\\": 168,\\\\\\\\n-   \\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"7dd71550-7221-41db-b64d-f87ffead2f56\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {},\\\\\\\\n-   \\\\\\\\\\\\\\\"outputs\\\\\\\\\\\\\\\": [\\\\\\\\n-    {\\\\\\\\n-     \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"stdout\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"output_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"stream\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\": [\\\\\\\\n-      \\\\\\\\\\\\\\\"\\\\\\\\u2705 Draft created: 7vtzn-76461\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"  \\\\\\\\u2022 Uploaded plots/RandomForest_Iris_v20250423_230422/confusion_matrix.png\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"\\\\\\\\u274c PUT failed (400): {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"status\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 400, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"The file upload transfer failed, please try again.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n-     ]\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-     \\\\\\\\\\\\\\\"ename\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"HTTPError\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"evalue\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"400 Client Error: BAD REQUEST for url: https://127.0.0.1:5000/api/records/7vtzn-76461/draft/files/plots/RandomForest_Iris_v20250423_230422/confusion_matrix.png/content\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"output_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"error\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"traceback\\\\\\\\\\\\\\\": [\\\\\\\\n-      \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\u001b[1;31m---------------------------------------------------------------------------\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\u001b[1;31mHTTPError\\\\\\\\\\\\\\\\u001b[0m                                 Traceback (most recent call last)\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Cell \\\\\\\\\\\\\\\\u001b[1;32mIn[168], line 84\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m     82\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[38;5;28;01mif\\\\\\\\\\\\\\\\u001b[39;00m \\\\\\\\\\\\\\\\u001b[38;5;129;01mnot\\\\\\\\\\\\\\\\u001b[39;00m r2\\\\\\\\\\\\\\\\u001b[38;5;241m.\\\\\\\\\\\\\\\\u001b[39mok:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m     83\\\\\\\\\\\\\\\\u001b[0m     \\\\\\\\\\\\\\\\u001b[38;5;28mprint\\\\\\\\\\\\\\\\u001b[39m(\\\\\\\\\\\\\\\\u001b[38;5;124mf\\\\\\\\\\\\\\\\u001b[39m\\\\\\\\\\\\\\\\u001b[38;5;124m\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\u001b[39m\\\\\\\\\\\\\\\\u001b[38;5;124m\\\\\\\\u274c PUT failed (\\\\\\\\\\\\\\\\u001b[39m\\\\\\\\\\\\\\\\u001b[38;5;132;01m{\\\\\\\\\\\\\\\\u001b[39;00mr2\\\\\\\\\\\\\\\\u001b[38;5;241m.\\\\\\\\\\\\\\\\u001b[39mstatus_code\\\\\\\\\\\\\\\\u001b[38;5;132;01m}\\\\\\\\\\\\\\\\u001b[39;00m\\\\\\\\\\\\\\\\u001b[38;5;124m): \\\\\\\\\\\\\\\\u001b[39m\\\\\\\\\\\\\\\\u001b[38;5;132;01m{\\\\\\\\\\\\\\\\u001b[39;00mr2\\\\\\\\\\\\\\\\u001b[38;5;241m.\\\\\\\\\\\\\\\\u001b[39mtext\\\\\\\\\\\\\\\\u001b[38;5;132;01m}\\\\\\\\\\\\\\\\u001b[39;00m\\\\\\\\\\\\\\\\u001b[38;5;124m\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\u001b[39m)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[1;32m---> 84\\\\\\\\\\\\\\\\u001b[0m     \\\\\\\\\\\\\\\\u001b[43mr2\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[38;5;241;43m.\\\\\\\\\\\\\\\\u001b[39;49m\\\\\\\\\\\\\\\\u001b[43mraise_for_status\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m(\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m)\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m     86\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[38;5;66;03m# 2c) commit the upload\\\\\\\\\\\\\\\\u001b[39;00m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m     87\\\\\\\\\\\\\\\\u001b[0m r3 \\\\\\\\\\\\\\\\u001b[38;5;241m=\\\\\\\\\\\\\\\\u001b[39m requests\\\\\\\\\\\\\\\\u001b[38;5;241m.\\\\\\\\\\\\\\\\u001b[39mpost(\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m     88\\\\\\\\\\\\\\\\u001b[0m     commit_url,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m     89\\\\\\\\\\\\\\\\u001b[0m     headers\\\\\\\\\\\\\\\\u001b[38;5;241m=\\\\\\\\\\\\\\\\u001b[39mH_JSON,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m     90\\\\\\\\\\\\\\\\u001b[0m     verify\\\\\\\\\\\\\\\\u001b[38;5;241m=\\\\\\\\\\\\\\\\u001b[39mVERIFY_SSL\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m     91\\\\\\\\\\\\\\\\u001b[0m )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"File \\\\\\\\\\\\\\\\u001b[1;32m~\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\requests\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\models.py:1021\\\\\\\\\\\\\\\\u001b[0m, in \\\\\\\\\\\\\\\\u001b[0;36mResponse.raise_for_status\\\\\\\\\\\\\\\\u001b[1;34m(self)\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m   1016\\\\\\\\\\\\\\\\u001b[0m     http_error_msg \\\\\\\\\\\\\\\\u001b[38;5;241m=\\\\\\\\\\\\\\\\u001b[39m (\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m   1017\\\\\\\\\\\\\\\\u001b[0m         \\\\\\\\\\\\\\\\u001b[38;5;124mf\\\\\\\\\\\\\\\\u001b[39m\\\\\\\\\\\\\\\\u001b[38;5;124m\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\u001b[39m\\\\\\\\\\\\\\\\u001b[38;5;132;01m{\\\\\\\\\\\\\\\\u001b[39;00m\\\\\\\\\\\\\\\\u001b[38;5;28mself\\\\\\\\\\\\\\\\u001b[39m\\\\\\\\\\\\\\\\u001b[38;5;241m.\\\\\\\\\\\\\\\\u001b[39mstatus_code\\\\\\\\\\\\\\\\u001b[38;5;132;01m}\\\\\\\\\\\\\\\\u001b[39;00m\\\\\\\\\\\\\\\\u001b[38;5;124m Server Error: \\\\\\\\\\\\\\\\u001b[39m\\\\\\\\\\\\\\\\u001b[38;5;132;01m{\\\\\\\\\\\\\\\\u001b[39;00mreason\\\\\\\\\\\\\\\\u001b[38;5;132;01m}\\\\\\\\\\\\\\\\u001b[39;00m\\\\\\\\\\\\\\\\u001b[38;5;124m for url: \\\\\\\\\\\\\\\\u001b[39m\\\\\\\\\\\\\\\\u001b[38;5;132;01m{\\\\\\\\\\\\\\\\u001b[39;00m\\\\\\\\\\\\\\\\u001b[38;5;28mself\\\\\\\\\\\\\\\\u001b[39m\\\\\\\\\\\\\\\\u001b[38;5;241m.\\\\\\\\\\\\\\\\u001b[39murl\\\\\\\\\\\\\\\\u001b[38;5;132;01m}\\\\\\\\\\\\\\\\u001b[39;00m\\\\\\\\\\\\\\\\u001b[38;5;124m\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\u001b[39m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m   1018\\\\\\\\\\\\\\\\u001b[0m     )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m   1020\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[38;5;28;01mif\\\\\\\\\\\\\\\\u001b[39;00m http_error_msg:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[1;32m-> 1021\\\\\\\\\\\\\\\\u001b[0m     \\\\\\\\\\\\\\\\u001b[38;5;28;01mraise\\\\\\\\\\\\\\\\u001b[39;00m HTTPError(http_error_msg, response\\\\\\\\\\\\\\\\u001b[38;5;241m=\\\\\\\\\\\\\\\\u001b[39m\\\\\\\\\\\\\\\\u001b[38;5;28mself\\\\\\\\\\\\\\\\u001b[39m)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\u001b[1;31mHTTPError\\\\\\\\\\\\\\\\u001b[0m: 400 Client Error: BAD REQUEST for url: https://127.0.0.1:5000/api/records/7vtzn-76461/draft/files/plots/RandomForest_Iris_v20250423_230422/confusion_matrix.png/content\\\\\\\\\\\\\\\"\\\\\\\\n-     ]\\\\\\\\n-    }\\\\\\\\n-   ],\\\\\\\\n-   \\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\": [\\\\\\\\n-    \\\\\\\\\\\\\\\"import os\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"import json\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"import requests\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# -----------------------------------------------------------------------------\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# Configuration\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# -----------------------------------------------------------------------------\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"API_BASE   = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"https://127.0.0.1:5000\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"TOKEN      = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"ZctHtk65umtROkzOFq2Ot7WbJTqz46q5wS8uAYc2WOMry2c2rT9CqaRbySNp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"VERIFY_SSL = False  # only for local dev with self-signed cert\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"H_JSON = {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Accept\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"application/json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Content-Type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"application/json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Authorization\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Bearer {TOKEN}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"H_OCTET = {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Content-Type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"application/octet-stream\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Authorization\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Bearer {TOKEN}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"TO_UPLOAD = [\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"plots\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"MODEL_PROVENANCE\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# -----------------------------------------------------------------------------\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# 1) Create a new draft record\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# -----------------------------------------------------------------------------\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"payload = {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"title\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":       \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"My trained ML model\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"description\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Unstructured metadata + artifacts for RandomForest on Iris\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"creator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":     \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Reema Dass\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"r = requests.post(\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{API_BASE}/api/records\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    headers=H_JSON,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    data=json.dumps(payload),\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    verify=VERIFY_SSL\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"r.raise_for_status()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"draft = r.json()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"recid = draft[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"links = draft[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"links\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\u2705 Draft created: {recid}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# -----------------------------------------------------------------------------\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# 2) Walk & upload every file\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# -----------------------------------------------------------------------------\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"for topdir in TO_UPLOAD:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    if not os.path.isdir(topdir):\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\u26a0\\\\\\\\ufe0f  Skipping missing folder {topdir}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        continue\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    for root, _, files in os.walk(topdir):\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        for fn in files:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            local_path = os.path.join(root, fn)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            # build a key that preserves the folder structure under topdir\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            key = os.path.relpath(local_path, start=os.path.dirname(topdir)).replace(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"/\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            # 2a) register the file key\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            register_body = [{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"key\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": key}]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            r1 = requests.post(\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"                links[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"files\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"],\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"                headers=H_JSON,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"                data=json.dumps(register_body),\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"                verify=VERIFY_SSL\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            r1.raise_for_status()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            entry = r1.json()[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"entries\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"][0]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            upload_url = entry[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"links\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"][\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            commit_url = entry[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"links\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"][\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"commit\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            # 2b) read & PUT the file in one shot so Content-Length is set\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            with open(local_path, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"rb\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\") as fp:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"                data = fp.read()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            r2 = requests.put(\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"                upload_url,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"                headers=H_OCTET,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"                data=data,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"                verify=VERIFY_SSL\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            if not r2.ok:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"                print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\u274c PUT failed ({r2.status_code}): {r2.text}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"                r2.raise_for_status()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            # 2c) commit the upload\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            r3 = requests.post(\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"                commit_url,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"                headers=H_JSON,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"                verify=VERIFY_SSL\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            r3.raise_for_status()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"  \\\\\\\\u2022 Uploaded {key}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# -----------------------------------------------------------------------------\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# 3) Publish the draft\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# -----------------------------------------------------------------------------\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"rpub = requests.post(\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    links[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"publish\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"],\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    headers=H_JSON,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    verify=VERIFY_SSL\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"rpub.raise_for_status()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\u2705 Published: {rpub.json()['id']}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n-   ]\\\\\\\\n-  },\\\\\\\\n-  {\\\\\\\\n-   \\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"code\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\\\": 209,\\\\\\\\n-   \\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"d1809a51-46a4-4595-bea9-da64e86f9b87\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {},\\\\\\\\n-   \\\\\\\\\\\\\\\"outputs\\\\\\\\\\\\\\\": [\\\\\\\\n-    {\\\\\\\\n-     \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"stdout\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"output_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"stream\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\": [\\\\\\\\n-      \\\\\\\\\\\\\\\"Collecting streamlit-agraph\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"  Obtaining dependency information for streamlit-agraph from https://files.pythonhosted.org/packages/b9/80/8a666e700332a9fe19e458678c95fab4d78340251d2f12da7d2ad915458a/streamlit_agraph-0.0.45-py3-none-any.whl.metadata\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"  Downloading streamlit_agraph-0.0.45-py3-none-any.whl.metadata (3.2 kB)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Requirement already satisfied: streamlit>=0.63 in c:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\reema\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages (from streamlit-agraph) (1.44.1)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Requirement already satisfied: networkx>=2.5 in c:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\reema\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages (from streamlit-agraph) (3.1)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Requirement already satisfied: rdflib>=6.0.2 in c:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\reema\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages (from streamlit-agraph) (6.3.2)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Requirement already satisfied: isodate<0.7.0,>=0.6.0 in c:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\reema\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages (from rdflib>=6.0.2->streamlit-agraph) (0.6.1)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Requirement already satisfied: pyparsing<4,>=2.1.0 in c:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\reema\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages (from rdflib>=6.0.2->streamlit-agraph) (3.0.9)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Requirement already satisfied: altair<6,>=4.0 in c:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\reema\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages (from streamlit>=0.63->streamlit-agraph) (5.5.0)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Requirement already satisfied: blinker<2,>=1.0.0 in c:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\reema\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages (from streamlit>=0.63->streamlit-agraph) (1.9.0)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Requirement already satisfied: cachetools<6,>=4.0 in c:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\reema\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages (from streamlit>=0.63->streamlit-agraph) (5.5.2)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Requirement already satisfied: click<9,>=7.0 in c:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\reema\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages (from streamlit>=0.63->streamlit-agraph) (8.1.8)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Requirement already satisfied: numpy<3,>=1.23 in c:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\reema\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages (from streamlit>=0.63->streamlit-agraph) (1.24.4)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Requirement already satisfied: packaging<25,>=20 in c:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\reema\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages (from streamlit>=0.63->streamlit-agraph) (23.1)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Requirement already satisfied: pandas<3,>=1.4.0 in c:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\reema\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages (from streamlit>=0.63->streamlit-agraph) (2.2.3)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Requirement already satisfied: pillow<12,>=7.1.0 in c:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\reema\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages (from streamlit>=0.63->streamlit-agraph) (9.4.0)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Requirement already satisfied: protobuf<6,>=3.20 in c:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\reema\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages (from streamlit>=0.63->streamlit-agraph) (5.29.3)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Requirement already satisfied: pyarrow>=7.0 in c:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\reema\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages (from streamlit>=0.63->streamlit-agraph) (11.0.0)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Requirement already satisfied: requests<3,>=2.27 in c:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\reema\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages (from streamlit>=0.63->streamlit-agraph) (2.31.0)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Requirement already satisfied: tenacity<10,>=8.1.0 in c:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\reema\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages (from streamlit>=0.63->streamlit-agraph) (8.2.2)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Requirement already satisfied: toml<2,>=0.10.1 in c:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\reema\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages (from streamlit>=0.63->streamlit-agraph) (0.10.2)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Requirement already satisfied: typing-extensions<5,>=4.4.0 in c:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\reema\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages (from streamlit>=0.63->streamlit-agraph) (4.12.2)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Requirement already satisfied: watchdog<7,>=2.1.5 in c:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\reema\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages (from streamlit>=0.63->streamlit-agraph) (2.1.6)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in c:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\reema\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages (from streamlit>=0.63->streamlit-agraph) (3.1.43)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Requirement already satisfied: pydeck<1,>=0.8.0b4 in c:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\reema\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages (from streamlit>=0.63->streamlit-agraph) (0.9.1)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Requirement already satisfied: tornado<7,>=6.0.3 in c:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\reema\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\appdata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\roaming\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\python\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\python311\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages (from streamlit>=0.63->streamlit-agraph) (6.3.2)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Requirement already satisfied: jinja2 in c:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\reema\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages (from altair<6,>=4.0->streamlit>=0.63->streamlit-agraph) (3.1.2)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Requirement already satisfied: jsonschema>=3.0 in c:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\reema\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages (from altair<6,>=4.0->streamlit>=0.63->streamlit-agraph) (4.23.0)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Requirement already satisfied: narwhals>=1.14.2 in c:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\reema\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages (from altair<6,>=4.0->streamlit>=0.63->streamlit-agraph) (1.30.0)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Requirement already satisfied: colorama in c:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\reema\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\appdata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\roaming\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\python\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\python311\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages (from click<9,>=7.0->streamlit>=0.63->streamlit-agraph) (0.4.6)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\reema\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit>=0.63->streamlit-agraph) (4.0.11)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Requirement already satisfied: six in c:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\reema\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages (from isodate<0.7.0,>=0.6.0->rdflib>=6.0.2->streamlit-agraph) (1.17.0)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Requirement already satisfied: python-dateutil>=2.8.2 in c:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\reema\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages (from pandas<3,>=1.4.0->streamlit>=0.63->streamlit-agraph) (2.9.0.post0)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Requirement already satisfied: pytz>=2020.1 in c:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\reema\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages (from pandas<3,>=1.4.0->streamlit>=0.63->streamlit-agraph) (2025.2)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Requirement already satisfied: tzdata>=2022.7 in c:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\reema\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages (from pandas<3,>=1.4.0->streamlit>=0.63->streamlit-agraph) (2025.2)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Requirement already satisfied: charset-normalizer<4,>=2 in c:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\reema\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages (from requests<3,>=2.27->streamlit>=0.63->streamlit-agraph) (2.0.4)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Requirement already satisfied: idna<4,>=2.5 in c:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\reema\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages (from requests<3,>=2.27->streamlit>=0.63->streamlit-agraph) (3.4)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\reema\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages (from requests<3,>=2.27->streamlit>=0.63->streamlit-agraph) (1.26.16)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Requirement already satisfied: certifi>=2017.4.17 in c:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\reema\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages (from requests<3,>=2.27->streamlit>=0.63->streamlit-agraph) (2023.7.22)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Requirement already satisfied: smmap<6,>=3.0.1 in c:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\reema\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit>=0.63->streamlit-agraph) (5.0.1)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Requirement already satisfied: MarkupSafe>=2.0 in c:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\reema\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages (from jinja2->altair<6,>=4.0->streamlit>=0.63->streamlit-agraph) (2.1.1)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Requirement already satisfied: attrs>=22.2.0 in c:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\reema\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.63->streamlit-agraph) (23.2.0)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\reema\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.63->streamlit-agraph) (2024.10.1)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Requirement already satisfied: referencing>=0.28.4 in c:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\reema\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.63->streamlit-agraph) (0.35.1)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Requirement already satisfied: rpds-py>=0.7.1 in c:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\reema\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.63->streamlit-agraph) (0.22.3)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Downloading streamlit_agraph-0.0.45-py3-none-any.whl (1.3 MB)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"    --------------------------------------- 0.0/1.3 MB 1.3 MB/s eta 0:00:02\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"   ------------------- -------------------- 0.7/1.3 MB 10.2 MB/s eta 0:00:01\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"   ------------------------------- -------- 1.0/1.3 MB 13.1 MB/s eta 0:00:01\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"   ------------------------------- -------- 1.0/1.3 MB 13.1 MB/s eta 0:00:01\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"   ------------------------------- -------- 1.0/1.3 MB 13.1 MB/s eta 0:00:01\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"   ---------------------------------------- 1.3/1.3 MB 5.5 MB/s eta 0:00:00\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Installing collected packages: streamlit-agraph\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Successfully installed streamlit-agraph-0.0.45\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n-     ]\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-     \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"stderr\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"output_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"stream\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\": [\\\\\\\\n-      \\\\\\\\\\\\\\\"WARNING: There was an error checking the latest version of pip.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n-     ]\\\\\\\\n-    }\\\\\\\\n-   ],\\\\\\\\n-   \\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\": [\\\\\\\\n-    \\\\\\\\\\\\\\\"!pip install streamlit-agraph\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n-   ]\\\\\\\\n-  },\\\\\\\\n-  {\\\\\\\\n-   \\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"code\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\\\": 169,\\\\\\\\n-   \\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"962a7e5d-f305-40f1-b853-0a236b444d86\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {},\\\\\\\\n-   \\\\\\\\\\\\\\\"outputs\\\\\\\\\\\\\\\": [\\\\\\\\n-    {\\\\\\\\n-     \\\\\\\\\\\\\\\"ename\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"FileNotFoundError\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"evalue\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"[Errno 2] No such file or directory: 'MODEL_PROVENANCE/run1234.json'\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"output_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"error\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"traceback\\\\\\\\\\\\\\\": [\\\\\\\\n-      \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\u001b[1;31m---------------------------------------------------------------------------\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\u001b[1;31mFileNotFoundError\\\\\\\\\\\\\\\\u001b[0m                         Traceback (most recent call last)\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Cell \\\\\\\\\\\\\\\\u001b[1;32mIn[169], line 37\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m     32\\\\\\\\\\\\\\\\u001b[0m     \\\\\\\\\\\\\\\\u001b[38;5;28;01mreturn\\\\\\\\\\\\\\\\u001b[39;00m json\\\\\\\\\\\\\\\\u001b[38;5;241m.\\\\\\\\\\\\\\\\u001b[39mloads(g\\\\\\\\\\\\\\\\u001b[38;5;241m.\\\\\\\\\\\\\\\\u001b[39mserialize(\\\\\\\\\\\\\\\\u001b[38;5;28mformat\\\\\\\\\\\\\\\\u001b[39m\\\\\\\\\\\\\\\\u001b[38;5;241m=\\\\\\\\\\\\\\\\u001b[39m\\\\\\\\\\\\\\\\u001b[38;5;124m\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\u001b[39m\\\\\\\\\\\\\\\\u001b[38;5;124mjson-ld\\\\\\\\\\\\\\\\u001b[39m\\\\\\\\\\\\\\\\u001b[38;5;124m\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\u001b[39m))\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m     34\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[38;5;66;03m# -----------------------------------------------------------------------------\\\\\\\\\\\\\\\\u001b[39;00m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m     35\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[38;5;66;03m#  1) Read your raw provenance JSON\\\\\\\\\\\\\\\\u001b[39;00m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m     36\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[38;5;66;03m# -----------------------------------------------------------------------------\\\\\\\\\\\\\\\\u001b[39;00m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[1;32m---> 37\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[38;5;28;01mwith\\\\\\\\\\\\\\\\u001b[39;00m \\\\\\\\\\\\\\\\u001b[38;5;28;43mopen\\\\\\\\\\\\\\\\u001b[39;49m\\\\\\\\\\\\\\\\u001b[43m(\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[38;5;124;43m\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\u001b[39;49m\\\\\\\\\\\\\\\\u001b[38;5;124;43mMODEL_PROVENANCE/run1234.json\\\\\\\\\\\\\\\\u001b[39;49m\\\\\\\\\\\\\\\\u001b[38;5;124;43m\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\u001b[39;49m\\\\\\\\\\\\\\\\u001b[43m)\\\\\\\\\\\\\\\\u001b[49m \\\\\\\\\\\\\\\\u001b[38;5;28;01mas\\\\\\\\\\\\\\\\u001b[39;00m fp:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m     38\\\\\\\\\\\\\\\\u001b[0m     run_meta \\\\\\\\\\\\\\\\u001b[38;5;241m=\\\\\\\\\\\\\\\\u001b[39m json\\\\\\\\\\\\\\\\u001b[38;5;241m.\\\\\\\\\\\\\\\\u001b[39mload(fp)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m     40\\\\\\\\\\\\\\\\u001b[0m ttl \\\\\\\\\\\\\\\\u001b[38;5;241m=\\\\\\\\\\\\\\\\u001b[39m json_to_prov_ttl(run_meta)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"File \\\\\\\\\\\\\\\\u001b[1;32m~\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\AppData\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Roaming\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Python\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Python311\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\IPython\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\core\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\interactiveshell.py:284\\\\\\\\\\\\\\\\u001b[0m, in \\\\\\\\\\\\\\\\u001b[0;36m_modified_open\\\\\\\\\\\\\\\\u001b[1;34m(file, *args, **kwargs)\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m    277\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[38;5;28;01mif\\\\\\\\\\\\\\\\u001b[39;00m file \\\\\\\\\\\\\\\\u001b[38;5;129;01min\\\\\\\\\\\\\\\\u001b[39;00m {\\\\\\\\\\\\\\\\u001b[38;5;241m0\\\\\\\\\\\\\\\\u001b[39m, \\\\\\\\\\\\\\\\u001b[38;5;241m1\\\\\\\\\\\\\\\\u001b[39m, \\\\\\\\\\\\\\\\u001b[38;5;241m2\\\\\\\\\\\\\\\\u001b[39m}:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m    278\\\\\\\\\\\\\\\\u001b[0m     \\\\\\\\\\\\\\\\u001b[38;5;28;01mraise\\\\\\\\\\\\\\\\u001b[39;00m \\\\\\\\\\\\\\\\u001b[38;5;167;01mValueError\\\\\\\\\\\\\\\\u001b[39;00m(\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m    279\\\\\\\\\\\\\\\\u001b[0m         \\\\\\\\\\\\\\\\u001b[38;5;124mf\\\\\\\\\\\\\\\\u001b[39m\\\\\\\\\\\\\\\\u001b[38;5;124m\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\u001b[39m\\\\\\\\\\\\\\\\u001b[38;5;124mIPython won\\\\\\\\\\\\\\\\u001b[39m\\\\\\\\\\\\\\\\u001b[38;5;124m'\\\\\\\\\\\\\\\\u001b[39m\\\\\\\\\\\\\\\\u001b[38;5;124mt let you open fd=\\\\\\\\\\\\\\\\u001b[39m\\\\\\\\\\\\\\\\u001b[38;5;132;01m{\\\\\\\\\\\\\\\\u001b[39;00mfile\\\\\\\\\\\\\\\\u001b[38;5;132;01m}\\\\\\\\\\\\\\\\u001b[39;00m\\\\\\\\\\\\\\\\u001b[38;5;124m by default \\\\\\\\\\\\\\\\u001b[39m\\\\\\\\\\\\\\\\u001b[38;5;124m\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\u001b[39m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m    280\\\\\\\\\\\\\\\\u001b[0m         \\\\\\\\\\\\\\\\u001b[38;5;124m\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\u001b[39m\\\\\\\\\\\\\\\\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \\\\\\\\\\\\\\\\u001b[39m\\\\\\\\\\\\\\\\u001b[38;5;124m\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\u001b[39m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m    281\\\\\\\\\\\\\\\\u001b[0m         \\\\\\\\\\\\\\\\u001b[38;5;124m\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\u001b[39m\\\\\\\\\\\\\\\\u001b[38;5;124myou can use builtins\\\\\\\\\\\\\\\\u001b[39m\\\\\\\\\\\\\\\\u001b[38;5;124m'\\\\\\\\\\\\\\\\u001b[39m\\\\\\\\\\\\\\\\u001b[38;5;124m open.\\\\\\\\\\\\\\\\u001b[39m\\\\\\\\\\\\\\\\u001b[38;5;124m\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\u001b[39m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m    282\\\\\\\\\\\\\\\\u001b[0m     )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[1;32m--> 284\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[38;5;28;01mreturn\\\\\\\\\\\\\\\\u001b[39;00m \\\\\\\\\\\\\\\\u001b[43mio_open\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m(\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43mfile\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m,\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m \\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[38;5;241;43m*\\\\\\\\\\\\\\\\u001b[39;49m\\\\\\\\\\\\\\\\u001b[43margs\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m,\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m \\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[38;5;241;43m*\\\\\\\\\\\\\\\\u001b[39;49m\\\\\\\\\\\\\\\\u001b[38;5;241;43m*\\\\\\\\\\\\\\\\u001b[39;49m\\\\\\\\\\\\\\\\u001b[43mkwargs\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m)\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\u001b[1;31mFileNotFoundError\\\\\\\\\\\\\\\\u001b[0m: [Errno 2] No such file or directory: 'MODEL_PROVENANCE/run1234.json'\\\\\\\\\\\\\\\"\\\\\\\\n-     ]\\\\\\\\n-    }\\\\\\\\n-   ],\\\\\\\\n-   \\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\": []\\\\\\\\n-  },\\\\\\\\n-  {\\\\\\\\n-   \\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"code\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\\\": 207,\\\\\\\\n-   \\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"31d1fd16-0257-4fbb-b20d-4b05424d67ca\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {},\\\\\\\\n-   \\\\\\\\\\\\\\\"outputs\\\\\\\\\\\\\\\": [\\\\\\\\n-    {\\\\\\\\n-     \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"stdout\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"output_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"stream\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\": [\\\\\\\\n-      \\\\\\\\\\\\\\\"Collecting streamlit-option-menu\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"  Obtaining dependency information for streamlit-option-menu from https://files.pythonhosted.org/packages/fd/52/2f525ad4262dc83d67297f69ec5afcee1438b9e9ae22aa318396725ddbed/streamlit_option_menu-0.4.0-py3-none-any.whl.metadata\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"  Downloading streamlit_option_menu-0.4.0-py3-none-any.whl.metadata (2.5 kB)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Requirement already satisfied: streamlit>=1.36 in c:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\reema\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages (from streamlit-option-menu) (1.44.1)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Requirement already satisfied: altair<6,>=4.0 in c:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\reema\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages (from streamlit>=1.36->streamlit-option-menu) (5.5.0)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Requirement already satisfied: blinker<2,>=1.0.0 in c:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\reema\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages (from streamlit>=1.36->streamlit-option-menu) (1.9.0)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Requirement already satisfied: cachetools<6,>=4.0 in c:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\reema\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages (from streamlit>=1.36->streamlit-option-menu) (5.5.2)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Requirement already satisfied: click<9,>=7.0 in c:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\reema\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages (from streamlit>=1.36->streamlit-option-menu) (8.1.8)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Requirement already satisfied: numpy<3,>=1.23 in c:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\reema\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages (from streamlit>=1.36->streamlit-option-menu) (1.24.4)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Requirement already satisfied: packaging<25,>=20 in c:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\reema\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages (from streamlit>=1.36->streamlit-option-menu) (23.1)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Requirement already satisfied: pandas<3,>=1.4.0 in c:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\reema\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages (from streamlit>=1.36->streamlit-option-menu) (2.2.3)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Requirement already satisfied: pillow<12,>=7.1.0 in c:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\reema\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages (from streamlit>=1.36->streamlit-option-menu) (9.4.0)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Requirement already satisfied: protobuf<6,>=3.20 in c:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\reema\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages (from streamlit>=1.36->streamlit-option-menu) (5.29.3)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Requirement already satisfied: pyarrow>=7.0 in c:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\reema\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages (from streamlit>=1.36->streamlit-option-menu) (11.0.0)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Requirement already satisfied: requests<3,>=2.27 in c:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\reema\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages (from streamlit>=1.36->streamlit-option-menu) (2.31.0)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Requirement already satisfied: tenacity<10,>=8.1.0 in c:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\reema\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages (from streamlit>=1.36->streamlit-option-menu) (8.2.2)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Requirement already satisfied: toml<2,>=0.10.1 in c:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\reema\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages (from streamlit>=1.36->streamlit-option-menu) (0.10.2)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Requirement already satisfied: typing-extensions<5,>=4.4.0 in c:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\reema\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages (from streamlit>=1.36->streamlit-option-menu) (4.12.2)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Requirement already satisfied: watchdog<7,>=2.1.5 in c:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\reema\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages (from streamlit>=1.36->streamlit-option-menu) (2.1.6)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in c:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\reema\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages (from streamlit>=1.36->streamlit-option-menu) (3.1.43)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Requirement already satisfied: pydeck<1,>=0.8.0b4 in c:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\reema\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages (from streamlit>=1.36->streamlit-option-menu) (0.9.1)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Requirement already satisfied: tornado<7,>=6.0.3 in c:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\reema\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\appdata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\roaming\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\python\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\python311\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages (from streamlit>=1.36->streamlit-option-menu) (6.3.2)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Requirement already satisfied: jinja2 in c:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\reema\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages (from altair<6,>=4.0->streamlit>=1.36->streamlit-option-menu) (3.1.2)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Requirement already satisfied: jsonschema>=3.0 in c:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\reema\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages (from altair<6,>=4.0->streamlit>=1.36->streamlit-option-menu) (4.23.0)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Requirement already satisfied: narwhals>=1.14.2 in c:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\reema\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages (from altair<6,>=4.0->streamlit>=1.36->streamlit-option-menu) (1.30.0)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Requirement already satisfied: colorama in c:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\reema\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\appdata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\roaming\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\python\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\python311\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages (from click<9,>=7.0->streamlit>=1.36->streamlit-option-menu) (0.4.6)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\reema\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit>=1.36->streamlit-option-menu) (4.0.11)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Requirement already satisfied: python-dateutil>=2.8.2 in c:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\reema\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages (from pandas<3,>=1.4.0->streamlit>=1.36->streamlit-option-menu) (2.9.0.post0)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Requirement already satisfied: pytz>=2020.1 in c:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\reema\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages (from pandas<3,>=1.4.0->streamlit>=1.36->streamlit-option-menu) (2025.2)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Requirement already satisfied: tzdata>=2022.7 in c:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\reema\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages (from pandas<3,>=1.4.0->streamlit>=1.36->streamlit-option-menu) (2025.2)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Requirement already satisfied: charset-normalizer<4,>=2 in c:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\reema\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages (from requests<3,>=2.27->streamlit>=1.36->streamlit-option-menu) (2.0.4)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Requirement already satisfied: idna<4,>=2.5 in c:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\reema\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages (from requests<3,>=2.27->streamlit>=1.36->streamlit-option-menu) (3.4)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\reema\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages (from requests<3,>=2.27->streamlit>=1.36->streamlit-option-menu) (1.26.16)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Requirement already satisfied: certifi>=2017.4.17 in c:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\reema\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages (from requests<3,>=2.27->streamlit>=1.36->streamlit-option-menu) (2023.7.22)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Requirement already satisfied: smmap<6,>=3.0.1 in c:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\reema\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit>=1.36->streamlit-option-menu) (5.0.1)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Requirement already satisfied: MarkupSafe>=2.0 in c:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\reema\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages (from jinja2->altair<6,>=4.0->streamlit>=1.36->streamlit-option-menu) (2.1.1)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Requirement already satisfied: attrs>=22.2.0 in c:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\reema\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=1.36->streamlit-option-menu) (23.2.0)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\reema\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=1.36->streamlit-option-menu) (2024.10.1)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Requirement already satisfied: referencing>=0.28.4 in c:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\reema\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=1.36->streamlit-option-menu) (0.35.1)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Requirement already satisfied: rpds-py>=0.7.1 in c:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\reema\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=1.36->streamlit-option-menu) (0.22.3)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Requirement already satisfied: six>=1.5 in c:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\reema\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit>=1.36->streamlit-option-menu) (1.17.0)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Downloading streamlit_option_menu-0.4.0-py3-none-any.whl (829 kB)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"   ---------------------------------------- 0.0/829.3 kB ? eta -:--:--\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"   ---------------------------------------- 0.0/829.3 kB ? eta -:--:--\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"    -------------------------------------- 20.5/829.3 kB 682.7 kB/s eta 0:00:02\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"   -------- ------------------------------- 184.3/829.3 kB 2.8 MB/s eta 0:00:01\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"   ---------------------------------------- 829.3/829.3 kB 7.5 MB/s eta 0:00:00\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Installing collected packages: streamlit-option-menu\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Successfully installed streamlit-option-menu-0.4.0\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n-     ]\\\\\\\\n-    },\\\\\\\\n-    {\\\\\\\\n-     \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"stderr\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"output_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"stream\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\": [\\\\\\\\n-      \\\\\\\\\\\\\\\"WARNING: There was an error checking the latest version of pip.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n-     ]\\\\\\\\n-    }\\\\\\\\n-   ],\\\\\\\\n-   \\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\": [\\\\\\\\n-    \\\\\\\\\\\\\\\"!pip install streamlit-option-menu\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n-   ]\\\\\\\\n-  },\\\\\\\\n-  {\\\\\\\\n-   \\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"code\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\\\": 170,\\\\\\\\n-   \\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"fb02692d-ffdb-4431-997d-5198e3e8f755\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {},\\\\\\\\n-   \\\\\\\\\\\\\\\"outputs\\\\\\\\\\\\\\\": [\\\\\\\\n-    {\\\\\\\\n-     \\\\\\\\\\\\\\\"ename\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"HTTPError\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"evalue\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"403 Client Error: FORBIDDEN for url: https://127.0.0.1:5000/api/records\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"output_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"error\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"traceback\\\\\\\\\\\\\\\": [\\\\\\\\n-      \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\u001b[1;31m---------------------------------------------------------------------------\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\u001b[1;31mHTTPError\\\\\\\\\\\\\\\\u001b[0m                                 Traceback (most recent call last)\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Cell \\\\\\\\\\\\\\\\u001b[1;32mIn[170], line 84\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m     77\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[38;5;66;03m# -----------------------------------------------------------------------------\\\\\\\\\\\\\\\\u001b[39;00m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m     78\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[38;5;66;03m#  2) Create a new draft\\\\\\\\\\\\\\\\u001b[39;00m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m     79\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[38;5;66;03m# -----------------------------------------------------------------------------\\\\\\\\\\\\\\\\u001b[39;00m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m     80\\\\\\\\\\\\\\\\u001b[0m r \\\\\\\\\\\\\\\\u001b[38;5;241m=\\\\\\\\\\\\\\\\u001b[39m requests\\\\\\\\\\\\\\\\u001b[38;5;241m.\\\\\\\\\\\\\\\\u001b[39mpost(\\\\\\\\\\\\\\\\u001b[38;5;124mf\\\\\\\\\\\\\\\\u001b[39m\\\\\\\\\\\\\\\\u001b[38;5;124m\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\u001b[39m\\\\\\\\\\\\\\\\u001b[38;5;132;01m{\\\\\\\\\\\\\\\\u001b[39;00mAPI_BASE\\\\\\\\\\\\\\\\u001b[38;5;132;01m}\\\\\\\\\\\\\\\\u001b[39;00m\\\\\\\\\\\\\\\\u001b[38;5;124m/api/records\\\\\\\\\\\\\\\\u001b[39m\\\\\\\\\\\\\\\\u001b[38;5;124m\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\u001b[39m,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m     81\\\\\\\\\\\\\\\\u001b[0m                   headers\\\\\\\\\\\\\\\\u001b[38;5;241m=\\\\\\\\\\\\\\\\u001b[39mH_JSON,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m     82\\\\\\\\\\\\\\\\u001b[0m                   json\\\\\\\\\\\\\\\\u001b[38;5;241m=\\\\\\\\\\\\\\\\u001b[39mmeta,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m     83\\\\\\\\\\\\\\\\u001b[0m                   verify\\\\\\\\\\\\\\\\u001b[38;5;241m=\\\\\\\\\\\\\\\\u001b[39mVERIFY_SSL)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[1;32m---> 84\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[43mr\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[38;5;241;43m.\\\\\\\\\\\\\\\\u001b[39;49m\\\\\\\\\\\\\\\\u001b[43mraise_for_status\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m(\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m)\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m     85\\\\\\\\\\\\\\\\u001b[0m draft \\\\\\\\\\\\\\\\u001b[38;5;241m=\\\\\\\\\\\\\\\\u001b[39m r\\\\\\\\\\\\\\\\u001b[38;5;241m.\\\\\\\\\\\\\\\\u001b[39mjson()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m     86\\\\\\\\\\\\\\\\u001b[0m recid \\\\\\\\\\\\\\\\u001b[38;5;241m=\\\\\\\\\\\\\\\\u001b[39m draft[\\\\\\\\\\\\\\\\u001b[38;5;124m\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\u001b[39m\\\\\\\\\\\\\\\\u001b[38;5;124mid\\\\\\\\\\\\\\\\u001b[39m\\\\\\\\\\\\\\\\u001b[38;5;124m\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\u001b[39m]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"File \\\\\\\\\\\\\\\\u001b[1;32m~\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\requests\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\models.py:1021\\\\\\\\\\\\\\\\u001b[0m, in \\\\\\\\\\\\\\\\u001b[0;36mResponse.raise_for_status\\\\\\\\\\\\\\\\u001b[1;34m(self)\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m   1016\\\\\\\\\\\\\\\\u001b[0m     http_error_msg \\\\\\\\\\\\\\\\u001b[38;5;241m=\\\\\\\\\\\\\\\\u001b[39m (\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m   1017\\\\\\\\\\\\\\\\u001b[0m         \\\\\\\\\\\\\\\\u001b[38;5;124mf\\\\\\\\\\\\\\\\u001b[39m\\\\\\\\\\\\\\\\u001b[38;5;124m\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\u001b[39m\\\\\\\\\\\\\\\\u001b[38;5;132;01m{\\\\\\\\\\\\\\\\u001b[39;00m\\\\\\\\\\\\\\\\u001b[38;5;28mself\\\\\\\\\\\\\\\\u001b[39m\\\\\\\\\\\\\\\\u001b[38;5;241m.\\\\\\\\\\\\\\\\u001b[39mstatus_code\\\\\\\\\\\\\\\\u001b[38;5;132;01m}\\\\\\\\\\\\\\\\u001b[39;00m\\\\\\\\\\\\\\\\u001b[38;5;124m Server Error: \\\\\\\\\\\\\\\\u001b[39m\\\\\\\\\\\\\\\\u001b[38;5;132;01m{\\\\\\\\\\\\\\\\u001b[39;00mreason\\\\\\\\\\\\\\\\u001b[38;5;132;01m}\\\\\\\\\\\\\\\\u001b[39;00m\\\\\\\\\\\\\\\\u001b[38;5;124m for url: \\\\\\\\\\\\\\\\u001b[39m\\\\\\\\\\\\\\\\u001b[38;5;132;01m{\\\\\\\\\\\\\\\\u001b[39;00m\\\\\\\\\\\\\\\\u001b[38;5;28mself\\\\\\\\\\\\\\\\u001b[39m\\\\\\\\\\\\\\\\u001b[38;5;241m.\\\\\\\\\\\\\\\\u001b[39murl\\\\\\\\\\\\\\\\u001b[38;5;132;01m}\\\\\\\\\\\\\\\\u001b[39;00m\\\\\\\\\\\\\\\\u001b[38;5;124m\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\u001b[39m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m   1018\\\\\\\\\\\\\\\\u001b[0m     )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m   1020\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[38;5;28;01mif\\\\\\\\\\\\\\\\u001b[39;00m http_error_msg:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[1;32m-> 1021\\\\\\\\\\\\\\\\u001b[0m     \\\\\\\\\\\\\\\\u001b[38;5;28;01mraise\\\\\\\\\\\\\\\\u001b[39;00m HTTPError(http_error_msg, response\\\\\\\\\\\\\\\\u001b[38;5;241m=\\\\\\\\\\\\\\\\u001b[39m\\\\\\\\\\\\\\\\u001b[38;5;28mself\\\\\\\\\\\\\\\\u001b[39m)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\u001b[1;31mHTTPError\\\\\\\\\\\\\\\\u001b[0m: 403 Client Error: FORBIDDEN for url: https://127.0.0.1:5000/api/records\\\\\\\\\\\\\\\"\\\\\\\\n-     ]\\\\\\\\n-    }\\\\\\\\n-   ],\\\\\\\\n-   \\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\": [\\\\\\\\n-    \\\\\\\\\\\\\\\"import os\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"import json\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"import requests\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"from rdflib import Graph, URIRef, Literal\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"from rdflib.namespace import PROV, XSD\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# -----------------------------------------------------------------------------\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#  CONFIGURATION\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# -----------------------------------------------------------------------------\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"API_BASE   = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"https://127.0.0.1:5000\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"TOKEN      = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"ZctHtk65umtROkzOFq2Ot7WbJTqz46q5w8SOMry2c2rT9CqaRbySNp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"VERIFY_SSL = False   # for local self-signed\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"H_JSON = {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Accept\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"application/json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Content-Type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"application/json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Authorization\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Bearer {TOKEN}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"H_OCTET = {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Authorization\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Bearer {TOKEN}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Content-Type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"application/octet-stream\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# top-level folders you want to push\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"TO_UPLOAD = [\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Trained_models\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"plots\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"MODEL_PROVENANCE\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# -----------------------------------------------------------------------------\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#  OPTIONAL: turn your JSON provenance \\\\\\\\u2192 PROV-O \\\\\\\\u2192 JSON-LD (if you want structured metadata)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# -----------------------------------------------------------------------------\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"def json_to_prov_ttl(raw: dict) -> str:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    g   = Graph()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    run = URIRef(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"urn:run:{raw['run_id']}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    g.bind(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"prov\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", PROV)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # example: timestamps\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    g.add((run, PROV.startedAtTime,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"           Literal(raw[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"start_time\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"], datatype=XSD.dateTime)))\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # params \\\\\\\\u2192 prov:hadParameter\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    for k, v in raw.get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"params\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", {}).items():\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        g.add((run, PROV.hadParameter, Literal(v, datatype=XSD.string)))\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # metrics \\\\\\\\u2192 prov:hadQuality\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    for k, v in raw.get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metrics\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", {}).items():\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        g.add((run, PROV.hadQuality, Literal(v, datatype=XSD.decimal)))\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    return g.serialize(format=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"turtle\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\").decode()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"def ttl_to_jsonld(ttl: str) -> dict:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    g = Graph().parse(data=ttl, format=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"turtle\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    return json.loads(g.serialize(format=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"json-ld\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"))\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# -----------------------------------------------------------------------------\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#  1) (optional) read your raw provenance JSON and embed as JSON-LD under \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# -----------------------------------------------------------------------------\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# with open(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"MODEL_PROVENANCE/run1234.json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\") as fp:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     raw_meta = json.load(fp)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# ttl    = json_to_prov_ttl(raw_meta)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# jsonld = ttl_to_jsonld(ttl)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# meta   = {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"title\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":       f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Iris RF run {raw_meta['run_id']}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"description\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Structured PROV-O in JSON-LD\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"@context\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": jsonld.get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"@context\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", {}),\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"@graph\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":   jsonld.get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"@graph\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", [])\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# -----------------------------------------------------------------------------\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#  1') Or, if you don\\\\\\\\u2019t need JSON-LD, just supply minimal metadata:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# -----------------------------------------------------------------------------\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"meta = {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"title\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":       \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"My trained ML model\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"description\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"All artifacts for RandomForest on Iris\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"creator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":     \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Reema Dass\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# -----------------------------------------------------------------------------\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#  2) Create a new draft\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# -----------------------------------------------------------------------------\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"r = requests.post(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{API_BASE}/api/records\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"                  headers=H_JSON,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"                  json=meta,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"                  verify=VERIFY_SSL)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"r.raise_for_status()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"draft = r.json()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"recid = draft[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"files_link = draft[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"links\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"][\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"files\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\u2705 Draft created: {recid}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# -----------------------------------------------------------------------------\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#  3) Walk & upload every file in each folder\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# -----------------------------------------------------------------------------\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"for folder in TO_UPLOAD:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    if not os.path.isdir(folder):\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\u26a0\\\\\\\\ufe0f  Skipping missing folder {folder}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        continue\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    for root, _, filenames in os.walk(folder):\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        for fn in filenames:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            local_path = os.path.join(root, fn)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            # build the \\\\\\\\u201ckey\\\\\\\\u201d so that in Invenio it shows up under folder/\\\\\\\\u2026\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            rel = os.path.relpath(local_path, start=folder).replace(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"/\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            key = f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{folder}/{rel}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            # 3a) register the file in the draft\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            entry = [{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"key\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": key}]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            r1 = requests.post(files_link,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"                               headers=H_JSON,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"                               json=entry,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"                               verify=VERIFY_SSL)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            r1.raise_for_status()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            file_links = r1.json()[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"entries\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"][0][\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"links\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            # 3b) upload the content\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            with open(local_path, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"rb\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\") as fp:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"                r2 = requests.put(file_links[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"],\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"                                  headers=H_OCTET,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"                                  data=fp,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"                                  verify=VERIFY_SSL)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            r2.raise_for_status()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            # 3c) commit it\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            r3 = requests.post(file_links[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"commit\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"],\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"                               headers=H_JSON,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"                               verify=VERIFY_SSL)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            r3.raise_for_status()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"  \\\\\\\\u2022 Uploaded {key}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# -----------------------------------------------------------------------------\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#  4) Publish the draft\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# -----------------------------------------------------------------------------\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"rp = requests.post(draft[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"links\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"][\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"publish\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"],\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"                   headers=H_JSON,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"                   verify=VERIFY_SSL)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"rp.raise_for_status()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\u2705 Published:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", rp.json()[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"])\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n-   ]\\\\\\\\n-  },\\\\\\\\n-  {\\\\\\\\n-   \\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"code\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\\\": 176,\\\\\\\\n-   \\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"82bda3d9-62af-44e8-96a5-58008973bd70\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {},\\\\\\\\n-   \\\\\\\\\\\\\\\"outputs\\\\\\\\\\\\\\\": [\\\\\\\\n-    {\\\\\\\\n-     \\\\\\\\\\\\\\\"ename\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"HTTPError\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"evalue\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"403 Client Error: FORBIDDEN for url: https://127.0.0.1:5000/api/records\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"output_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"error\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"traceback\\\\\\\\\\\\\\\": [\\\\\\\\n-      \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\u001b[1;31m---------------------------------------------------------------------------\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\u001b[1;31mHTTPError\\\\\\\\\\\\\\\\u001b[0m                                 Traceback (most recent call last)\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Cell \\\\\\\\\\\\\\\\u001b[1;32mIn[176], line 43\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m     38\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[38;5;66;03m# 3) Create the draft record\\\\\\\\\\\\\\\\u001b[39;00m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m     39\\\\\\\\\\\\\\\\u001b[0m r \\\\\\\\\\\\\\\\u001b[38;5;241m=\\\\\\\\\\\\\\\\u001b[39m requests\\\\\\\\\\\\\\\\u001b[38;5;241m.\\\\\\\\\\\\\\\\u001b[39mpost(\\\\\\\\\\\\\\\\u001b[38;5;124mf\\\\\\\\\\\\\\\\u001b[39m\\\\\\\\\\\\\\\\u001b[38;5;124m\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\u001b[39m\\\\\\\\\\\\\\\\u001b[38;5;132;01m{\\\\\\\\\\\\\\\\u001b[39;00mAPI_BASE\\\\\\\\\\\\\\\\u001b[38;5;132;01m}\\\\\\\\\\\\\\\\u001b[39;00m\\\\\\\\\\\\\\\\u001b[38;5;124m/api/records\\\\\\\\\\\\\\\\u001b[39m\\\\\\\\\\\\\\\\u001b[38;5;124m\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\u001b[39m,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m     40\\\\\\\\\\\\\\\\u001b[0m                   headers\\\\\\\\\\\\\\\\u001b[38;5;241m=\\\\\\\\\\\\\\\\u001b[39mH_JSON,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m     41\\\\\\\\\\\\\\\\u001b[0m                   json\\\\\\\\\\\\\\\\u001b[38;5;241m=\\\\\\\\\\\\\\\\u001b[39mpayload,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m     42\\\\\\\\\\\\\\\\u001b[0m                   verify\\\\\\\\\\\\\\\\u001b[38;5;241m=\\\\\\\\\\\\\\\\u001b[39mVERIFY_SSL)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[1;32m---> 43\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[43mr\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[38;5;241;43m.\\\\\\\\\\\\\\\\u001b[39;49m\\\\\\\\\\\\\\\\u001b[43mraise_for_status\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m(\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\u001b[43m)\\\\\\\\\\\\\\\\u001b[49m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m     44\\\\\\\\\\\\\\\\u001b[0m draft \\\\\\\\\\\\\\\\u001b[38;5;241m=\\\\\\\\\\\\\\\\u001b[39m r\\\\\\\\\\\\\\\\u001b[38;5;241m.\\\\\\\\\\\\\\\\u001b[39mjson()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m     45\\\\\\\\\\\\\\\\u001b[0m recid \\\\\\\\\\\\\\\\u001b[38;5;241m=\\\\\\\\\\\\\\\\u001b[39m draft[\\\\\\\\\\\\\\\\u001b[38;5;124m\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\u001b[39m\\\\\\\\\\\\\\\\u001b[38;5;124mid\\\\\\\\\\\\\\\\u001b[39m\\\\\\\\\\\\\\\\u001b[38;5;124m\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\u001b[39m]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"File \\\\\\\\\\\\\\\\u001b[1;32m~\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\anaconda3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Lib\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\site-packages\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\requests\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\models.py:1021\\\\\\\\\\\\\\\\u001b[0m, in \\\\\\\\\\\\\\\\u001b[0;36mResponse.raise_for_status\\\\\\\\\\\\\\\\u001b[1;34m(self)\\\\\\\\\\\\\\\\u001b[0m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m   1016\\\\\\\\\\\\\\\\u001b[0m     http_error_msg \\\\\\\\\\\\\\\\u001b[38;5;241m=\\\\\\\\\\\\\\\\u001b[39m (\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m   1017\\\\\\\\\\\\\\\\u001b[0m         \\\\\\\\\\\\\\\\u001b[38;5;124mf\\\\\\\\\\\\\\\\u001b[39m\\\\\\\\\\\\\\\\u001b[38;5;124m\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\u001b[39m\\\\\\\\\\\\\\\\u001b[38;5;132;01m{\\\\\\\\\\\\\\\\u001b[39;00m\\\\\\\\\\\\\\\\u001b[38;5;28mself\\\\\\\\\\\\\\\\u001b[39m\\\\\\\\\\\\\\\\u001b[38;5;241m.\\\\\\\\\\\\\\\\u001b[39mstatus_code\\\\\\\\\\\\\\\\u001b[38;5;132;01m}\\\\\\\\\\\\\\\\u001b[39;00m\\\\\\\\\\\\\\\\u001b[38;5;124m Server Error: \\\\\\\\\\\\\\\\u001b[39m\\\\\\\\\\\\\\\\u001b[38;5;132;01m{\\\\\\\\\\\\\\\\u001b[39;00mreason\\\\\\\\\\\\\\\\u001b[38;5;132;01m}\\\\\\\\\\\\\\\\u001b[39;00m\\\\\\\\\\\\\\\\u001b[38;5;124m for url: \\\\\\\\\\\\\\\\u001b[39m\\\\\\\\\\\\\\\\u001b[38;5;132;01m{\\\\\\\\\\\\\\\\u001b[39;00m\\\\\\\\\\\\\\\\u001b[38;5;28mself\\\\\\\\\\\\\\\\u001b[39m\\\\\\\\\\\\\\\\u001b[38;5;241m.\\\\\\\\\\\\\\\\u001b[39murl\\\\\\\\\\\\\\\\u001b[38;5;132;01m}\\\\\\\\\\\\\\\\u001b[39;00m\\\\\\\\\\\\\\\\u001b[38;5;124m\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\u001b[39m\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m   1018\\\\\\\\\\\\\\\\u001b[0m     )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[0;32m   1020\\\\\\\\\\\\\\\\u001b[0m \\\\\\\\\\\\\\\\u001b[38;5;28;01mif\\\\\\\\\\\\\\\\u001b[39;00m http_error_msg:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\u001b[1;32m-> 1021\\\\\\\\\\\\\\\\u001b[0m     \\\\\\\\\\\\\\\\u001b[38;5;28;01mraise\\\\\\\\\\\\\\\\u001b[39;00m HTTPError(http_error_msg, response\\\\\\\\\\\\\\\\u001b[38;5;241m=\\\\\\\\\\\\\\\\u001b[39m\\\\\\\\\\\\\\\\u001b[38;5;28mself\\\\\\\\\\\\\\\\u001b[39m)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\u001b[1;31mHTTPError\\\\\\\\\\\\\\\\u001b[0m: 403 Client Error: FORBIDDEN for url: https://127.0.0.1:5000/api/records\\\\\\\\\\\\\\\"\\\\\\\\n-     ]\\\\\\\\n-    }\\\\\\\\n-   ],\\\\\\\\n-   \\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\": [\\\\\\\\n-    \\\\\\\\\\\\\\\"import os\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"import json\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"import requests\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# -----------------------------------------------------------------------------\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# CONFIGURATION\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# -----------------------------------------------------------------------------\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"API_BASE   = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"https://127.0.0.1:5000\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"TOKEN      = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"ZctHtk65umtROkzOFq2Ot7WbJTqz46q5w8SOMry2c2rT9CqaRbySNp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"VERIFY_SSL = False  # only for local dev\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"H_JSON = {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Accept\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"application/json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Content-Type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"application/json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Authorization\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Bearer {TOKEN}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"H_OCTET = {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Accept\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"application/json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Content-Type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"application/octet-stream\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Authorization\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Bearer {TOKEN}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# -----------------------------------------------------------------------------\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# 1) Point this at your folder that contains only .pkl (and maybe other) files\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# -----------------------------------------------------------------------------\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"RECORD_FOLDER = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Trained_models\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"     # \\\\\\\\u2190 adjust as needed\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"CREATOR       = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Reema Dass\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"         # your name or email\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# -----------------------------------------------------------------------------\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# 2) Build a minimal metadata payload in\\\\\\\\u2010memory\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# -----------------------------------------------------------------------------\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"payload = {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"title\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":       os.path.basename(RECORD_FOLDER),\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"description\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"All artifacts in folder `{RECORD_FOLDER}`\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"creator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":     CREATOR\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# 3) Create the draft record\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"r = requests.post(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{API_BASE}/api/records\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"                  headers=H_JSON,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"                  json=payload,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"                  verify=VERIFY_SSL)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"r.raise_for_status()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"draft = r.json()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"recid = draft[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"links = draft[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"links\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\u2705 Draft created: {recid}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# -----------------------------------------------------------------------------\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# 4) Walk your folder and upload every file you find\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# -----------------------------------------------------------------------------\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"for root, _, filenames in os.walk(RECORD_FOLDER):\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    for fn in filenames:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        local_path = os.path.join(root, fn)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        # compute the \\\\\\\\u201ckey\\\\\\\\u201d under which it\\\\\\\\u2019ll live in your record\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        key = os.path.relpath(local_path, start=RECORD_FOLDER).replace(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"/\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        # a) register that key\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        entry = [{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"key\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": key}]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        r1 = requests.post(links[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"files\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"],\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"                           headers=H_JSON,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"                           json=entry,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"                           verify=VERIFY_SSL)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        r1.raise_for_status()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        file_links = r1.json()[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"entries\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"][0][\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"links\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        # b) upload bytes\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        with open(local_path, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"rb\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\") as fp:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            r2 = requests.put(file_links[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"],\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"                              headers=H_OCTET,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"                              data=fp,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"                              verify=VERIFY_SSL)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        r2.raise_for_status()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        # c) commit\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        r3 = requests.post(file_links[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"commit\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"],\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"                           headers=H_JSON,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"                           verify=VERIFY_SSL)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        r3.raise_for_status()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"  \\\\\\\\u2022 Uploaded {key}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# -----------------------------------------------------------------------------\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# 5) Publish\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# -----------------------------------------------------------------------------\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"rpub = requests.post(links[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"publish\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"],\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"                     headers=H_JSON,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"                     verify=VERIFY_SSL)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"rpub.raise_for_status()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\u2705 Published: {rpub.json()['id']}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n-   ]\\\\\\\\n-  },\\\\\\\\n-  {\\\\\\\\n-   \\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"code\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\\\": 178,\\\\\\\\n-   \\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"94115adc-62d2-413a-9f51-5b13d3f46392\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {\\\\\\\\n-    \\\\\\\\\\\\\\\"scrolled\\\\\\\\\\\\\\\": true\\\\\\\\n-   },\\\\\\\\n-   \\\\\\\\\\\\\\\"outputs\\\\\\\\\\\\\\\": [\\\\\\\\n-    {\\\\\\\\n-     \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"stdout\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"output_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"stream\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\": [\\\\\\\\n-      \\\\\\\\\\\\\\\"200\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"200 {'hits': {'hits': [{'id': 'a5eb3-j9f36', 'created': '2025-04-24T11:52:42.696314+00:00', 'updated': '2025-04-24T11:52:42.961276+00:00', 'links': {'self': 'https://127.0.0.1:5000/api/records/a5eb3-j9f36', 'self_html': 'https://127.0.0.1:5000/records/a5eb3-j9f36', 'parent': 'https://127.0.0.1:5000/api/records/39q9z-4cp60', 'parent_html': 'https://127.0.0.1:5000/records/39q9z-4cp60', 'self_iiif_manifest': 'https://127.0.0.1:5000/api/iiif/record:a5eb3-j9f36/manifest', 'self_iiif_sequence': 'https://127.0.0.1:5000/api/iiif/record:a5eb3-j9f36/sequence/default', 'files': 'https://127.0.0.1:5000/api/records/a5eb3-j9f36/files', 'media_files': 'https://127.0.0.1:5000/api/records/a5eb3-j9f36/media-files', 'archive': 'https://127.0.0.1:5000/api/records/a5eb3-j9f36/files-archive', 'archive_media': 'https://127.0.0.1:5000/api/records/a5eb3-j9f36/media-files-archive', 'latest': 'https://127.0.0.1:5000/api/records/a5eb3-j9f36/versions/latest', 'latest_html': 'https://127.0.0.1:5000/records/a5eb3-j9f36/latest', 'draft': 'https://127.0.0.1:5000/api/records/a5eb3-j9f36/draft', 'versions': 'https://127.0.0.1:5000/api/records/a5eb3-j9f36/versions', 'access_links': 'https://127.0.0.1:5000/api/records/a5eb3-j9f36/access/links', 'access_grants': 'https://127.0.0.1:5000/api/records/a5eb3-j9f36/access/grants', 'access_users': 'https://127.0.0.1:5000/api/records/a5eb3-j9f36/access/users', 'access_groups': 'https://127.0.0.1:5000/api/records/a5eb3-j9f36/access/groups', 'access_request': 'https://127.0.0.1:5000/api/records/a5eb3-j9f36/access/request', 'access': 'https://127.0.0.1:5000/api/records/a5eb3-j9f36/access', 'reserve_doi': 'https://127.0.0.1:5000/api/records/a5eb3-j9f36/draft/pids/doi', 'communities': 'https://127.0.0.1:5000/api/records/a5eb3-j9f36/communities', 'communities-suggestions': 'https://127.0.0.1:5000/api/records/a5eb3-j9f36/communities-suggestions', 'requests': 'https://127.0.0.1:5000/api/records/a5eb3-j9f36/requests'}, 'revision_id': 4, 'parent': {'id': '39q9z-4cp60', 'access': {'grants': [], 'owned_by': {'user': '3'}, 'links': [], 'settings': {'allow_user_requests': False, 'allow_guest_requests': False, 'accept_conditions_text': None, 'secret_link_expiration': 0}}, 'communities': {}, 'pids': {}}, 'versions': {'is_latest': True, 'is_latest_draft': True, 'index': 1}, 'is_published': True, 'is_draft': False, 'pids': {'oai': {'identifier': 'oai:my-site.com:a5eb3-j9f36', 'provider': 'oai'}}, 'metadata': {'resource_type': {'id': 'other', 'title': {'de': 'Sonstige', 'en': 'Other', 'sv': '\\\\\\\\u00d6vrig'}}, 'creators': [{'person_or_org': {'type': 'personal', 'name': 'Dass, Reema', 'given_name': 'Reema', 'family_name': 'Dass'}}], 'title': 'ML model', 'publisher': 'My Site', 'publication_date': '2025-04-24', 'rights': [{'id': 'cc-by-4.0', 'title': {'en': 'Creative Commons Attribution 4.0 International'}, 'description': {'en': 'The Creative Commons Attribution license allows re-distribution and re-use of a licensed work on the condition that the creator is appropriately credited.'}, 'icon': 'cc-by-icon', 'props': {'url': 'https://creativecommons.org/licenses/by/4.0/', 'scheme': 'spdx'}}]}, 'custom_fields': {}, 'access': {'record': 'public', 'files': 'public', 'embargo': {'active': False, 'reason': None}, 'status': 'open'}, 'files': {'enabled': True, 'order': [], 'count': 9, 'total_bytes': 171368, 'entries': {'roc_curve_cls_1.png': {'id': '4f4c8b29-02b3-40c4-af33-412f589a05f4', 'checksum': 'md5:917e9847fda527b030c0bcad8f2a2ea3', 'ext': 'png', 'size': 20143, 'mimetype': 'image/png', 'key': 'roc_curve_cls_1.png', 'metadata': {'width': 640, 'height': 480}, 'access': {'hidden': False}}, 'shap_summary.png': {'id': 'aebc0a0b-0b09-44ea-85ef-83ad0ac64fb3', 'checksum': 'md5:ac7959b6085a30cab3d8778a32d54d1a', 'ext': 'png', 'size': 16885, 'mimetype': 'image/png', 'key': 'shap_summary.png', 'metadata': {'width': 1150, 'height': 660}, 'access': {'hidden': False}}, 'roc_curve_cls_2.png': {'id': '2dfc6ced-6321-42dc-80bf-294dfaffe88c', 'checksum': 'md5:c076643c49b9ae7ba3cf0794b18f74db', 'ext': 'png', 'size': 20227, 'mimetype': 'image/png', 'key': 'roc_curve_cls_2.png', 'metadata': {'width': 640, 'height': 480}, 'access': {'hidden': False}}, 'confusion_matrix.png': {'id': 'dde4083c-8029-44de-b64e-bdef98e75601', 'checksum': 'md5:41c356960df1b924d7db4d4a5cc9b254', 'ext': 'png', 'size': 14453, 'mimetype': 'image/png', 'key': 'confusion_matrix.png', 'metadata': {'width': 600, 'height': 600}, 'access': {'hidden': False}}, 'feature_importances.png': {'id': 'cdfb75da-1e15-4fdb-a5fe-3bc5e181bf84', 'checksum': 'md5:1702afd2578c67988efdcf1f28fe1b04', 'ext': 'png', 'size': 19167, 'mimetype': 'image/png', 'key': 'feature_importances.png', 'metadata': {'width': 800, 'height': 600}, 'access': {'hidden': False}}, 'pr_curve_cls_0.png': {'id': '363871b4-6f5a-4c89-b197-e5cc5cbccf2f', 'checksum': 'md5:30a6a3742bcbd69750bc5fd30aea58d2', 'ext': 'png', 'size': 20358, 'mimetype': 'image/png', 'key': 'pr_curve_cls_0.png', 'metadata': {'width': 640, 'height': 480}, 'access': {'hidden': False}}, 'pr_curve_cls_1.png': {'id': '77ca9443-8953-4b20-8b6f-293961b4eabd', 'checksum': 'md5:7f396723afbfa90eb3d5f3e850f52c80', 'ext': 'png', 'size': 20226, 'mimetype': 'image/png', 'key': 'pr_curve_cls_1.png', 'metadata': {'width': 640, 'height': 480}, 'access': {'hidden': False}}, 'pr_curve_cls_2.png': {'id': '74ce57eb-f11d-434c-b030-7f045c467f48', 'checksum': 'md5:22a124dad652fd24fb3a5691abcae494', 'ext': 'png', 'size': 19809, 'mimetype': 'image/png', 'key': 'pr_curve_cls_2.png', 'metadata': {'width': 640, 'height': 480}, 'access': {'hidden': False}}, 'roc_curve_cls_0.png': {'id': 'f0e6047e-2af3-477d-936d-6041ed4d5d85', 'checksum': 'md5:f6d5e559a27d81fb010b416bddc2fb02', 'ext': 'png', 'size': 20100, 'mimetype': 'image/png', 'key': 'roc_curve_cls_0.png', 'metadata': {'width': 640, 'height': 480}, 'access': {'hidden': False}}}}, 'media_files': {'enabled': False, 'order': [], 'count': 0, 'total_bytes': 0, 'entries': {}}, 'status': 'published', 'deletion_status': {'is_deleted': False, 'status': 'P'}, 'stats': {'this_version': {'views': 0, 'unique_views': 0, 'downloads': 0, 'unique_downloads': 0, 'data_volume': 0.0}, 'all_versions': {'views': 0, 'unique_views': 0, 'downloads': 0, 'unique_downloads': 0, 'data_volume': 0.0}}}], 'total': 101}, 'aggregations': {'access_status': {'buckets': [{'key': 'metadata-only', 'doc_count': 100, 'label': 'Metadata-only', 'is_selected': False}, {'key': 'open', 'doc_count': 1, 'label': 'Open', 'is_selected': False}], 'label': 'Access status'}, 'file_type': {'buckets': [{'key': 'png', 'doc_count': 1, 'label': 'PNG', 'is_selected': False}], 'label': 'File type'}, 'resource_type': {'buckets': [{'key': 'publication', 'doc_count': 50, 'label': 'Publication', 'is_selected': False, 'inner': {'buckets': [{'key': 'publication-annotationcollection', 'doc_count': 4, 'label': 'Annotation collection', 'is_selected': False}, {'key': 'publication-datapaper', 'doc_count': 4, 'label': 'Data paper', 'is_selected': False}, {'key': 'publication-peerreview', 'doc_count': 4, 'label': 'Peer review', 'is_selected': False}, {'key': 'publication-deliverable', 'doc_count': 3, 'label': 'Project deliverable', 'is_selected': False}, {'key': 'publication-preprint', 'doc_count': 3, 'label': 'Preprint', 'is_selected': False}, {'key': 'publication-section', 'doc_count': 3, 'label': 'Book chapter', 'is_selected': False}, {'key': 'publication-taxonomictreatment', 'doc_count': 3, 'label': 'Taxonomic treatment', 'is_selected': False}, {'key': 'publication-thesis', 'doc_count': 3, 'label': 'Thesis', 'is_selected': False}, {'key': 'publication-book', 'doc_count': 2, 'label': 'Book', 'is_selected': False}, {'key': 'publication-datamanagementplan', 'doc_count': 2, 'label': 'Output management plan', 'is_selected': False}]}}, {'key': 'image', 'doc_count': 19, 'label': 'Image', 'is_selected': False, 'inner': {'buckets': [{'key': 'image-diagram', 'doc_count': 5, 'label': 'Diagram', 'is_selected': False}, {'key': 'image-other', 'doc_count': 5, 'label': 'Other', 'is_selected': False}, {'key': 'image-photo', 'doc_count': 4, 'label': 'Photo', 'is_selected': False}, {'key': 'image-plot', 'doc_count': 2, 'label': 'Plot', 'is_selected': False}, {'key': 'image-drawing', 'doc_count': 1, 'label': 'Drawing', 'is_selected': False}, {'key': 'image-figure', 'doc_count': 1, 'label': 'Figure', 'is_selected': False}]}}, {'key': 'software', 'doc_count': 6, 'label': 'Software', 'is_selected': False, 'inner': {'buckets': [{'key': 'software-computationalnotebook', 'doc_count': 2, 'label': 'Computational notebook', 'is_selected': False}]}}, {'key': 'model', 'doc_count': 5, 'label': 'Model', 'is_selected': False, 'inner': {'buckets': []}}, {'key': 'dataset', 'doc_count': 4, 'label': 'Dataset', 'is_selected': False, 'inner': {'buckets': []}}, {'key': 'other', 'doc_count': 4, 'label': 'Other', 'is_selected': False, 'inner': {'buckets': []}}, {'key': 'workflow', 'doc_count': 3, 'label': 'Workflow', 'is_selected': False, 'inner': {'buckets': []}}, {'key': 'audio', 'doc_count': 2, 'label': 'Audio', 'is_selected': False, 'inner': {'buckets': []}}, {'key': 'physicalobject', 'doc_count': 2, 'label': 'Physical object', 'is_selected': False, 'inner': {'buckets': []}}, {'key': 'presentation', 'doc_count': 2, 'label': 'Presentation', 'is_selected': False, 'inner': {'buckets': []}}], 'label': 'Resource types'}}, 'sortBy': 'newest', 'links': {'self': 'https://127.0.0.1:5000/api/records?page=1&size=1&sort=newest', 'next': 'https://127.0.0.1:5000/api/records?page=2&size=1&sort=newest'}}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n-     ]\\\\\\\\n-    }\\\\\\\\n-   ],\\\\\\\\n-   \\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\": [\\\\\\\\n-    \\\\\\\\\\\\\\\"import requests\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"API_BASE = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"https://127.0.0.1:5000\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"TOKEN    = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"8LnqJuz3TsBHffnDJ3isPLHYHtRbWrC0M667Nb5haEbnXpWqGbFRyfDApymr\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# 1) Test read\\\\\\\\u2010scope by listing records (no size param or size=1)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"resp = requests.get(\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{API_BASE}/api/records\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    headers={\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Authorization\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Bearer {TOKEN}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"},\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    verify=False\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"print(resp.status_code)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# should be 200 and a JSON page of records\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# or explicitly:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"resp = requests.get(\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{API_BASE}/api/records?size=1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    headers={\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Authorization\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Bearer {TOKEN}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"},\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    verify=False\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"print(resp.status_code, resp.json())\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n-   ]\\\\\\\\n-  },\\\\\\\\n-  {\\\\\\\\n-   \\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"code\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\\\": 179,\\\\\\\\n-   \\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"8965535e-fa56-49c6-a489-e75b63900fd6\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {},\\\\\\\\n-   \\\\\\\\\\\\\\\"outputs\\\\\\\\\\\\\\\": [\\\\\\\\n-    {\\\\\\\\n-     \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"stdout\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"output_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"stream\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\": [\\\\\\\\n-      \\\\\\\\\\\\\\\"Allowed methods: HEAD, POST, OPTIONS, GET\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n-     ]\\\\\\\\n-    }\\\\\\\\n-   ],\\\\\\\\n-   \\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\": [\\\\\\\\n-    \\\\\\\\\\\\\\\"import requests\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"API_BASE = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"https://127.0.0.1:5000\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"TOKEN    = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"8LnqJuz3TsBHffnDJ3isPLHYHtRbWrC0M667Nb5haEbnXpWqGbFRyfDApymr\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"resp = requests.options(\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{API_BASE}/api/records\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    headers={\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Authorization\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Bearer {TOKEN}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"},\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    verify=False\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Allowed methods:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", resp.headers.get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Allow\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"))\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n-   ]\\\\\\\\n-  },\\\\\\\\n-  {\\\\\\\\n-   \\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"code\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\\\": 188,\\\\\\\\n-   \\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"7e5b2cc5-ecf3-4e13-8cac-47f57f12cbdd\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {},\\\\\\\\n-   \\\\\\\\\\\\\\\"outputs\\\\\\\\\\\\\\\": [\\\\\\\\n-    {\\\\\\\\n-     \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"stdout\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"output_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"stream\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\": [\\\\\\\\n-      \\\\\\\\\\\\\\\"\\\\\\\\u2705 Draft created: p8a8y-1bn93\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"  \\\\\\\\u2022 Uploaded RandomForest_Iris_v20250423_230422.pkl\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"  \\\\\\\\u2022 Uploaded RandomForest_Iris_v20250424_111946.pkl\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"  \\\\\\\\u2022 Uploaded RandomForest_Iris_v20250423_230422/confusion_matrix.png\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"  \\\\\\\\u2022 Uploaded RandomForest_Iris_v20250423_230422/feature_importances.png\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"  \\\\\\\\u2022 Uploaded RandomForest_Iris_v20250423_230422/pr_curve_cls_0.png\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"  \\\\\\\\u2022 Uploaded RandomForest_Iris_v20250423_230422/pr_curve_cls_1.png\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"  \\\\\\\\u2022 Uploaded RandomForest_Iris_v20250423_230422/pr_curve_cls_2.png\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"  \\\\\\\\u2022 Uploaded RandomForest_Iris_v20250423_230422/roc_curve_cls_0.png\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"  \\\\\\\\u2022 Uploaded RandomForest_Iris_v20250423_230422/roc_curve_cls_1.png\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"  \\\\\\\\u2022 Uploaded RandomForest_Iris_v20250423_230422/roc_curve_cls_2.png\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"  \\\\\\\\u2022 Uploaded RandomForest_Iris_v20250423_230422/shap_summary.png\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"  \\\\\\\\u2022 Uploaded RandomForest_Iris_v20250424_110923/confusion_matrix.png\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"  \\\\\\\\u2022 Uploaded RandomForest_Iris_v20250424_110923/feature_importances.png\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"  \\\\\\\\u2022 Uploaded RandomForest_Iris_v20250424_110923/pr_curve_cls_0.png\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"  \\\\\\\\u2022 Uploaded RandomForest_Iris_v20250424_110923/pr_curve_cls_1.png\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"  \\\\\\\\u2022 Uploaded RandomForest_Iris_v20250424_110923/pr_curve_cls_2.png\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"  \\\\\\\\u2022 Uploaded RandomForest_Iris_v20250424_110923/roc_curve_cls_0.png\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"  \\\\\\\\u2022 Uploaded RandomForest_Iris_v20250424_110923/roc_curve_cls_1.png\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"  \\\\\\\\u2022 Uploaded RandomForest_Iris_v20250424_110923/roc_curve_cls_2.png\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"  \\\\\\\\u2022 Uploaded RandomForest_Iris_v20250424_110923/shap_summary.png\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"  \\\\\\\\u2022 Uploaded RandomForest_Iris_v20250424_111946/confusion_matrix.png\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"  \\\\\\\\u2022 Uploaded RandomForest_Iris_v20250424_111946/feature_importances.png\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"  \\\\\\\\u2022 Uploaded RandomForest_Iris_v20250424_111946/pr_curve_cls_0.png\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"  \\\\\\\\u2022 Uploaded RandomForest_Iris_v20250424_111946/pr_curve_cls_1.png\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"  \\\\\\\\u2022 Uploaded RandomForest_Iris_v20250424_111946/pr_curve_cls_2.png\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"  \\\\\\\\u2022 Uploaded RandomForest_Iris_v20250424_111946/roc_curve_cls_0.png\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"  \\\\\\\\u2022 Uploaded RandomForest_Iris_v20250424_111946/roc_curve_cls_1.png\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"  \\\\\\\\u2022 Uploaded RandomForest_Iris_v20250424_111946/roc_curve_cls_2.png\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"  \\\\\\\\u2022 Uploaded RandomForest_Iris_v20250424_111946/shap_summary.png\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"  \\\\\\\\u2022 Uploaded RandomForest_Iris_v20250423_230422.jsonld\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"  \\\\\\\\u2022 Uploaded RandomForest_Iris_v20250423_230422.ttl\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"  \\\\\\\\u2022 Uploaded RandomForest_Iris_v20250423_230422_run_summary.json\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"  \\\\\\\\u2022 Uploaded RandomForest_Iris_v20250424_110923_run_summary.json\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"  \\\\\\\\u2022 Uploaded RandomForest_Iris_v20250424_111946_run_summary.json\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"  \\\\\\\\u2022 Uploaded .ipynb_checkpoints/RandomForest_Iris_v20250423_230422_run_summary-checkpoint.json\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"  \\\\\\\\u2022 Uploaded .ipynb_checkpoints/RandomForest_Iris_v20250424_110923_run_summary-checkpoint.json\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"  \\\\\\\\u2022 Uploaded .ipynb_checkpoints/RandomForest_Iris_v20250424_111946_run_summary-checkpoint.json\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"\\\\\\\\u2705 Published: p8a8y-1bn93\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"\\\\\\\\u2705 Metadata fetched successfully\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"\\\\\\\\u2705 Metadata saved as metadata_p8a8y-1bn93.json\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"None\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n-     ]\\\\\\\\n-    }\\\\\\\\n-   ],\\\\\\\\n-   \\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\": [\\\\\\\\n-    \\\\\\\\\\\\\\\"import os, json, requests\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# -----------------------------------------------------------------------------\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# Configuration\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# -----------------------------------------------------------------------------\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"API_BASE   = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"https://127.0.0.1:5000\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"TOKEN      = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"8LnqJuz3TsBHffnDJ3isPLHYHtRbWrC0M667Nb5haEbnXpWqGbFRyfDApymr\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"VERIFY_SSL = False  # only for self\\\\\\\\u2010signed dev\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"HEADERS_JSON = {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Accept\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"application/json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Content-Type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"application/json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Authorization\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Bearer {TOKEN}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"HEADERS_OCTET = {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Content-Type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"application/octet-stream\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Authorization\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Bearer {TOKEN}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# The folders you want to walk & upload:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"TO_UPLOAD = [\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Trained_models\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"plots\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"MODEL_PROVENANCE\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# -----------------------------------------------------------------------------\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# 1) Create draft with ALL required metadata\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# -----------------------------------------------------------------------------\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"def create_draft():\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    payload = {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"title\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"RandomForest Iris Model Artifacts\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"creators\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": [ {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"person_or_org\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"personal\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"given_name\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Reema\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"family_name\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Dass\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"      }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    } ],\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"publication_date\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"2025-04-24\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"resource_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":    { \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"software\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" },\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"access\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"record\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"public\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"files\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"public\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"  }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    r = requests.post(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{API_BASE}/api/records\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"                      headers=HEADERS_JSON,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"                      json=payload,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"                      verify=VERIFY_SSL)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    r.raise_for_status()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    draft = r.json()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\u2705 Draft created:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", draft[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"])\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    return draft[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"], draft[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"links\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# -----------------------------------------------------------------------------\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# 2) Register, upload and commit a single file\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# -----------------------------------------------------------------------------\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"def upload_and_commit(links, key, path):\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # 2a) register the filename in the draft\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    r1 = requests.post(links[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"files\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"],\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"                       headers=HEADERS_JSON,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"                       json=[{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"key\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": key}],\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"                       verify=VERIFY_SSL)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    r1.raise_for_status()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    entry = next(e for e in r1.json()[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"entries\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"] if e[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"key\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"] == key)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    file_links = entry[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"links\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # 2b) upload the bytes\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    with open(path, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"rb\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\") as fp:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        r2 = requests.put(file_links[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"],\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"                          headers=HEADERS_OCTET,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"                          data=fp,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"                          verify=VERIFY_SSL)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    r2.raise_for_status()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # 2c) commit the upload\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    r3 = requests.post(file_links[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"commit\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"],\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"                       headers=HEADERS_JSON,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"                       verify=VERIFY_SSL)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    r3.raise_for_status()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"  \\\\\\\\u2022 Uploaded {key}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# -----------------------------------------------------------------------------\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# 3) Walk each folder and upload every file\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# -----------------------------------------------------------------------------\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"def upload_folder(links):\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    for folder in TO_UPLOAD:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        if not os.path.isdir(folder):\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\u26a0\\\\\\\\ufe0f Skipping missing folder {folder}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            continue\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        base = os.path.dirname(folder) or folder\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        for root, _, files in os.walk(folder):\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            for fn in files:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"                local = os.path.join(root, fn)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"                # create a POSIX\\\\\\\\u2010style key preserving subfolders\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"                key = os.path.relpath(local, start=base).replace(os.sep, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"/\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"                upload_and_commit(links, key, local)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# -----------------------------------------------------------------------------\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# 4) Publish the draft\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# -----------------------------------------------------------------------------\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"def publish(links):\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    r = requests.post(links[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"publish\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"],\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"                      headers=HEADERS_JSON,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"                      verify=VERIFY_SSL)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    if not r.ok:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\u274c Publish failed:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", r.status_code, r.text)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        try: print(r.json())\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        except: pass\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        r.raise_for_status()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\u2705 Published:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", r.json()[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"])\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# -----------------------------------------------------------------------------\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# 5) Fetch metadata and save to a file\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# -----------------------------------------------------------------------------\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"def fetch_metadata(record_id):\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    r = requests.get(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{API_BASE}/api/records/{record_id}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"                     headers=HEADERS_JSON,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"                     verify=VERIFY_SSL)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    r.raise_for_status()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    metadata = r.json()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\u2705 Metadata fetched successfully\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # Save the metadata to a file\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    with open(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata_{record_id}.json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"w\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\") as f:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        json.dump(metadata, f, indent=4)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\u2705 Metadata saved as metadata_{record_id}.json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# -----------------------------------------------------------------------------\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# Main\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# -----------------------------------------------------------------------------\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"if __name__ == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"__main__\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    recid, links = create_draft()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    upload_folder(links)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    publish(links)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # Fetch and save metadata after publishing\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    print(fetch_metadata(recid))\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n-   ]\\\\\\\\n-  },\\\\\\\\n-  {\\\\\\\\n-   \\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"code\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\\\": 201,\\\\\\\\n-   \\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"0013878b-37da-4a22-9586-3773531bfd01\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {\\\\\\\\n-    \\\\\\\\\\\\\\\"scrolled\\\\\\\\\\\\\\\": true\\\\\\\\n-   },\\\\\\\\n-   \\\\\\\\\\\\\\\"outputs\\\\\\\\\\\\\\\": [\\\\\\\\n-    {\\\\\\\\n-     \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"stdout\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"output_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"stream\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\": [\\\\\\\\n-      \\\\\\\\\\\\\\\"Debug: Original Metadata (start): {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"p8a8y-1bn93\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"created\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"2025-04-24T13:48:33.108906+00:00\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"updated\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"2025-04-24T13:48:34.519283+00:00\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"links\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"self\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"https://127.0.0.1:5000/api/records/p8a8y-1bn93\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"self_html\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"https://127.0.0.1:5000/records/p8a8y-1bn93\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"parent\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"https://127.0.0.1:5000/api/records/0r0p8-gzf02\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"parent_html\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"https://127.0.0.1:5000/records/0r0p8-gzf02\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"self_iiif_manifest\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"https://127.0.0.1:5000/api/iiif/record:p8a8y-1bn93/manifest\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"self_iiif_sequence\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"https://127.0.0.1:5000/api/iiif/record:p8a8y-1bn93/sequence/default\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"files\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"https://127.0.0.1:5000/api/records/p8a8y-1bn93/files\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"media_files\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"https://127.0.0.1:5000/api/records/p8a8y-1bn93/media-files\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"archive\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"https://127.0.0.1:5000/api/records/p8a8y-1bn93/files-archive\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"archive_media\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"https://127.0.0.1:5000/api/records/p8a8y-1bn93/media-files-archive\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"latest\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"https://127.0.0.1:5000/api/records/p8\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Debug: Metadata loaded successfully\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"p8a8y-1bn93\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Debug: Extracting fields from metadata...\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Debug: Extracted Metadata: {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"invenio_metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"p8a8y-1bn93\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"title\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"RandomForest Iris Model Artifacts\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"creator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Dass, Reema\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"publication_date\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"2025-04-24\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"files\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": [\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"            {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"key\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"RandomForest_Iris_v20250423_230422.pkl\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"url\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"https://127.0.0.1:5000/api/records/p8a8y-1bn93/files/RandomForest_Iris_v20250423_230422.pkl/content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 282910,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"mimetype\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"application/octet-stream\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"checksum\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"md5:a9f9e15b9c808d94c8e5737089beaa7d\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"            },\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"            {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"key\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"RandomForest_Iris_v20250424_110923/pr_curve_cls_1.png\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"url\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"https://127.0.0.1:5000/api/records/p8a8y-1bn93/files/RandomForest_Iris_v20250424_110923/pr_curve_cls_1.png/content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 20226,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"mimetype\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"image/png\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"checksum\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"md5:7f396723afbfa90eb3d5f3e850f52c80\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"width\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 640,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"height\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 480\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"            },\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"            {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"key\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"RandomForest_Iris_v20250423_230422/confusion_matrix.png\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"url\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"https://127.0.0.1:5000/api/records/p8a8y-1bn93/files/RandomForest_Iris_v20250423_230422/confusion_matrix.png/content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 14453,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"mimetype\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"image/png\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"checksum\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"md5:41c356960df1b924d7db4d4a5cc9b254\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"width\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 600,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"height\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 600\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"            },\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"            {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"key\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"RandomForest_Iris_v20250424_110923/feature_importances.png\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"url\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"https://127.0.0.1:5000/api/records/p8a8y-1bn93/files/RandomForest_Iris_v20250424_110923/feature_importances.png/content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 19167,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"mimetype\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"image/png\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"checksum\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"md5:1702afd2578c67988efdcf1f28fe1b04\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"width\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 800,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"height\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 600\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"            },\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"            {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"key\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"RandomForest_Iris_v20250423_230422/roc_curve_cls_1.png\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"url\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"https://127.0.0.1:5000/api/records/p8a8y-1bn93/files/RandomForest_Iris_v20250423_230422/roc_curve_cls_1.png/content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 20143,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"mimetype\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"image/png\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"checksum\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"md5:917e9847fda527b030c0bcad8f2a2ea3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"width\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 640,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"height\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 480\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"            },\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"            {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"key\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"RandomForest_Iris_v20250423_230422/pr_curve_cls_0.png\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"url\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"https://127.0.0.1:5000/api/records/p8a8y-1bn93/files/RandomForest_Iris_v20250423_230422/pr_curve_cls_0.png/content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 20358,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"mimetype\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"image/png\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"checksum\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"md5:30a6a3742bcbd69750bc5fd30aea58d2\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"width\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 640,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"height\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 480\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"            },\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"            {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"key\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"RandomForest_Iris_v20250423_230422/pr_curve_cls_2.png\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"url\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"https://127.0.0.1:5000/api/records/p8a8y-1bn93/files/RandomForest_Iris_v20250423_230422/pr_curve_cls_2.png/content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 19809,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"mimetype\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"image/png\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"checksum\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"md5:22a124dad652fd24fb3a5691abcae494\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"width\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 640,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"height\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 480\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"            },\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"            {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"key\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"RandomForest_Iris_v20250424_110923/pr_curve_cls_0.png\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"url\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"https://127.0.0.1:5000/api/records/p8a8y-1bn93/files/RandomForest_Iris_v20250424_110923/pr_curve_cls_0.png/content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 20358,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"mimetype\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"image/png\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"checksum\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"md5:30a6a3742bcbd69750bc5fd30aea58d2\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"width\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 640,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"height\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 480\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"            },\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"            {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"key\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"RandomForest_Iris_v20250423_230422/shap_summary.png\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"url\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"https://127.0.0.1:5000/api/records/p8a8y-1bn93/files/RandomForest_Iris_v20250423_230422/shap_summary.png/content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 16939,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"mimetype\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"image/png\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"checksum\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"md5:ac330a1d4feeb8463ca1e9551303c4c8\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"width\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1150,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"height\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 660\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"            },\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"            {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"key\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"RandomForest_Iris_v20250424_110923/roc_curve_cls_0.png\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"url\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"https://127.0.0.1:5000/api/records/p8a8y-1bn93/files/RandomForest_Iris_v20250424_110923/roc_curve_cls_0.png/content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 20100,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"mimetype\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"image/png\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"checksum\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"md5:f6d5e559a27d81fb010b416bddc2fb02\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"width\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 640,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"height\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 480\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"            },\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"            {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"key\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"RandomForest_Iris_v20250424_110923/pr_curve_cls_2.png\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"url\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"https://127.0.0.1:5000/api/records/p8a8y-1bn93/files/RandomForest_Iris_v20250424_110923/pr_curve_cls_2.png/content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 19809,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"mimetype\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"image/png\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"checksum\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"md5:22a124dad652fd24fb3a5691abcae494\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"width\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 640,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"height\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 480\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"            },\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"            {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"key\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"RandomForest_Iris_v20250424_110923/roc_curve_cls_1.png\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"url\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"https://127.0.0.1:5000/api/records/p8a8y-1bn93/files/RandomForest_Iris_v20250424_110923/roc_curve_cls_1.png/content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 20143,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"mimetype\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"image/png\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"checksum\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"md5:917e9847fda527b030c0bcad8f2a2ea3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"width\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 640,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"height\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 480\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"            },\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"            {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"key\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"RandomForest_Iris_v20250424_110923/roc_curve_cls_2.png\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"url\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"https://127.0.0.1:5000/api/records/p8a8y-1bn93/files/RandomForest_Iris_v20250424_110923/roc_curve_cls_2.png/content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 20227,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"mimetype\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"image/png\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"checksum\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"md5:c076643c49b9ae7ba3cf0794b18f74db\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"width\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 640,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"height\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 480\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"            },\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"            {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"key\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"RandomForest_Iris_v20250424_110923/shap_summary.png\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"url\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"https://127.0.0.1:5000/api/records/p8a8y-1bn93/files/RandomForest_Iris_v20250424_110923/shap_summary.png/content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 16821,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"mimetype\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"image/png\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"checksum\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"md5:28ee8be9c0dbf6dc16c4acd70b42273d\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"width\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1150,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"height\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 660\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"            },\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"            {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"key\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"RandomForest_Iris_v20250424_111946/confusion_matrix.png\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"url\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"https://127.0.0.1:5000/api/records/p8a8y-1bn93/files/RandomForest_Iris_v20250424_111946/confusion_matrix.png/content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 14453,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"mimetype\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"image/png\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"checksum\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"md5:41c356960df1b924d7db4d4a5cc9b254\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"width\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 600,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"height\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 600\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"            },\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"            {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"key\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"RandomForest_Iris_v20250423_230422/pr_curve_cls_1.png\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"url\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"https://127.0.0.1:5000/api/records/p8a8y-1bn93/files/RandomForest_Iris_v20250423_230422/pr_curve_cls_1.png/content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 20226,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"mimetype\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"image/png\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"checksum\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"md5:7f396723afbfa90eb3d5f3e850f52c80\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"width\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 640,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"height\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 480\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"            },\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"            {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"key\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"RandomForest_Iris_v20250424_111946.pkl\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"url\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"https://127.0.0.1:5000/api/records/p8a8y-1bn93/files/RandomForest_Iris_v20250424_111946.pkl/content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 282910,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"mimetype\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"application/octet-stream\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"checksum\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"md5:5055123396a01237596e771a2621a82f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"            },\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"            {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"key\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"RandomForest_Iris_v20250423_230422/feature_importances.png\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"url\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"https://127.0.0.1:5000/api/records/p8a8y-1bn93/files/RandomForest_Iris_v20250423_230422/feature_importances.png/content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 19167,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"mimetype\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"image/png\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"checksum\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"md5:1702afd2578c67988efdcf1f28fe1b04\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"width\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 800,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"height\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 600\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"            },\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"            {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"key\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"RandomForest_Iris_v20250423_230422/roc_curve_cls_0.png\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"url\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"https://127.0.0.1:5000/api/records/p8a8y-1bn93/files/RandomForest_Iris_v20250423_230422/roc_curve_cls_0.png/content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 20100,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"mimetype\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"image/png\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"checksum\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"md5:f6d5e559a27d81fb010b416bddc2fb02\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"width\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 640,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"height\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 480\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"            },\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"            {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"key\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"RandomForest_Iris_v20250423_230422/roc_curve_cls_2.png\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"url\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"https://127.0.0.1:5000/api/records/p8a8y-1bn93/files/RandomForest_Iris_v20250423_230422/roc_curve_cls_2.png/content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 20227,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"mimetype\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"image/png\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"checksum\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"md5:c076643c49b9ae7ba3cf0794b18f74db\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"width\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 640,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"height\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 480\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"            },\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"            {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"key\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"RandomForest_Iris_v20250424_110923/confusion_matrix.png\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"url\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"https://127.0.0.1:5000/api/records/p8a8y-1bn93/files/RandomForest_Iris_v20250424_110923/confusion_matrix.png/content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 14453,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"mimetype\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"image/png\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"checksum\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"md5:41c356960df1b924d7db4d4a5cc9b254\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"width\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 600,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"height\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 600\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"            },\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"            {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"key\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"RandomForest_Iris_v20250424_111946/feature_importances.png\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"url\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"https://127.0.0.1:5000/api/records/p8a8y-1bn93/files/RandomForest_Iris_v20250424_111946/feature_importances.png/content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 19167,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"mimetype\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"image/png\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"checksum\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"md5:1702afd2578c67988efdcf1f28fe1b04\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"width\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 800,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"height\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 600\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"            },\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"            {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"key\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"RandomForest_Iris_v20250424_111946/pr_curve_cls_1.png\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"url\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"https://127.0.0.1:5000/api/records/p8a8y-1bn93/files/RandomForest_Iris_v20250424_111946/pr_curve_cls_1.png/content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 20226,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"mimetype\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"image/png\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"checksum\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"md5:7f396723afbfa90eb3d5f3e850f52c80\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"width\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 640,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"height\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 480\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"            },\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"            {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"key\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"RandomForest_Iris_v20250424_111946/roc_curve_cls_0.png\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"url\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"https://127.0.0.1:5000/api/records/p8a8y-1bn93/files/RandomForest_Iris_v20250424_111946/roc_curve_cls_0.png/content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 20100,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"mimetype\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"image/png\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"checksum\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"md5:f6d5e559a27d81fb010b416bddc2fb02\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"width\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 640,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"height\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 480\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"            },\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"            {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"key\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"RandomForest_Iris_v20250424_111946/roc_curve_cls_2.png\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"url\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"https://127.0.0.1:5000/api/records/p8a8y-1bn93/files/RandomForest_Iris_v20250424_111946/roc_curve_cls_2.png/content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 20227,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"mimetype\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"image/png\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"checksum\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"md5:c076643c49b9ae7ba3cf0794b18f74db\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"width\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 640,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"height\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 480\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"            },\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"            {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"key\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"RandomForest_Iris_v20250424_111946/pr_curve_cls_0.png\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"url\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"https://127.0.0.1:5000/api/records/p8a8y-1bn93/files/RandomForest_Iris_v20250424_111946/pr_curve_cls_0.png/content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 20358,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"mimetype\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"image/png\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"checksum\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"md5:30a6a3742bcbd69750bc5fd30aea58d2\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"width\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 640,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"height\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 480\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"            },\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"            {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"key\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"RandomForest_Iris_v20250424_111946/pr_curve_cls_2.png\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"url\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"https://127.0.0.1:5000/api/records/p8a8y-1bn93/files/RandomForest_Iris_v20250424_111946/pr_curve_cls_2.png/content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 19809,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"mimetype\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"image/png\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"checksum\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"md5:22a124dad652fd24fb3a5691abcae494\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"width\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 640,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"height\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 480\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"            },\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"            {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"key\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"RandomForest_Iris_v20250424_111946/roc_curve_cls_1.png\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"url\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"https://127.0.0.1:5000/api/records/p8a8y-1bn93/files/RandomForest_Iris_v20250424_111946/roc_curve_cls_1.png/content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 20143,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"mimetype\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"image/png\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"checksum\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"md5:917e9847fda527b030c0bcad8f2a2ea3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"width\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 640,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"height\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 480\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"            },\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"            {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"key\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"RandomForest_Iris_v20250424_111946/shap_summary.png\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"url\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"https://127.0.0.1:5000/api/records/p8a8y-1bn93/files/RandomForest_Iris_v20250424_111946/shap_summary.png/content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 16885,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"mimetype\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"image/png\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"checksum\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"md5:ac7959b6085a30cab3d8778a32d54d1a\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"width\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1150,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"height\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 660\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"            },\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"            {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"key\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"RandomForest_Iris_v20250423_230422.jsonld\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"url\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"https://127.0.0.1:5000/api/records/p8a8y-1bn93/files/RandomForest_Iris_v20250423_230422.jsonld/content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 11745,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"mimetype\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"application/ld+json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"checksum\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"md5:e037b37c0a582b6f32c1c638c003480b\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"            },\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"            {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"key\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"RandomForest_Iris_v20250423_230422.ttl\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"url\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"https://127.0.0.1:5000/api/records/p8a8y-1bn93/files/RandomForest_Iris_v20250423_230422.ttl/content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 10107,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"mimetype\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"text/turtle\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"checksum\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"md5:50f91e3780c4abfb55bf58d6ac5388d7\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"            },\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"            {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"key\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"RandomForest_Iris_v20250423_230422_run_summary.json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"url\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"https://127.0.0.1:5000/api/records/p8a8y-1bn93/files/RandomForest_Iris_v20250423_230422_run_summary.json/content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 135528,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"mimetype\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"application/json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"checksum\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"md5:b017a4306d62eb2ef12f95d992b2946d\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"            },\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"            {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"key\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"RandomForest_Iris_v20250424_110923_run_summary.json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"url\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"https://127.0.0.1:5000/api/records/p8a8y-1bn93/files/RandomForest_Iris_v20250424_110923_run_summary.json/content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 152427,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"mimetype\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"application/json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"checksum\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"md5:dbec09724b35b554410d3df63d89e334\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"            },\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"            {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"key\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"RandomForest_Iris_v20250424_111946_run_summary.json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"url\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"https://127.0.0.1:5000/api/records/p8a8y-1bn93/files/RandomForest_Iris_v20250424_111946_run_summary.json/content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 155273,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"mimetype\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"application/json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"checksum\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"md5:1b0f020894735a7e335f8dd9715b8157\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"            },\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"            {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"key\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".ipynb_checkpoints/RandomForest_Iris_v20250423_230422_run_summary-checkpoint.json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"url\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"https://127.0.0.1:5000/api/records/p8a8y-1bn93/files/.ipynb_checkpoints/RandomForest_Iris_v20250423_230422_run_summary-checkpoint.json/content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 135528,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"mimetype\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"application/json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"checksum\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"md5:b017a4306d62eb2ef12f95d992b2946d\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"            },\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"            {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"key\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".ipynb_checkpoints/RandomForest_Iris_v20250424_110923_run_summary-checkpoint.json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"url\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"https://127.0.0.1:5000/api/records/p8a8y-1bn93/files/.ipynb_checkpoints/RandomForest_Iris_v20250424_110923_run_summary-checkpoint.json/content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 152427,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"mimetype\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"application/json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"checksum\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"md5:dbec09724b35b554410d3df63d89e334\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"            },\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"            {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"key\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".ipynb_checkpoints/RandomForest_Iris_v20250424_111946_run_summary-checkpoint.json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"url\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"https://127.0.0.1:5000/api/records/p8a8y-1bn93/files/.ipynb_checkpoints/RandomForest_Iris_v20250424_111946_run_summary-checkpoint.json/content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 155273,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"mimetype\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"application/json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"checksum\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"md5:1b0f020894735a7e335f8dd9715b8157\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"            }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"        ],\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"pids\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"oai\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"identifier\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"oai:my-site.com:p8a8y-1bn93\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"provider\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"oai\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"            }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"        },\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"version_info\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"is_latest\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": true,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"is_latest_draft\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": true,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"index\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"        },\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"status\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"published\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"views\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 0,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"downloads\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 0\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"    }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"\\\\\\\\u2705 New dynamic metadata added successfully!\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n-     ]\\\\\\\\n-    }\\\\\\\\n-   ],\\\\\\\\n-   \\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\": [\\\\\\\\n-    \\\\\\\\\\\\\\\"import json\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# Function to dynamically extract and structure metadata from the original JSON\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"def extract_metadata(metadata):\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # Debug: Check if metadata is loaded correctly\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Debug: Metadata loaded successfully\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    print(metadata.get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"))  # Check if 'id' is being fetched\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # Check if the required fields are in the metadata\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Debug: Extracting fields from metadata...\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    extracted_data = {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"invenio_metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": metadata.get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"),\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"title\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": metadata.get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", {}).get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"title\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"),\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"creator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".join([creator[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"person_or_org\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"].get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\") for creator in metadata.get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", {}).get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"creators\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", [])]),\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"publication_date\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": metadata.get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", {}).get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"publication_date\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"),\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"files\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": [],  # Initialize 'files' as a list\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"pids\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": metadata.get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"pids\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", {}),\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"version_info\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": metadata.get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"versions\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", {}),\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"status\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": metadata.get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"status\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"),\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"views\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": metadata.get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"stats\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", {}).get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"this_version\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", {}).get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"views\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", 0),\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"downloads\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": metadata.get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"stats\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", {}).get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"this_version\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", {}).get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"downloads\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", 0),\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    # Extract file details from the metadata\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    for key, file_info in metadata.get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"files\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", {}).get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"entries\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", {}).items():\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        file_detail = {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"key\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": key,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"url\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": file_info[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"links\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"].get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"),\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": file_info.get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", 0),\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"mimetype\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": file_info.get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"mimetype\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"),\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"checksum\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": file_info.get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"checksum\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"),\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": file_info.get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", {}),\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        extracted_data[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"invenio_metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"][\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"files\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"].append(file_detail)  # Append to the 'files' list\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    return extracted_data\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# Load the original metadata from the JSON file (replace with your actual file path)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"with open('metadata_p8a8y-1bn93.json', 'r') as f: \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    original_metadata = json.load(f)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# Debugging: print out the first part of the original metadata to verify its structure\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Debug: Original Metadata (start):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", json.dumps(original_metadata, indent=4)[:1000])  # Print only the start for review\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# Extract relevant details dynamically\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"extracted_metadata = extract_metadata(original_metadata)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# Debugging: print the extracted metadata to verify it's correct\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Debug: Extracted Metadata:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", json.dumps(extracted_metadata, indent=4))\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# Load the existing JSON file (replace with your actual file path)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"with open('MODEL_PROVENANCE/RandomForest_Iris_v20250424_111946_run_summary.json', 'r') as f:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    existing_metadata = json.load(f)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# Add the extracted metadata as a new node\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"existing_metadata.update(extracted_metadata)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# Save the updated metadata back to the file\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"with open('updated_metadata.json', 'w') as f:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    json.dump(existing_metadata, f, indent=4)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\u2705 New dynamic metadata added successfully!\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n-   ]\\\\\\\\n-  },\\\\\\\\n-  {\\\\\\\\n-   \\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"code\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\\\": null,\\\\\\\\n-   \\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"f55d4a99-2bf2-4bd2-aeb0-4cbcb3698f90\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {},\\\\\\\\n-   \\\\\\\\\\\\\\\"outputs\\\\\\\\\\\\\\\": [],\\\\\\\\n-   \\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\": []\\\\\\\\n-  },\\\\\\\\n-  {\\\\\\\\n-   \\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"code\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\\\": 204,\\\\\\\\n-   \\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"38a807a7-6ecd-4ea7-93ac-78c0f853825c\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {},\\\\\\\\n-   \\\\\\\\\\\\\\\"outputs\\\\\\\\\\\\\\\": [\\\\\\\\n-    {\\\\\\\\n-     \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"stderr\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"output_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"stream\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\": [\\\\\\\\n-      \\\\\\\\\\\\\\\"[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.0s\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    0.3s\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    0.4s finished\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"[Parallel(n_jobs=12)]: Done 200 out of 200 | elapsed:    0.0s finished\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"[Parallel(n_jobs=12)]: Done 200 out of 200 | elapsed:    0.0s finished\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"[Parallel(n_jobs=12)]: Done 200 out of 200 | elapsed:    0.0s finished\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"[Parallel(n_jobs=12)]: Done 200 out of 200 | elapsed:    0.0s finished\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"[Parallel(n_jobs=12)]: Done 200 out of 200 | elapsed:    0.0s finished\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n-     ]\\\\\\\\n-    }\\\\\\\\n-   ],\\\\\\\\n-   \\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\": [\\\\\\\\n-    \\\\\\\\\\\\\\\"import mlflow\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"import mlflow.sklearn\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"from sklearn.datasets import load_iris\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"from sklearn.ensemble import RandomForestClassifier\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"X, y = load_iris(return_X_y=True)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"mlflow.sklearn.autolog()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"with mlflow.start_run() as run:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    model = RandomForestClassifier(**hyperparams)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    model.fit(X_train, y_train)\\\\\\\\\\\\\\\"\\\\\\\\n-   ]\\\\\\\\n-  },\\\\\\\\n-  {\\\\\\\\n-   \\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"code\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\\\": null,\\\\\\\\n-   \\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"570fa169-a5e2-47b3-b7f5-44f9577f22ad\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {},\\\\\\\\n-   \\\\\\\\\\\\\\\"outputs\\\\\\\\\\\\\\\": [],\\\\\\\\n-   \\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\": []\\\\\\\\n-  },\\\\\\\\n-  {\\\\\\\\n-   \\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"code\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\\\": null,\\\\\\\\n-   \\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"f67b7a46-a70d-44ea-976c-322a1a795311\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {\\\\\\\\n-    \\\\\\\\\\\\\\\"scrolled\\\\\\\\\\\\\\\": true\\\\\\\\n-   },\\\\\\\\n-   \\\\\\\\\\\\\\\"outputs\\\\\\\\\\\\\\\": [],\\\\\\\\n-   \\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\": [\\\\\\\\n-    \\\\\\\\\\\\\\\"# # ============================\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# # \\\\\\\\ud83d\\\\\\\\ude80 Start MLflow Run CURRENT BACKUP\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# # ============================\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# with mlflow.start_run() as run:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     model_name = f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"RandomForest_Iris_v1.0.0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     training_time_start = time.time()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     # \\\\\\\\ud83d\\\\\\\\udcc8 Model Training\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     model = RandomForestClassifier(n_estimators=100, random_state=42)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     model.fit(X_train, y_train)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     y_pred = model.predict(X_test)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     y_proba = model.predict_proba(X_test)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     acc = accuracy_score(y_test, y_pred)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     auc = roc_auc_score(y_test, y_proba, multi_class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"ovr\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     # \\\\\\\\u2705 Log Environment Automatically\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     mlflow.log_params({\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"python_version\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": platform.python_version(),\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"os_platform\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{platform.system()} {platform.release()}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sklearn_version\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": sklearn.__version__,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"pandas_version\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": pd.__version__,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"numpy_version\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": np.__version__,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"matplotlib_version\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": matplotlib.__version__,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"seaborn_version\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": sns.__version__,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"shap_version\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": shap.__version__,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     })\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     # \\\\\\\\u2705 Git and Notebook Metadata\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     mlflow.set_tag(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"notebook_name\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"RQ1.ipynb\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     # \\\\\\\\u2705 Dataset Metadata Tags\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     mlflow.set_tag(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"dataset_name\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Iris\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\") #TODO\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     mlflow.set_tag(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"dataset_version\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"1.0.0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\") #TODO\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     mlflow.set_tag(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"dataset_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"iris_local\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\") #TODO\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     # \\\\\\\\u2705 Confusion Matrix Plot\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     cm = confusion_matrix(y_test, y_pred)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     plt.figure(figsize=(6, 6))\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     sns.heatmap(cm, annot=True, fmt=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"d\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", cmap=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Blues\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     plt.title(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Confusion Matrix\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     plt.xlabel(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Predicted\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     plt.ylabel(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Actual\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     cm_path = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"confusion_matrix.png\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     plt.savefig(cm_path)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     mlflow.log_artifact(cm_path)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     # \\\\\\\\u2705 SHAP Summary\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     explainer = shap.TreeExplainer(model)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     shap_values = explainer.shap_values(X_test)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     shap.summary_plot(shap_values, X_test, show=False)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     shap_path = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"shap_summary.png\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     plt.savefig(shap_path)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     mlflow.log_artifact(shap_path)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     def get_latest_commit_hash(repo_path=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"):\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         # returns the full SHA of HEAD\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         res = subprocess.run(\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#             [\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"git\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"-C\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", repo_path, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"rev-parse\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"HEAD\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"],\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#             capture_output=True, text=True, check=True\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         return res.stdout.strip()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     def get_remote_url(repo_path=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", remote=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"origin\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"):\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         # returns something like git@github.com:user/repo.git or https://...\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         res = subprocess.run(\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#             [\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"git\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"-C\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", repo_path, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"config\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"--get\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"remote.{remote}.url\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"],\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#             capture_output=True, text=True, check=True\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         return res.stdout.strip()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     def make_commit_link(remote_url, commit_hash):\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         # handle GitHub/GitLab convention; strip \\\\\\\\u201c.git\\\\\\\\u201d if present\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         base = remote_url.rstrip(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".git\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         # if SSH form (git@github.com:owner/repo), convert to https\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         if base.startswith(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"git@\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"):\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#             base = base.replace(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"/\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\").replace(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"git@\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"https://\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         return f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{base}/commit/{commit_hash}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     def simple_commit_and_push_and_log(repo_path=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", message=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Auto commit\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", remote=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"origin\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", branch=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"main\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"):\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     # 1) Check for changes\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         status = subprocess.run(\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#             [\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"git\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"-C\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", repo_path, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"status\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"--porcelain\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"],\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#             capture_output=True, text=True\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         if not status.stdout.strip():\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#             print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\ud83d\\\\\\\\udfe1 No changes to commit.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#             return None, None\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         # 2) Stage everything\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         add = subprocess.run(\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#             [\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"git\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"-C\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", repo_path, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"add\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"--all\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"],\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#             capture_output=True, text=True\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         if add.returncode:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#             print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\u274c git add failed:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", add.stderr)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#             return None, None\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         # 3) Commit\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         commit = subprocess.run(\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#             [\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"git\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"-C\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", repo_path, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"commit\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"-m\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", message],\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#             capture_output=True, text=True\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         if commit.returncode:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#             print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\u274c git commit failed:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", commit.stderr)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#             return None, None\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\u2705 Commit successful.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         # 4) Push\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         push = subprocess.run(\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#             [\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"git\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"-C\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", repo_path, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"push\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"-u\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", remote, branch],\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#             capture_output=True, text=True\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         if push.returncode:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#             print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\u274c git push failed:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", push.stderr)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         else:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#             print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\ud83d\\\\\\\\ude80 Push successful.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         # 5) Retrieve hash & remote URL\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         sha = get_latest_commit_hash(repo_path)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         url = get_remote_url(repo_path, remote)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         link = make_commit_link(url, sha)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         return sha, link\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"      \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     sha, link = simple_commit_and_push_and_log(\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         repo_path=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         message=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Auto commit after successful training\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     if sha and link:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         diff_text = subprocess.check_output(\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#             [\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"git\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"-C\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"diff\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", previous_commit_hash, sha], text=True\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"                \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         # 1) Get your repo\\\\\\\\u2019s remote URL and normalize to HTTPS\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         remote_url = subprocess.check_output(\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#             [\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"git\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"config\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"--get\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"remote.origin.url\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"],\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#             text=True\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         ).strip().rstrip(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".git\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         if remote_url.startswith(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"git@\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"):\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#             # git@github.com:owner/repo.git \\\\\\\\u2192 https://github.com/owner/repo\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#             remote_url = remote_url.replace(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"/\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\").replace(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"git@\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"https://\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"        \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         # 2) Build commit URLs\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         previous_commit_url  = f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{remote_url}/commit/{previous_commit_hash}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         current_commit_url = f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{remote_url}/commit/{sha}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         diff_data = {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#             \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"previous_commit\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":  previous_commit_hash,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#             \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"previous_commit_url\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":previous_commit_url,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#             \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"current_commit_url\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":current_commit_url,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#             \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"current_commit\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": sha,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#             \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"diff\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": diff_text\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         mlflow.log_dict(\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#             diff_data,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#             artifact_file=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"commit_diff.json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         mlflow.set_tag(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"git_previous_commit_hash\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", previous_commit_hash)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         mlflow.set_tag(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"git_current_commit_hash\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", sha)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         mlflow.set_tag(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"git__current_commit_url\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", link) \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     client   = MlflowClient()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     run_id    = run.info.run_id\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     run_info  = client.get_run(run_id).info\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     run_data  = client.get_run(run_id).data\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     # 1) params, metrics, tags\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     params  = dict(run_data.params)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     metrics = dict(run_data.metrics)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     tags    = dict(run_data.tags)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     # (4) List artifacts under a specific subfolder\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     artifact_paths = [af.path for af in client.list_artifacts(run_id)]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     # # 2) recursively gather all artifact paths\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     # artifact_paths = []\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     # def _gather(path=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"):\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     #     for af in client.list_artifacts(run_id, path):\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     #         if af.is_dir:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     #             _gather(af.path)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     #         else:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     #             artifact_paths.append(af.path)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     # _gather()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     # 3) assemble summary\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     summary = {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"run_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":         run_id,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"run_name\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": run_info.run_name,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"experiment_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":  run_info.experiment_id,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"start_time\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":     run_info.start_time,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"end_time\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":       run_info.end_time,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"params\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":         params,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metrics\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":        metrics,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"tags\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":           tags,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"artifacts\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":      artifact_paths\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     # 1) Create (or reuse) a base folder for run summaries\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     base_dir = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"run_summaries\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     os.makedirs(base_dir, exist_ok=True)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#    # 2) Pick next numeric folder\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     existing = [\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         d for d in os.listdir(base_dir)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         if os.path.isdir(os.path.join(base_dir, d)) and d.isdigit()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     ]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     next_num = max(map(int, existing), default=0) + 1\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     mlflow.log_dict(\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         summary,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         artifact_file=f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"run_summaries/{next_num}/run_summary.json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     # 3) Save the summary JSON into that folder\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     # local_path = os.path.join(run_folder, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"run_summary.json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     # with open(local_path, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"w\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\") as f:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     #     json.dump(summary, f, indent=2)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     # # 4) (Optional) Mirror it into MLflow artifacts under the same counter path\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     # mlflow.log_artifact(local_path, artifact_path=f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"run_summaries/{next_num}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"    \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     # 5) Also tag the run with the folder name for easy reference\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     mlflow.set_tag(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"summary_folder\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", str(next_num))\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         # with open(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"model_metadata_fair4ml.json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"w\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\") as f:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     #     json.dump(fair4ml_metadata, f, indent=2)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     # mlflow.log_artifact(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"model_metadata_fair4ml.json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     mlflow.end_run()\\\\\\\\\\\\\\\"\\\\\\\\n-   ]\\\\\\\\n-  },\\\\\\\\n-  {\\\\\\\\n-   \\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"code\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\\\": null,\\\\\\\\n-   \\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"4211bdef-5785-472d-8ea5-0bc24a3faf3c\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {},\\\\\\\\n-   \\\\\\\\\\\\\\\"outputs\\\\\\\\\\\\\\\": [],\\\\\\\\n-   \\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\": [\\\\\\\\n-    \\\\\\\\\\\\\\\"# # ============================\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# # \\\\\\\\ud83d\\\\\\\\ude80 Start MLflow Run\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# # ============================\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# with mlflow.start_run() as run:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     model_name = f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"RandomForest_Iris_v1.0.0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     training_time_start = time.time()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     # \\\\\\\\ud83d\\\\\\\\udcc8 Model Training\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     model = RandomForestClassifier(n_estimators=100, random_state=42)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     model.fit(X_train, y_train)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     y_pred = model.predict(X_test)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     y_proba = model.predict_proba(X_test)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     acc = accuracy_score(y_test, y_pred)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     auc = roc_auc_score(y_test, y_proba, multi_class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"ovr\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     # \\\\\\\\u2705 Log Environment Automatically\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     mlflow.log_params({\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"python_version\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": platform.python_version(),\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"os_platform\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{platform.system()} {platform.release()}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sklearn_version\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": sklearn.__version__,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"pandas_version\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": pd.__version__,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"numpy_version\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": np.__version__,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"matplotlib_version\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": matplotlib.__version__,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"seaborn_version\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": sns.__version__,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"shap_version\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": shap.__version__,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     })\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     # \\\\\\\\u2705 Git and Notebook Metadata\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     mlflow.set_tag(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"git_commit_hash\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", commit_hash)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     mlflow.set_tag(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"notebook_name\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"RQ1.ipynb\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     # \\\\\\\\u2705 Dataset Metadata Tags\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     mlflow.set_tag(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"dataset_name\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Iris\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     mlflow.set_tag(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"dataset_version\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"1.0.0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     mlflow.set_tag(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"dataset_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"iris_local\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     # \\\\\\\\u2705 Confusion Matrix Plot\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     cm = confusion_matrix(y_test, y_pred)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     plt.figure(figsize=(6, 6))\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     sns.heatmap(cm, annot=True, fmt=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"d\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", cmap=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Blues\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     plt.title(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Confusion Matrix\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     plt.xlabel(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Predicted\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     plt.ylabel(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Actual\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     cm_path = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"confusion_matrix.png\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     plt.savefig(cm_path)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     mlflow.log_artifact(cm_path)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     # \\\\\\\\u2705 SHAP Summary\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     explainer = shap.TreeExplainer(model)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     shap_values = explainer.shap_values(X_test)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     shap.summary_plot(shap_values, X_test, show=False)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     shap_path = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"shap_summary.png\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     plt.savefig(shap_path)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     mlflow.log_artifact(shap_path)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     # \\\\\\\\u2705 FAIR4ML-style Metadata JSON\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     fair4ml_metadata = {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"@type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"MLModel\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": model_name,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"algorithm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"RandomForestClassifier\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"hyperParameters\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": model.get_params(),\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"trainingDataset\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#             \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Iris\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#             \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"version\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"1.0.0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#             \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"identifier\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"iris_local\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         },\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"trainingMetrics\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#             \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"accuracy\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": acc,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#             \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"roc_auc\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": auc,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#             \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"precision\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": precision_score(y_test, y_pred, average='macro'),\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#             \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"recall\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": recall_score(y_test, y_pred, average='macro'),\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#             \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"f1_score\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": f1_score(y_test, y_pred, average='macro')\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         },\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"environment\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#             \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"python\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": platform.python_version(),\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#             \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"os\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{platform.system()} {platform.release()}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#             \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"libraries\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#                 \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sklearn\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": sklearn.__version__,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#                 \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"pandas\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": pd.__version__,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#                 \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"numpy\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": np.__version__\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#             }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         },\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#             \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"git_commit\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": commit_hash,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#             \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"notebook\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"RQ1.ipynb\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     # \\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500 UPDATE: Save FAIR4ML metadata as artifact (already in place)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     with open(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"model_metadata_fair4ml.json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"w\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\") as f:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         json.dump(fair4ml_metadata, f, indent=2)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     mlflow.log_artifact(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"model_metadata_fair4ml.json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     # \\\\\\\\u2190 NEW: Import PROV\\\\\\\\u2011O library for RQ1.2\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     from prov.model import ProvDocument, Namespace, PROV\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     # \\\\\\\\u2190 NEW: Build PROV\\\\\\\\u2011O document for the training run (RQ1.2)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     prov = ProvDocument()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     ex = Namespace(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"ex\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"http://example.org/\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     prov.add_namespace(ex)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     # \\\\\\\\u2190 NEW: Define entities and activity\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     data_ent = prov.entity(ex[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"dataset/iris\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"], {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"prov:label\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Iris Dataset\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"ex:split\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"80/20\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     })\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     model_ent = prov.entity(ex[f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"model/{run.info.run_id}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"], {\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"prov:label\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"RandomForestClassifier\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"ex:params\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": json.dumps(model.get_params())\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     })\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     act_train = prov.activity(\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         ex[f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"activity/train/{run.info.run_id}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"],\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         None, None,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"prov:label\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Model training\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#          \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"ex:startTime\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": run.info.start_time,\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#          \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"ex:endTime\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": run.info.end_time}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     prov.wasGeneratedBy(model_ent, act_train)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     prov.used(act_train, data_ent)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     # \\\\\\\\u2190 NEW: Serialize & log PROV\\\\\\\\u2011O JSON\\\\\\\\u2011LD artifact\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     prov_path = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"model_provenance.jsonld\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     with open(prov_path, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"w\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\") as f:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         f.write(prov.serialize(indent=2))\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     mlflow.log_artifact(prov_path)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     # (your existing git\\\\\\\\u2010commit & push helpers unchanged\\\\\\\\u2026)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     sha, link = simple_commit_and_push_and_log(\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         repo_path=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         message=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Auto commit after successful training\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     if sha and link:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         mlflow.set_tag(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"git_commit_hash\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", sha)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         mlflow.set_tag(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"git_commit_url\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", link)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     mlflow.end_run()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# # \\\\\\\\u2190 NEW: RQ2 helper functions for auditing and reproducibility checks\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# def trace_run_provenance(run_id):\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Print key metadata and artifacts for a given MLflow run.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     from mlflow.tracking import MlflowClient\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     client = MlflowClient()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     run = client.get_run(run_id)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\ud83d\\\\\\\\udcdd Run {run_id} provenance:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"  \\\\\\\\u2022 Git SHA:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", run.data.tags.get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"git_commit_hash\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"))\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"  \\\\\\\\u2022 Commit URL:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", run.data.tags.get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"git_commit_url\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"))\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"  \\\\\\\\u2022 Dataset split:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", run.data.tags.get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"dataset_split\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"))\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"  \\\\\\\\u2022 Metrics:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", run.data.metrics)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"  \\\\\\\\u2022 Artifacts:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", [a.path for a in client.list_artifacts(run_id)])\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# def detect_deprecated_code(run_id, grace_days=7):\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     Check if the run's commit is older than origin/main by > grace_days.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     import subprocess\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     from mlflow.tracking import MlflowClient\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     client = MlflowClient()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     run = client.get_run(run_id)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     sha = run.data.tags.get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"git_commit_hash\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     main_ts = int(subprocess.check_output(\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         [\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"git\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"log\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"-1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"--format=%ct\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"origin/main\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     ).strip())\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     run_ts = int(subprocess.check_output(\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         [\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"git\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"log\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"-1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"--format=%ct\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", sha]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     ).strip())\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     age = (main_ts - run_ts) / 86400\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     status = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\u26a0\\\\\\\\ufe0f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" if age > grace_days else \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\u2705\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{status} Run {run_id} is {age:.1f} days behind main.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# # \\\\\\\\u2500\\\\\\\\u2500\\\\\\\\u2500 USAGE:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# # After you execute your training cell, you can call:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# # trace_run_provenance(<run_id>)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# # detect_deprecated_code(<run_id>, grace_days=5)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n-   ]\\\\\\\\n-  },\\\\\\\\n-  {\\\\\\\\n-   \\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"code\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\\\": null,\\\\\\\\n-   \\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"9d4d71f2-ef66-4e04-9d9b-c4b381d45590\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {},\\\\\\\\n-   \\\\\\\\\\\\\\\"outputs\\\\\\\\\\\\\\\": [],\\\\\\\\n-   \\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\": []\\\\\\\\n-  }\\\\\\\\n- ],\\\\\\\\n- \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {\\\\\\\\n-  \\\\\\\\\\\\\\\"kernelspec\\\\\\\\\\\\\\\": {\\\\\\\\n-   \\\\\\\\\\\\\\\"display_name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Python 3 (ipykernel)\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"language\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"python\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"python3\\\\\\\\\\\\\\\"\\\\\\\\n-  },\\\\\\\\n-  \\\\\\\\\\\\\\\"language_info\\\\\\\\\\\\\\\": {\\\\\\\\n-   \\\\\\\\\\\\\\\"codemirror_mode\\\\\\\\\\\\\\\": {\\\\\\\\n-    \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"ipython\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"version\\\\\\\\\\\\\\\": 3\\\\\\\\n-   },\\\\\\\\n-   \\\\\\\\\\\\\\\"file_extension\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\".py\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"mimetype\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"text/x-python\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"python\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"nbconvert_exporter\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"python\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"pygments_lexer\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"ipython3\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"version\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"3.11.5\\\\\\\\\\\\\\\"\\\\\\\\n-  }\\\\\\\\n- },\\\\\\\\n- \\\\\\\\\\\\\\\"nbformat\\\\\\\\\\\\\\\": 4,\\\\\\\\n- \\\\\\\\\\\\\\\"nbformat_minor\\\\\\\\\\\\\\\": 5\\\\\\\\n-}\\\\\\\\ndiff --git a/notebooks/RQ_notebooks/Trained_models/RandomForest_Iris_v20250425_120852.pkl b/notebooks/RQ_notebooks/Trained_models/RandomForest_Iris_v20250425_120852.pkl\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..650175a\\\\\\\\nBinary files /dev/null and b/notebooks/RQ_notebooks/Trained_models/RandomForest_Iris_v20250425_120852.pkl differ\\\\\\\\ndiff --git a/notebooks/RQ_notebooks/Trained_models/RandomForest_Iris_v20250425_121328.pkl b/notebooks/RQ_notebooks/Trained_models/RandomForest_Iris_v20250425_121328.pkl\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..044631a\\\\\\\\nBinary files /dev/null and b/notebooks/RQ_notebooks/Trained_models/RandomForest_Iris_v20250425_121328.pkl differ\\\\\\\\ndiff --git a/notebooks/RQ_notebooks/config.toml b/notebooks/RQ_notebooks/config.toml\\\\\\\\ndeleted file mode 100644\\\\\\\\nindex e1ec245..0000000\\\\\\\\n--- a/notebooks/RQ_notebooks/config.toml\\\\\\\\n+++ /dev/null\\\\\\\\n@@ -1,7 +0,0 @@\\\\\\\\n-[theme]\\\\\\\\n-base = \\\\\\\\\\\\\\\"dark\\\\\\\\\\\\\\\"\\\\\\\\n-primaryColor = \\\\\\\\\\\\\\\"#00d4ff\\\\\\\\\\\\\\\"\\\\\\\\n-backgroundColor = \\\\\\\\\\\\\\\"#0e1117\\\\\\\\\\\\\\\"\\\\\\\\n-secondaryBackgroundColor = \\\\\\\\\\\\\\\"#262730\\\\\\\\\\\\\\\"\\\\\\\\n-textColor = \\\\\\\\\\\\\\\"#fafafa\\\\\\\\\\\\\\\"\\\\\\\\n-font = \\\\\\\\\\\\\\\"monospace\\\\\\\\\\\\\\\"\\\\\\\\ndiff --git a/notebooks/RQ_notebooks/infra_flow.html b/notebooks/RQ_notebooks/infra_flow.html\\\\\\\\ndeleted file mode 100644\\\\\\\\nindex 0fe8f57..0000000\\\\\\\\n--- a/notebooks/RQ_notebooks/infra_flow.html\\\\\\\\n+++ /dev/null\\\\\\\\n@@ -1,127 +0,0 @@\\\\\\\\n-<html>\\\\\\\\n-    <head>\\\\\\\\n-        <meta charset=\\\\\\\\\\\\\\\"utf-8\\\\\\\\\\\\\\\">\\\\\\\\n-        \\\\\\\\n-            <script src=\\\\\\\\\\\\\\\"lib/bindings/utils.js\\\\\\\\\\\\\\\"></script>\\\\\\\\n-            <link rel=\\\\\\\\\\\\\\\"stylesheet\\\\\\\\\\\\\\\" href=\\\\\\\\\\\\\\\"https://cdnjs.cloudflare.com/ajax/libs/vis-network/9.1.2/dist/dist/vis-network.min.css\\\\\\\\\\\\\\\" integrity=\\\\\\\\\\\\\\\"sha512-WgxfT5LWjfszlPHXRmBWHkV2eceiWTOBvrKCNbdgDYTHrT2AeLCGbF4sZlZw3UMN3WtL0tGUoIAKsu8mllg/XA==\\\\\\\\\\\\\\\" crossorigin=\\\\\\\\\\\\\\\"anonymous\\\\\\\\\\\\\\\" referrerpolicy=\\\\\\\\\\\\\\\"no-referrer\\\\\\\\\\\\\\\" />\\\\\\\\n-            <script src=\\\\\\\\\\\\\\\"https://cdnjs.cloudflare.com/ajax/libs/vis-network/9.1.2/dist/vis-network.min.js\\\\\\\\\\\\\\\" integrity=\\\\\\\\\\\\\\\"sha512-LnvoEWDFrqGHlHmDD2101OrLcbsfkrzoSpvtSQtxK3RMnRV0eOkhhBN2dXHKRrUU8p2DGRTk35n4O8nWSVe1mQ==\\\\\\\\\\\\\\\" crossorigin=\\\\\\\\\\\\\\\"anonymous\\\\\\\\\\\\\\\" referrerpolicy=\\\\\\\\\\\\\\\"no-referrer\\\\\\\\\\\\\\\"></script>\\\\\\\\n-            \\\\\\\\n-        \\\\\\\\n-<center>\\\\\\\\n-<h1></h1>\\\\\\\\n-</center>\\\\\\\\n-\\\\\\\\n-<!-- <link rel=\\\\\\\\\\\\\\\"stylesheet\\\\\\\\\\\\\\\" href=\\\\\\\\\\\\\\\"../node_modules/vis/dist/vis.min.css\\\\\\\\\\\\\\\" type=\\\\\\\\\\\\\\\"text/css\\\\\\\\\\\\\\\" />\\\\\\\\n-<script type=\\\\\\\\\\\\\\\"text/javascript\\\\\\\\\\\\\\\" src=\\\\\\\\\\\\\\\"../node_modules/vis/dist/vis.js\\\\\\\\\\\\\\\"> </script>-->\\\\\\\\n-        <link\\\\\\\\n-          href=\\\\\\\\\\\\\\\"https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta3/dist/css/bootstrap.min.css\\\\\\\\\\\\\\\"\\\\\\\\n-          rel=\\\\\\\\\\\\\\\"stylesheet\\\\\\\\\\\\\\\"\\\\\\\\n-          integrity=\\\\\\\\\\\\\\\"sha384-eOJMYsd53ii+scO/bJGFsiCZc+5NDVN2yr8+0RDqr0Ql0h+rP48ckxlpbzKgwra6\\\\\\\\\\\\\\\"\\\\\\\\n-          crossorigin=\\\\\\\\\\\\\\\"anonymous\\\\\\\\\\\\\\\"\\\\\\\\n-        />\\\\\\\\n-        <script\\\\\\\\n-          src=\\\\\\\\\\\\\\\"https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta3/dist/js/bootstrap.bundle.min.js\\\\\\\\\\\\\\\"\\\\\\\\n-          integrity=\\\\\\\\\\\\\\\"sha384-JEW9xMcG8R+pH31jmWH6WWP0WintQrMb4s7ZOdauHnUtxwoG2vI5DkLtS3qm9Ekf\\\\\\\\\\\\\\\"\\\\\\\\n-          crossorigin=\\\\\\\\\\\\\\\"anonymous\\\\\\\\\\\\\\\"\\\\\\\\n-        ></script>\\\\\\\\n-\\\\\\\\n-\\\\\\\\n-        <center>\\\\\\\\n-          <h1></h1>\\\\\\\\n-        </center>\\\\\\\\n-        <style type=\\\\\\\\\\\\\\\"text/css\\\\\\\\\\\\\\\">\\\\\\\\n-\\\\\\\\n-             #mynetwork {\\\\\\\\n-                 width: 100%;\\\\\\\\n-                 height: 500px;\\\\\\\\n-                 background-color: #ffffff;\\\\\\\\n-                 border: 1px solid lightgray;\\\\\\\\n-                 position: relative;\\\\\\\\n-                 float: left;\\\\\\\\n-             }\\\\\\\\n-\\\\\\\\n-             \\\\\\\\n-\\\\\\\\n-             \\\\\\\\n-\\\\\\\\n-             \\\\\\\\n-        </style>\\\\\\\\n-    </head>\\\\\\\\n-\\\\\\\\n-\\\\\\\\n-    <body>\\\\\\\\n-        <div class=\\\\\\\\\\\\\\\"card\\\\\\\\\\\\\\\" style=\\\\\\\\\\\\\\\"width: 100%\\\\\\\\\\\\\\\">\\\\\\\\n-            \\\\\\\\n-            \\\\\\\\n-            <div id=\\\\\\\\\\\\\\\"mynetwork\\\\\\\\\\\\\\\" class=\\\\\\\\\\\\\\\"card-body\\\\\\\\\\\\\\\"></div>\\\\\\\\n-        </div>\\\\\\\\n-\\\\\\\\n-        \\\\\\\\n-        \\\\\\\\n-\\\\\\\\n-        <script type=\\\\\\\\\\\\\\\"text/javascript\\\\\\\\\\\\\\\">\\\\\\\\n-\\\\\\\\n-              // initialize global variables.\\\\\\\\n-              var edges;\\\\\\\\n-              var nodes;\\\\\\\\n-              var allNodes;\\\\\\\\n-              var allEdges;\\\\\\\\n-              var nodeColors;\\\\\\\\n-              var originalNodes;\\\\\\\\n-              var network;\\\\\\\\n-              var container;\\\\\\\\n-              var options, data;\\\\\\\\n-              var filter = {\\\\\\\\n-                  item : '',\\\\\\\\n-                  property : '',\\\\\\\\n-                  value : []\\\\\\\\n-              };\\\\\\\\n-\\\\\\\\n-              \\\\\\\\n-\\\\\\\\n-              \\\\\\\\n-\\\\\\\\n-              // This method is responsible for drawing the graph, returns the drawn network\\\\\\\\n-              function drawGraph() {\\\\\\\\n-                  var container = document.getElementById('mynetwork');\\\\\\\\n-\\\\\\\\n-                  \\\\\\\\n-\\\\\\\\n-                  // parsing and collecting nodes and edges from the python\\\\\\\\n-                  nodes = new vis.DataSet([{\\\\\\\\\\\\\\\"color\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"#97c2fc\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"DBRepo (Structured Repository)\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"DBRepo (Structured Repository)\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"shape\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"dot\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\": 10}, {\\\\\\\\\\\\\\\"color\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"#97c2fc\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Virtual Research Environment (VRE)\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Virtual Research Environment (VRE)\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"shape\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"dot\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\": 10}, {\\\\\\\\\\\\\\\"color\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"#97c2fc\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Invenio (Unstructured Repository)\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Invenio (Unstructured Repository)\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"shape\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"dot\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\": 10}, {\\\\\\\\\\\\\\\"color\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"#97c2fc\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"JupyterHub (Computational Layer)\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"JupyterHub (Computational Layer)\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"shape\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"dot\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\": 10}, {\\\\\\\\\\\\\\\"color\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"#97c2fc\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"GitHub (Version Control)\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"GitHub (Version Control)\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"shape\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"dot\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\": 10}, {\\\\\\\\\\\\\\\"color\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"#97c2fc\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Interactive Visualization\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Interactive Visualization\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"shape\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"dot\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\": 10}, {\\\\\\\\\\\\\\\"color\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"#97c2fc\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Metadata Extraction\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Metadata Extraction\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"shape\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"dot\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\": 10}, {\\\\\\\\\\\\\\\"color\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"#97c2fc\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Provenance JSON\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"label\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Provenance JSON\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"shape\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"dot\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\": 10}]);\\\\\\\\n-                  edges = new vis.DataSet([{\\\\\\\\\\\\\\\"arrows\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"to\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"from\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"DBRepo (Structured Repository)\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"to\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Virtual Research Environment (VRE)\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"width\\\\\\\\\\\\\\\": 1}, {\\\\\\\\\\\\\\\"arrows\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"to\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"from\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Invenio (Unstructured Repository)\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"to\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Virtual Research Environment (VRE)\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"width\\\\\\\\\\\\\\\": 1}, {\\\\\\\\\\\\\\\"arrows\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"to\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"from\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"JupyterHub (Computational Layer)\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"to\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Virtual Research Environment (VRE)\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"width\\\\\\\\\\\\\\\": 1}, {\\\\\\\\\\\\\\\"arrows\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"to\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"from\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"GitHub (Version Control)\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"to\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Virtual Research Environment (VRE)\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"width\\\\\\\\\\\\\\\": 1}, {\\\\\\\\\\\\\\\"arrows\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"to\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"from\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Virtual Research Environment (VRE)\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"to\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Interactive Visualization\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"width\\\\\\\\\\\\\\\": 1}, {\\\\\\\\\\\\\\\"arrows\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"to\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"from\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Metadata Extraction\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"to\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Provenance JSON\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"width\\\\\\\\\\\\\\\": 1}, {\\\\\\\\\\\\\\\"arrows\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"to\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"from\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Provenance JSON\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"to\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Interactive Visualization\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"width\\\\\\\\\\\\\\\": 1}]);\\\\\\\\n-\\\\\\\\n-                  nodeColors = {};\\\\\\\\n-                  allNodes = nodes.get({ returnType: \\\\\\\\\\\\\\\"Object\\\\\\\\\\\\\\\" });\\\\\\\\n-                  for (nodeId in allNodes) {\\\\\\\\n-                    nodeColors[nodeId] = allNodes[nodeId].color;\\\\\\\\n-                  }\\\\\\\\n-                  allEdges = edges.get({ returnType: \\\\\\\\\\\\\\\"Object\\\\\\\\\\\\\\\" });\\\\\\\\n-                  // adding nodes and edges to the graph\\\\\\\\n-                  data = {nodes: nodes, edges: edges};\\\\\\\\n-\\\\\\\\n-                  var options = {\\\\\\\\\\\\\\\"nodes\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\"font\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\": 14}, \\\\\\\\\\\\\\\"shape\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"box\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"color\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\"background\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"#add8e6\\\\\\\\\\\\\\\"}}, \\\\\\\\\\\\\\\"edges\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\"arrows\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\"to\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\"enabled\\\\\\\\\\\\\\\": true}}, \\\\\\\\\\\\\\\"smooth\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"cubicBezier\\\\\\\\\\\\\\\"}}, \\\\\\\\\\\\\\\"physics\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\"enabled\\\\\\\\\\\\\\\": true, \\\\\\\\\\\\\\\"barnesHut\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\"gravitationalConstant\\\\\\\\\\\\\\\": -20000}}};\\\\\\\\n-\\\\\\\\n-                  \\\\\\\\n-\\\\\\\\n-\\\\\\\\n-                  \\\\\\\\n-\\\\\\\\n-                  network = new vis.Network(container, data, options);\\\\\\\\n-\\\\\\\\n-                  \\\\\\\\n-\\\\\\\\n-                  \\\\\\\\n-\\\\\\\\n-                  \\\\\\\\n-\\\\\\\\n-\\\\\\\\n-                  \\\\\\\\n-\\\\\\\\n-                  return network;\\\\\\\\n-\\\\\\\\n-              }\\\\\\\\n-              drawGraph();\\\\\\\\n-        </script>\\\\\\\\n-    </body>\\\\\\\\n-</html>\\\\\\\\n\\\\\\\\\\\\\\\\ No newline at end of file\\\\\\\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120045/confusion_matrix.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120045/confusion_matrix.png\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..5bf98dd\\\\\\\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120045/confusion_matrix.png differ\\\\\\\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120045/feature_importances.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120045/feature_importances.png\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..65481a2\\\\\\\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120045/feature_importances.png differ\\\\\\\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120045/pr_curve_cls_0.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120045/pr_curve_cls_0.png\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..a8d230a\\\\\\\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120045/pr_curve_cls_0.png differ\\\\\\\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120045/pr_curve_cls_1.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120045/pr_curve_cls_1.png\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..b36796e\\\\\\\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120045/pr_curve_cls_1.png differ\\\\\\\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120045/pr_curve_cls_2.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120045/pr_curve_cls_2.png\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..86bc90f\\\\\\\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120045/pr_curve_cls_2.png differ\\\\\\\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120045/roc_curve_cls_0.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120045/roc_curve_cls_0.png\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..5ae6a09\\\\\\\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120045/roc_curve_cls_0.png differ\\\\\\\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120045/roc_curve_cls_1.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120045/roc_curve_cls_1.png\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..7d3f039\\\\\\\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120045/roc_curve_cls_1.png differ\\\\\\\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120045/roc_curve_cls_2.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120045/roc_curve_cls_2.png\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..24b4468\\\\\\\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120045/roc_curve_cls_2.png differ\\\\\\\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120045/shap_summary.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120045/shap_summary.png\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..d6c6ef0\\\\\\\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120045/shap_summary.png differ\\\\\\\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120852/confusion_matrix.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120852/confusion_matrix.png\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..5bf98dd\\\\\\\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120852/confusion_matrix.png differ\\\\\\\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120852/feature_importances.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120852/feature_importances.png\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..65481a2\\\\\\\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120852/feature_importances.png differ\\\\\\\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120852/pr_curve_cls_0.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120852/pr_curve_cls_0.png\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..a8d230a\\\\\\\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120852/pr_curve_cls_0.png differ\\\\\\\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120852/pr_curve_cls_1.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120852/pr_curve_cls_1.png\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..b36796e\\\\\\\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120852/pr_curve_cls_1.png differ\\\\\\\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120852/pr_curve_cls_2.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120852/pr_curve_cls_2.png\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..86bc90f\\\\\\\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120852/pr_curve_cls_2.png differ\\\\\\\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120852/roc_curve_cls_0.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120852/roc_curve_cls_0.png\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..5ae6a09\\\\\\\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120852/roc_curve_cls_0.png differ\\\\\\\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120852/roc_curve_cls_1.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120852/roc_curve_cls_1.png\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..7d3f039\\\\\\\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120852/roc_curve_cls_1.png differ\\\\\\\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120852/roc_curve_cls_2.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120852/roc_curve_cls_2.png\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..24b4468\\\\\\\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120852/roc_curve_cls_2.png differ\\\\\\\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120852/shap_summary.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120852/shap_summary.png\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..294954e\\\\\\\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120852/shap_summary.png differ\\\\\\\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_121328/confusion_matrix.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_121328/confusion_matrix.png\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..5bf98dd\\\\\\\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_121328/confusion_matrix.png differ\\\\\\\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_121328/feature_importances.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_121328/feature_importances.png\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..65481a2\\\\\\\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_121328/feature_importances.png differ\\\\\\\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_121328/pr_curve_cls_0.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_121328/pr_curve_cls_0.png\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..a8d230a\\\\\\\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_121328/pr_curve_cls_0.png differ\\\\\\\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_121328/pr_curve_cls_1.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_121328/pr_curve_cls_1.png\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..b36796e\\\\\\\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_121328/pr_curve_cls_1.png differ\\\\\\\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_121328/pr_curve_cls_2.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_121328/pr_curve_cls_2.png\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..86bc90f\\\\\\\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_121328/pr_curve_cls_2.png differ\\\\\\\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_121328/roc_curve_cls_0.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_121328/roc_curve_cls_0.png\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..5ae6a09\\\\\\\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_121328/roc_curve_cls_0.png differ\\\\\\\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_121328/roc_curve_cls_1.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_121328/roc_curve_cls_1.png\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..7d3f039\\\\\\\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_121328/roc_curve_cls_1.png differ\\\\\\\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_121328/roc_curve_cls_2.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_121328/roc_curve_cls_2.png\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..24b4468\\\\\\\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_121328/roc_curve_cls_2.png differ\\\\\\\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_121328/shap_summary.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_121328/shap_summary.png\\\\\\\\nnew file mode 100644\\\\\\\\nindex 0000000..8cdf7ae\\\\\\\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_121328/shap_summary.png differ\\\\\\\\ndiff --git a/notebooks/RQ_notebooks/ref_for creating venv.ipynb b/notebooks/RQ_notebooks/ref_for creating venv.ipynb\\\\\\\\ndeleted file mode 100644\\\\\\\\nindex b6923ef..0000000\\\\\\\\n--- a/notebooks/RQ_notebooks/ref_for creating venv.ipynb\\\\\\\\t\\\\\\\\n+++ /dev/null\\\\\\\\n@@ -1,74 +0,0 @@\\\\\\\\n-{\\\\\\\\n- \\\\\\\\\\\\\\\"cells\\\\\\\\\\\\\\\": [\\\\\\\\n-  {\\\\\\\\n-   \\\\\\\\\\\\\\\"cell_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"code\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"execution_count\\\\\\\\\\\\\\\": 4,\\\\\\\\n-   \\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"02474ffc-32c9-44fa-8317-46211ed44b6d\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {},\\\\\\\\n-   \\\\\\\\\\\\\\\"outputs\\\\\\\\\\\\\\\": [\\\\\\\\n-    {\\\\\\\\n-     \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"stdout\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"output_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"stream\\\\\\\\\\\\\\\",\\\\\\\\n-     \\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\": [\\\\\\\\n-      \\\\\\\\\\\\\\\"Conda environment created successfully.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"ipykernel installed successfully.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-      \\\\\\\\\\\\\\\"Kernel added to Jupyter successfully.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n-     ]\\\\\\\\n-    }\\\\\\\\n-   ],\\\\\\\\n-   \\\\\\\\\\\\\\\"source\\\\\\\\\\\\\\\": [\\\\\\\\n-    \\\\\\\\\\\\\\\"# import subprocess\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# import sys\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# import os\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# # Step 1: Create the conda environment\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# def create_conda_env():\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     try:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         subprocess.check_call([sys.executable, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"-m\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"conda\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"create\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"-n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"thesis-env\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"python=3.10\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"-y\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"])\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Conda environment created successfully.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     except subprocess.CalledProcessError as e:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Error creating conda environment: {e}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         raise\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# # Step 2: Install ipykernel and add the conda environment to Jupyter\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# def install_ipykernel_and_add_to_jupyter():\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     try:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         # Activate the conda environment using subprocess and install ipykernel\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         subprocess.check_call([sys.executable, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"-m\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"conda\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"run\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"-n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"thesis-env\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"pip\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"install\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"ipykernel\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"])\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"ipykernel installed successfully.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         # Add the conda environment to Jupyter as a new kernel\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         subprocess.check_call([sys.executable, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"-m\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"conda\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"run\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"-n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"thesis-env\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"python\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"-m\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"ipykernel\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"install\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"--user\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"--name=thesis-env\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"--display-name=Python (thesis-env)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"])\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Kernel added to Jupyter successfully.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#     except subprocess.CalledProcessError as e:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Error installing ipykernel or adding kernel to Jupyter: {e}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"#         raise\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# # Run the functions to create the environment and add it to Jupyter\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# create_conda_env()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"# install_ipykernel_and_add_to_jupyter()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n-   ]\\\\\\\\n-  }\\\\\\\\n- ],\\\\\\\\n- \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {\\\\\\\\n-  \\\\\\\\\\\\\\\"kernelspec\\\\\\\\\\\\\\\": {\\\\\\\\n-   \\\\\\\\\\\\\\\"display_name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Python 3 (ipykernel)\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"language\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"python\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"python3\\\\\\\\\\\\\\\"\\\\\\\\n-  },\\\\\\\\n-  \\\\\\\\\\\\\\\"language_info\\\\\\\\\\\\\\\": {\\\\\\\\n-   \\\\\\\\\\\\\\\"codemirror_mode\\\\\\\\\\\\\\\": {\\\\\\\\n-    \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"ipython\\\\\\\\\\\\\\\",\\\\\\\\n-    \\\\\\\\\\\\\\\"version\\\\\\\\\\\\\\\": 3\\\\\\\\n-   },\\\\\\\\n-   \\\\\\\\\\\\\\\"file_extension\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\".py\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"mimetype\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"text/x-python\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"python\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"nbconvert_exporter\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"python\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"pygments_lexer\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"ipython3\\\\\\\\\\\\\\\",\\\\\\\\n-   \\\\\\\\\\\\\\\"version\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"3.11.5\\\\\\\\\\\\\\\"\\\\\\\\n-  }\\\\\\\\n- },\\\\\\\\n- \\\\\\\\\\\\\\\"nbformat\\\\\\\\\\\\\\\": 4,\\\\\\\\n- \\\\\\\\\\\\\\\"nbformat_minor\\\\\\\\\\\\\\\": 5\\\\\\\\n-}\\\\\\\\n\\\\\\\"\\\\n}\\\"\\n+    },\\n+    {\\n+      \\\"path\\\": \\\"confusion_matrix.png\\\",\\n+      \\\"type\\\": \\\"image\\\",\\n+      \\\"uri\\\": \\\"file:///C:/Users/reema/REPO/notebooks/RQ_notebooks/mlrunlogs/mlflow.db/615223710259862608/28f01e38b7f04d2f948fe21f57f41d0c/artifacts/confusion_matrix.png\\\"\\n+    },\\n+    {\\n+      \\\"path\\\": \\\"estimator.html\\\",\\n+      \\\"type\\\": \\\"other\\\",\\n+      \\\"uri\\\": \\\"file:///C:/Users/reema/REPO/notebooks/RQ_notebooks/mlrunlogs/mlflow.db/615223710259862608/28f01e38b7f04d2f948fe21f57f41d0c/artifacts/estimator.html\\\"\\n+    },\\n+    {\\n+      \\\"path\\\": \\\"feature_importances.png\\\",\\n+      \\\"type\\\": \\\"image\\\",\\n+      \\\"uri\\\": \\\"file:///C:/Users/reema/REPO/notebooks/RQ_notebooks/mlrunlogs/mlflow.db/615223710259862608/28f01e38b7f04d2f948fe21f57f41d0c/artifacts/feature_importances.png\\\"\\n+    },\\n+    {\\n+      \\\"path\\\": \\\"label_mapping.json\\\",\\n+      \\\"type\\\": \\\"text\\\",\\n+      \\\"content\\\": \\\"{\\\\n  \\\\\\\"0\\\\\\\": \\\\\\\"Iris-setosa\\\\\\\",\\\\n  \\\\\\\"1\\\\\\\": \\\\\\\"Iris-versicolor\\\\\\\",\\\\n  \\\\\\\"2\\\\\\\": \\\\\\\"Iris-virginica\\\\\\\"\\\\n}\\\"\\n+    },\\n+    {\\n+      \\\"path\\\": \\\"metric_info.json\\\",\\n+      \\\"type\\\": \\\"text\\\",\\n+      \\\"content\\\": \\\"{\\\\n  \\\\\\\"accuracy_score_X_test\\\\\\\": \\\\\\\"accuracy_score(y_true=y_test, y_pred=y_pred)\\\\\\\",\\\\n  \\\\\\\"f1_score_X_test\\\\\\\": \\\\\\\"f1_score(y_true=y_test, y_pred=y_pred, average='macro')\\\\\\\",\\\\n  \\\\\\\"precision_score_X_test\\\\\\\": \\\\\\\"precision_score(y_true=y_test, y_pred=y_pred, average='macro')\\\\\\\",\\\\n  \\\\\\\"recall_score_X_test\\\\\\\": \\\\\\\"recall_score(y_true=y_test, y_pred=y_pred, average='macro')\\\\\\\",\\\\n  \\\\\\\"roc_auc_score_X_test\\\\\\\": \\\\\\\"roc_auc_score(y_true=y_test, y_score=y_proba, multi_class='ovr')\\\\\\\"\\\\n}\\\"\\n+    },\\n+    {\\n+      \\\"path\\\": \\\"model/MLmodel\\\",\\n+      \\\"type\\\": \\\"other\\\",\\n+      \\\"uri\\\": \\\"file:///C:/Users/reema/REPO/notebooks/RQ_notebooks/mlrunlogs/mlflow.db/615223710259862608/28f01e38b7f04d2f948fe21f57f41d0c/artifacts/model/MLmodel\\\"\\n+    },\\n+    {\\n+      \\\"path\\\": \\\"model/conda.yaml\\\",\\n+      \\\"type\\\": \\\"other\\\",\\n+      \\\"uri\\\": \\\"file:///C:/Users/reema/REPO/notebooks/RQ_notebooks/mlrunlogs/mlflow.db/615223710259862608/28f01e38b7f04d2f948fe21f57f41d0c/artifacts/model/conda.yaml\\\"\\n+    },\\n+    {\\n+      \\\"path\\\": \\\"model/input_example.json\\\",\\n+      \\\"type\\\": \\\"text\\\",\\n+      \\\"content\\\": \\\"{\\\\\\\"columns\\\\\\\": [\\\\\\\"sepallengthcm\\\\\\\", \\\\\\\"sepalwidthcm\\\\\\\", \\\\\\\"petallengthcm\\\\\\\", \\\\\\\"petalwidthcm\\\\\\\"], \\\\\\\"data\\\\\\\": [[4.6, 3.6, 1.0, 0.2], [5.7, 4.4, 1.5, 0.4], [6.7, 3.1, 4.4, 1.4], [4.8, 3.4, 1.6, 0.2], [4.4, 3.2, 1.3, 0.2]]}\\\"\\n+    },\\n+    {\\n+      \\\"path\\\": \\\"model/model.pkl\\\",\\n+      \\\"type\\\": \\\"other\\\",\\n+      \\\"uri\\\": \\\"file:///C:/Users/reema/REPO/notebooks/RQ_notebooks/mlrunlogs/mlflow.db/615223710259862608/28f01e38b7f04d2f948fe21f57f41d0c/artifacts/model/model.pkl\\\"\\n+    },\\n+    {\\n+      \\\"path\\\": \\\"model/python_env.yaml\\\",\\n+      \\\"type\\\": \\\"other\\\",\\n+      \\\"uri\\\": \\\"file:///C:/Users/reema/REPO/notebooks/RQ_notebooks/mlrunlogs/mlflow.db/615223710259862608/28f01e38b7f04d2f948fe21f57f41d0c/artifacts/model/python_env.yaml\\\"\\n+    },\\n+    {\\n+      \\\"path\\\": \\\"model/requirements.txt\\\",\\n+      \\\"type\\\": \\\"text\\\",\\n+      \\\"content\\\": \\\"mlflow==2.21.2\\\\nbackports-functools-lru-cache==1.6.4\\\\nbackports-tempfile==1.0\\\\ncloudpickle==2.2.1\\\\njaraco-classes==3.2.1\\\\njaraco-collections==5.1.0\\\\nlz4==4.3.2\\\\nnumpy==1.24.4\\\\npathlib==1.0.1\\\\npsutil==5.9.5\\\\nscikit-learn==1.3.0\\\\nscipy==1.11.1\\\"\\n+    },\\n+    {\\n+      \\\"path\\\": \\\"model/serving_input_example.json\\\",\\n+      \\\"type\\\": \\\"text\\\",\\n+      \\\"content\\\": \\\"{\\\\n  \\\\\\\"dataframe_split\\\\\\\": {\\\\n    \\\\\\\"columns\\\\\\\": [\\\\n      \\\\\\\"sepallengthcm\\\\\\\",\\\\n      \\\\\\\"sepalwidthcm\\\\\\\",\\\\n      \\\\\\\"petallengthcm\\\\\\\",\\\\n      \\\\\\\"petalwidthcm\\\\\\\"\\\\n    ],\\\\n    \\\\\\\"data\\\\\\\": [\\\\n      [\\\\n        4.6,\\\\n        3.6,\\\\n        1.0,\\\\n        0.2\\\\n      ],\\\\n      [\\\\n        5.7,\\\\n        4.4,\\\\n        1.5,\\\\n        0.4\\\\n      ],\\\\n      [\\\\n        6.7,\\\\n        3.1,\\\\n        4.4,\\\\n        1.4\\\\n      ],\\\\n      [\\\\n        4.8,\\\\n        3.4,\\\\n        1.6,\\\\n        0.2\\\\n      ],\\\\n      [\\\\n        4.4,\\\\n        3.2,\\\\n        1.3,\\\\n        0.2\\\\n      ]\\\\n    ]\\\\n  }\\\\n}\\\"\\n+    },\\n+    {\\n+      \\\"path\\\": \\\"pr_curve_cls_0.png\\\",\\n+      \\\"type\\\": \\\"image\\\",\\n+      \\\"uri\\\": \\\"file:///C:/Users/reema/REPO/notebooks/RQ_notebooks/mlrunlogs/mlflow.db/615223710259862608/28f01e38b7f04d2f948fe21f57f41d0c/artifacts/pr_curve_cls_0.png\\\"\\n+    },\\n+    {\\n+      \\\"path\\\": \\\"pr_curve_cls_1.png\\\",\\n+      \\\"type\\\": \\\"image\\\",\\n+      \\\"uri\\\": \\\"file:///C:/Users/reema/REPO/notebooks/RQ_notebooks/mlrunlogs/mlflow.db/615223710259862608/28f01e38b7f04d2f948fe21f57f41d0c/artifacts/pr_curve_cls_1.png\\\"\\n+    },\\n+    {\\n+      \\\"path\\\": \\\"pr_curve_cls_2.png\\\",\\n+      \\\"type\\\": \\\"image\\\",\\n+      \\\"uri\\\": \\\"file:///C:/Users/reema/REPO/notebooks/RQ_notebooks/mlrunlogs/mlflow.db/615223710259862608/28f01e38b7f04d2f948fe21f57f41d0c/artifacts/pr_curve_cls_2.png\\\"\\n+    },\\n+    {\\n+      \\\"path\\\": \\\"public_datasetRepository_metadata.json\\\",\\n+      \\\"type\\\": \\\"text\\\",\\n+      \\\"content\\\": \\\"{\\\\n  \\\\\\\"zenodo\\\\\\\": {\\\\n    \\\\\\\"title\\\\\\\": \\\\\\\"Scikit-Learn Iris\\\\\\\",\\\\n    \\\\\\\"doi\\\\\\\": \\\\\\\"10.5281/ZENODO.1404173\\\\\\\",\\\\n    \\\\\\\"authors\\\\\\\": [\\\\n      \\\\\\\"Marshall Michael\\\\\\\"\\\\n    ],\\\\n    \\\\\\\"published\\\\\\\": \\\\\\\"2018-8-27\\\\\\\",\\\\n    \\\\\\\"publisher\\\\\\\": \\\\\\\"Zenodo\\\\\\\"\\\\n  }\\\\n}\\\"\\n+    },\\n+    {\\n+      \\\"path\\\": \\\"roc_curve_cls_0.png\\\",\\n+      \\\"type\\\": \\\"image\\\",\\n+      \\\"uri\\\": \\\"file:///C:/Users/reema/REPO/notebooks/RQ_notebooks/mlrunlogs/mlflow.db/615223710259862608/28f01e38b7f04d2f948fe21f57f41d0c/artifacts/roc_curve_cls_0.png\\\"\\n+    },\\n+    {\\n+      \\\"path\\\": \\\"roc_curve_cls_1.png\\\",\\n+      \\\"type\\\": \\\"image\\\",\\n+      \\\"uri\\\": \\\"file:///C:/Users/reema/REPO/notebooks/RQ_notebooks/mlrunlogs/mlflow.db/615223710259862608/28f01e38b7f04d2f948fe21f57f41d0c/artifacts/roc_curve_cls_1.png\\\"\\n+    },\\n+    {\\n+      \\\"path\\\": \\\"roc_curve_cls_2.png\\\",\\n+      \\\"type\\\": \\\"image\\\",\\n+      \\\"uri\\\": \\\"file:///C:/Users/reema/REPO/notebooks/RQ_notebooks/mlrunlogs/mlflow.db/615223710259862608/28f01e38b7f04d2f948fe21f57f41d0c/artifacts/roc_curve_cls_2.png\\\"\\n+    },\\n+    {\\n+      \\\"path\\\": \\\"shap_summary.png\\\",\\n+      \\\"type\\\": \\\"image\\\",\\n+      \\\"uri\\\": \\\"file:///C:/Users/reema/REPO/notebooks/RQ_notebooks/mlrunlogs/mlflow.db/615223710259862608/28f01e38b7f04d2f948fe21f57f41d0c/artifacts/shap_summary.png\\\"\\n+    },\\n+    {\\n+      \\\"path\\\": \\\"training_confusion_matrix.png\\\",\\n+      \\\"type\\\": \\\"image\\\",\\n+      \\\"uri\\\": \\\"file:///C:/Users/reema/REPO/notebooks/RQ_notebooks/mlrunlogs/mlflow.db/615223710259862608/28f01e38b7f04d2f948fe21f57f41d0c/artifacts/training_confusion_matrix.png\\\"\\n+    }\\n+  ],\\n+  \\\"tags\\\": {\\n+    \\\"dataset_id\\\": \\\"iris_local\\\",\\n+    \\\"dataset_name\\\": \\\"Iris\\\",\\n+    \\\"dataset_version\\\": \\\"1.0.0\\\",\\n+    \\\"data_source\\\": \\\"http://localhost/api/database/c3a42d17-42b7-43c9-a504-2363fb4c9c8d/table/5315e7da-64fb-4fdb-b493-95b4138c765f/data?size=100000&page=0\\\",\\n+    \\\"dbrepo.admin_email\\\": \\\"noreply@localhost\\\",\\n+    \\\"dbrepo.base_url\\\": \\\"http://localhost\\\",\\n+    \\\"dbrepo.granularity\\\": \\\"YYYY-MM-DDThh:mm:ssZ\\\",\\n+    \\\"dbrepo.protocol_version\\\": \\\"2.0\\\",\\n+    \\\"dbrepo.repository_name\\\": \\\"Database Repository\\\",\\n+    \\\"dbrepo.table_last_modified\\\": \\\"2025-04-23T20:42:29.501Z\\\",\\n+    \\\"estimator_class\\\": \\\"sklearn.ensemble._forest.RandomForestClassifier\\\",\\n+    \\\"estimator_name\\\": \\\"RandomForestClassifier\\\",\\n+    \\\"git_current_commit_hash\\\": \\\"b88aa7eddfb150c58ed3dee766f1c62d3107975a\\\",\\n+    \\\"git_previous_commit_hash\\\": \\\"8c5c1cb1d6a5e4a1d63b6ffdef1f78328209301a\\\",\\n+    \\\"git__current_commit_url\\\": \\\"https://github.com/reema-dass26/REPO/commit/b88aa7eddfb150c58ed3dee766f1c62d3107975a\\\",\\n+    \\\"mlflow.log-model.history\\\": \\\"[{\\\\\\\"run_id\\\\\\\": \\\\\\\"28f01e38b7f04d2f948fe21f57f41d0c\\\\\\\", \\\\\\\"artifact_path\\\\\\\": \\\\\\\"model\\\\\\\", \\\\\\\"utc_time_created\\\\\\\": \\\\\\\"2025-04-25 10:13:29.372297\\\\\\\", \\\\\\\"model_uuid\\\\\\\": \\\\\\\"db8567f44744439885318d1e3243a19a\\\\\\\", \\\\\\\"flavors\\\\\\\": {\\\\\\\"python_function\\\\\\\": {\\\\\\\"model_path\\\\\\\": \\\\\\\"model.pkl\\\\\\\", \\\\\\\"predict_fn\\\\\\\": \\\\\\\"predict\\\\\\\", \\\\\\\"loader_module\\\\\\\": \\\\\\\"mlflow.sklearn\\\\\\\", \\\\\\\"python_version\\\\\\\": \\\\\\\"3.11.5\\\\\\\", \\\\\\\"env\\\\\\\": {\\\\\\\"conda\\\\\\\": \\\\\\\"conda.yaml\\\\\\\", \\\\\\\"virtualenv\\\\\\\": \\\\\\\"python_env.yaml\\\\\\\"}}, \\\\\\\"sklearn\\\\\\\": {\\\\\\\"pickled_model\\\\\\\": \\\\\\\"model.pkl\\\\\\\", \\\\\\\"sklearn_version\\\\\\\": \\\\\\\"1.3.0\\\\\\\", \\\\\\\"serialization_format\\\\\\\": \\\\\\\"cloudpickle\\\\\\\", \\\\\\\"code\\\\\\\": null}}}]\\\",\\n+    \\\"mlflow.runName\\\": \\\"amazing-sponge-952\\\",\\n+    \\\"mlflow.source.name\\\": \\\"C:\\\\\\\\Users\\\\\\\\reema\\\\\\\\AppData\\\\\\\\Roaming\\\\\\\\Python\\\\\\\\Python311\\\\\\\\site-packages\\\\\\\\ipykernel_launcher.py\\\",\\n+    \\\"mlflow.source.type\\\": \\\"LOCAL\\\",\\n+    \\\"mlflow.user\\\": \\\"reema\\\",\\n+    \\\"model_name\\\": \\\"RandomForest_Iris_v20250425_121328\\\",\\n+    \\\"notebook_name\\\": \\\"RQ1.ipynb\\\",\\n+    \\\"target_name\\\": \\\"[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\\\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\\\\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\\\\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\\\\n 2 2]\\\",\\n+    \\\"training_end_time\\\": \\\"2025-04-25T12:13:34.836937\\\",\\n+    \\\"training_start_time\\\": \\\"2025-04-25T12:13:28.505405\\\"\\n+  },\\n+  \\\"start_time\\\": \\\"2025-04-25T10:13:27.206000+00:00\\\",\\n+  \\\"used\\\": [],\\n+  \\\"generated\\\": [\\n+    \\\"file:///C:/Users/reema/REPO/notebooks/RQ_notebooks/mlrunlogs/mlflow.db/615223710259862608/28f01e38b7f04d2f948fe21f57f41d0c/artifacts/RandomForest_Iris_v20250425_121328/RandomForest_Iris_v20250425_121328.pkl\\\",\\n+    \\\"commit_diff.json\\\",\\n+    \\\"file:///C:/Users/reema/REPO/notebooks/RQ_notebooks/mlrunlogs/mlflow.db/615223710259862608/28f01e38b7f04d2f948fe21f57f41d0c/artifacts/confusion_matrix.png\\\",\\n+    \\\"file:///C:/Users/reema/REPO/notebooks/RQ_notebooks/mlrunlogs/mlflow.db/615223710259862608/28f01e38b7f04d2f948fe21f57f41d0c/artifacts/estimator.html\\\",\\n+    \\\"file:///C:/Users/reema/REPO/notebooks/RQ_notebooks/mlrunlogs/mlflow.db/615223710259862608/28f01e38b7f04d2f948fe21f57f41d0c/artifacts/feature_importances.png\\\",\\n+    \\\"label_mapping.json\\\",\\n+    \\\"metric_info.json\\\",\\n+    \\\"file:///C:/Users/reema/REPO/notebooks/RQ_notebooks/mlrunlogs/mlflow.db/615223710259862608/28f01e38b7f04d2f948fe21f57f41d0c/artifacts/model/MLmodel\\\",\\n+    \\\"file:///C:/Users/reema/REPO/notebooks/RQ_notebooks/mlrunlogs/mlflow.db/615223710259862608/28f01e38b7f04d2f948fe21f57f41d0c/artifacts/model/conda.yaml\\\",\\n+    \\\"model/input_example.json\\\",\\n+    \\\"file:///C:/Users/reema/REPO/notebooks/RQ_notebooks/mlrunlogs/mlflow.db/615223710259862608/28f01e38b7f04d2f948fe21f57f41d0c/artifacts/model/model.pkl\\\",\\n+    \\\"file:///C:/Users/reema/REPO/notebooks/RQ_notebooks/mlrunlogs/mlflow.db/615223710259862608/28f01e38b7f04d2f948fe21f57f41d0c/artifacts/model/python_env.yaml\\\",\\n+    \\\"model/requirements.txt\\\",\\n+    \\\"model/serving_input_example.json\\\",\\n+    \\\"file:///C:/Users/reema/REPO/notebooks/RQ_notebooks/mlrunlogs/mlflow.db/615223710259862608/28f01e38b7f04d2f948fe21f57f41d0c/artifacts/pr_curve_cls_0.png\\\",\\n+    \\\"file:///C:/Users/reema/REPO/notebooks/RQ_notebooks/mlrunlogs/mlflow.db/615223710259862608/28f01e38b7f04d2f948fe21f57f41d0c/artifacts/pr_curve_cls_1.png\\\",\\n+    \\\"file:///C:/Users/reema/REPO/notebooks/RQ_notebooks/mlrunlogs/mlflow.db/615223710259862608/28f01e38b7f04d2f948fe21f57f41d0c/artifacts/pr_curve_cls_2.png\\\",\\n+    \\\"public_datasetRepository_metadata.json\\\",\\n+    \\\"file:///C:/Users/reema/REPO/notebooks/RQ_notebooks/mlrunlogs/mlflow.db/615223710259862608/28f01e38b7f04d2f948fe21f57f41d0c/artifacts/roc_curve_cls_0.png\\\",\\n+    \\\"file:///C:/Users/reema/REPO/notebooks/RQ_notebooks/mlrunlogs/mlflow.db/615223710259862608/28f01e38b7f04d2f948fe21f57f41d0c/artifacts/roc_curve_cls_1.png\\\",\\n+    \\\"file:///C:/Users/reema/REPO/notebooks/RQ_notebooks/mlrunlogs/mlflow.db/615223710259862608/28f01e38b7f04d2f948fe21f57f41d0c/artifacts/roc_curve_cls_2.png\\\",\\n+    \\\"file:///C:/Users/reema/REPO/notebooks/RQ_notebooks/mlrunlogs/mlflow.db/615223710259862608/28f01e38b7f04d2f948fe21f57f41d0c/artifacts/shap_summary.png\\\",\\n+    \\\"file:///C:/Users/reema/REPO/notebooks/RQ_notebooks/mlrunlogs/mlflow.db/615223710259862608/28f01e38b7f04d2f948fe21f57f41d0c/artifacts/training_confusion_matrix.png\\\"\\n+  ]\\n+}\\n\\\\ No newline at end of file\\ndiff --git a/notebooks/RQ_notebooks/MODEL_PROVENANCE/RandomForest_Iris_v20250425_121328/RandomForest_Iris_v20250425_121328.ttl b/notebooks/RQ_notebooks/MODEL_PROVENANCE/RandomForest_Iris_v20250425_121328/RandomForest_Iris_v20250425_121328.ttl\\nnew file mode 100644\\nindex 0000000..8f3655d\\n--- /dev/null\\n+++ b/notebooks/RQ_notebooks/MODEL_PROVENANCE/RandomForest_Iris_v20250425_121328/RandomForest_Iris_v20250425_121328.ttl\\n@@ -0,0 +1,57 @@\\n+@prefix prov: <http://www.w3.org/ns/prov#> .\\n+@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .\\n+\\n+[] <artifacts> [ ],\\n+        [ ],\\n+        [ ],\\n+        [ ],\\n+        [ ],\\n+        [ ],\\n+        [ ],\\n+        [ ],\\n+        [ ],\\n+        [ ],\\n+        [ ],\\n+        [ ],\\n+        [ ],\\n+        [ ],\\n+        [ ],\\n+        [ ],\\n+        [ ],\\n+        [ ],\\n+        [ ],\\n+        [ ],\\n+        [ ],\\n+        [ ],\\n+        [ ] ;\\n+    <experiment_id> \\\"615223710259862608\\\" ;\\n+    prov:generated <file:///C:/Users/reema/REPO/notebooks/RQ_notebooks/commit_diff.json>,\\n+        <file:///C:/Users/reema/REPO/notebooks/RQ_notebooks/label_mapping.json>,\\n+        <file:///C:/Users/reema/REPO/notebooks/RQ_notebooks/metric_info.json>,\\n+        <file:///C:/Users/reema/REPO/notebooks/RQ_notebooks/mlrunlogs/mlflow.db/615223710259862608/28f01e38b7f04d2f948fe21f57f41d0c/artifacts/RandomForest_Iris_v20250425_121328/RandomForest_Iris_v20250425_121328.pkl>,\\n+        <file:///C:/Users/reema/REPO/notebooks/RQ_notebooks/mlrunlogs/mlflow.db/615223710259862608/28f01e38b7f04d2f948fe21f57f41d0c/artifacts/confusion_matrix.png>,\\n+        <file:///C:/Users/reema/REPO/notebooks/RQ_notebooks/mlrunlogs/mlflow.db/615223710259862608/28f01e38b7f04d2f948fe21f57f41d0c/artifacts/estimator.html>,\\n+        <file:///C:/Users/reema/REPO/notebooks/RQ_notebooks/mlrunlogs/mlflow.db/615223710259862608/28f01e38b7f04d2f948fe21f57f41d0c/artifacts/feature_importances.png>,\\n+        <file:///C:/Users/reema/REPO/notebooks/RQ_notebooks/mlrunlogs/mlflow.db/615223710259862608/28f01e38b7f04d2f948fe21f57f41d0c/artifacts/model/MLmodel>,\\n+        <file:///C:/Users/reema/REPO/notebooks/RQ_notebooks/mlrunlogs/mlflow.db/615223710259862608/28f01e38b7f04d2f948fe21f57f41d0c/artifacts/model/conda.yaml>,\\n+        <file:///C:/Users/reema/REPO/notebooks/RQ_notebooks/mlrunlogs/mlflow.db/615223710259862608/28f01e38b7f04d2f948fe21f57f41d0c/artifacts/model/model.pkl>,\\n+        <file:///C:/Users/reema/REPO/notebooks/RQ_notebooks/mlrunlogs/mlflow.db/615223710259862608/28f01e38b7f04d2f948fe21f57f41d0c/artifacts/model/python_env.yaml>,\\n+        <file:///C:/Users/reema/REPO/notebooks/RQ_notebooks/mlrunlogs/mlflow.db/615223710259862608/28f01e38b7f04d2f948fe21f57f41d0c/artifacts/pr_curve_cls_0.png>,\\n+        <file:///C:/Users/reema/REPO/notebooks/RQ_notebooks/mlrunlogs/mlflow.db/615223710259862608/28f01e38b7f04d2f948fe21f57f41d0c/artifacts/pr_curve_cls_1.png>,\\n+        <file:///C:/Users/reema/REPO/notebooks/RQ_notebooks/mlrunlogs/mlflow.db/615223710259862608/28f01e38b7f04d2f948fe21f57f41d0c/artifacts/pr_curve_cls_2.png>,\\n+        <file:///C:/Users/reema/REPO/notebooks/RQ_notebooks/mlrunlogs/mlflow.db/615223710259862608/28f01e38b7f04d2f948fe21f57f41d0c/artifacts/roc_curve_cls_0.png>,\\n+        <file:///C:/Users/reema/REPO/notebooks/RQ_notebooks/mlrunlogs/mlflow.db/615223710259862608/28f01e38b7f04d2f948fe21f57f41d0c/artifacts/roc_curve_cls_1.png>,\\n+        <file:///C:/Users/reema/REPO/notebooks/RQ_notebooks/mlrunlogs/mlflow.db/615223710259862608/28f01e38b7f04d2f948fe21f57f41d0c/artifacts/roc_curve_cls_2.png>,\\n+        <file:///C:/Users/reema/REPO/notebooks/RQ_notebooks/mlrunlogs/mlflow.db/615223710259862608/28f01e38b7f04d2f948fe21f57f41d0c/artifacts/shap_summary.png>,\\n+        <file:///C:/Users/reema/REPO/notebooks/RQ_notebooks/mlrunlogs/mlflow.db/615223710259862608/28f01e38b7f04d2f948fe21f57f41d0c/artifacts/training_confusion_matrix.png>,\\n+        <file:///C:/Users/reema/REPO/notebooks/RQ_notebooks/model/input_example.json>,\\n+        <file:///C:/Users/reema/REPO/notebooks/RQ_notebooks/model/requirements.txt>,\\n+        <file:///C:/Users/reema/REPO/notebooks/RQ_notebooks/model/serving_input_example.json>,\\n+        <file:///C:/Users/reema/REPO/notebooks/RQ_notebooks/public_datasetRepository_metadata.json> ;\\n+    prov:startedAtTime \\\"2025-04-25T10:13:27.206000+00:00\\\"^^xsd:dateTime ;\\n+    <metrics> [ ] ;\\n+    <params> [ ] ;\\n+    <run_id> \\\"28f01e38b7f04d2f948fe21f57f41d0c\\\" ;\\n+    <run_name> \\\"amazing-sponge-952\\\" ;\\n+    <tags> [ ] .\\n+\\ndiff --git a/notebooks/RQ_notebooks/RQ1.ipynb b/notebooks/RQ_notebooks/RQ1.ipynb\\ndeleted file mode 100644\\nindex 468a62a..0000000\\n--- a/notebooks/RQ_notebooks/RQ1.ipynb\\n+++ /dev/null\\n@@ -1,1093 +0,0 @@\\n-{\\n- \\\"cells\\\": [\\n-  {\\n-   \\\"cell_type\\\": \\\"markdown\\\",\\n-   \\\"id\\\": \\\"d55b8ff1-b8ac-4dbf-861f-458e234526f3\\\",\\n-   \\\"metadata\\\": {},\\n-   \\\"source\\\": [\\n-    \\\"TODO\\\\n\\\",\\n-    \\\"create venv to wrap up all installation programatically\\\\n\\\",\\n-    \\\"set the experiment name in mlflow dynamically\\\\n\\\",\\n-    \\\"update teh target name dynamic after db repo integration\\\"\\n-   ]\\n-  },\\n-  {\\n-   \\\"cell_type\\\": \\\"code\\\",\\n-   \\\"execution_count\\\": null,\\n-   \\\"id\\\": \\\"387a312e-e0db-4522-b4b2-4a346fd008ba\\\",\\n-   \\\"metadata\\\": {\\n-    \\\"editable\\\": true,\\n-    \\\"scrolled\\\": true,\\n-    \\\"slideshow\\\": {\\n-     \\\"slide_type\\\": \\\"\\\"\\n-    },\\n-    \\\"tags\\\": []\\n-   },\\n-   \\\"outputs\\\": [],\\n-   \\\"source\\\": [\\n-    \\\"# \\u2699\\ufe0f Install required packages in the notebook itself\\\\n\\\",\\n-    \\\"# !pip install --quiet --upgrade pip\\\\n\\\",\\n-    \\\"!pip install mlflow scikit-learn\\\\n\\\",\\n-    \\\"!pip install pandas\\\\n\\\",\\n-    \\\"!pip install numpy\\\\n\\\",\\n-    \\\"!pip install jupyter\\\\n\\\",\\n-    \\\"!pip install shap\\\\n\\\"\\n-   ]\\n-  },\\n-  {\\n-   \\\"cell_type\\\": \\\"code\\\",\\n-   \\\"execution_count\\\": null,\\n-   \\\"id\\\": \\\"1d52b769-2727-457d-ba78-29726ebf4fe3\\\",\\n-   \\\"metadata\\\": {},\\n-   \\\"outputs\\\": [],\\n-   \\\"source\\\": [\\n-    \\\"!pip install scikit-learn\\\"\\n-   ]\\n-  },\\n-  {\\n-   \\\"cell_type\\\": \\\"code\\\",\\n-   \\\"execution_count\\\": null,\\n-   \\\"id\\\": \\\"3e42e4c3-ab59-40dd-ac48-aef4bbecd4b6\\\",\\n-   \\\"metadata\\\": {\\n-    \\\"scrolled\\\": true\\n-   },\\n-   \\\"outputs\\\": [],\\n-   \\\"source\\\": [\\n-    \\\"!pip uninstall numpy\\\\n\\\",\\n-    \\\"!pip install numpy --force-reinstall --upgrade\\\\n\\\",\\n-    \\\"!pip uninstall shap\\\\n\\\",\\n-    \\\"!pip install shap --upgrade\\\\n\\\",\\n-    \\\"!pip install mkl\\\"\\n-   ]\\n-  },\\n-  {\\n-   \\\"cell_type\\\": \\\"code\\\",\\n-   \\\"execution_count\\\": 69,\\n-   \\\"id\\\": \\\"8e95a3c5-c669-421f-891a-a58799d81de1\\\",\\n-   \\\"metadata\\\": {\\n-    \\\"editable\\\": true,\\n-    \\\"scrolled\\\": true,\\n-    \\\"slideshow\\\": {\\n-     \\\"slide_type\\\": \\\"\\\"\\n-    },\\n-    \\\"tags\\\": []\\n-   },\\n-   \\\"outputs\\\": [],\\n-   \\\"source\\\": [\\n-    \\\"import git  \\\\n\\\",\\n-    \\\"import mlflow\\\\n\\\",\\n-    \\\"from mlflow import MlflowClient\\\\n\\\",\\n-    \\\"import time\\\\n\\\",\\n-    \\\"import psutil\\\\n\\\",\\n-    \\\"import platform\\\\n\\\",\\n-    \\\"import sklearn\\\\n\\\",\\n-    \\\"import pandas as pd\\\\n\\\",\\n-    \\\"import numpy as np\\\\n\\\",\\n-    \\\"import matplotlib\\\\n\\\",\\n-    \\\"import seaborn\\\\n\\\",\\n-    \\\"import json\\\\n\\\",\\n-    \\\"import os\\\\n\\\",\\n-    \\\"import sys\\\\n\\\",\\n-    \\\"from sklearn.ensemble import RandomForestClassifier\\\\n\\\",\\n-    \\\"from sklearn.model_selection import train_test_split\\\\n\\\",\\n-    \\\"from sklearn.metrics import (\\\\n\\\",\\n-    \\\"    accuracy_score, roc_auc_score, confusion_matrix,\\\\n\\\",\\n-    \\\"    precision_score, recall_score, f1_score, roc_curve\\\\n\\\",\\n-    \\\")\\\\n\\\",\\n-    \\\"import shap\\\\n\\\",\\n-    \\\"import seaborn as sns\\\\n\\\",\\n-    \\\"import matplotlib.pyplot as plt\\\\n\\\",\\n-    \\\"os.environ[\\\\\\\"MLFLOW_SYSTEM_METRICS_ENABLED\\\\\\\"] = \\\\\\\"true\\\\\\\"\\\\n\\\"\\n-   ]\\n-  },\\n-  {\\n-   \\\"cell_type\\\": \\\"code\\\",\\n-   \\\"execution_count\\\": 70,\\n-   \\\"id\\\": \\\"b5930009-6cf8-4258-9375-0ee20f290bc3\\\",\\n-   \\\"metadata\\\": {},\\n-   \\\"outputs\\\": [\\n-    {\\n-     \\\"name\\\": \\\"stdout\\\",\\n-     \\\"output_type\\\": \\\"stream\\\",\\n-     \\\"text\\\": [\\n-      \\\"Tracking URI set to: mlrunlogs/mlflow.db\\\\n\\\"\\n-     ]\\n-    },\\n-    {\\n-     \\\"data\\\": {\\n-      \\\"text/plain\\\": [\\n-       \\\"<Experiment: artifact_location='file:///C:/Users/reema/OneDrive/Dokumente/Provenance_tracking_thesis/Provenence-Tracking-Thesis-Research/notebooks/RQ_notebooks/mlrunlogs/mlflow.db/350083769514222255', creation_time=1744653654888, experiment_id='350083769514222255', last_update_time=1744653654888, lifecycle_stage='active', name='RandomForest-Iris-CSV', tags={}>\\\"\\n-      ]\\n-     },\\n-     \\\"execution_count\\\": 70,\\n-     \\\"metadata\\\": {},\\n-     \\\"output_type\\\": \\\"execute_result\\\"\\n-    }\\n-   ],\\n-   \\\"source\\\": [\\n-    \\\"# Set experiment name\\\\n\\\",\\n-    \\\"# ============================\\\\n\\\",\\n-    \\\"# \\ud83d\\udd27 Configuration\\\\n\\\",\\n-    \\\"# ============================\\\\n\\\",\\n-    \\\"pproject_dir = os.getcwd()\\\\n\\\",\\n-    \\\"tracking_dir = os.path.join(project_dir, \\\\\\\"mlruns\\\\\\\")\\\\n\\\",\\n-    \\\"mlflow.set_tracking_uri(\\\\\\\"mlrunlogs/mlflow.db\\\\\\\")  # Setting the MLflow tracking URI\\\\n\\\",\\n-    \\\"print(\\\\\\\"Tracking URI set to:\\\\\\\", mlflow.get_tracking_uri())\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"mlflow.set_experiment(\\\\\\\"RandomForest-Iris-CSV\\\\\\\")\\\"\\n-   ]\\n-  },\\n-  {\\n-   \\\"cell_type\\\": \\\"code\\\",\\n-   \\\"execution_count\\\": 71,\\n-   \\\"id\\\": \\\"055a90d6-b671-46bc-8daf-b1b442347915\\\",\\n-   \\\"metadata\\\": {},\\n-   \\\"outputs\\\": [],\\n-   \\\"source\\\": [\\n-    \\\"# ============================\\\\n\\\",\\n-    \\\"# \\ud83d\\udce5 Load Data from CSV\\\\n\\\",\\n-    \\\"# ============================\\\\n\\\",\\n-    \\\"# Read data from CSV file\\\\n\\\",\\n-    \\\"df = pd.read_csv(\\\\\\\"C:/Users/reema/OneDrive/Dokumente/Provenance_tracking_thesis/Provenence-Tracking-Thesis-Research/data/Iris.csv\\\\\\\")\\\\n\\\",\\n-    \\\"# Use the last column as the target variable\\\\n\\\",\\n-    \\\"X = df.iloc[:, :-1]  # All columns except the last one are features\\\\n\\\",\\n-    \\\"y = df.iloc[:, -1]   # The last column is the target\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# Create a dataset object with mlflow.data\\\\n\\\",\\n-    \\\"dataset = mlflow.data.from_pandas(df, name=\\\\\\\"Iris Dataset\\\\\\\")\\\"\\n-   ]\\n-  },\\n-  {\\n-   \\\"cell_type\\\": \\\"code\\\",\\n-   \\\"execution_count\\\": 72,\\n-   \\\"id\\\": \\\"91732c7f-362c-4557-8b8e-71ed640ae8d4\\\",\\n-   \\\"metadata\\\": {},\\n-   \\\"outputs\\\": [],\\n-   \\\"source\\\": [\\n-    \\\"# Dataset Metadata to be logged 'TODO_update based on DBREPO LOG\\\\n\\\",\\n-    \\\"dataset_metadata = {\\\\n\\\",\\n-    \\\"    \\\\\\\"dataset_name\\\\\\\": \\\\\\\"Iris Dataset\\\\\\\",\\\\n\\\",\\n-    \\\"    \\\\\\\"dataset_version\\\\\\\": \\\\\\\"1.0.0\\\\\\\",  # or use a Git commit hash or timestamp\\\\n\\\",\\n-    \\\"    \\\\\\\"dataset_source_url_or_path\\\\\\\": \\\\\\\"C:/Users/reema/OneDrive/Dokumente/Provenance_tracking_thesis/Provenence-Tracking-Thesis-Research/data/Iris.csv\\\\\\\",\\\\n\\\",\\n-    \\\"    \\\\\\\"dataset_size_bytes\\\\\\\": os.path.getsize(\\\\\\\"C:/Users/reema/OneDrive/Dokumente/Provenance_tracking_thesis/Provenence-Tracking-Thesis-Research/data/Iris.csv\\\\\\\"),\\\\n\\\",\\n-    \\\"    \\\\\\\"dataset_shape\\\\\\\": f\\\\\\\"{df.shape[0]} x {df.shape[1]}\\\\\\\",\\\\n\\\",\\n-    \\\"    \\\\\\\"dataset_format\\\\\\\": \\\\\\\"CSV\\\\\\\",\\\\n\\\",\\n-    \\\"    \\\\\\\"feature_names\\\\\\\": list(X.columns),\\\\n\\\",\\n-    \\\"    \\\\\\\"feature_types\\\\\\\": [str(X[col].dtype) for col in X.columns],\\\\n\\\",\\n-    \\\"    \\\\\\\"target_column\\\\\\\": y.name,\\\\n\\\",\\n-    \\\"    \\\\\\\"class_distribution\\\\\\\": y.value_counts().to_dict(),\\\\n\\\",\\n-    \\\"    \\\\\\\"missing_value_strategy\\\\\\\": \\\\\\\"None\\\\\\\",  # Update based on your strategy (e.g., imputation or dropping missing values)\\\\n\\\",\\n-    \\\"    \\\\\\\"scaling_encoding_steps\\\\\\\": \\\\\\\"None\\\\\\\",  # Update if any scaling or encoding is performed\\\\n\\\",\\n-    \\\"    \\\\\\\"data_split_method\\\\\\\": \\\\\\\"Train-test split (80-20)\\\\\\\",\\\\n\\\",\\n-    \\\"    \\\\\\\"data_random_seed\\\\\\\": 42,  # Random state for reproducibility\\\\n\\\",\\n-    \\\"    \\\\\\\"preprocessing_pipeline\\\\\\\": \\\\\\\"None\\\\\\\",  # Or provide a path or summary of preprocessing steps\\\\n\\\",\\n-    \\\"}\\\"\\n-   ]\\n-  },\\n-  {\\n-   \\\"cell_type\\\": \\\"code\\\",\\n-   \\\"execution_count\\\": 73,\\n-   \\\"id\\\": \\\"f47aa487-ab46-4032-b00f-4b8067a12066\\\",\\n-   \\\"metadata\\\": {},\\n-   \\\"outputs\\\": [\\n-    {\\n-     \\\"name\\\": \\\"stderr\\\",\\n-     \\\"output_type\\\": \\\"stream\\\",\\n-     \\\"text\\\": [\\n-      \\\"2025/04/14 22:10:03 INFO mlflow.tracking.fluent: Autologging successfully enabled for statsmodels.\\\\n\\\"\\n-     ]\\n-    },\\n-    {\\n-     \\\"name\\\": \\\"stdout\\\",\\n-     \\\"output_type\\\": \\\"stream\\\",\\n-     \\\"text\\\": [\\n-      \\\"Git commit: 8f07816bad4ec2acee3ef8dbb7370db46c6d172b\\\\n\\\",\\n-      \\\"Git commit: 8f07816bad4ec2acee3ef8dbb7370db46c6d172b\\\\n\\\",\\n-      \\\"Python version: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]\\\\n\\\",\\n-      \\\"Platform: Windows\\\\n\\\"\\n-     ]\\n-    }\\n-   ],\\n-   \\\"source\\\": [\\n-    \\\"# Capture Git commit hash\\\\n\\\",\\n-    \\\"repo_dir = \\\\\\\"C:/Users/reema/OneDrive/Dokumente/Provenance_tracking_thesis/Provenence-Tracking-Thesis-Research\\\\\\\"\\\\n\\\",\\n-    \\\"repo = git.Repo(repo_dir)\\\\n\\\",\\n-    \\\"commit_hash = repo.head.object.hexsha\\\\n\\\",\\n-    \\\"print(f\\\\\\\"Git commit: {commit_hash}\\\\\\\")\\\\n\\\",\\n-    \\\"# Log system information\\\\n\\\",\\n-    \\\"python_version = sys.version\\\\n\\\",\\n-    \\\"platform_info = platform.system()\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"print(f\\\\\\\"Git commit: {commit_hash}\\\\\\\")\\\\n\\\",\\n-    \\\"print(f\\\\\\\"Python version: {python_version}\\\\\\\")\\\\n\\\",\\n-    \\\"print(f\\\\\\\"Platform: {platform_info}\\\\\\\")\\\\n\\\",\\n-    \\\"# \\ud83e\\udde0 MLflow Autologging\\\\n\\\",\\n-    \\\"mlflow.autolog(log_input_examples=True, log_model_signatures=True)\\\"\\n-   ]\\n-  },\\n-  {\\n-   \\\"cell_type\\\": \\\"code\\\",\\n-   \\\"execution_count\\\": 74,\\n-   \\\"id\\\": \\\"b469604a-0b98-45ae-a52a-5a97a14a0657\\\",\\n-   \\\"metadata\\\": {},\\n-   \\\"outputs\\\": [\\n-    {\\n-     \\\"name\\\": \\\"stderr\\\",\\n-     \\\"output_type\\\": \\\"stream\\\",\\n-     \\\"text\\\": [\\n-      \\\"2025/04/14 22:10:03 INFO mlflow.tracking.fluent: Autologging successfully enabled for statsmodels.\\\\n\\\",\\n-      \\\"2025/04/14 22:10:05 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\\\\n\\\"\\n-     ]\\n-    },\\n-    {\\n-     \\\"name\\\": \\\"stdout\\\",\\n-     \\\"output_type\\\": \\\"stream\\\",\\n-     \\\"text\\\": [\\n-      \\\"Model 'RandomForest_IrisDataset_v1.0.0' already exists. Registering a new version...\\\\n\\\"\\n-     ]\\n-    },\\n-    {\\n-     \\\"name\\\": \\\"stderr\\\",\\n-     \\\"output_type\\\": \\\"stream\\\",\\n-     \\\"text\\\": [\\n-      \\\"2025/04/14 22:10:11 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\\\\n\\\",\\n-      \\\"Registered model 'RandomForest_IrisDataset_v1.0.0' already exists. Creating a new version of this model...\\\\n\\\",\\n-      \\\"Created version '7' of model 'RandomForest_IrisDataset_v1.0.0'.\\\\n\\\",\\n-      \\\"C:\\\\\\\\Users\\\\\\\\reema\\\\\\\\AppData\\\\\\\\Local\\\\\\\\Temp\\\\\\\\ipykernel_14504\\\\\\\\2059064886.py:38: FutureWarning: ``mlflow.tracking.client.MlflowClient.get_latest_versions`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages\\\\n\\\",\\n-      \\\"  model_versions = client.get_latest_versions(model_name)\\\\n\\\"\\n-     ]\\n-    },\\n-    {\\n-     \\\"name\\\": \\\"stdout\\\",\\n-     \\\"output_type\\\": \\\"stream\\\",\\n-     \\\"text\\\": [\\n-      \\\"\\u2705 Model logged and registered as: RandomForest_IrisDataset_v1.0.0, Version: 7\\\\n\\\"\\n-     ]\\n-    },\\n-    {\\n-     \\\"name\\\": \\\"stderr\\\",\\n-     \\\"output_type\\\": \\\"stream\\\",\\n-     \\\"text\\\": [\\n-      \\\"C:\\\\\\\\Users\\\\\\\\reema\\\\\\\\anaconda3\\\\\\\\Lib\\\\\\\\site-packages\\\\\\\\sklearn\\\\\\\\metrics\\\\\\\\_ranking.py:1132: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\\\\n\\\",\\n-      \\\"  warnings.warn(\\\\n\\\",\\n-      \\\"C:\\\\\\\\Users\\\\\\\\reema\\\\\\\\anaconda3\\\\\\\\Lib\\\\\\\\site-packages\\\\\\\\shap\\\\\\\\plots\\\\\\\\_beeswarm.py:1153: UserWarning: The figure layout has changed to tight\\\\n\\\",\\n-      \\\"  pl.tight_layout()\\\\n\\\",\\n-      \\\"C:\\\\\\\\Users\\\\\\\\reema\\\\\\\\anaconda3\\\\\\\\Lib\\\\\\\\site-packages\\\\\\\\shap\\\\\\\\plots\\\\\\\\_beeswarm.py:761: UserWarning: The figure layout has changed to tight\\\\n\\\",\\n-      \\\"  pl.tight_layout(pad=0, w_pad=0, h_pad=0.0)\\\\n\\\"\\n-     ]\\n-    },\\n-    {\\n-     \\\"name\\\": \\\"stdout\\\",\\n-     \\\"output_type\\\": \\\"stream\\\",\\n-     \\\"text\\\": [\\n-      \\\"Run logged with ID: 21017b4179494ef49706508240ab526e\\\\n\\\"\\n-     ]\\n-    },\\n-    {\\n-     \\\"data\\\": {\\n-      \\\"image/png\\\": \\\"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\\\",\\n-      \\\"text/plain\\\": [\\n-       \\\"<Figure size 600x600 with 2 Axes>\\\"\\n-      ]\\n-     },\\n-     \\\"metadata\\\": {},\\n-     \\\"output_type\\\": \\\"display_data\\\"\\n-    },\\n-    {\\n-     \\\"data\\\": {\\n-      \\\"text/plain\\\": [\\n-       \\\"<Figure size 640x480 with 0 Axes>\\\"\\n-      ]\\n-     },\\n-     \\\"metadata\\\": {},\\n-     \\\"output_type\\\": \\\"display_data\\\"\\n-    },\\n-    {\\n-     \\\"data\\\": {\\n-      \\\"image/png\\\": \\\"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\\\",\\n-      \\\"text/plain\\\": [\\n-       \\\"<Figure size 1150x660 with 1 Axes>\\\"\\n-      ]\\n-     },\\n-     \\\"metadata\\\": {},\\n-     \\\"output_type\\\": \\\"display_data\\\"\\n-    }\\n-   ],\\n-   \\\"source\\\": [\\n-    \\\"# \\ud83e\\udde0 MLflow Autologging Enabled\\\\n\\\",\\n-    \\\"mlflow.autolog(log_input_examples=True, log_model_signatures=True)\\\\n\\\",\\n-    \\\"# ============================\\\\n\\\",\\n-    \\\"# \\ud83d\\ude80 Start MLflow Run\\\\n\\\",\\n-    \\\"# ============================\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# \\u2705 Logging Dataset Metadata\\\\n\\\",\\n-    \\\"with mlflow.start_run() as run:\\\\n\\\",\\n-    \\\"    # Track system metrics manually\\\\n\\\",\\n-    \\\"    cpu_before = psutil.cpu_percent(interval=1)\\\\n\\\",\\n-    \\\"    mem_before = psutil.virtual_memory().percent\\\\n\\\",\\n-    \\\"    training_time_start = time.time()\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    # Log dataset metadata\\\\n\\\",\\n-    \\\"    mlflow.log_params(dataset_metadata)\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    # Define dynamic model name\\\\n\\\",\\n-    \\\"    model_name = f\\\\\\\"RandomForest_{dataset_metadata['dataset_name'].replace(' ', '')}_v{dataset_metadata['dataset_version']}\\\\\\\"\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    # Use the MLflow client to check if the model already exists\\\\n\\\",\\n-    \\\"    client = MlflowClient()\\\\n\\\",\\n-    \\\"    model_registered = False\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    for model in client.search_registered_models():\\\\n\\\",\\n-    \\\"        if model.name == model_name:\\\\n\\\",\\n-    \\\"            model_registered = True\\\\n\\\",\\n-    \\\"            break\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    # Register the model or update with a new version\\\\n\\\",\\n-    \\\"    if model_registered:\\\\n\\\",\\n-    \\\"        print(f\\\\\\\"Model '{model_name}' already exists. Registering a new version...\\\\\\\")\\\\n\\\",\\n-    \\\"        mlflow.sklearn.log_model(model, artifact_path=\\\\\\\"model\\\\\\\", registered_model_name=model_name)\\\\n\\\",\\n-    \\\"    else:\\\\n\\\",\\n-    \\\"        print(f\\\\\\\"Registering new model '{model_name}'...\\\\\\\")\\\\n\\\",\\n-    \\\"        mlflow.sklearn.log_model(model, artifact_path=\\\\\\\"model\\\\\\\", registered_model_name=model_name)\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    # Fetch the model version\\\\n\\\",\\n-    \\\"    model_versions = client.get_latest_versions(model_name)\\\\n\\\",\\n-    \\\"    latest_version = model_versions[0].version if model_versions else None\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    # Log the model version and other details\\\\n\\\",\\n-    \\\"    mlflow.log_param(\\\\\\\"model_name\\\\\\\", model_name)\\\\n\\\",\\n-    \\\"    mlflow.log_param(\\\\\\\"model_version\\\\\\\", latest_version)\\\\n\\\",\\n-    \\\"    mlflow.log_param(\\\\\\\"all_model_version\\\\\\\", model_versions)\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    print(f\\\\\\\"\\u2705 Model logged and registered as: {model_name}, Version: {latest_version}\\\\\\\")\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    # Save input data as CSV and log it\\\\n\\\",\\n-    \\\"    Xy = X.copy()\\\\n\\\",\\n-    \\\"    Xy[\\\\\\\"target\\\\\\\"] = y\\\\n\\\",\\n-    \\\"    data_path = \\\\\\\"iris_dataset.csv\\\\\\\"\\\\n\\\",\\n-    \\\"    Xy.to_csv(data_path, index=False)\\\\n\\\",\\n-    \\\"    mlflow.log_artifact(data_path, artifact_path=\\\\\\\"input_data\\\\\\\")\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    # Model training\\\\n\\\",\\n-    \\\"    try:\\\\n\\\",\\n-    \\\"        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\\\\n\\\",\\n-    \\\"        model = RandomForestClassifier(n_estimators=100, random_state=42)\\\\n\\\",\\n-    \\\"        model.fit(X_train, y_train)\\\\n\\\",\\n-    \\\"    except ValueError as e:\\\\n\\\",\\n-    \\\"        error_code = 1001  # Example error code\\\\n\\\",\\n-    \\\"        mlflow.log_param(\\\\\\\"error_code\\\\\\\", error_code)  # Log the error code\\\\n\\\",\\n-    \\\"        error_message = str(e)\\\\n\\\",\\n-    \\\"        mlflow.log_param(\\\\\\\"error_message\\\\\\\", error_message)  # Log the specific error message\\\\n\\\",\\n-    \\\"        with open(\\\\\\\"error_log.txt\\\\\\\", \\\\\\\"w\\\\\\\") as error_file:\\\\n\\\",\\n-    \\\"            error_file.write(f\\\\\\\"Error Code: {error_code}\\\\\\\\nError Message: {error_message}\\\\\\\")\\\\n\\\",\\n-    \\\"        mlflow.log_artifact(\\\\\\\"error_log.txt\\\\\\\")  # Log the error log file\\\\n\\\",\\n-    \\\"        print(f\\\\\\\"Error Code: {error_code}, Message: {error_message}\\\\\\\")\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    \\\\n\\\",\\n-    \\\"    training_time_end = time.time()\\\\n\\\",\\n-    \\\"    training_time = training_time_end - training_time_start\\\\n\\\",\\n-    \\\"    cpu_after = psutil.cpu_percent(interval=1)\\\\n\\\",\\n-    \\\"    mem_after = psutil.virtual_memory().percent\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    # Log base params\\\\n\\\",\\n-    \\\"    mlflow.log_params({\\\\n\\\",\\n-    \\\"        \\\\\\\"model_type\\\\\\\": type(model).__name__,\\\\n\\\",\\n-    \\\"        \\\\\\\"model_library\\\\\\\": \\\\\\\"scikit-learn\\\\\\\",\\\\n\\\",\\n-    \\\"        \\\\\\\"dataset_source\\\\\\\": \\\\\\\"DBrepo\\\\\\\",\\\\n\\\",\\n-    \\\"        \\\\\\\"training_time_start\\\\\\\": training_time_start,\\\\n\\\",\\n-    \\\"        \\\\\\\"training_time_end\\\\\\\": training_time_end\\\\n\\\",\\n-    \\\"    })\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    # Save model metadata\\\\n\\\",\\n-    \\\"    model_metadata = {\\\\n\\\",\\n-    \\\"        \\\\\\\"model_type\\\\\\\": \\\\\\\"RandomForestClassifier\\\\\\\",\\\\n\\\",\\n-    \\\"        \\\\\\\"commit_hash\\\\\\\": commit_hash,\\\\n\\\",\\n-    \\\"        \\\\\\\"experiment_id\\\\\\\": mlflow.active_run().info.experiment_id,\\\\n\\\",\\n-    \\\"        \\\\\\\"training_timestamp\\\\\\\": time.strftime(\\\\\\\"%Y-%m-%d %H:%M:%S\\\\\\\"),\\\\n\\\",\\n-    \\\"        \\\\\\\"training_error\\\\\\\": \\\\\\\"None\\\\\\\",\\\\n\\\",\\n-    \\\"        \\\\\\\"training_dataset_version\\\\\\\": \\\\\\\"1.0.0\\\\\\\",\\\\n\\\",\\n-    \\\"        \\\\\\\"testing_dataset_version\\\\\\\": \\\\\\\"1.0.0\\\\\\\",\\\\n\\\",\\n-    \\\"        \\\\\\\"python_version\\\\\\\": python_version,\\\\n\\\",\\n-    \\\"        \\\\\\\"platform\\\\\\\": platform_info\\\\n\\\",\\n-    \\\"    }\\\\n\\\",\\n-    \\\"    # Evaluation\\\\n\\\",\\n-    \\\"    y_pred = model.predict(X_test)\\\\n\\\",\\n-    \\\"    y_proba = model.predict_proba(X_test)\\\\n\\\",\\n-    \\\"    acc = accuracy_score(y_test, y_pred)\\\\n\\\",\\n-    \\\"    auc = roc_auc_score(y_test, y_proba, multi_class=\\\\\\\"ovr\\\\\\\")\\\\n\\\",\\n-    \\\"    mlflow.log_metrics({\\\\n\\\",\\n-    \\\"        \\\\\\\"accuracy\\\\\\\": acc,\\\\n\\\",\\n-    \\\"        \\\\\\\"roc_auc\\\\\\\": auc,\\\\n\\\",\\n-    \\\"        \\\\\\\"precision\\\\\\\": precision_score(y_test, y_pred, average='macro'),\\\\n\\\",\\n-    \\\"        \\\\\\\"recall\\\\\\\": recall_score(y_test, y_pred, average='macro'),\\\\n\\\",\\n-    \\\"        \\\\\\\"f1_score\\\\\\\": f1_score(y_test, y_pred, average='macro')\\\\n\\\",\\n-    \\\"    })\\\\n\\\",\\n-    \\\"    # Log full model hyperparameters\\\\n\\\",\\n-    \\\"    mlflow.log_params(model.get_params())\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    # Log metrics\\\\n\\\",\\n-    \\\"    mlflow.log_metrics({\\\\n\\\",\\n-    \\\"        \\\\\\\"cpu_before\\\\\\\": cpu_before,\\\\n\\\",\\n-    \\\"        \\\\\\\"cpu_after\\\\\\\": cpu_after,\\\\n\\\",\\n-    \\\"        \\\\\\\"mem_before\\\\\\\": mem_before,\\\\n\\\",\\n-    \\\"        \\\\\\\"mem_after\\\\\\\": mem_after,\\\\n\\\",\\n-    \\\"        \\\\\\\"training_duration_seconds\\\\\\\": training_time\\\\n\\\",\\n-    \\\"    })\\\\n\\\",\\n-    \\\"    mlflow.log_param(\\\\\\\"python_version\\\\\\\", python_version)\\\\n\\\",\\n-    \\\"    mlflow.log_param(\\\\\\\"platform\\\\\\\", platform_info)\\\\n\\\",\\n-    \\\"    mlflow.log_param(\\\\\\\"commit_hash\\\\\\\", commit_hash)\\\\n\\\",\\n-    \\\"    mlflow.log_param(\\\\\\\"training_timestamp\\\\\\\", time.strftime(\\\\\\\"%Y-%m-%d %H:%M:%S\\\\\\\"))\\\\n\\\",\\n-    \\\"    mlflow.log_param(\\\\\\\"training_error\\\\\\\", \\\\\\\"None\\\\\\\")\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    mlflow.log_params({\\\\n\\\",\\n-    \\\"        \\\\\\\"model\\\\\\\": \\\\\\\"RandomForestClassifier\\\\\\\",\\\\n\\\",\\n-    \\\"        \\\\\\\"n_estimators\\\\\\\": 100,\\\\n\\\",\\n-    \\\"        \\\\\\\"dataset_source\\\\\\\": \\\\\\\"DBrepo\\\\\\\"\\\\n\\\",\\n-    \\\"    })\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    # Confusion Matrix\\\\n\\\",\\n-    \\\"    confusion = confusion_matrix(y_test, y_pred)\\\\n\\\",\\n-    \\\"    plt.figure(figsize=(6, 6))\\\\n\\\",\\n-    \\\"    sns.heatmap(confusion, annot=True, fmt=\\\\\\\"d\\\\\\\", cmap=\\\\\\\"Blues\\\\\\\")\\\\n\\\",\\n-    \\\"    plt.title(\\\\\\\"Confusion Matrix\\\\\\\")\\\\n\\\",\\n-    \\\"    plt.xlabel(\\\\\\\"Predicted\\\\\\\")\\\\n\\\",\\n-    \\\"    plt.ylabel(\\\\\\\"Actual\\\\\\\")\\\\n\\\",\\n-    \\\"    cm_path = \\\\\\\"confusion_matrix.png\\\\\\\"\\\\n\\\",\\n-    \\\"    plt.savefig(cm_path)\\\\n\\\",\\n-    \\\"    mlflow.log_artifact(cm_path)\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    # ROC Curve\\\\n\\\",\\n-    \\\"    fpr, tpr, _ = roc_curve(y_test, y_proba[:, 1], pos_label=1)\\\\n\\\",\\n-    \\\"    plt.figure()\\\\n\\\",\\n-    \\\"    plt.plot(fpr, tpr, label=f\\\\\\\"ROC AUC = {auc:.2f}\\\\\\\")\\\\n\\\",\\n-    \\\"    plt.plot([0, 1], [0, 1], \\\\\\\"k--\\\\\\\")\\\\n\\\",\\n-    \\\"    plt.xlabel(\\\\\\\"False Positive Rate\\\\\\\")\\\\n\\\",\\n-    \\\"    plt.ylabel(\\\\\\\"True Positive Rate\\\\\\\")\\\\n\\\",\\n-    \\\"    plt.title(\\\\\\\"ROC Curve\\\\\\\")\\\\n\\\",\\n-    \\\"    roc_path = \\\\\\\"roc_curve.png\\\\\\\"\\\\n\\\",\\n-    \\\"    plt.savefig(roc_path)\\\\n\\\",\\n-    \\\"    mlflow.log_artifact(roc_path)\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    # SHAP values\\\\n\\\",\\n-    \\\"    explainer = shap.TreeExplainer(model)\\\\n\\\",\\n-    \\\"    shap_values = explainer.shap_values(X_test)\\\\n\\\",\\n-    \\\"    shap.summary_plot(shap_values, X_test, show=False)\\\\n\\\",\\n-    \\\"    shap_path = \\\\\\\"shap_summary.png\\\\\\\"\\\\n\\\",\\n-    \\\"    plt.savefig(shap_path)\\\\n\\\",\\n-    \\\"    mlflow.log_artifact(shap_path)\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    # Feature importance\\\\n\\\",\\n-    \\\"    feat_imp = pd.DataFrame({\\\\n\\\",\\n-    \\\"        \\\\\\\"Feature\\\\\\\": X.columns,\\\\n\\\",\\n-    \\\"        \\\\\\\"Importance\\\\\\\": model.feature_importances_\\\\n\\\",\\n-    \\\"    }).sort_values(by=\\\\\\\"Importance\\\\\\\", ascending=False)\\\\n\\\",\\n-    \\\"    feat_path = \\\\\\\"feature_importance.csv\\\\\\\"\\\\n\\\",\\n-    \\\"    feat_imp.to_csv(feat_path, index=False)\\\\n\\\",\\n-    \\\"    mlflow.log_artifact(feat_path)\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    # Save and log dataset as artifact\\\\n\\\",\\n-    \\\"    Xy = X.copy()\\\\n\\\",\\n-    \\\"    Xy[\\\\\\\"target\\\\\\\"] = y\\\\n\\\",\\n-    \\\"    data_path = \\\\\\\"iris_dataset.csv\\\\\\\"\\\\n\\\",\\n-    \\\"    Xy.to_csv(data_path, index=False)\\\\n\\\",\\n-    \\\"    mlflow.log_artifact(data_path, artifact_path=\\\\\\\"input_data\\\\\\\")\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    # Log input and output schema\\\\n\\\",\\n-    \\\"    input_schema = X.dtypes.astype(str).to_dict()\\\\n\\\",\\n-    \\\"    with open(\\\\\\\"input_schema.json\\\\\\\", \\\\\\\"w\\\\\\\") as f:\\\\n\\\",\\n-    \\\"        json.dump(input_schema, f)\\\\n\\\",\\n-    \\\"    mlflow.log_artifact(\\\\\\\"input_schema.json\\\\\\\")\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    output_schema = {\\\\n\\\",\\n-    \\\"        \\\\\\\"output_type\\\\\\\": str(type(y_pred[0])),\\\\n\\\",\\n-    \\\"        \\\\\\\"classes\\\\\\\": model.classes_.tolist()\\\\n\\\",\\n-    \\\"    }\\\\n\\\",\\n-    \\\"    with open(\\\\\\\"output_schema.json\\\\\\\", \\\\\\\"w\\\\\\\") as f:\\\\n\\\",\\n-    \\\"        json.dump(output_schema, f)\\\\n\\\",\\n-    \\\"    mlflow.log_artifact(\\\\\\\"output_schema.json\\\\\\\")\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    # Git commit and push after successful run\\\\n\\\",\\n-    \\\"    repo.git.add(A=True)  # Add all changes to git\\\\n\\\",\\n-    \\\"    repo.index.commit(f\\\\\\\"Model training and logging complete: {commit_hash}\\\\\\\")\\\\n\\\",\\n-    \\\"    repo.remotes.origin.push()  # Push to the remote repository\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    # Log model version and Git commit after successful run\\\\n\\\",\\n-    \\\"    model_uri = f\\\\\\\"runs:/{run.info.run_id}/random_forest_model\\\\\\\"\\\\n\\\",\\n-    \\\"    print(f\\\\\\\"Run logged with ID: {run.info.run_id}\\\\\\\")\\\\n\\\",\\n-    \\\"    mlflow.end_run()\\\"\\n-   ]\\n-  },\\n-  {\\n-   \\\"cell_type\\\": \\\"code\\\",\\n-   \\\"execution_count\\\": 78,\\n-   \\\"id\\\": \\\"2526ebe3-18f0-4951-a553-05a21d96db12\\\",\\n-   \\\"metadata\\\": {},\\n-   \\\"outputs\\\": [\\n-    {\\n-     \\\"name\\\": \\\"stdout\\\",\\n-     \\\"output_type\\\": \\\"stream\\\",\\n-     \\\"text\\\": [\\n-      \\\"Forked by: reemagdass - https://github.com/reemagdass/Provenence-Tracking-Thesis-Research\\\\n\\\"\\n-     ]\\n-    }\\n-   ],\\n-   \\\"source\\\": [\\n-    \\\"import requests\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# GitHub repository details\\\\n\\\",\\n-    \\\"owner = \\\\\\\"reema-dass26\\\\\\\"\\\\n\\\",\\n-    \\\"repo = \\\\\\\"Provenence-Tracking-Thesis-Research\\\\\\\"\\\\n\\\",\\n-    \\\"token = \\\\\\\"REMOVED_SECRET\\\\\\\"  # A GitHub token with read access to public repositories\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# GitHub API URL to get forks\\\\n\\\",\\n-    \\\"url = f\\\\\\\"https://api.github.com/repos/{owner}/{repo}/forks\\\\\\\"\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# Set headers with authorization token\\\\n\\\",\\n-    \\\"headers = {\\\\n\\\",\\n-    \\\"    \\\\\\\"Authorization\\\\\\\": f\\\\\\\"token {token}\\\\\\\"\\\\n\\\",\\n-    \\\"}\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# Make the GET request to fetch the forks\\\\n\\\",\\n-    \\\"response = requests.get(url, headers=headers)\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# Check if the request was successful\\\\n\\\",\\n-    \\\"if response.status_code == 200:\\\\n\\\",\\n-    \\\"    forks = response.json()\\\\n\\\",\\n-    \\\"    for fork in forks:\\\\n\\\",\\n-    \\\"        print(f\\\\\\\"Forked by: {fork['owner']['login']} - {fork['html_url']}\\\\\\\")\\\\n\\\",\\n-    \\\"else:\\\\n\\\",\\n-    \\\"    print(f\\\\\\\"Failed to fetch forks: {response.status_code}\\\\\\\")\\\\n\\\"\\n-   ]\\n-  },\\n-  {\\n-   \\\"cell_type\\\": \\\"code\\\",\\n-   \\\"execution_count\\\": 82,\\n-   \\\"id\\\": \\\"d4623d09-6e7f-4246-a6e5-18ba9ef387ed\\\",\\n-   \\\"metadata\\\": {},\\n-   \\\"outputs\\\": [\\n-    {\\n-     \\\"name\\\": \\\"stdout\\\",\\n-     \\\"output_type\\\": \\\"stream\\\",\\n-     \\\"text\\\": [\\n-      \\\"Forked by: reemagdass - https://github.com/reemagdass/Provenence-Tracking-Thesis-Research\\\\n\\\",\\n-      \\\"\\u274c Failed to create issue for @reemagdass: 404 - {\\\\\\\"message\\\\\\\":\\\\\\\"Not Found\\\\\\\",\\\\\\\"documentation_url\\\\\\\":\\\\\\\"https://docs.github.com/rest/issues/issues#create-an-issue\\\\\\\",\\\\\\\"status\\\\\\\":\\\\\\\"404\\\\\\\"}\\\\n\\\"\\n-     ]\\n-    }\\n-   ],\\n-   \\\"source\\\": [\\n-    \\\"# import requests\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# # GitHub repository details\\\\n\\\",\\n-    \\\"# owner = \\\\\\\"reema-dass26\\\\\\\"\\\\n\\\",\\n-    \\\"# repo = \\\\\\\"Provenence-Tracking-Thesis-Research\\\\\\\"\\\\n\\\",\\n-    \\\"# token = \\\\\\\"REMOVED_SECRET\\\\\\\"  # GitHub token with 'repo' or 'public_repo' scope\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# # Headers for authentication\\\\n\\\",\\n-    \\\"# headers = {\\\\n\\\",\\n-    \\\"#     \\\\\\\"Authorization\\\\\\\": f\\\\\\\"token {token}\\\\\\\",\\\\n\\\",\\n-    \\\"#     \\\\\\\"Accept\\\\\\\": \\\\\\\"application/vnd.github.v3+json\\\\\\\"\\\\n\\\",\\n-    \\\"# }\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# # Step 1: Get all forks of the repo\\\\n\\\",\\n-    \\\"# forks_url = f\\\\\\\"https://api.github.com/repos/{owner}/{repo}/forks\\\\\\\"\\\\n\\\",\\n-    \\\"# response = requests.get(forks_url, headers=headers)\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# if response.status_code == 200:\\\\n\\\",\\n-    \\\"#     forks = response.json()\\\\n\\\",\\n-    \\\"    \\\\n\\\",\\n-    \\\"#     for fork in forks:\\\\n\\\",\\n-    \\\"#         forked_by = fork['owner']['login']\\\\n\\\",\\n-    \\\"#         fork_url = fork['html_url']\\\\n\\\",\\n-    \\\"#         print(f\\\\\\\"Forked by: {forked_by} - {fork_url}\\\\\\\")\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"#         # Step 2: Create an issue in the original repo to notify the forker\\\\n\\\",\\n-    \\\"#         issue_url = f\\\\\\\"https://api.github.com/repos/{owner}/{repo}/issues\\\\\\\"\\\\n\\\",\\n-    \\\"#         issue_data = {\\\\n\\\",\\n-    \\\"#             \\\\\\\"title\\\\\\\": f\\\\\\\"Repository Update Notification for @{forked_by}\\\\\\\",\\\\n\\\",\\n-    \\\"#             \\\\\\\"body\\\\\\\": (\\\\n\\\",\\n-    \\\"#                 f\\\\\\\"Hi @{forked_by},\\\\\\\\n\\\\\\\\n\\\\\\\"\\\\n\\\",\\n-    \\\"#                 \\\\\\\"We noticed you have forked this repository. \\\\\\\"\\\\n\\\",\\n-    \\\"#                 \\\\\\\"Just wanted to notify you that there have been recent updates. \\\\\\\"\\\\n\\\",\\n-    \\\"#                 \\\\\\\"Please pull the latest changes to stay up to date.\\\\\\\\n\\\\\\\\n\\\\\\\"\\\\n\\\",\\n-    \\\"#                 \\\\\\\"Let us know if you face any issues! \\ud83d\\ude0a\\\\\\\"\\\\n\\\",\\n-    \\\"#             )\\\\n\\\",\\n-    \\\"#         }\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"#         issue_response = requests.post(issue_url, headers=headers, json=issue_data)\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"#         if issue_response.status_code == 201:\\\\n\\\",\\n-    \\\"#             print(f\\\\\\\"\\u2705 Issue successfully created to notify @{forked_by}\\\\\\\")\\\\n\\\",\\n-    \\\"#         else:\\\\n\\\",\\n-    \\\"#             print(f\\\\\\\"\\u274c Failed to create issue for @{forked_by}: {issue_response.status_code} - {issue_response.text}\\\\\\\")\\\\n\\\",\\n-    \\\"# else:\\\\n\\\",\\n-    \\\"#     print(f\\\\\\\"\\u274c Failed to fetch forks: {response.status_code} - {response.text}\\\\\\\")\\\\n\\\"\\n-   ]\\n-  },\\n-  {\\n-   \\\"cell_type\\\": \\\"code\\\",\\n-   \\\"execution_count\\\": 84,\\n-   \\\"id\\\": \\\"c1732bfb-b3b3-4ce7-b793-981046700624\\\",\\n-   \\\"metadata\\\": {},\\n-   \\\"outputs\\\": [\\n-    {\\n-     \\\"name\\\": \\\"stdout\\\",\\n-     \\\"output_type\\\": \\\"stream\\\",\\n-     \\\"text\\\": [\\n-      \\\"404\\\\n\\\",\\n-      \\\"{'message': 'Not Found', 'documentation_url': 'https://docs.github.com/rest/issues/issues#create-an-issue', 'status': '404'}\\\\n\\\"\\n-     ]\\n-    }\\n-   ],\\n-   \\\"source\\\": [\\n-    \\\"# import requests\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# # Basic test issue creation\\\\n\\\",\\n-    \\\"# owner = \\\\\\\"reema-dass26\\\\\\\"\\\\n\\\",\\n-    \\\"# repo = \\\\\\\"Provenence-Tracking-Thesis-Research\\\\\\\"\\\\n\\\",\\n-    \\\"# token = \\\\\\\"REMOVED_SECRET\\\\\\\"\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# headers = {\\\\n\\\",\\n-    \\\"#     \\\\\\\"Authorization\\\\\\\": f\\\\\\\"token {token}\\\\\\\",\\\\n\\\",\\n-    \\\"#     \\\\\\\"Accept\\\\\\\": \\\\\\\"application/vnd.github.v3+json\\\\\\\"\\\\n\\\",\\n-    \\\"# }\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# url = f\\\\\\\"https://api.github.com/repos/{owner}/{repo}/issues\\\\\\\"\\\\n\\\",\\n-    \\\"# data = {\\\\n\\\",\\n-    \\\"#     \\\\\\\"title\\\\\\\": \\\\\\\"Test Issue from Script\\\\\\\",\\\\n\\\",\\n-    \\\"#     \\\\\\\"body\\\\\\\": \\\\\\\"This is a test issue to check access permissions.\\\\\\\"\\\\n\\\",\\n-    \\\"# }\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# response = requests.post(url, headers=headers, json=data)\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# print(response.status_code)\\\\n\\\",\\n-    \\\"# print(response.json())\\\\n\\\"\\n-   ]\\n-  },\\n-  {\\n-   \\\"cell_type\\\": \\\"code\\\",\\n-   \\\"execution_count\\\": 92,\\n-   \\\"id\\\": \\\"98db1e21-5646-4aed-b686-7c57e6b709fa\\\",\\n-   \\\"metadata\\\": {},\\n-   \\\"outputs\\\": [\\n-    {\\n-     \\\"name\\\": \\\"stdout\\\",\\n-     \\\"output_type\\\": \\\"stream\\\",\\n-     \\\"text\\\": [\\n-      \\\"\\u274c Failed to create issue: 404 - {\\\\\\\"message\\\\\\\":\\\\\\\"Not Found\\\\\\\",\\\\\\\"documentation_url\\\\\\\":\\\\\\\"https://docs.github.com/rest/issues/issues#create-an-issue\\\\\\\",\\\\\\\"status\\\\\\\":\\\\\\\"404\\\\\\\"}\\\\n\\\"\\n-     ]\\n-    }\\n-   ],\\n-   \\\"source\\\": [\\n-    \\\"# import requests\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# # GitHub authentication\\\\n\\\",\\n-    \\\"# token = \\\\\\\"REMOVED_SECRET\\\\\\\"\\\\n\\\",\\n-    \\\"# owner = \\\\\\\"reema-dass26\\\\\\\"\\\\n\\\",\\n-    \\\"# repo = \\\\\\\"Provenence-Tracking-Thesis-Research\\\\\\\"\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# # Headers for authentication\\\\n\\\",\\n-    \\\"# headers = {\\\\n\\\",\\n-    \\\"#     \\\\\\\"Authorization\\\\\\\": f\\\\\\\"token {token}\\\\\\\",\\\\n\\\",\\n-    \\\"#     \\\\\\\"Accept\\\\\\\": \\\\\\\"application/vnd.github+json\\\\\\\"\\\\n\\\",\\n-    \\\"# }\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# # Step 1: Fetch all forks\\\\n\\\",\\n-    \\\"# forks_url = f\\\\\\\"https://api.github.com/repos/{owner}/{repo}/forks\\\\\\\"\\\\n\\\",\\n-    \\\"# response = requests.get(forks_url, headers=headers)\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# if response.status_code == 200:\\\\n\\\",\\n-    \\\"#     forks = response.json()\\\\n\\\",\\n-    \\\"#     usernames = [f\\\\\\\"@{fork['owner']['login']}\\\\\\\" for fork in forks]\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"#     if not usernames:\\\\n\\\",\\n-    \\\"#         print(\\\\\\\"No forks found.\\\\\\\")\\\\n\\\",\\n-    \\\"#     else:\\\\n\\\",\\n-    \\\"#         mention_line = \\\\\\\", \\\\\\\".join(usernames)\\\\n\\\",\\n-    \\\"#         title = \\\\\\\"\\ud83d\\udd14 Repository Update Notification\\\\\\\"\\\\n\\\",\\n-    \\\"#         body = f\\\\\\\"Hi {mention_line},\\\\\\\\n\\\\\\\\nThere have been some updates or changes to the main repository. Please pull the latest changes or check if any part is broken.\\\\\\\\n\\\\\\\\nThanks for contributing! \\u2764\\ufe0f\\\\\\\"\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"#         # Step 2: Create an issue on your repo with mentions\\\\n\\\",\\n-    \\\"#         issues_url = f\\\\\\\"https://api.github.com/repos/{owner}/{repo}/issues\\\\\\\"\\\\n\\\",\\n-    \\\"#         issue_data = {\\\\n\\\",\\n-    \\\"#             \\\\\\\"title\\\\\\\": title,\\\\n\\\",\\n-    \\\"#             \\\\\\\"body\\\\\\\": body,\\\\n\\\",\\n-    \\\"#         }\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"#         create_issue = requests.post(issues_url, headers=headers, json=issue_data)\\\\n\\\",\\n-    \\\"#         if create_issue.status_code == 201:\\\\n\\\",\\n-    \\\"#             print(\\\\\\\"\\u2705 Issue created successfully and users notified!\\\\\\\")\\\\n\\\",\\n-    \\\"#         else:\\\\n\\\",\\n-    \\\"#             print(f\\\\\\\"\\u274c Failed to create issue: {create_issue.status_code} - {create_issue.text}\\\\\\\")\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# else:\\\\n\\\",\\n-    \\\"#     print(f\\\\\\\"\\u274c Failed to fetch forks: {response.status_code} - {response.text}\\\\\\\")\\\\n\\\"\\n-   ]\\n-  },\\n-  {\\n-   \\\"cell_type\\\": \\\"code\\\",\\n-   \\\"execution_count\\\": 97,\\n-   \\\"id\\\": \\\"782b6dee-7d02-46bc-a092-0c75d854572e\\\",\\n-   \\\"metadata\\\": {},\\n-   \\\"outputs\\\": [\\n-    {\\n-     \\\"name\\\": \\\"stdout\\\",\\n-     \\\"output_type\\\": \\\"stream\\\",\\n-     \\\"text\\\": [\\n-      \\\"Could not create Issue \\\\\\\"Issue Title\\\\\\\"\\\\n\\\",\\n-      \\\"Response: b'{\\\\\\\"message\\\\\\\":\\\\\\\"Not Found\\\\\\\",\\\\\\\"documentation_url\\\\\\\":\\\\\\\"https://docs.github.com/rest/issues/issues#create-an-issue\\\\\\\",\\\\\\\"status\\\\\\\":\\\\\\\"404\\\\\\\"}'\\\\n\\\"\\n-     ]\\n-    }\\n-   ],\\n-   \\\"source\\\": [\\n-    \\\"# import requests\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# # Authentication for user filing issue (must have read/write access to\\\\n\\\",\\n-    \\\"# # repository to add issue to)\\\\n\\\",\\n-    \\\"# TOKEN = 'REMOVED_SECRET'  # Use your GitHub Personal Access Token\\\\n\\\",\\n-    \\\"# USERNAME = 'reema-dass26'\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# # The repository to add this issue to\\\\n\\\",\\n-    \\\"# REPO_OWNER = 'reema-dass26'  # Your GitHub username or organization\\\\n\\\",\\n-    \\\"# REPO_NAME = 'Provenence-Tracking-Thesis-Research'  # Your repository name\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# def make_github_issue(title, body=None, assignee=None, milestone=None, labels=None):\\\\n\\\",\\n-    \\\"#     '''Create an issue on github.com using the given parameters.'''\\\\n\\\",\\n-    \\\"#     # URL to create issues via POST\\\\n\\\",\\n-    \\\"#     url = f'https://api.github.com/repos/{REPO_OWNER}/{REPO_NAME}/issues'\\\\n\\\",\\n-    \\\"    \\\\n\\\",\\n-    \\\"#     # Create the headers including the token for authentication\\\\n\\\",\\n-    \\\"#     headers = {\\\\n\\\",\\n-    \\\"#         'Authorization': f'token {TOKEN}',\\\\n\\\",\\n-    \\\"#         'Accept': 'application/vnd.github+json'\\\\n\\\",\\n-    \\\"#     }\\\\n\\\",\\n-    \\\"    \\\\n\\\",\\n-    \\\"#     # Create our issue\\\\n\\\",\\n-    \\\"#     issue = {\\\\n\\\",\\n-    \\\"#         'title': title,\\\\n\\\",\\n-    \\\"#         'body': body,\\\\n\\\",\\n-    \\\"#         'assignee': assignee,\\\\n\\\",\\n-    \\\"#         'milestone': milestone,\\\\n\\\",\\n-    \\\"#         'labels': labels\\\\n\\\",\\n-    \\\"#     }\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"#     # Add the issue to our repository\\\\n\\\",\\n-    \\\"#     r = requests.post(url, headers=headers, json=issue)\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"#     # Check if the request was successful\\\\n\\\",\\n-    \\\"#     if r.status_code == 201:\\\\n\\\",\\n-    \\\"#         print(f'Successfully created Issue \\\\\\\"{title}\\\\\\\"')\\\\n\\\",\\n-    \\\"#     else:\\\\n\\\",\\n-    \\\"#         print(f'Could not create Issue \\\\\\\"{title}\\\\\\\"')\\\\n\\\",\\n-    \\\"#         print('Response:', r.content)\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# # Example usage\\\\n\\\",\\n-    \\\"# make_github_issue('Issue Title', 'Body text', 'assigned_user', 3, ['bug'])\\\\n\\\"\\n-   ]\\n-  },\\n-  {\\n-   \\\"cell_type\\\": \\\"code\\\",\\n-   \\\"execution_count\\\": null,\\n-   \\\"id\\\": \\\"43d84ba7-bf8a-4a8a-a797-de01d1aec67a\\\",\\n-   \\\"metadata\\\": {},\\n-   \\\"outputs\\\": [],\\n-   \\\"source\\\": [\\n-    \\\"#     # Track system metrics manually\\\\n\\\",\\n-    \\\"#     cpu_before = psutil.cpu_percent(interval=1)\\\\n\\\",\\n-    \\\"#     mem_before = psutil.virtual_memory().percent\\\\n\\\",\\n-    \\\"#     training_time_start  = time.time()\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"#     # Log dataset metadata\\\\n\\\",\\n-    \\\"#     mlflow.log_params(dataset_metadata)\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"#      # Define dynamic model name\\\\n\\\",\\n-    \\\"#     model_name = f\\\\\\\"RandomForest_{dataset_metadata['dataset_name'].replace(' ', '')}_v{dataset_metadata['dataset_version']}\\\\\\\"\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"#     # Use the MLflow client to check if the model already exists\\\\n\\\",\\n-    \\\"#     client = MlflowClient()\\\\n\\\",\\n-    \\\"#      # Check if model already exists\\\\n\\\",\\n-    \\\"#     existing_models = client.search_registered_models()\\\\n\\\",\\n-    \\\"#     model_registered = False\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"#     for model in existing_models:\\\\n\\\",\\n-    \\\"#         if model.name == model_name:\\\\n\\\",\\n-    \\\"#             model_registered = True\\\\n\\\",\\n-    \\\"#             break\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"#     # Register the model or update with a new version\\\\n\\\",\\n-    \\\"#     if model_registered:\\\\n\\\",\\n-    \\\"#         print(f\\\\\\\"Model '{model_name}' already exists. Registering a new version...\\\\\\\")\\\\n\\\",\\n-    \\\"#         mlflow.sklearn.log_model(\\\\n\\\",\\n-    \\\"#             sk_model=model,\\\\n\\\",\\n-    \\\"#             artifact_path=\\\\\\\"model\\\\\\\",\\\\n\\\",\\n-    \\\"#             registered_model_name=model_name\\\\n\\\",\\n-    \\\"#         )\\\\n\\\",\\n-    \\\"#     else:\\\\n\\\",\\n-    \\\"#         print(f\\\\\\\"Registering new model '{model_name}'...\\\\\\\")\\\\n\\\",\\n-    \\\"#         mlflow.sklearn.log_model(\\\\n\\\",\\n-    \\\"#             sk_model=model,\\\\n\\\",\\n-    \\\"#             artifact_path=\\\\\\\"model\\\\\\\",\\\\n\\\",\\n-    \\\"#             registered_model_name=model_name\\\\n\\\",\\n-    \\\"#         )\\\\n\\\",\\n-    \\\"#          # Fetch the model version after logging it\\\\n\\\",\\n-    \\\"#     model_versions = client.get_latest_versions(model_name)\\\\n\\\",\\n-    \\\"#     latest_version = model_versions[0].version if model_versions else None\\\\n\\\",\\n-    \\\"#     mlflow.log_param(\\\\\\\"model_name\\\\\\\", model_name)  \\\\n\\\",\\n-    \\\"#     mlflow.log_param(\\\\\\\"model_version\\\\\\\", latest_version)\\\\n\\\",\\n-    \\\"#     mlflow.log_param(\\\\\\\"all_model_version\\\\\\\", model_versions)  \\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"#     print(f\\\\\\\"\\u2705 Model logged and registered as: {model_name}, Version: {latest_version}\\\\\\\")\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"#     print(f\\\\\\\"\\u2705 Model logged and registered as: {model_name}\\\\\\\")\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"#     # Save input data as CSV and log it\\\\n\\\",\\n-    \\\"#     Xy = X.copy()\\\\n\\\",\\n-    \\\"#     Xy[\\\\\\\"target\\\\\\\"] = y\\\\n\\\",\\n-    \\\"#     data_path = \\\\\\\"iris_dataset.csv\\\\\\\"\\\\n\\\",\\n-    \\\"#     Xy.to_csv(data_path, index=False)\\\\n\\\",\\n-    \\\"#     mlflow.log_artifact(data_path, artifact_path=\\\\\\\"input_data\\\\\\\")\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"#    # Model training\\\\n\\\",\\n-    \\\"#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\\\\n\\\",\\n-    \\\"#     model = RandomForestClassifier(n_estimators=100, random_state=42)\\\\n\\\",\\n-    \\\"#     model.fit(X_train, y_train)\\\\n\\\",\\n-    \\\"    \\\\n\\\",\\n-    \\\"#     training_time_end = time.time()\\\\n\\\",\\n-    \\\"#     training_time = training_time_end - training_time_start\\\\n\\\",\\n-    \\\"#     cpu_after = psutil.cpu_percent(interval=1)\\\\n\\\",\\n-    \\\"#     mem_after = psutil.virtual_memory().percent\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    \\\\n\\\",\\n-    \\\"#      # Log base params\\\\n\\\",\\n-    \\\"#     mlflow.log_params({\\\\n\\\",\\n-    \\\"#         \\\\\\\"model_type\\\\\\\": type(model).__name__,\\\\n\\\",\\n-    \\\"#         \\\\\\\"model_library\\\\\\\": \\\\\\\"scikit-learn\\\\\\\",\\\\n\\\",\\n-    \\\"#         \\\\\\\"dataset_source\\\\\\\": \\\\\\\"DBrepo\\\\\\\",\\\\n\\\",\\n-    \\\"#         \\\\\\\"training_time_start\\\\\\\": training_time_start,\\\\n\\\",\\n-    \\\"#         \\\\\\\"training_time_end\\\\\\\": training_time_end\\\\n\\\",\\n-    \\\"#     })\\\\n\\\",\\n-    \\\"#       # Save the model metadata \\ud83d\\udc48 **New**\\\\n\\\",\\n-    \\\"#     model_metadata = {\\\\n\\\",\\n-    \\\"#         \\\\\\\"model_type\\\\\\\": \\\\\\\"RandomForestClassifier\\\\\\\",\\\\n\\\",\\n-    \\\"#         \\\\\\\"commit_hash\\\\\\\": commit_hash,\\\\n\\\",\\n-    \\\"#         \\\\\\\"experiment_id\\\\\\\": mlflow.active_run().info.experiment_id,\\\\n\\\",\\n-    \\\"#         \\\\\\\"training_timestamp\\\\\\\": time.strftime(\\\\\\\"%Y-%m-%d %H:%M:%S\\\\\\\"),\\\\n\\\",\\n-    \\\"#         \\\\\\\"training_error\\\\\\\": \\\\\\\"None\\\\\\\",\\\\n\\\",\\n-    \\\"#         \\\\\\\"training_dataset_version\\\\\\\": \\\\\\\"1.0.0\\\\\\\",\\\\n\\\",\\n-    \\\"#         \\\\\\\"testing_dataset_version\\\\\\\": \\\\\\\"1.0.0\\\\\\\",\\\\n\\\",\\n-    \\\"#         \\\\\\\"python_version\\\\\\\": python_version,\\\\n\\\",\\n-    \\\"#         \\\\\\\"platform\\\\\\\": platform_info\\\\n\\\",\\n-    \\\"#     }\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"#      # Log full model hyperparameters\\\\n\\\",\\n-    \\\"#     mlflow.log_params(model.get_params())\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"#     # Log metrics\\\\n\\\",\\n-    \\\"#     mlflow.log_metrics({\\\\n\\\",\\n-    \\\"#         \\\\\\\"cpu_before\\\\\\\": cpu_before,\\\\n\\\",\\n-    \\\"#         \\\\\\\"cpu_after\\\\\\\": cpu_after,\\\\n\\\",\\n-    \\\"#         \\\\\\\"mem_before\\\\\\\": mem_before,\\\\n\\\",\\n-    \\\"#         \\\\\\\"mem_after\\\\\\\": mem_after,\\\\n\\\",\\n-    \\\"#         \\\\\\\"training_duration_seconds\\\\\\\": training_time\\\\n\\\",\\n-    \\\"#     })\\\\n\\\",\\n-    \\\"#     # Log environment details \\ud83d\\udc48 **New**\\\\n\\\",\\n-    \\\"#     mlflow.log_param(\\\\\\\"python_version\\\\\\\", python_version)\\\\n\\\",\\n-    \\\"#     mlflow.log_param(\\\\\\\"platform\\\\\\\", platform_info)\\\\n\\\",\\n-    \\\"#     mlflow.log_param(\\\\\\\"commit_hash\\\\\\\", commit_hash)\\\\n\\\",\\n-    \\\"#     # Log the training timestamp \\ud83d\\udc48 **New**\\\\n\\\",\\n-    \\\"#     mlflow.log_param(\\\\\\\"training_timestamp\\\\\\\", time.strftime(\\\\\\\"%Y-%m-%d %H:%M:%S\\\\\\\"))\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"#     # Log error tracking (e.g., error messages during training, testing, or inference) \\ud83d\\udc48 **New**\\\\n\\\",\\n-    \\\"#     mlflow.log_param(\\\\\\\"training_error\\\\\\\", \\\\\\\"None\\\\\\\")  # Update if any errors are caught during training or inference\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"#     # Notify about deprecated dataset versions (implement a notification system if needed) \\ud83d\\udc48 **New**\\\\n\\\",\\n-    \\\"#     if \\\\\\\"deprecated_version\\\\\\\" in mlflow.params:\\\\n\\\",\\n-    \\\"#         mlflow.log_param(\\\\\\\"deprecated_version\\\\\\\", \\\\\\\"1.0.0\\\\\\\")  # This could be dynamically checked\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"#     # Log input features\\\\n\\\",\\n-    \\\"#     mlflow.log_param(\\\\\\\"model_input_features\\\\\\\", list(X.columns))\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"#     # Log script path\\\\n\\\",\\n-    \\\"#     mlflow.log_param(\\\\\\\"training_script_path\\\\\\\", \\\\\\\"RQ1.ipynb\\\\\\\")  # or use __file__ if script\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"#       # Log Python, OS, and libraries\\\\n\\\",\\n-    \\\"#     mlflow.log_params({\\\\n\\\",\\n-    \\\"#         \\\\\\\"python_version\\\\\\\": platform.python_version(),\\\\n\\\",\\n-    \\\"#         \\\\\\\"os_platform\\\\\\\": f\\\\\\\"{platform.system()} {platform.release()}\\\\\\\",\\\\n\\\",\\n-    \\\"#         \\\\\\\"sklearn_version\\\\\\\": sklearn.__version__,\\\\n\\\",\\n-    \\\"#         \\\\\\\"pandas_version\\\\\\\": pd.__version__,\\\\n\\\",\\n-    \\\"#         \\\\\\\"numpy_version\\\\\\\": np.__version__,\\\\n\\\",\\n-    \\\"#         \\\\\\\"matplotlib_version\\\\\\\": matplotlib.__version__,\\\\n\\\",\\n-    \\\"#         \\\\\\\"seaborn_version\\\\\\\": seaborn.__version__,\\\\n\\\",\\n-    \\\"#         \\\\\\\"virtual_env\\\\\\\": os.environ.get(\\\\\\\"VIRTUAL_ENV\\\\\\\") or os.environ.get(\\\\\\\"CONDA_DEFAULT_ENV\\\\\\\", \\\\\\\"not_detected\\\\\\\")\\\\n\\\",\\n-    \\\"#     })\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"#      # Log model\\\\n\\\",\\n-    \\\"#     mlflow.sklearn.log_model(model, \\\\\\\"random_forest_model\\\\\\\")\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"#     # Evaluation\\\\n\\\",\\n-    \\\"#     y_pred = model.predict(X_test)\\\\n\\\",\\n-    \\\"#     y_proba = model.predict_proba(X_test)\\\\n\\\",\\n-    \\\"#     acc = accuracy_score(y_test, y_pred)\\\\n\\\",\\n-    \\\"#     auc = roc_auc_score(y_test, y_proba, multi_class=\\\\\\\"ovr\\\\\\\")\\\\n\\\",\\n-    \\\"#     mlflow.log_metrics({\\\\n\\\",\\n-    \\\"#         \\\\\\\"accuracy\\\\\\\": acc,\\\\n\\\",\\n-    \\\"#         \\\\\\\"roc_auc\\\\\\\": auc,\\\\n\\\",\\n-    \\\"#         \\\\\\\"precision\\\\\\\": precision_score(y_test, y_pred, average='macro'),\\\\n\\\",\\n-    \\\"#         \\\\\\\"recall\\\\\\\": recall_score(y_test, y_pred, average='macro'),\\\\n\\\",\\n-    \\\"#         \\\\\\\"f1_score\\\\\\\": f1_score(y_test, y_pred, average='macro')\\\\n\\\",\\n-    \\\"#     })\\\\n\\\",\\n-    \\\"   \\\\n\\\",\\n-    \\\"#     # Optionally log the model metadata as a JSON file or another structure\\\\n\\\",\\n-    \\\"#     mlflow.log_dict(model_metadata, \\\\\\\"model_metadata.json\\\\\\\")\\\\n\\\",\\n-    \\\"#     # Log parameters and metrics\\\\n\\\",\\n-    \\\"#     mlflow.log_params({\\\\n\\\",\\n-    \\\"#         \\\\\\\"model\\\\\\\": \\\\\\\"RandomForestClassifier\\\\\\\",\\\\n\\\",\\n-    \\\"#         \\\\\\\"n_estimators\\\\\\\": 100,\\\\n\\\",\\n-    \\\"#         \\\\\\\"dataset_source\\\\\\\": \\\\\\\"DBrepo\\\\\\\"\\\\n\\\",\\n-    \\\"#     })\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\" \\\\n\\\",\\n-    \\\"  \\\\n\\\",\\n-    \\\"#    # Confusion Matrix\\\\n\\\",\\n-    \\\"#     confusion = confusion_matrix(y_test, y_pred)\\\\n\\\",\\n-    \\\"#     plt.figure(figsize=(6, 6))\\\\n\\\",\\n-    \\\"#     sns.heatmap(confusion, annot=True, fmt=\\\\\\\"d\\\\\\\", cmap=\\\\\\\"Blues\\\\\\\")\\\\n\\\",\\n-    \\\"#     plt.title(\\\\\\\"Confusion Matrix\\\\\\\")\\\\n\\\",\\n-    \\\"#     plt.xlabel(\\\\\\\"Predicted\\\\\\\")\\\\n\\\",\\n-    \\\"#     plt.ylabel(\\\\\\\"Actual\\\\\\\")\\\\n\\\",\\n-    \\\"#     cm_path = \\\\\\\"confusion_matrix.png\\\\\\\"\\\\n\\\",\\n-    \\\"#     plt.savefig(cm_path)\\\\n\\\",\\n-    \\\"#     mlflow.log_artifact(cm_path)\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"#     # ROC Curve\\\\n\\\",\\n-    \\\"#     fpr, tpr, _ = roc_curve(y_test, y_proba[:, 1], pos_label=1)\\\\n\\\",\\n-    \\\"#     plt.figure()\\\\n\\\",\\n-    \\\"#     plt.plot(fpr, tpr, label=f\\\\\\\"ROC AUC = {auc:.2f}\\\\\\\")\\\\n\\\",\\n-    \\\"#     plt.plot([0, 1], [0, 1], \\\\\\\"k--\\\\\\\")\\\\n\\\",\\n-    \\\"#     plt.xlabel(\\\\\\\"False Positive Rate\\\\\\\")\\\\n\\\",\\n-    \\\"#     plt.ylabel(\\\\\\\"True Positive Rate\\\\\\\")\\\\n\\\",\\n-    \\\"#     plt.title(\\\\\\\"ROC Curve\\\\\\\")\\\\n\\\",\\n-    \\\"#     roc_path = \\\\\\\"roc_curve.png\\\\\\\"\\\\n\\\",\\n-    \\\"#     plt.savefig(roc_path)\\\\n\\\",\\n-    \\\"#     mlflow.log_artifact(roc_path)\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"#     # SHAP\\\\n\\\",\\n-    \\\"#     explainer = shap.TreeExplainer(model)\\\\n\\\",\\n-    \\\"#     shap_values = explainer.shap_values(X_test)\\\\n\\\",\\n-    \\\"#     shap.summary_plot(shap_values, X_test, show=False)\\\\n\\\",\\n-    \\\"#     shap_path = \\\\\\\"shap_summary.png\\\\\\\"\\\\n\\\",\\n-    \\\"#     plt.savefig(shap_path)\\\\n\\\",\\n-    \\\"#     mlflow.log_artifact(shap_path)\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"#     # Feature importance\\\\n\\\",\\n-    \\\"#     feat_imp = pd.DataFrame({\\\\n\\\",\\n-    \\\"#         \\\\\\\"Feature\\\\\\\": X.columns,\\\\n\\\",\\n-    \\\"#         \\\\\\\"Importance\\\\\\\": model.feature_importances_\\\\n\\\",\\n-    \\\"#     }).sort_values(by=\\\\\\\"Importance\\\\\\\", ascending=False)\\\\n\\\",\\n-    \\\"#     feat_path = \\\\\\\"feature_importance.csv\\\\\\\"\\\\n\\\",\\n-    \\\"#     feat_imp.to_csv(feat_path, index=False)\\\\n\\\",\\n-    \\\"#     mlflow.log_artifact(feat_path)\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"#     # \\ud83d\\uddc3\\ufe0f Save and log dataset as artifact\\\\n\\\",\\n-    \\\"#     Xy = X.copy()\\\\n\\\",\\n-    \\\"#     Xy[\\\\\\\"target\\\\\\\"] = y\\\\n\\\",\\n-    \\\"#     data_path = \\\\\\\"iris_dataset.csv\\\\\\\"\\\\n\\\",\\n-    \\\"#     Xy.to_csv(data_path, index=False)\\\\n\\\",\\n-    \\\"#     mlflow.log_artifact(data_path, artifact_path=\\\\\\\"input_data\\\\\\\")\\\\n\\\",\\n-    \\\"    \\\\n\\\",\\n-    \\\"#   # Input schema\\\\n\\\",\\n-    \\\"#     input_schema = X.dtypes.astype(str).to_dict()\\\\n\\\",\\n-    \\\"#     with open(\\\\\\\"input_schema.json\\\\\\\", \\\\\\\"w\\\\\\\") as f:\\\\n\\\",\\n-    \\\"#         json.dump(input_schema, f)\\\\n\\\",\\n-    \\\"#     mlflow.log_artifact(\\\\\\\"input_schema.json\\\\\\\")\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"#     # Output schema\\\\n\\\",\\n-    \\\"#     output_schema = {\\\\n\\\",\\n-    \\\"#         \\\\\\\"output_type\\\\\\\": str(type(y_pred[0])),\\\\n\\\",\\n-    \\\"#         \\\\\\\"classes\\\\\\\": model.classes_.tolist()\\\\n\\\",\\n-    \\\"#     }\\\\n\\\",\\n-    \\\"#     with open(\\\\\\\"output_schema.json\\\\\\\", \\\\\\\"w\\\\\\\") as f:\\\\n\\\",\\n-    \\\"#         json.dump(output_schema, f)\\\\n\\\",\\n-    \\\"#     mlflow.log_artifact(\\\\\\\"output_schema.json\\\\\\\")\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"#     # Register model\\\\n\\\",\\n-    \\\"#     model_uri = f\\\\\\\"runs:/{run.info.run_id}/random_forest_model\\\\\\\"\\\\n\\\",\\n-    \\\"#     # mlflow.register_model(model_uri, \\\\\\\"RandomForest_Iris_CSV_Model\\\\\\\")\\\\n\\\",\\n-    \\\"#     print(f\\\\\\\"Run logged with ID: {run.info.run_id}\\\\\\\")\\\\n\\\",\\n-    \\\"#     mlflow.end_run()\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# mlflow.set_experiment(\\\\\\\"RandomForest-Iris-CSV\\\\\\\")\\\\n\\\",\\n-    \\\"# client = MlflowClient()\\\"\\n-   ]\\n-  },\\n-  {\\n-   \\\"cell_type\\\": \\\"code\\\",\\n-   \\\"execution_count\\\": null,\\n-   \\\"id\\\": \\\"389db24b-0578-40a0-8731-2c2f9d58d0ef\\\",\\n-   \\\"metadata\\\": {},\\n-   \\\"outputs\\\": [],\\n-   \\\"source\\\": []\\n-  },\\n-  {\\n-   \\\"cell_type\\\": \\\"code\\\",\\n-   \\\"execution_count\\\": null,\\n-   \\\"id\\\": \\\"cc4f0725-805c-44ce-9926-d0d849fce621\\\",\\n-   \\\"metadata\\\": {},\\n-   \\\"outputs\\\": [],\\n-   \\\"source\\\": []\\n-  },\\n-  {\\n-   \\\"cell_type\\\": \\\"code\\\",\\n-   \\\"execution_count\\\": null,\\n-   \\\"id\\\": \\\"9202135f-8c33-4f97-9458-173183b92111\\\",\\n-   \\\"metadata\\\": {},\\n-   \\\"outputs\\\": [],\\n-   \\\"source\\\": []\\n-  },\\n-  {\\n-   \\\"cell_type\\\": \\\"code\\\",\\n-   \\\"execution_count\\\": null,\\n-   \\\"id\\\": \\\"a4703d1d-9cf2-4416-b627-74ef93e009e4\\\",\\n-   \\\"metadata\\\": {},\\n-   \\\"outputs\\\": [],\\n-   \\\"source\\\": []\\n-  },\\n-  {\\n-   \\\"cell_type\\\": \\\"code\\\",\\n-   \\\"execution_count\\\": null,\\n-   \\\"id\\\": \\\"e39da051-b6cc-4d52-bc9b-ada392d4de47\\\",\\n-   \\\"metadata\\\": {},\\n-   \\\"outputs\\\": [],\\n-   \\\"source\\\": []\\n-  }\\n- ],\\n- \\\"metadata\\\": {\\n-  \\\"kernelspec\\\": {\\n-   \\\"display_name\\\": \\\"Python 3 (ipykernel)\\\",\\n-   \\\"language\\\": \\\"python\\\",\\n-   \\\"name\\\": \\\"python3\\\"\\n-  },\\n-  \\\"language_info\\\": {\\n-   \\\"codemirror_mode\\\": {\\n-    \\\"name\\\": \\\"ipython\\\",\\n-    \\\"version\\\": 3\\n-   },\\n-   \\\"file_extension\\\": \\\".py\\\",\\n-   \\\"mimetype\\\": \\\"text/x-python\\\",\\n-   \\\"name\\\": \\\"python\\\",\\n-   \\\"nbconvert_exporter\\\": \\\"python\\\",\\n-   \\\"pygments_lexer\\\": \\\"ipython3\\\",\\n-   \\\"version\\\": \\\"3.11.5\\\"\\n-  }\\n- },\\n- \\\"nbformat\\\": 4,\\n- \\\"nbformat_minor\\\": 5\\n-}\\ndiff --git a/notebooks/RQ_notebooks/RQ1_updated-Backup.ipynb b/notebooks/RQ_notebooks/RQ1_updated-Backup.ipynb\\nnew file mode 100644\\nindex 0000000..1ff819b\\n--- /dev/null\\n+++ b/notebooks/RQ_notebooks/RQ1_updated-Backup.ipynb\\n@@ -0,0 +1,3270 @@\\n+{\\n+ \\\"cells\\\": [\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 8,\\n+   \\\"id\\\": \\\"12fa6f59-927c-4003-964f-83e53793fd36\\\",\\n+   \\\"metadata\\\": {\\n+    \\\"scrolled\\\": true\\n+   },\\n+   \\\"outputs\\\": [],\\n+   \\\"source\\\": [\\n+    \\\"# TODO: atm the mlflow autolog isnt capturing metrics n params\\\\n\\\",\\n+    \\\"# and sklearn.autolog throws error( posted the issue on github)\\\\n\\\",\\n+    \\\"# Ideally, I should be able to fetch most of the imp detail via MLFLOW AUTOLOG. will check that later in time\\\\n\\\",\\n+    \\\"#============================\\\\n\\\",\\n+    \\\"# \\ud83e\\udde0 MLflow Autologging\\\\n\\\",\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# mlflow.autolog(log_input_examples=True, log_model_signatures=True)\\\\n\\\",\\n+    \\\"# mlflow.sklearn.autolog() \\\\n\\\",\\n+    \\\"# mlflow.sklearn.autolog(\\\\n\\\",\\n+    \\\"#     log_input_examples=True,\\\\n\\\",\\n+    \\\"#     log_model_signatures=True,\\\\n\\\",\\n+    \\\"#     log_post_training_metrics=True,        # calls model.score() \\u2192 accuracy\\\\n\\\",\\n+    \\\"#     disable_for_unsupported_versions=True,  # skips if versions still wonky\\\\n\\\",\\n+    \\\"#     exclusive=True                          # only patch the sklearn integration\\\\n\\\",\\n+    \\\"# )\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 9,\\n+   \\\"id\\\": \\\"1ce1a579-f08b-40bd-b4db-21b388aaea74\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [],\\n+   \\\"source\\\": [\\n+    \\\"\\\\n\\\",\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"# \\u2699\\ufe0f Install Dependencies (if needed )\\\\n\\\",\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"# !pip install mlflow scikit-learn pandas numpy matplotlib seaborn shap requests GitPython\\\\n\\\",\\n+    \\\"# !pip install --upgrade threadpoolctl\\\\n\\\",\\n+    \\\"# !pip install setuptools\\\\n\\\",\\n+    \\\"# !pip install ace_tools \\\\n\\\",\\n+    \\\"# !pip install rdflib\\\\n\\\",\\n+    \\\"# !pip install streamlit-option-menu\\\\n\\\",\\n+    \\\"# !pip install streamlit-agraph\\\\n\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"1ca4f0ae-39ee-4b22-b013-dfb1fa1b5694\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"LIBRARY IMPORTS:\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 51,\\n+   \\\"id\\\": \\\"8ca332e5-6501-4310-920b-2b769477b46e\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [],\\n+   \\\"source\\\": [\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"# \\ud83d\\udce6 Standard Library Imports\\\\n\\\",\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"import os\\\\n\\\",\\n+    \\\"import glob\\\\n\\\",\\n+    \\\"import io\\\\n\\\",\\n+    \\\"import json\\\\n\\\",\\n+    \\\"import time\\\\n\\\",\\n+    \\\"import ast\\\\n\\\",\\n+    \\\"import pickle\\\\n\\\",\\n+    \\\"import platform\\\\n\\\",\\n+    \\\"import subprocess\\\\n\\\",\\n+    \\\"from datetime import datetime, timezone\\\\n\\\",\\n+    \\\"from pprint import pprint\\\\n\\\",\\n+    \\\"from typing import List, Dict, Any\\\\n\\\",\\n+    \\\"import xml.etree.ElementTree as ET\\\\n\\\",\\n+    \\\"import urllib.parse\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"# \\ud83d\\udcca Data and Visualization\\\\n\\\",\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"import pandas as pd\\\\n\\\",\\n+    \\\"import numpy as np\\\\n\\\",\\n+    \\\"import seaborn as sns\\\\n\\\",\\n+    \\\"import matplotlib\\\\n\\\",\\n+    \\\"import matplotlib.pyplot as plt\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"# \\ud83e\\udd16 Machine Learning\\\\n\\\",\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"import sklearn\\\\n\\\",\\n+    \\\"from sklearn.datasets import load_iris\\\\n\\\",\\n+    \\\"from sklearn.ensemble import RandomForestClassifier\\\\n\\\",\\n+    \\\"from sklearn.model_selection import train_test_split\\\\n\\\",\\n+    \\\"from sklearn.preprocessing import LabelEncoder, label_binarize\\\\n\\\",\\n+    \\\"from sklearn.metrics import (\\\\n\\\",\\n+    \\\"    accuracy_score,\\\\n\\\",\\n+    \\\"    roc_auc_score,\\\\n\\\",\\n+    \\\"    confusion_matrix,\\\\n\\\",\\n+    \\\"    precision_score,\\\\n\\\",\\n+    \\\"    recall_score,\\\\n\\\",\\n+    \\\"    f1_score,\\\\n\\\",\\n+    \\\"    RocCurveDisplay,\\\\n\\\",\\n+    \\\"    PrecisionRecallDisplay\\\\n\\\",\\n+    \\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"# \\ud83d\\udd2c Experiment Tracking\\\\n\\\",\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"import mlflow\\\\n\\\",\\n+    \\\"import mlflow.sklearn\\\\n\\\",\\n+    \\\"from mlflow import MlflowClient\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"# \\ud83c\\udf10 Web / API / Networking\\\\n\\\",\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"import requests\\\\n\\\",\\n+    \\\"from dotenv import load_dotenv\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"# \\ud83e\\uddea Git & Version Control\\\\n\\\",\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"import git\\\\n\\\",\\n+    \\\"from git import Repo, GitCommandError\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"# \\ud83e\\udde0 SHAP for Explainability\\\\n\\\",\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"import shap\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"# \\ud83e\\uddec RDF & Provenance (rdflib)\\\\n\\\",\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"from rdflib import Graph, URIRef, Literal\\\\n\\\",\\n+    \\\"from rdflib.namespace import PROV, XSD\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"# \\u2699\\ufe0f System Monitoring\\\\n\\\",\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"import psutil\\\\n\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"61d4d6b8-34a9-47b5-974d-5927c0ee2256\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"DBREPO INTEGRETION\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 32,\\n+   \\\"id\\\": \\\"8e3570e2-9a60-45b4-8653-28060071e728\\\",\\n+   \\\"metadata\\\": {\\n+    \\\"scrolled\\\": true\\n+   },\\n+   \\\"outputs\\\": [\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"API Response: [{'id': '1', 'sepallengthcm': '5.100000000000000000', 'sepalwidthcm': '3.500000000000000000', 'petallengthcm': '1.400000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '2', 'sepallengthcm': '4.900000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '1.400000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '3', 'sepallengthcm': '4.700000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '1.300000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '4', 'sepallengthcm': '4.600000000000000000', 'sepalwidthcm': '3.100000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '5', 'sepallengthcm': '5.000000000000000000', 'sepalwidthcm': '3.600000000000000000', 'petallengthcm': '1.400000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '6', 'sepallengthcm': '5.400000000000000000', 'sepalwidthcm': '3.900000000000000000', 'petallengthcm': '1.700000000000000000', 'petalwidthcm': '0.400000000000000000', 'species': 'Iris-setosa'}, {'id': '7', 'sepallengthcm': '4.600000000000000000', 'sepalwidthcm': '3.400000000000000000', 'petallengthcm': '1.400000000000000000', 'petalwidthcm': '0.300000000000000000', 'species': 'Iris-setosa'}, {'id': '8', 'sepallengthcm': '5.000000000000000000', 'sepalwidthcm': '3.400000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '9', 'sepallengthcm': '4.400000000000000000', 'sepalwidthcm': '2.900000000000000000', 'petallengthcm': '1.400000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '10', 'sepallengthcm': '4.900000000000000000', 'sepalwidthcm': '3.100000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.100000000000000000', 'species': 'Iris-setosa'}, {'id': '11', 'sepallengthcm': '5.400000000000000000', 'sepalwidthcm': '3.700000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '12', 'sepallengthcm': '4.800000000000000000', 'sepalwidthcm': '3.400000000000000000', 'petallengthcm': '1.600000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '13', 'sepallengthcm': '4.800000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '1.400000000000000000', 'petalwidthcm': '0.100000000000000000', 'species': 'Iris-setosa'}, {'id': '14', 'sepallengthcm': '4.300000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '1.100000000000000000', 'petalwidthcm': '0.100000000000000000', 'species': 'Iris-setosa'}, {'id': '15', 'sepallengthcm': '5.800000000000000000', 'sepalwidthcm': '4.000000000000000000', 'petallengthcm': '1.200000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '16', 'sepallengthcm': '5.700000000000000000', 'sepalwidthcm': '4.400000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.400000000000000000', 'species': 'Iris-setosa'}, {'id': '17', 'sepallengthcm': '5.400000000000000000', 'sepalwidthcm': '3.900000000000000000', 'petallengthcm': '1.300000000000000000', 'petalwidthcm': '0.400000000000000000', 'species': 'Iris-setosa'}, {'id': '18', 'sepallengthcm': '5.100000000000000000', 'sepalwidthcm': '3.500000000000000000', 'petallengthcm': '1.400000000000000000', 'petalwidthcm': '0.300000000000000000', 'species': 'Iris-setosa'}, {'id': '19', 'sepallengthcm': '5.700000000000000000', 'sepalwidthcm': '3.800000000000000000', 'petallengthcm': '1.700000000000000000', 'petalwidthcm': '0.300000000000000000', 'species': 'Iris-setosa'}, {'id': '20', 'sepallengthcm': '5.100000000000000000', 'sepalwidthcm': '3.800000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.300000000000000000', 'species': 'Iris-setosa'}, {'id': '21', 'sepallengthcm': '5.400000000000000000', 'sepalwidthcm': '3.400000000000000000', 'petallengthcm': '1.700000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '22', 'sepallengthcm': '5.100000000000000000', 'sepalwidthcm': '3.700000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.400000000000000000', 'species': 'Iris-setosa'}, {'id': '23', 'sepallengthcm': '4.600000000000000000', 'sepalwidthcm': '3.600000000000000000', 'petallengthcm': '1.000000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '24', 'sepallengthcm': '5.100000000000000000', 'sepalwidthcm': '3.300000000000000000', 'petallengthcm': '1.700000000000000000', 'petalwidthcm': '0.500000000000000000', 'species': 'Iris-setosa'}, {'id': '25', 'sepallengthcm': '4.800000000000000000', 'sepalwidthcm': '3.400000000000000000', 'petallengthcm': '1.900000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '26', 'sepallengthcm': '5.000000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '1.600000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '27', 'sepallengthcm': '5.000000000000000000', 'sepalwidthcm': '3.400000000000000000', 'petallengthcm': '1.600000000000000000', 'petalwidthcm': '0.400000000000000000', 'species': 'Iris-setosa'}, {'id': '28', 'sepallengthcm': '5.200000000000000000', 'sepalwidthcm': '3.500000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '29', 'sepallengthcm': '5.200000000000000000', 'sepalwidthcm': '3.400000000000000000', 'petallengthcm': '1.400000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '30', 'sepallengthcm': '4.700000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '1.600000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '31', 'sepallengthcm': '4.800000000000000000', 'sepalwidthcm': '3.100000000000000000', 'petallengthcm': '1.600000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '32', 'sepallengthcm': '5.400000000000000000', 'sepalwidthcm': '3.400000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.400000000000000000', 'species': 'Iris-setosa'}, {'id': '33', 'sepallengthcm': '5.200000000000000000', 'sepalwidthcm': '4.100000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.100000000000000000', 'species': 'Iris-setosa'}, {'id': '34', 'sepallengthcm': '5.500000000000000000', 'sepalwidthcm': '4.200000000000000000', 'petallengthcm': '1.400000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '35', 'sepallengthcm': '4.900000000000000000', 'sepalwidthcm': '3.100000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.100000000000000000', 'species': 'Iris-setosa'}, {'id': '36', 'sepallengthcm': '5.000000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '1.200000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '37', 'sepallengthcm': '5.500000000000000000', 'sepalwidthcm': '3.500000000000000000', 'petallengthcm': '1.300000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '38', 'sepallengthcm': '4.900000000000000000', 'sepalwidthcm': '3.100000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.100000000000000000', 'species': 'Iris-setosa'}, {'id': '39', 'sepallengthcm': '4.400000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '1.300000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '40', 'sepallengthcm': '5.100000000000000000', 'sepalwidthcm': '3.400000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '41', 'sepallengthcm': '5.000000000000000000', 'sepalwidthcm': '3.500000000000000000', 'petallengthcm': '1.300000000000000000', 'petalwidthcm': '0.300000000000000000', 'species': 'Iris-setosa'}, {'id': '42', 'sepallengthcm': '4.500000000000000000', 'sepalwidthcm': '2.300000000000000000', 'petallengthcm': '1.300000000000000000', 'petalwidthcm': '0.300000000000000000', 'species': 'Iris-setosa'}, {'id': '43', 'sepallengthcm': '4.400000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '1.300000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '44', 'sepallengthcm': '5.000000000000000000', 'sepalwidthcm': '3.500000000000000000', 'petallengthcm': '1.600000000000000000', 'petalwidthcm': '0.600000000000000000', 'species': 'Iris-setosa'}, {'id': '45', 'sepallengthcm': '5.100000000000000000', 'sepalwidthcm': '3.800000000000000000', 'petallengthcm': '1.900000000000000000', 'petalwidthcm': '0.400000000000000000', 'species': 'Iris-setosa'}, {'id': '46', 'sepallengthcm': '4.800000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '1.400000000000000000', 'petalwidthcm': '0.300000000000000000', 'species': 'Iris-setosa'}, {'id': '47', 'sepallengthcm': '5.100000000000000000', 'sepalwidthcm': '3.800000000000000000', 'petallengthcm': '1.600000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '48', 'sepallengthcm': '4.600000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '1.400000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '49', 'sepallengthcm': '5.300000000000000000', 'sepalwidthcm': '3.700000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '50', 'sepallengthcm': '5.000000000000000000', 'sepalwidthcm': '3.300000000000000000', 'petallengthcm': '1.400000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '51', 'sepallengthcm': '7.000000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '4.700000000000000000', 'petalwidthcm': '1.400000000000000000', 'species': 'Iris-versicolor'}, {'id': '52', 'sepallengthcm': '6.400000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '4.500000000000000000', 'petalwidthcm': '1.500000000000000000', 'species': 'Iris-versicolor'}, {'id': '53', 'sepallengthcm': '6.900000000000000000', 'sepalwidthcm': '3.100000000000000000', 'petallengthcm': '4.900000000000000000', 'petalwidthcm': '1.500000000000000000', 'species': 'Iris-versicolor'}, {'id': '54', 'sepallengthcm': '5.500000000000000000', 'sepalwidthcm': '2.300000000000000000', 'petallengthcm': '4.000000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '55', 'sepallengthcm': '6.500000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '4.600000000000000000', 'petalwidthcm': '1.500000000000000000', 'species': 'Iris-versicolor'}, {'id': '56', 'sepallengthcm': '5.700000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '4.500000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '57', 'sepallengthcm': '6.300000000000000000', 'sepalwidthcm': '3.300000000000000000', 'petallengthcm': '4.700000000000000000', 'petalwidthcm': '1.600000000000000000', 'species': 'Iris-versicolor'}, {'id': '58', 'sepallengthcm': '4.900000000000000000', 'sepalwidthcm': '2.400000000000000000', 'petallengthcm': '3.300000000000000000', 'petalwidthcm': '1.000000000000000000', 'species': 'Iris-versicolor'}, {'id': '59', 'sepallengthcm': '6.600000000000000000', 'sepalwidthcm': '2.900000000000000000', 'petallengthcm': '4.600000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '60', 'sepallengthcm': '5.200000000000000000', 'sepalwidthcm': '2.700000000000000000', 'petallengthcm': '3.900000000000000000', 'petalwidthcm': '1.400000000000000000', 'species': 'Iris-versicolor'}, {'id': '61', 'sepallengthcm': '5.000000000000000000', 'sepalwidthcm': '2.000000000000000000', 'petallengthcm': '3.500000000000000000', 'petalwidthcm': '1.000000000000000000', 'species': 'Iris-versicolor'}, {'id': '62', 'sepallengthcm': '5.900000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '4.200000000000000000', 'petalwidthcm': '1.500000000000000000', 'species': 'Iris-versicolor'}, {'id': '63', 'sepallengthcm': '6.000000000000000000', 'sepalwidthcm': '2.200000000000000000', 'petallengthcm': '4.000000000000000000', 'petalwidthcm': '1.000000000000000000', 'species': 'Iris-versicolor'}, {'id': '64', 'sepallengthcm': '6.100000000000000000', 'sepalwidthcm': '2.900000000000000000', 'petallengthcm': '4.700000000000000000', 'petalwidthcm': '1.400000000000000000', 'species': 'Iris-versicolor'}, {'id': '65', 'sepallengthcm': '5.600000000000000000', 'sepalwidthcm': '2.900000000000000000', 'petallengthcm': '3.600000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '66', 'sepallengthcm': '6.700000000000000000', 'sepalwidthcm': '3.100000000000000000', 'petallengthcm': '4.400000000000000000', 'petalwidthcm': '1.400000000000000000', 'species': 'Iris-versicolor'}, {'id': '67', 'sepallengthcm': '5.600000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '4.500000000000000000', 'petalwidthcm': '1.500000000000000000', 'species': 'Iris-versicolor'}, {'id': '68', 'sepallengthcm': '5.800000000000000000', 'sepalwidthcm': '2.700000000000000000', 'petallengthcm': '4.100000000000000000', 'petalwidthcm': '1.000000000000000000', 'species': 'Iris-versicolor'}, {'id': '69', 'sepallengthcm': '6.200000000000000000', 'sepalwidthcm': '2.200000000000000000', 'petallengthcm': '4.500000000000000000', 'petalwidthcm': '1.500000000000000000', 'species': 'Iris-versicolor'}, {'id': '70', 'sepallengthcm': '5.600000000000000000', 'sepalwidthcm': '2.500000000000000000', 'petallengthcm': '3.900000000000000000', 'petalwidthcm': '1.100000000000000000', 'species': 'Iris-versicolor'}, {'id': '71', 'sepallengthcm': '5.900000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '4.800000000000000000', 'petalwidthcm': '1.800000000000000000', 'species': 'Iris-versicolor'}, {'id': '72', 'sepallengthcm': '6.100000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '4.000000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '73', 'sepallengthcm': '6.300000000000000000', 'sepalwidthcm': '2.500000000000000000', 'petallengthcm': '4.900000000000000000', 'petalwidthcm': '1.500000000000000000', 'species': 'Iris-versicolor'}, {'id': '74', 'sepallengthcm': '6.100000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '4.700000000000000000', 'petalwidthcm': '1.200000000000000000', 'species': 'Iris-versicolor'}, {'id': '75', 'sepallengthcm': '6.400000000000000000', 'sepalwidthcm': '2.900000000000000000', 'petallengthcm': '4.300000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '76', 'sepallengthcm': '6.600000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '4.400000000000000000', 'petalwidthcm': '1.400000000000000000', 'species': 'Iris-versicolor'}, {'id': '77', 'sepallengthcm': '6.800000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '4.800000000000000000', 'petalwidthcm': '1.400000000000000000', 'species': 'Iris-versicolor'}, {'id': '78', 'sepallengthcm': '6.700000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '5.000000000000000000', 'petalwidthcm': '1.700000000000000000', 'species': 'Iris-versicolor'}, {'id': '79', 'sepallengthcm': '6.000000000000000000', 'sepalwidthcm': '2.900000000000000000', 'petallengthcm': '4.500000000000000000', 'petalwidthcm': '1.500000000000000000', 'species': 'Iris-versicolor'}, {'id': '80', 'sepallengthcm': '5.700000000000000000', 'sepalwidthcm': '2.600000000000000000', 'petallengthcm': '3.500000000000000000', 'petalwidthcm': '1.000000000000000000', 'species': 'Iris-versicolor'}, {'id': '81', 'sepallengthcm': '5.500000000000000000', 'sepalwidthcm': '2.400000000000000000', 'petallengthcm': '3.800000000000000000', 'petalwidthcm': '1.100000000000000000', 'species': 'Iris-versicolor'}, {'id': '82', 'sepallengthcm': '5.500000000000000000', 'sepalwidthcm': '2.400000000000000000', 'petallengthcm': '3.700000000000000000', 'petalwidthcm': '1.000000000000000000', 'species': 'Iris-versicolor'}, {'id': '83', 'sepallengthcm': '5.800000000000000000', 'sepalwidthcm': '2.700000000000000000', 'petallengthcm': '3.900000000000000000', 'petalwidthcm': '1.200000000000000000', 'species': 'Iris-versicolor'}, {'id': '84', 'sepallengthcm': '6.000000000000000000', 'sepalwidthcm': '2.700000000000000000', 'petallengthcm': '5.100000000000000000', 'petalwidthcm': '1.600000000000000000', 'species': 'Iris-versicolor'}, {'id': '85', 'sepallengthcm': '5.400000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '4.500000000000000000', 'petalwidthcm': '1.500000000000000000', 'species': 'Iris-versicolor'}, {'id': '86', 'sepallengthcm': '6.000000000000000000', 'sepalwidthcm': '3.400000000000000000', 'petallengthcm': '4.500000000000000000', 'petalwidthcm': '1.600000000000000000', 'species': 'Iris-versicolor'}, {'id': '87', 'sepallengthcm': '6.700000000000000000', 'sepalwidthcm': '3.100000000000000000', 'petallengthcm': '4.700000000000000000', 'petalwidthcm': '1.500000000000000000', 'species': 'Iris-versicolor'}, {'id': '88', 'sepallengthcm': '6.300000000000000000', 'sepalwidthcm': '2.300000000000000000', 'petallengthcm': '4.400000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '89', 'sepallengthcm': '5.600000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '4.100000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '90', 'sepallengthcm': '5.500000000000000000', 'sepalwidthcm': '2.500000000000000000', 'petallengthcm': '4.000000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '91', 'sepallengthcm': '5.500000000000000000', 'sepalwidthcm': '2.600000000000000000', 'petallengthcm': '4.400000000000000000', 'petalwidthcm': '1.200000000000000000', 'species': 'Iris-versicolor'}, {'id': '92', 'sepallengthcm': '6.100000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '4.600000000000000000', 'petalwidthcm': '1.400000000000000000', 'species': 'Iris-versicolor'}, {'id': '93', 'sepallengthcm': '5.800000000000000000', 'sepalwidthcm': '2.600000000000000000', 'petallengthcm': '4.000000000000000000', 'petalwidthcm': '1.200000000000000000', 'species': 'Iris-versicolor'}, {'id': '94', 'sepallengthcm': '5.000000000000000000', 'sepalwidthcm': '2.300000000000000000', 'petallengthcm': '3.300000000000000000', 'petalwidthcm': '1.000000000000000000', 'species': 'Iris-versicolor'}, {'id': '95', 'sepallengthcm': '5.600000000000000000', 'sepalwidthcm': '2.700000000000000000', 'petallengthcm': '4.200000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '96', 'sepallengthcm': '5.700000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '4.200000000000000000', 'petalwidthcm': '1.200000000000000000', 'species': 'Iris-versicolor'}, {'id': '97', 'sepallengthcm': '5.700000000000000000', 'sepalwidthcm': '2.900000000000000000', 'petallengthcm': '4.200000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '98', 'sepallengthcm': '6.200000000000000000', 'sepalwidthcm': '2.900000000000000000', 'petallengthcm': '4.300000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '99', 'sepallengthcm': '5.100000000000000000', 'sepalwidthcm': '2.500000000000000000', 'petallengthcm': '3.000000000000000000', 'petalwidthcm': '1.100000000000000000', 'species': 'Iris-versicolor'}, {'id': '100', 'sepallengthcm': '5.700000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '4.100000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '101', 'sepallengthcm': '6.300000000000000000', 'sepalwidthcm': '3.300000000000000000', 'petallengthcm': '6.000000000000000000', 'petalwidthcm': '2.500000000000000000', 'species': 'Iris-virginica'}, {'id': '102', 'sepallengthcm': '5.800000000000000000', 'sepalwidthcm': '2.700000000000000000', 'petallengthcm': '5.100000000000000000', 'petalwidthcm': '1.900000000000000000', 'species': 'Iris-virginica'}, {'id': '103', 'sepallengthcm': '7.100000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '5.900000000000000000', 'petalwidthcm': '2.100000000000000000', 'species': 'Iris-virginica'}, {'id': '104', 'sepallengthcm': '6.300000000000000000', 'sepalwidthcm': '2.900000000000000000', 'petallengthcm': '5.600000000000000000', 'petalwidthcm': '1.800000000000000000', 'species': 'Iris-virginica'}, {'id': '105', 'sepallengthcm': '6.500000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '5.800000000000000000', 'petalwidthcm': '2.200000000000000000', 'species': 'Iris-virginica'}, {'id': '106', 'sepallengthcm': '7.600000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '6.600000000000000000', 'petalwidthcm': '2.100000000000000000', 'species': 'Iris-virginica'}, {'id': '107', 'sepallengthcm': '4.900000000000000000', 'sepalwidthcm': '2.500000000000000000', 'petallengthcm': '4.500000000000000000', 'petalwidthcm': '1.700000000000000000', 'species': 'Iris-virginica'}, {'id': '108', 'sepallengthcm': '7.300000000000000000', 'sepalwidthcm': '2.900000000000000000', 'petallengthcm': '6.300000000000000000', 'petalwidthcm': '1.800000000000000000', 'species': 'Iris-virginica'}, {'id': '109', 'sepallengthcm': '6.700000000000000000', 'sepalwidthcm': '2.500000000000000000', 'petallengthcm': '5.800000000000000000', 'petalwidthcm': '1.800000000000000000', 'species': 'Iris-virginica'}, {'id': '110', 'sepallengthcm': '7.200000000000000000', 'sepalwidthcm': '3.600000000000000000', 'petallengthcm': '6.100000000000000000', 'petalwidthcm': '2.500000000000000000', 'species': 'Iris-virginica'}, {'id': '111', 'sepallengthcm': '6.500000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '5.100000000000000000', 'petalwidthcm': '2.000000000000000000', 'species': 'Iris-virginica'}, {'id': '112', 'sepallengthcm': '6.400000000000000000', 'sepalwidthcm': '2.700000000000000000', 'petallengthcm': '5.300000000000000000', 'petalwidthcm': '1.900000000000000000', 'species': 'Iris-virginica'}, {'id': '113', 'sepallengthcm': '6.800000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '5.500000000000000000', 'petalwidthcm': '2.100000000000000000', 'species': 'Iris-virginica'}, {'id': '114', 'sepallengthcm': '5.700000000000000000', 'sepalwidthcm': '2.500000000000000000', 'petallengthcm': '5.000000000000000000', 'petalwidthcm': '2.000000000000000000', 'species': 'Iris-virginica'}, {'id': '115', 'sepallengthcm': '5.800000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '5.100000000000000000', 'petalwidthcm': '2.400000000000000000', 'species': 'Iris-virginica'}, {'id': '116', 'sepallengthcm': '6.400000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '5.300000000000000000', 'petalwidthcm': '2.300000000000000000', 'species': 'Iris-virginica'}, {'id': '117', 'sepallengthcm': '6.500000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '5.500000000000000000', 'petalwidthcm': '1.800000000000000000', 'species': 'Iris-virginica'}, {'id': '118', 'sepallengthcm': '7.700000000000000000', 'sepalwidthcm': '3.800000000000000000', 'petallengthcm': '6.700000000000000000', 'petalwidthcm': '2.200000000000000000', 'species': 'Iris-virginica'}, {'id': '119', 'sepallengthcm': '7.700000000000000000', 'sepalwidthcm': '2.600000000000000000', 'petallengthcm': '6.900000000000000000', 'petalwidthcm': '2.300000000000000000', 'species': 'Iris-virginica'}, {'id': '120', 'sepallengthcm': '6.000000000000000000', 'sepalwidthcm': '2.200000000000000000', 'petallengthcm': '5.000000000000000000', 'petalwidthcm': '1.500000000000000000', 'species': 'Iris-virginica'}, {'id': '121', 'sepallengthcm': '6.900000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '5.700000000000000000', 'petalwidthcm': '2.300000000000000000', 'species': 'Iris-virginica'}, {'id': '122', 'sepallengthcm': '5.600000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '4.900000000000000000', 'petalwidthcm': '2.000000000000000000', 'species': 'Iris-virginica'}, {'id': '123', 'sepallengthcm': '7.700000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '6.700000000000000000', 'petalwidthcm': '2.000000000000000000', 'species': 'Iris-virginica'}, {'id': '124', 'sepallengthcm': '6.300000000000000000', 'sepalwidthcm': '2.700000000000000000', 'petallengthcm': '4.900000000000000000', 'petalwidthcm': '1.800000000000000000', 'species': 'Iris-virginica'}, {'id': '125', 'sepallengthcm': '6.700000000000000000', 'sepalwidthcm': '3.300000000000000000', 'petallengthcm': '5.700000000000000000', 'petalwidthcm': '2.100000000000000000', 'species': 'Iris-virginica'}, {'id': '126', 'sepallengthcm': '7.200000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '6.000000000000000000', 'petalwidthcm': '1.800000000000000000', 'species': 'Iris-virginica'}, {'id': '127', 'sepallengthcm': '6.200000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '4.800000000000000000', 'petalwidthcm': '1.800000000000000000', 'species': 'Iris-virginica'}, {'id': '128', 'sepallengthcm': '6.100000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '4.900000000000000000', 'petalwidthcm': '1.800000000000000000', 'species': 'Iris-virginica'}, {'id': '129', 'sepallengthcm': '6.400000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '5.600000000000000000', 'petalwidthcm': '2.100000000000000000', 'species': 'Iris-virginica'}, {'id': '130', 'sepallengthcm': '7.200000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '5.800000000000000000', 'petalwidthcm': '1.600000000000000000', 'species': 'Iris-virginica'}, {'id': '131', 'sepallengthcm': '7.400000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '6.100000000000000000', 'petalwidthcm': '1.900000000000000000', 'species': 'Iris-virginica'}, {'id': '132', 'sepallengthcm': '7.900000000000000000', 'sepalwidthcm': '3.800000000000000000', 'petallengthcm': '6.400000000000000000', 'petalwidthcm': '2.000000000000000000', 'species': 'Iris-virginica'}, {'id': '133', 'sepallengthcm': '6.400000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '5.600000000000000000', 'petalwidthcm': '2.200000000000000000', 'species': 'Iris-virginica'}, {'id': '134', 'sepallengthcm': '6.300000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '5.100000000000000000', 'petalwidthcm': '1.500000000000000000', 'species': 'Iris-virginica'}, {'id': '135', 'sepallengthcm': '6.100000000000000000', 'sepalwidthcm': '2.600000000000000000', 'petallengthcm': '5.600000000000000000', 'petalwidthcm': '1.400000000000000000', 'species': 'Iris-virginica'}, {'id': '136', 'sepallengthcm': '7.700000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '6.100000000000000000', 'petalwidthcm': '2.300000000000000000', 'species': 'Iris-virginica'}, {'id': '137', 'sepallengthcm': '6.300000000000000000', 'sepalwidthcm': '3.400000000000000000', 'petallengthcm': '5.600000000000000000', 'petalwidthcm': '2.400000000000000000', 'species': 'Iris-virginica'}, {'id': '138', 'sepallengthcm': '6.400000000000000000', 'sepalwidthcm': '3.100000000000000000', 'petallengthcm': '5.500000000000000000', 'petalwidthcm': '1.800000000000000000', 'species': 'Iris-virginica'}, {'id': '139', 'sepallengthcm': '6.000000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '4.800000000000000000', 'petalwidthcm': '1.800000000000000000', 'species': 'Iris-virginica'}, {'id': '140', 'sepallengthcm': '6.900000000000000000', 'sepalwidthcm': '3.100000000000000000', 'petallengthcm': '5.400000000000000000', 'petalwidthcm': '2.100000000000000000', 'species': 'Iris-virginica'}, {'id': '141', 'sepallengthcm': '6.700000000000000000', 'sepalwidthcm': '3.100000000000000000', 'petallengthcm': '5.600000000000000000', 'petalwidthcm': '2.400000000000000000', 'species': 'Iris-virginica'}, {'id': '142', 'sepallengthcm': '6.900000000000000000', 'sepalwidthcm': '3.100000000000000000', 'petallengthcm': '5.100000000000000000', 'petalwidthcm': '2.300000000000000000', 'species': 'Iris-virginica'}, {'id': '143', 'sepallengthcm': '5.800000000000000000', 'sepalwidthcm': '2.700000000000000000', 'petallengthcm': '5.100000000000000000', 'petalwidthcm': '1.900000000000000000', 'species': 'Iris-virginica'}, {'id': '144', 'sepallengthcm': '6.800000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '5.900000000000000000', 'petalwidthcm': '2.300000000000000000', 'species': 'Iris-virginica'}, {'id': '145', 'sepallengthcm': '6.700000000000000000', 'sepalwidthcm': '3.300000000000000000', 'petallengthcm': '5.700000000000000000', 'petalwidthcm': '2.500000000000000000', 'species': 'Iris-virginica'}, {'id': '146', 'sepallengthcm': '6.700000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '5.200000000000000000', 'petalwidthcm': '2.300000000000000000', 'species': 'Iris-virginica'}, {'id': '147', 'sepallengthcm': '6.300000000000000000', 'sepalwidthcm': '2.500000000000000000', 'petallengthcm': '5.000000000000000000', 'petalwidthcm': '1.900000000000000000', 'species': 'Iris-virginica'}, {'id': '148', 'sepallengthcm': '6.500000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '5.200000000000000000', 'petalwidthcm': '2.000000000000000000', 'species': 'Iris-virginica'}, {'id': '149', 'sepallengthcm': '6.200000000000000000', 'sepalwidthcm': '3.400000000000000000', 'petallengthcm': '5.400000000000000000', 'petalwidthcm': '2.300000000000000000', 'species': 'Iris-virginica'}, {'id': '150', 'sepallengthcm': '5.900000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '5.100000000000000000', 'petalwidthcm': '1.800000000000000000', 'species': 'Iris-virginica'}]\\\\n\\\",\\n+      \\\"<built-in method count of list object at 0x000001B2518C1700>\\\\n\\\"\\n+     ]\\n+    }\\n+   ],\\n+   \\\"source\\\": [\\n+    \\\"# API endpoint URL\\\\n\\\",\\n+    \\\"API_URL = \\\\\\\"http://localhost/api/database/c3a42d17-42b7-43c9-a504-2363fb4c9c8d/table/5315e7da-64fb-4fdb-b493-95b4138c765f/data?size=100000&page=0\\\\\\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# Define the headers\\\\n\\\",\\n+    \\\"headers = {\\\\n\\\",\\n+    \\\"    \\\\\\\"Accept\\\\\\\": \\\\\\\"application/json\\\\\\\"  # Specify the expected response format\\\\n\\\",\\n+    \\\"}\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"try:\\\\n\\\",\\n+    \\\"    # Send a GET request to the API with the Accept header\\\\n\\\",\\n+    \\\"    response = requests.get(API_URL, headers=headers)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # Check if the request was successful\\\\n\\\",\\n+    \\\"    if response.status_code == 200:\\\\n\\\",\\n+    \\\"        # Parse the JSON response\\\\n\\\",\\n+    \\\"        dataset = response.json()\\\\n\\\",\\n+    \\\"        print(\\\\\\\"API Response:\\\\\\\", dataset)\\\\n\\\",\\n+    \\\"        print( dataset.count)\\\\n\\\",\\n+    \\\"    else:\\\\n\\\",\\n+    \\\"        print(f\\\\\\\"Error: Received status code {response.status_code}\\\\\\\")\\\\n\\\",\\n+    \\\"        print(\\\\\\\"Response content:\\\\\\\", response.text)\\\\n\\\",\\n+    \\\"       \\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"except requests.exceptions.RequestException as e:\\\\n\\\",\\n+    \\\"    print(f\\\\\\\"Request failed: {e}\\\\\\\")\\\\n\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"09557f94-325c-4bd6-882a-069a9e3c5ecd\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"replacing dynamic fetching of data When and if DBREPO isnt running \\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 11,\\n+   \\\"id\\\": \\\"ce6e020d-cb80-49ec-8bcc-687b1e08885c\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [],\\n+   \\\"source\\\": [\\n+    \\\"# 1. Read the JSON file id the API isnt available this data is saved locally but the data is from the API endpoint\\\\n\\\",\\n+    \\\"with open(\\\\\\\"iris_data.json\\\\\\\", \\\\\\\"r\\\\\\\") as f:\\\\n\\\",\\n+    \\\"    dataset = json.load(f)\\\\n\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"a6c6007a-2126-4b1a-90ee-3326eb39a362\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"Metadata fetching from db repo API CALLS\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"9165f478-a44e-4125-8929-a8d77fdcb4c5\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"METADATA ON DATABASE LEVEL\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 33,\\n+   \\\"id\\\": \\\"abe912e7-bf9b-4bbd-8e43-6046745ade3f\\\",\\n+   \\\"metadata\\\": {\\n+    \\\"scrolled\\\": true\\n+   },\\n+   \\\"outputs\\\": [],\\n+   \\\"source\\\": [\\n+    \\\"\\\\n\\\",\\n+    \\\"DB_API = \\\\\\\"http://localhost/api/database/{db_id}\\\\\\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"def fetch_db_metadata(db_id: str) -> dict:\\\\n\\\",\\n+    \\\"    url = DB_API.format(db_id=db_id)\\\\n\\\",\\n+    \\\"    try:\\\\n\\\",\\n+    \\\"        resp = requests.get(url)\\\\n\\\",\\n+    \\\"        resp.raise_for_status()\\\\n\\\",\\n+    \\\"        return resp.json()\\\\n\\\",\\n+    \\\"    except requests.exceptions.RequestException as e:\\\\n\\\",\\n+    \\\"        print(f\\\\\\\"[\\u26a0\\ufe0f Error] Failed to fetch DB metadata for {db_id}: {e}\\\\\\\")\\\\n\\\",\\n+    \\\"        return {}  # or return None, depending on what your app prefers\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"def log_db_metadata(db_meta: dict):\\\\n\\\",\\n+    \\\"    # 1) Core DB fields as params, defaulting to empty string if key is missing\\\\n\\\",\\n+    \\\"    mlflow.log_param(\\\\\\\"database.id\\\\\\\",          db_meta.get(\\\\\\\"id\\\\\\\", \\\\\\\"\\\\\\\"))\\\\n\\\",\\n+    \\\"    mlflow.log_param(\\\\\\\"database.name\\\\\\\",        db_meta.get(\\\\\\\"name\\\\\\\", \\\\\\\"\\\\\\\"))\\\\n\\\",\\n+    \\\"    mlflow.log_param(\\\\\\\"database.description\\\\\\\", db_meta.get(\\\\\\\"description\\\\\\\", \\\\\\\"\\\\\\\"))\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # 2) Handle nested keys safely for owner\\\\n\\\",\\n+    \\\"    try:\\\\n\\\",\\n+    \\\"        owner = db_meta.get(\\\\\\\"tables\\\\\\\", [{}])[0].get(\\\\\\\"owner\\\\\\\", {}).get(\\\\\\\"username\\\\\\\", \\\\\\\"\\\\\\\")\\\\n\\\",\\n+    \\\"    except Exception:\\\\n\\\",\\n+    \\\"        owner = \\\\\\\"\\\\\\\"\\\\n\\\",\\n+    \\\"    mlflow.log_param(\\\\\\\"database.owner\\\\\\\", owner)\\\\n\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"53cbd7eb-0d97-4326-9bfc-f6fcee14ef9c\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"MATADATA FROM: <ns0:OAI-PMH xmlns:ns0=\\\\\\\"http://www.openarchives.org/OAI/2.0/\\\\\\\" xmlns:xsi=\\\\\\\"http://www.w3.org/2001/XMLSchema-instance\\\\\\\" xsi:schemaLocation=\\\\\\\"http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd\\\\\\\">\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 34,\\n+   \\\"id\\\": \\\"296f307e-e01b-477a-9406-92cab9f2d7bf\\\",\\n+   \\\"metadata\\\": {\\n+    \\\"scrolled\\\": true\\n+   },\\n+   \\\"outputs\\\": [\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"<ns0:OAI-PMH xmlns:ns0=\\\\\\\"http://www.openarchives.org/OAI/2.0/\\\\\\\" xmlns:xsi=\\\\\\\"http://www.w3.org/2001/XMLSchema-instance\\\\\\\" xsi:schemaLocation=\\\\\\\"http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd\\\\\\\">\\\\n\\\",\\n+      \\\"    <ns0:responseDate>2025-04-25T09:55:50Z</ns0:responseDate>\\\\n\\\",\\n+      \\\"    <ns0:request verb=\\\\\\\"Identify\\\\\\\">https://localhost/api/oai</ns0:request>\\\\n\\\",\\n+      \\\"    <ns0:Identify>\\\\n\\\",\\n+      \\\"    <ns0:repositoryName>Database Repository</ns0:repositoryName>\\\\n\\\",\\n+      \\\"    <ns0:baseURL>http://localhost</ns0:baseURL>\\\\n\\\",\\n+      \\\"    <ns0:protocolVersion>2.0</ns0:protocolVersion>\\\\n\\\",\\n+      \\\"    <ns0:adminEmail>noreply@localhost</ns0:adminEmail>\\\\n\\\",\\n+      \\\"    <ns0:earliestDatestamp />\\\\n\\\",\\n+      \\\"    <ns0:deletedRecord>persistent</ns0:deletedRecord>\\\\n\\\",\\n+      \\\"    <ns0:granularity>YYYY-MM-DDThh:mm:ssZ</ns0:granularity>\\\\n\\\",\\n+      \\\"</ns0:Identify>\\\\n\\\",\\n+      \\\"</ns0:OAI-PMH>\\\\n\\\"\\n+     ]\\n+    }\\n+   ],\\n+   \\\"source\\\": [\\n+    \\\"# 1) Fetch your database metadata\\\\n\\\",\\n+    \\\"db_url = \\\\\\\"http://localhost/api/database/c3a42d17-42b7-43c9-a504-2363fb4c9c8d\\\\\\\"\\\\n\\\",\\n+    \\\"db_resp = requests.get(db_url)\\\\n\\\",\\n+    \\\"db_resp.raise_for_status()\\\\n\\\",\\n+    \\\"db_data = db_resp.json()\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"db_id  = db_data[\\\\\\\"id\\\\\\\"]\\\\n\\\",\\n+    \\\"tbl_id = db_data[\\\\\\\"tables\\\\\\\"][0][\\\\\\\"id\\\\\\\"]\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# 2) Build the OAI-PMH URL, URL-encoding the `set` param\\\\n\\\",\\n+    \\\"set_param   = f\\\\\\\"Databases/{db_id}/Tables/{tbl_id}\\\\\\\"\\\\n\\\",\\n+    \\\"encoded_set = urllib.parse.quote(set_param, safe=\\\\\\\"\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"oai_url = (\\\\n\\\",\\n+    \\\"    \\\\\\\"http://localhost/api/oai\\\\\\\"\\\\n\\\",\\n+    \\\"    f\\\\\\\"?metadataPrefix=oai_dc\\\\\\\"\\\\n\\\",\\n+    \\\"    f\\\\\\\"&from=2025-03-01\\\\\\\"\\\\n\\\",\\n+    \\\"    f\\\\\\\"&until=2025-03-07\\\\\\\"\\\\n\\\",\\n+    \\\"    f\\\\\\\"&set={encoded_set}\\\\\\\"\\\\n\\\",\\n+    \\\"    f\\\\\\\"&resumptionToken=string\\\\\\\"\\\\n\\\",\\n+    \\\"    f\\\\\\\"&fromDate=2025-03-07T19%3A35%3A51.476Z\\\\\\\"\\\\n\\\",\\n+    \\\"    f\\\\\\\"&untilDate=2025-03-07T19%3A35%3A51.476Z\\\\\\\"\\\\n\\\",\\n+    \\\"    f\\\\\\\"&parametersString=string\\\\\\\"\\\\n\\\",\\n+    \\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# 3) Call and parse\\\\n\\\",\\n+    \\\"try:\\\\n\\\",\\n+    \\\"    resp = requests.get(oai_url)\\\\n\\\",\\n+    \\\"    resp.raise_for_status()\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    if \\\\\\\"xml\\\\\\\" in resp.headers.get(\\\\\\\"Content-Type\\\\\\\", \\\\\\\"\\\\\\\"):\\\\n\\\",\\n+    \\\"        root = ET.fromstring(resp.text)\\\\n\\\",\\n+    \\\"        print(ET.tostring(root, encoding=\\\\\\\"utf-8\\\\\\\").decode())\\\\n\\\",\\n+    \\\"    else:\\\\n\\\",\\n+    \\\"        print(\\\\\\\"Non-XML response:\\\\\\\", resp.headers.get(\\\\\\\"Content-Type\\\\\\\"), resp.text)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"except requests.exceptions.RequestException as e:\\\\n\\\",\\n+    \\\"    print(\\\\\\\"Request failed:\\\\\\\", e)\\\\n\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 35,\\n+   \\\"id\\\": \\\"61cc99ab-4a5c-4142-8725-e7c940673ffd\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [],\\n+   \\\"source\\\": [\\n+    \\\"# \\u2026after you fetch & parse your XML into `root`\\u2026\\\\n\\\",\\n+    \\\"ns = {\\\\\\\"oai\\\\\\\": \\\\\\\"http://www.openarchives.org/OAI/2.0/\\\\\\\"}\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"repo_name   = root.findtext(\\\\\\\"oai:Identify/oai:repositoryName\\\\\\\", namespaces=ns) or \\\\\\\"N/A\\\\\\\"\\\\n\\\",\\n+    \\\"base_url    = root.findtext(\\\\\\\"oai:Identify/oai:baseURL\\\\\\\", namespaces=ns) or \\\\\\\"N/A\\\\\\\"\\\\n\\\",\\n+    \\\"protocol    = root.findtext(\\\\\\\"oai:Identify/oai:protocolVersion\\\\\\\", namespaces=ns) or \\\\\\\"N/A\\\\\\\"\\\\n\\\",\\n+    \\\"admin_email = root.findtext(\\\\\\\"oai:Identify/oai:adminEmail\\\\\\\", namespaces=ns) or \\\\\\\"N/A\\\\\\\"\\\\n\\\",\\n+    \\\"gran        = root.findtext(\\\\\\\"oai:Identify/oai:granularity\\\\\\\", namespaces=ns) or \\\\\\\"N/A\\\\\\\"\\\\n\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"74214aa7-c12f-414e-9feb-094a366b855b\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"METADATA ON History Logging\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 36,\\n+   \\\"id\\\": \\\"e9c74e9b-c9b0-4b4a-82eb-2a6e56456508\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"API Response: [{'timestamp': '2025-04-23T20:42:29.501Z', 'event': 'insert', 'total': 150}]\\\\n\\\"\\n+     ]\\n+    }\\n+   ],\\n+   \\\"source\\\": [\\n+    \\\"url = \\\\\\\"http://localhost/api/database/c3a42d17-42b7-43c9-a504-2363fb4c9c8d/table/5315e7da-64fb-4fdb-b493-95b4138c765f/history\\\\\\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"try:\\\\n\\\",\\n+    \\\"    # Send a GET request to the API\\\\n\\\",\\n+    \\\"    response = requests.get(url)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # Check if the request was successful\\\\n\\\",\\n+    \\\"    if response.status_code == 200:\\\\n\\\",\\n+    \\\"        # Parse the JSON response\\\\n\\\",\\n+    \\\"        data = response.json()\\\\n\\\",\\n+    \\\"        print(\\\\\\\"API Response:\\\\\\\", data)\\\\n\\\",\\n+    \\\"    else:\\\\n\\\",\\n+    \\\"        print(f\\\\\\\"Error: Received status code {response.status_code}\\\\\\\")\\\\n\\\",\\n+    \\\"        print(\\\\\\\"Response content:\\\\\\\", response.text)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"except requests.exceptions.RequestException as e:\\\\n\\\",\\n+    \\\"    print(f\\\\\\\"Request failed: {e}\\\\\\\")\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 37,\\n+   \\\"id\\\": \\\"3630c954-5ad2-4759-b9a0-fa6e20e184ef\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [],\\n+   \\\"source\\\": [\\n+    \\\"first   = data[0]\\\\n\\\",\\n+    \\\"last    = data[-1]\\\\n\\\",\\n+    \\\"count_0 = first[\\\\\\\"total\\\\\\\"]    # e.g. 149\\\\n\\\",\\n+    \\\"count_N = last[\\\\\\\"total\\\\\\\"]     # e.g. 149 again, or changed\\\\n\\\",\\n+    \\\"ts_last = last[\\\\\\\"timestamp\\\\\\\"]  # e.g. \\\\\\\"2025-03-28T17:42:38.058Z\\\\\\\"\\\\n\\\",\\n+    \\\"n_insert = sum(1 for ev in data if ev[\\\\\\\"event\\\\\\\"]==\\\\\\\"insert\\\\\\\")\\\\n\\\",\\n+    \\\"n_delete = sum(1 for ev in data if ev[\\\\\\\"event\\\\\\\"]==\\\\\\\"delete\\\\\\\")\\\\n\\\",\\n+    \\\"history = response.json()\\\\n\\\",\\n+    \\\"first, last = history[0], history[-1]\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# summary stats\\\\n\\\",\\n+    \\\"count_start = first[\\\\\\\"total\\\\\\\"]\\\\n\\\",\\n+    \\\"count_end   = last[\\\\\\\"total\\\\\\\"]\\\\n\\\",\\n+    \\\"ts_last     = last[\\\\\\\"timestamp\\\\\\\"]\\\\n\\\",\\n+    \\\"n_insert    = sum(1 for ev in history if ev[\\\\\\\"event\\\\\\\"]==\\\\\\\"insert\\\\\\\")\\\\n\\\",\\n+    \\\"n_delete    = sum(1 for ev in history if ev[\\\\\\\"event\\\\\\\"]==\\\\\\\"delete\\\\\\\")\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"1afd5dad-72d5-42e1-a0fa-b7bd3455937b\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"Dataset metadata fetching from ZONEDO or any public dataset repositories to gain more details\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 38,\\n+   \\\"id\\\": \\\"a7fa122a-c6e5-4b38-842a-dc81590a1f46\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [],\\n+   \\\"source\\\": [\\n+    \\\"\\\\n\\\",\\n+    \\\"def fetch_and_log_dataset_metadata_nested(doi_url: str):\\\\n\\\",\\n+    \\\"    # 1) fetch the CSL+JSON\\\\n\\\",\\n+    \\\"    headers = {\\\\\\\"Accept\\\\\\\": \\\\\\\"application/vnd.citationstyles.csl+json\\\\\\\"}\\\\n\\\",\\n+    \\\"    r = requests.get(doi_url, headers=headers); r.raise_for_status()\\\\n\\\",\\n+    \\\"    meta = r.json()\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # 2) pull out what you care about\\\\n\\\",\\n+    \\\"    authors = [f\\\\\\\"{a.get('family','')} {a.get('given','')}\\\\\\\".strip()\\\\n\\\",\\n+    \\\"               for a in meta.get(\\\\\\\"author\\\\\\\", [])]\\\\n\\\",\\n+    \\\"    pubdate = \\\\\\\"-\\\\\\\".join(str(x) for x in meta.get(\\\\\\\"issued\\\\\\\",{}).get(\\\\\\\"date-parts\\\\\\\",[[]])[0])\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # 3) assemble one nested dict\\\\n\\\",\\n+    \\\"    public_datasetRepository_metadata = {\\\\n\\\",\\n+    \\\"      \\\\\\\"zenodo\\\\\\\": {\\\\n\\\",\\n+    \\\"        \\\\\\\"title\\\\\\\":     meta.get(\\\\\\\"title\\\\\\\"),\\\\n\\\",\\n+    \\\"        \\\\\\\"doi\\\\\\\":       meta.get(\\\\\\\"DOI\\\\\\\"),\\\\n\\\",\\n+    \\\"        \\\\\\\"authors\\\\\\\":   authors,\\\\n\\\",\\n+    \\\"        \\\\\\\"published\\\\\\\": pubdate,\\\\n\\\",\\n+    \\\"        \\\\\\\"publisher\\\\\\\": meta.get(\\\\\\\"publisher\\\\\\\"),\\\\n\\\",\\n+    \\\"      },\\\\n\\\",\\n+    \\\"   \\\\n\\\",\\n+    \\\"    }\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"      # 4) log it as a single JSON artifact\\\\n\\\",\\n+    \\\"    mlflow.log_dict(public_datasetRepository_metadata,\\\\n\\\",\\n+    \\\"                \\\\\\\"public_datasetRepository_metadata.json\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # 2) Flatten and log the important bits as params:\\\\n\\\",\\n+    \\\"    z = public_datasetRepository_metadata[\\\\\\\"zenodo\\\\\\\"]\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    mlflow.log_param(\\\\\\\"dataset.title\\\\\\\",     z[\\\\\\\"title\\\\\\\"])\\\\n\\\",\\n+    \\\"    mlflow.log_param(\\\\\\\"dataset.doi\\\\\\\",       z[\\\\\\\"doi\\\\\\\"])\\\\n\\\",\\n+    \\\"    mlflow.log_param(\\\\\\\"dataset.authors\\\\\\\",   json.dumps(z[\\\\\\\"authors\\\\\\\"]))\\\\n\\\",\\n+    \\\"    mlflow.log_param(\\\\\\\"dataset.published\\\\\\\", z[\\\\\\\"published\\\\\\\"])\\\\n\\\",\\n+    \\\"    mlflow.log_param(\\\\\\\"dataset.publisher\\\\\\\", z[\\\\\\\"publisher\\\\\\\"])\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"   \\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"58c92e13-eb57-418d-b354-83777f88aa98\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"##################################################################\\\\n\\\",\\n+    \\\"# DATA PREPROCESSING STEPS\\\\n\\\",\\n+    \\\"###################################################################\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"9832d0df-af0a-4eee-90d0-fab926e03e85\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"STEP 1: LOAD DATASET\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 39,\\n+   \\\"id\\\": \\\"77402d80-22d1-4bed-9489-768958c3e9fa\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [],\\n+   \\\"source\\\": [\\n+    \\\"# \\u2500\\u2500 2) Load into a DataFrame \\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\\\n\\\",\\n+    \\\"df = pd.DataFrame(dataset)\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"6862e341-3ea1-43f6-a1ac-9a51188fe614\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"STEP2: seperate Dependent and Independent variables and drop unnecessary columns like ID\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 40,\\n+   \\\"id\\\": \\\"01309a7b-53d2-4df4-b334-0f0db8b03333\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"Shapes: (150, 4) (150,)\\\\n\\\"\\n+     ]\\n+    }\\n+   ],\\n+   \\\"source\\\": [\\n+    \\\"target_col = df.columns[-1]      # e.g. \\\\\\\"species\\\\\\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# 2) extract y as the Series of labels\\\\n\\\",\\n+    \\\"y = df[target_col]               # length == n_samples\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# 3) build X by dropping just that one column\\\\n\\\",\\n+    \\\"X = df.drop(columns=[target_col])\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# 4) drop any ID column (case-insensitive)\\\\n\\\",\\n+    \\\"id_cols = [c for c in X.columns if c.lower() == \\\\\\\"id\\\\\\\"]\\\\n\\\",\\n+    \\\"if id_cols:\\\\n\\\",\\n+    \\\"    X = X.drop(columns=id_cols)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# 5) coerce numeric where possible\\\\n\\\",\\n+    \\\"for c in X.columns:\\\\n\\\",\\n+    \\\"    try:\\\\n\\\",\\n+    \\\"        X[c] = pd.to_numeric(X[c])\\\\n\\\",\\n+    \\\"    except Exception:\\\\n\\\",\\n+    \\\"        pass\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"print(\\\\\\\"Shapes:\\\\\\\", X.shape, y.shape)\\\\n\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"367d6256-a30a-4f91-bc64-f20966d828ab\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"STEP3: Label Encoding as the target values are class names\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 41,\\n+   \\\"id\\\": \\\"11f5126d-6a03-48c6-9ecf-39ed0d43688c\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"Classes: ['Iris-setosa' 'Iris-versicolor' 'Iris-virginica']\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"data\\\": {\\n+      \\\"text/plain\\\": [\\n+       \\\"array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\\\\n\\\",\\n+       \\\"       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\\\\n\\\",\\n+       \\\"       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\\\\n\\\",\\n+       \\\"       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\\\\n\\\",\\n+       \\\"       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\\\\n\\\",\\n+       \\\"       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\\\\n\\\",\\n+       \\\"       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\\\"\\n+      ]\\n+     },\\n+     \\\"execution_count\\\": 41,\\n+     \\\"metadata\\\": {},\\n+     \\\"output_type\\\": \\\"execute_result\\\"\\n+    }\\n+   ],\\n+   \\\"source\\\": [\\n+    \\\"\\\\n\\\",\\n+    \\\"le = LabelEncoder()\\\\n\\\",\\n+    \\\"y = le.fit_transform(y)  \\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# now y_enc is a 1d numpy array of ints 0,1,2\\\\n\\\",\\n+    \\\"print(\\\\\\\"Classes:\\\\\\\", le.classes_)  \\\\n\\\",\\n+    \\\"y\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 42,\\n+   \\\"id\\\": \\\"68d0a924-c65f-4a44-a5cc-bbb32d17e96f\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [],\\n+   \\\"source\\\": [\\n+    \\\"# \\u2500\\u2500 4) Cast feature columns to numeric where possible \\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\\\n\\\",\\n+    \\\"for col in X.columns:\\\\n\\\",\\n+    \\\"    try:\\\\n\\\",\\n+    \\\"        X[col] = pd.to_numeric(X[col])   # no errors=\\\\\\\"ignore\\\\\\\"\\\\n\\\",\\n+    \\\"    except ValueError:\\\\n\\\",\\n+    \\\"        # if it can\\u2019t be cast, just leave it as-is\\\\n\\\",\\n+    \\\"        pass\\\\n\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 43,\\n+   \\\"id\\\": \\\"e17f39ce-3322-4626-83a6-079d304bbc04\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [],\\n+   \\\"source\\\": [\\n+    \\\"# \\u2500\\u2500 5) Drop any \\u201cid\\u201d column (case-insensitive) \\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\\\n\\\",\\n+    \\\"dropped = [c for c in X.columns if c.lower() == \\\\\\\"id\\\\\\\"]\\\\n\\\",\\n+    \\\"X = X.drop(columns=dropped, errors=\\\\\\\"ignore\\\\\\\")\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"6fcf2244-14dd-4e3d-b8cf-f7f3ba34f80f\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"# \\ud83d\\udcc2 Setup MLflow\\\\n\\\",\\n+    \\\"# ============================\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 44,\\n+   \\\"id\\\": \\\"cbe91ec0-6447-4586-b7cc-2c1f74d4218f\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [\\n+    {\\n+     \\\"data\\\": {\\n+      \\\"text/plain\\\": [\\n+       \\\"<Experiment: artifact_location='file:///C:/Users/reema/REPO/notebooks/RQ_notebooks/mlrunlogs/mlflow.db/615223710259862608', creation_time=1745329164532, experiment_id='615223710259862608', last_update_time=1745329164532, lifecycle_stage='active', name='RandomForest-Iris-CSV', tags={}>\\\"\\n+      ]\\n+     },\\n+     \\\"execution_count\\\": 44,\\n+     \\\"metadata\\\": {},\\n+     \\\"output_type\\\": \\\"execute_result\\\"\\n+    }\\n+   ],\\n+   \\\"source\\\": [\\n+    \\\"\\\\n\\\",\\n+    \\\"project_dir = os.getcwd()\\\\n\\\",\\n+    \\\"mlflow.set_tracking_uri(\\\\\\\"mlrunlogs/mlflow.db\\\\\\\")\\\\n\\\",\\n+    \\\"mlflow.set_experiment(\\\\\\\"RandomForest-Iris-CSV\\\\\\\")\\\\n\\\",\\n+    \\\"# mlflow.sklearn.autolog()\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"af2c2c5f-cc36-41a3-9643-83ef95b9f55e\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"# \\ud83d\\udd04 Git Commit Hash for previous commit for metadata\\\\n\\\",\\n+    \\\"# ============================\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 45,\\n+   \\\"id\\\": \\\"838dd233-25dc-4725-974d-4da89c257782\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [],\\n+   \\\"source\\\": [\\n+    \\\"\\\\n\\\",\\n+    \\\"repo_dir = \\\\\\\"C:/Users/reema/REPO\\\\\\\"\\\\n\\\",\\n+    \\\"previous_commit_repo = git.Repo(repo_dir)\\\\n\\\",\\n+    \\\"previous_commit_hash = previous_commit_repo.head.object.hexsha\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"430d15ef-3432-4e45-88fb-b7048a5b10a9\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"# Make threadpoolctl safe so MLflow\\u2019s autologger won\\u2019t crash \\u2500\\u2500\\u2500\\\\n\\\",\\n+    \\\"# ============================\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 46,\\n+   \\\"id\\\": \\\"9668451f-4352-4bdc-8b6b-bbe49074212a\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [\\n+    {\\n+     \\\"name\\\": \\\"stderr\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"2025/04/25 11:57:54 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\\\\n\\\",\\n+      \\\"2025/04/25 11:57:54 INFO mlflow.tracking.fluent: Autologging successfully enabled for statsmodels.\\\\n\\\"\\n+     ]\\n+    }\\n+   ],\\n+   \\\"source\\\": [\\n+    \\\"try:\\\\n\\\",\\n+    \\\"    import threadpoolctl\\\\n\\\",\\n+    \\\"    _orig = threadpoolctl.threadpool_info\\\\n\\\",\\n+    \\\"    def _safe_threadpool_info(*args, **kwargs):\\\\n\\\",\\n+    \\\"        try:\\\\n\\\",\\n+    \\\"            return _orig(*args, **kwargs)\\\\n\\\",\\n+    \\\"        except Exception:\\\\n\\\",\\n+    \\\"            return []\\\\n\\\",\\n+    \\\"    threadpoolctl.threadpool_info = _safe_threadpool_info\\\\n\\\",\\n+    \\\"except ImportError:\\\\n\\\",\\n+    \\\"    pass  # if threadpoolctl isn\\u2019t installed, autolog will skip unsupported versions\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# \\u2500\\u2500\\u2500 1) Enable generic autolog (will auto-patch sklearn under the hood) \\u2500\\u2500\\u2500\\\\n\\\",\\n+    \\\"import mlflow\\\\n\\\",\\n+    \\\"mlflow.autolog(\\\\n\\\",\\n+    \\\"    log_input_examples=True,\\\\n\\\",\\n+    \\\"    log_model_signatures=True\\\\n\\\",\\n+    \\\")\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"cba22f52-178f-48e6-a9e0-7ef23a886f01\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"#################################################\\\\n\\\",\\n+    \\\"# Justification LOGGER\\\\n\\\",\\n+    \\\"################################################\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 80,\\n+   \\\"id\\\": \\\"afb626b4-8532-4011-bdc8-7424a6289bb7\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [],\\n+   \\\"source\\\": []\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"9058319a-adba-4a6b-93e9-d17080c0594d\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"# \\ud83d\\ude80 Start MLflow Run \\\\n\\\",\\n+    \\\"# ============================\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 83,\\n+   \\\"id\\\": \\\"14c62f08-a116-4060-9689-f69968e9f240\\\",\\n+   \\\"metadata\\\": {\\n+    \\\"scrolled\\\": true\\n+   },\\n+   \\\"outputs\\\": [\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\\\n\\\",\\n+      \\\"\\ud83d\\udcdd Justification for `n_estimators` (Hyperparameter configuration)\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdin\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\u2192 Why did you choose this value?  GRID SEARCH suggesstion\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\\\n\\\",\\n+      \\\"\\ud83d\\udcdd Justification for `criterion` (Hyperparameter configuration)\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdin\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\u2192 Why did you choose this value?  GRID SEARCH suggesstion\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\\\n\\\",\\n+      \\\"\\ud83d\\udcdd Justification for `max_depth` (Hyperparameter configuration)\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdin\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\u2192 Why did you choose this value?  GRID SEARCH suggesstion\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\\\n\\\",\\n+      \\\"\\ud83d\\udcdd Justification for `min_samples_split` (Hyperparameter configuration)\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdin\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\u2192 Why did you choose this value?  GRID SEARCH suggesstion\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\\\n\\\",\\n+      \\\"\\ud83d\\udcdd Justification for `min_samples_leaf` (Hyperparameter configuration)\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdin\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\u2192 Why did you choose this value?  GRID SEARCH suggesstion\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\\\n\\\",\\n+      \\\"\\ud83d\\udcdd Justification for `max_features` (Hyperparameter configuration)\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdin\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\u2192 Why did you choose this value?  GRID SEARCH suggesstion\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\\\n\\\",\\n+      \\\"\\ud83d\\udcdd Justification for `bootstrap` (Hyperparameter configuration)\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdin\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\u2192 Why did you choose this value?  GRID SEARCH suggesstion\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\\\n\\\",\\n+      \\\"\\ud83d\\udcdd Justification for `oob_score` (Hyperparameter configuration)\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdin\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\u2192 Why did you choose this value?  GRID SEARCH suggesstion\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\\\n\\\",\\n+      \\\"\\ud83d\\udcdd Justification for `class_weight` (Hyperparameter configuration)\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdin\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\u2192 Why did you choose this value?  GRID SEARCH suggesstion\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\\\n\\\",\\n+      \\\"\\ud83d\\udcdd Justification for `random_state` (Hyperparameter configuration)\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdin\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\u2192 Why did you choose this value?  GRID SEARCH suggesstion\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\\\n\\\",\\n+      \\\"\\ud83d\\udcdd Justification for `verbose` (Hyperparameter configuration)\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdin\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\u2192 Why did you choose this value?  GRID SEARCH suggesstion\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\\\n\\\",\\n+      \\\"\\ud83d\\udcdd Justification for `n_jobs` (Hyperparameter configuration)\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdin\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\u2192 Why did you choose this value?  GRID SEARCH suggesstion\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\\\n\\\",\\n+      \\\"\\ud83d\\udcdd Justification for `model_choice`\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdin\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\u2192 Why did you choose RandomForestClassifier for this task?  easy model\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\\\n\\\",\\n+      \\\"\\ud83d\\udcdd Justification for `target_variable`\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdin\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\u2192 Why did you choose this column as the prediction target?  dataset info\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\\\n\\\",\\n+      \\\"\\ud83d\\udcdd Justification for `test_split`\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdin\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\u2192 Why this train/test ratio (e.g., 80/20)?  makes sense\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\\\n\\\",\\n+      \\\"\\ud83d\\udcdd Justification for `metric_choice`\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdin\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\u2192 Why accuracy/f1/ROC-AUC as your evaluation metric?  s\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\\\n\\\",\\n+      \\\"\\ud83d\\udcdd Justification for `threshold_accuracy`\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdin\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\u2192 Why 0.95 as performance threshold?  fluid atm\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\\\n\\\",\\n+      \\\"\\ud83d\\udcdd Justification for `dataset_version`\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdin\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\u2192 Why use this specific dataset version?  its available\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\\\n\\\",\\n+      \\\"\\ud83d\\udcdd Justification for `drop_column_X`\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdin\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\u2192 Why drop any specific columns from the dataset?  id\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\\\n\\\",\\n+      \\\"\\ud83d\\udcdd Justification for `experiment_name`\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdin\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\u2192 Any context behind this experiment name or setup?  makes sense\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stderr\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.0s\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    0.2s\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    0.2s finished\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Done 200 out of 200 | elapsed:    0.0s finished\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Done 200 out of 200 | elapsed:    0.0s finished\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Done 200 out of 200 | elapsed:    0.0s finished\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Done 200 out of 200 | elapsed:    0.0s finished\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Done 200 out of 200 | elapsed:    0.0s finished\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"data\\\": {\\n+      \\\"application/vnd.jupyter.widget-view+json\\\": {\\n+       \\\"model_id\\\": \\\"a64e4f0522d8493995df18aaaba889fc\\\",\\n+       \\\"version_major\\\": 2,\\n+       \\\"version_minor\\\": 0\\n+      },\\n+      \\\"text/plain\\\": [\\n+       \\\"Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]\\\"\\n+      ]\\n+     },\\n+     \\\"metadata\\\": {},\\n+     \\\"output_type\\\": \\\"display_data\\\"\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stderr\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Done 200 out of 200 | elapsed:    0.0s finished\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Done 200 out of 200 | elapsed:    0.0s finished\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Done 200 out of 200 | elapsed:    0.0s finished\\\\n\\\",\\n+      \\\"C:\\\\\\\\Users\\\\\\\\reema\\\\\\\\anaconda3\\\\\\\\Lib\\\\\\\\site-packages\\\\\\\\shap\\\\\\\\plots\\\\\\\\_beeswarm.py:1153: UserWarning: The figure layout has changed to tight\\\\n\\\",\\n+      \\\"  pl.tight_layout()\\\\n\\\",\\n+      \\\"C:\\\\\\\\Users\\\\\\\\reema\\\\\\\\anaconda3\\\\\\\\Lib\\\\\\\\site-packages\\\\\\\\shap\\\\\\\\plots\\\\\\\\_beeswarm.py:761: UserWarning: The figure layout has changed to tight\\\\n\\\",\\n+      \\\"  pl.tight_layout(pad=0, w_pad=0, h_pad=0.0)\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\u2705 Commit successful.\\\\n\\\",\\n+      \\\"\\ud83d\\ude80 Push successful.\\\\n\\\"\\n+     ]\\n+    }\\n+   ],\\n+   \\\"source\\\": [\\n+    \\\"\\\\n\\\",\\n+    \\\"with mlflow.start_run() as run:\\\\n\\\",\\n+    \\\"    #################################################\\\\n\\\",\\n+    \\\"# Justification LOGGER\\\\n\\\",\\n+    \\\"################################################\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    def log_with_justification(log_func, key, value, context=\\\\\\\"\\\\\\\"):\\\\n\\\",\\n+    \\\"        \\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\",\\n+    \\\"        Log a parameter/metric/tag using `log_func` and ask for justification via console.\\\\n\\\",\\n+    \\\"        \\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\",\\n+    \\\"        log_func(key, value)\\\\n\\\",\\n+    \\\"        print(f\\\\\\\"\\\\\\\\n\\ud83d\\udcdd Justification for `{key}` ({context})\\\\\\\")\\\\n\\\",\\n+    \\\"        user_reason = input(\\\\\\\"\\u2192 Why did you choose this value? \\\\\\\")\\\\n\\\",\\n+    \\\"        mlflow.set_tag(f\\\\\\\"justification_{key}\\\\\\\", user_reason or \\\\\\\"No justification provided\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    def log_justification(key: str, question: str):\\\\n\\\",\\n+    \\\"        print(f\\\\\\\"\\\\\\\\n\\ud83d\\udcdd Justification for `{key}`\\\\\\\")\\\\n\\\",\\n+    \\\"        user_reason = input(f\\\\\\\"\\u2192 {question} \\\\\\\")\\\\n\\\",\\n+    \\\"        mlflow.set_tag(f\\\\\\\"justification_{key}\\\\\\\", user_reason or \\\\\\\"No justification provided\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    meta = fetch_and_log_dataset_metadata_nested(\\\\n\\\",\\n+    \\\"            \\\\\\\"https://doi.org/10.5281/zenodo.1404173\\\\\\\",\\\\n\\\",\\n+    \\\"           \\\\n\\\",\\n+    \\\"        )\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    #Datasbase info logging\\\\n\\\",\\n+    \\\"    db_id = \\\\\\\"c3a42d17-42b7-43c9-a504-2363fb4c9c8d\\\\\\\"\\\\n\\\",\\n+    \\\"    db_meta = fetch_db_metadata(db_id)\\\\n\\\",\\n+    \\\"    log_db_metadata(db_meta)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    #OAI metadata logging from api endpoint\\\\n\\\",\\n+    \\\"    # log as tags\\\\n\\\",\\n+    \\\"    mlflow.set_tag(\\\\\\\"dbrepo.repository_name\\\\\\\", repo_name)\\\\n\\\",\\n+    \\\"    mlflow.set_tag(\\\\\\\"dbrepo.base_url\\\\\\\",       base_url)\\\\n\\\",\\n+    \\\"    mlflow.set_tag(\\\\\\\"dbrepo.protocol_version\\\\\\\", protocol)\\\\n\\\",\\n+    \\\"    mlflow.set_tag(\\\\\\\"dbrepo.admin_email\\\\\\\",     admin_email)\\\\n\\\",\\n+    \\\"    mlflow.set_tag(\\\\\\\"dbrepo.granularity\\\\\\\",     gran)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    #From history API logging\\\\n\\\",\\n+    \\\"    # provenance tags\\\\n\\\",\\n+    \\\"    mlflow.set_tag(\\\\\\\"dbrepo.table_last_modified\\\\\\\", ts_last)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # row-count metrics\\\\n\\\",\\n+    \\\"    mlflow.log_metric(\\\\\\\"dbrepo.row_count_start\\\\\\\", count_start)\\\\n\\\",\\n+    \\\"    mlflow.log_metric(\\\\\\\"dbrepo.row_count_end\\\\\\\",   count_end)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # change-event metrics\\\\n\\\",\\n+    \\\"    mlflow.log_metric(\\\\\\\"dbrepo.num_inserts\\\\\\\", n_insert)\\\\n\\\",\\n+    \\\"    mlflow.log_metric(\\\\\\\"dbrepo.num_deletes\\\\\\\", n_delete)\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    # 2) Capture raw metadata\\\\n\\\",\\n+    \\\"    mlflow.set_tag(\\\\\\\"data_source\\\\\\\", API_URL)\\\\n\\\",\\n+    \\\"    mlflow.log_param(\\\\\\\"retrieval_time\\\\\\\", datetime.utcnow().isoformat())\\\\n\\\",\\n+    \\\"    mlflow.log_param(\\\\\\\"n_records\\\\\\\", len(df))\\\\n\\\",\\n+    \\\"    mlflow.log_param(\\\\\\\"columns_raw\\\\\\\", df.columns.tolist())\\\\n\\\",\\n+    \\\"    mlflow.log_param(\\\\\\\"dropped_columns\\\\\\\", id_cols)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # 4) Post\\u2010processing metadata\\\\n\\\",\\n+    \\\"    mlflow.log_param(\\\\\\\"n_features_final\\\\\\\", X.shape[1])\\\\n\\\",\\n+    \\\"    mlflow.log_param(\\\\\\\"feature_names\\\\\\\", X.columns.tolist())\\\\n\\\",\\n+    \\\"    mlflow.set_tag(\\\\\\\"target_name\\\\\\\", y)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"       # Label encoding\\\\n\\\",\\n+    \\\"    label_map = {int(idx): cls for idx, cls in enumerate(le.classes_)}\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    # Save to an in-memory file\\\\n\\\",\\n+    \\\"    buffer = io.StringIO()\\\\n\\\",\\n+    \\\"    json.dump(label_map, buffer, indent=2)\\\\n\\\",\\n+    \\\"    buffer.seek(0)\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    # Log it to MLflow\\\\n\\\",\\n+    \\\"    mlflow.log_text(buffer.getvalue(), artifact_file=\\\\\\\"label_mapping.json\\\\\\\")\\\\n\\\",\\n+    \\\"   \\\\n\\\",\\n+    \\\"    ts = datetime.now().strftime(\\\\\\\"%Y%m%d_%H%M%S\\\\\\\")\\\\n\\\",\\n+    \\\"    model_name = f\\\\\\\"RandomForest_Iris_v{ts}\\\\\\\"\\\\n\\\",\\n+    \\\"    mlflow.set_tag(\\\\\\\"model_name\\\\\\\",model_name)\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    train_start_ts = datetime.now().isoformat()\\\\n\\\",\\n+    \\\"    mlflow.set_tag(\\\\\\\"training_start_time\\\\\\\", train_start_ts)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    test_size    = 0.2\\\\n\\\",\\n+    \\\"    random_state = 42\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    # \\ud83d\\udcc8 Model Training\\\\n\\\",\\n+    \\\"    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    # \\u2500\\u2500 2) Log dataset split params \\u2500\\u2500\\\\n\\\",\\n+    \\\"    mlflow.log_param(\\\\\\\"test_size\\\\\\\", test_size)\\\\n\\\",\\n+    \\\"    mlflow.log_param(\\\\\\\"random_state\\\\\\\", random_state)\\\\n\\\",\\n+    \\\"    mlflow.log_param(\\\\\\\"n_train_samples\\\\\\\", X_train.shape[0])\\\\n\\\",\\n+    \\\"    mlflow.log_param(\\\\\\\"n_test_samples\\\\\\\",  X_test.shape[0])\\\\n\\\",\\n+    \\\"    mlflow.log_param(\\\\\\\"n_features\\\\\\\",      X_train.shape[1])\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"     # 1) Define a more complex hyperparameter dict\\\\n\\\",\\n+    \\\"    hyperparams = {\\\\n\\\",\\n+    \\\"        \\\\\\\"n_estimators\\\\\\\":       200,\\\\n\\\",\\n+    \\\"        \\\\\\\"criterion\\\\\\\":          \\\\\\\"entropy\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"max_depth\\\\\\\":          12,\\\\n\\\",\\n+    \\\"        \\\\\\\"min_samples_split\\\\\\\":  5,\\\\n\\\",\\n+    \\\"        \\\\\\\"min_samples_leaf\\\\\\\":   2,\\\\n\\\",\\n+    \\\"        \\\\\\\"max_features\\\\\\\":       \\\\\\\"sqrt\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"bootstrap\\\\\\\":          True,\\\\n\\\",\\n+    \\\"        \\\\\\\"oob_score\\\\\\\":          False,\\\\n\\\",\\n+    \\\"        \\\\\\\"class_weight\\\\\\\":       None,\\\\n\\\",\\n+    \\\"        \\\\\\\"random_state\\\\\\\":       42,\\\\n\\\",\\n+    \\\"        \\\\\\\"verbose\\\\\\\":            1,\\\\n\\\",\\n+    \\\"        \\\\\\\"n_jobs\\\\\\\":             -1\\\\n\\\",\\n+    \\\"    }\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    # 2) Log them ALL at once\\\\n\\\",\\n+    \\\"    mlflow.log_params(hyperparams)\\\\n\\\",\\n+    \\\"    model = RandomForestClassifier(**hyperparams)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    for key, val in hyperparams.items():\\\\n\\\",\\n+    \\\"        log_with_justification(mlflow.log_param, key, val, context=\\\\\\\"Hyperparameter configuration\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # Prompt for and log justifications for high-level modeling decisions\\\\n\\\",\\n+    \\\"    log_justification(\\\\\\\"model_choice\\\\\\\", \\\\\\\"Why did you choose RandomForestClassifier for this task?\\\\\\\")\\\\n\\\",\\n+    \\\"    log_justification(\\\\\\\"target_variable\\\\\\\", \\\\\\\"Why did you choose this column as the prediction target?\\\\\\\")\\\\n\\\",\\n+    \\\"    log_justification(\\\\\\\"test_split\\\\\\\", \\\\\\\"Why this train/test ratio (e.g., 80/20)?\\\\\\\")\\\\n\\\",\\n+    \\\"    log_justification(\\\\\\\"metric_choice\\\\\\\", \\\\\\\"Why accuracy/f1/ROC-AUC as your evaluation metric?\\\\\\\")\\\\n\\\",\\n+    \\\"    log_justification(\\\\\\\"threshold_accuracy\\\\\\\", \\\\\\\"Why 0.95 as performance threshold?\\\\\\\")\\\\n\\\",\\n+    \\\"    log_justification(\\\\\\\"dataset_version\\\\\\\", \\\\\\\"Why use this specific dataset version?\\\\\\\")\\\\n\\\",\\n+    \\\"    log_justification(\\\\\\\"drop_column_X\\\\\\\", \\\\\\\"Why drop any specific columns from the dataset?\\\\\\\")\\\\n\\\",\\n+    \\\"    log_justification(\\\\\\\"experiment_name\\\\\\\", \\\\\\\"Any context behind this experiment name or setup?\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    model.fit(X_train, y_train)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    train_end_ts = datetime.now().isoformat()\\\\n\\\",\\n+    \\\"    mlflow.set_tag(\\\\\\\"training_end_time\\\\\\\", train_end_ts)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"     # \\u2500\\u2500 6) Predict & log metrics \\u2500\\u2500\\\\n\\\",\\n+    \\\"    y_pred = model.predict(X_test)\\\\n\\\",\\n+    \\\"    y_proba = model.predict_proba(X_test)\\\\n\\\",\\n+    \\\"    acc = accuracy_score(y_test, y_pred)\\\\n\\\",\\n+    \\\"    auc = roc_auc_score(y_test, y_proba, multi_class=\\\\\\\"ovr\\\\\\\")\\\\n\\\",\\n+    \\\"    prec = precision_score(y_test, y_pred, average=\\\\\\\"macro\\\\\\\")\\\\n\\\",\\n+    \\\"    rec  = recall_score(y_test,    y_pred, average=\\\\\\\"macro\\\\\\\")\\\\n\\\",\\n+    \\\"    f1   = f1_score(y_test,      y_pred, average=\\\\\\\"macro\\\\\\\")\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    mlflow.log_metric(\\\\\\\"precision_macro\\\\\\\", prec)\\\\n\\\",\\n+    \\\"    mlflow.log_metric(\\\\\\\"recall_macro\\\\\\\",    rec)\\\\n\\\",\\n+    \\\"    mlflow.log_metric(\\\\\\\"f1_macro\\\\\\\",        f1)\\\\n\\\",\\n+    \\\"    mlflow.log_metric(\\\\\\\"accuracy\\\\\\\", acc)\\\\n\\\",\\n+    \\\"    mlflow.log_metric(\\\\\\\"roc_auc\\\\\\\",   auc)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # \\u2705 Log Environment Automatically\\\\n\\\",\\n+    \\\"    mlflow.log_params({\\\\n\\\",\\n+    \\\"        \\\\\\\"python_version\\\\\\\": platform.python_version(),\\\\n\\\",\\n+    \\\"        \\\\\\\"os_platform\\\\\\\": f\\\\\\\"{platform.system()} {platform.release()}\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"sklearn_version\\\\\\\": sklearn.__version__,\\\\n\\\",\\n+    \\\"        \\\\\\\"pandas_version\\\\\\\": pd.__version__,\\\\n\\\",\\n+    \\\"        \\\\\\\"numpy_version\\\\\\\": np.__version__,\\\\n\\\",\\n+    \\\"        \\\\\\\"matplotlib_version\\\\\\\": matplotlib.__version__,\\\\n\\\",\\n+    \\\"        \\\\\\\"seaborn_version\\\\\\\": sns.__version__,\\\\n\\\",\\n+    \\\"        \\\\\\\"shap_version\\\\\\\": shap.__version__,\\\\n\\\",\\n+    \\\"    })\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # \\u2705 Git and Notebook Metadata\\\\n\\\",\\n+    \\\"    mlflow.set_tag(\\\\\\\"notebook_name\\\\\\\", \\\\\\\"RQ1.ipynb\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # \\u2705 Dataset Metadata Tags\\\\n\\\",\\n+    \\\"    mlflow.set_tag(\\\\\\\"dataset_name\\\\\\\", \\\\\\\"Iris\\\\\\\") #TODO\\\\n\\\",\\n+    \\\"    mlflow.set_tag(\\\\\\\"dataset_version\\\\\\\", \\\\\\\"1.0.0\\\\\\\") #TODO\\\\n\\\",\\n+    \\\"    mlflow.set_tag(\\\\\\\"dataset_id\\\\\\\", \\\\\\\"iris_local\\\\\\\") #TODO\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # \\u2500\\u2500\\u2500 2) Create a folder for this run\\u2019s plots \\u2500\\u2500\\u2500\\\\n\\\",\\n+    \\\"    plot_dir = os.path.join(\\\\\\\"plots\\\\\\\", model_name)\\\\n\\\",\\n+    \\\"    os.makedirs(plot_dir, exist_ok=True)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # 1) Feature Importance Bar Chart\\\\n\\\",\\n+    \\\"    importances = model.feature_importances_\\\\n\\\",\\n+    \\\"    try:\\\\n\\\",\\n+    \\\"        feature_names = X_train.columns\\\\n\\\",\\n+    \\\"    except AttributeError:\\\\n\\\",\\n+    \\\"        feature_names = [f\\\\\\\"f{i}\\\\\\\" for i in range(X_train.shape[1])]\\\\n\\\",\\n+    \\\"    fi_path = os.path.join(plot_dir, \\\\\\\"feature_importances.png\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    plt.figure(figsize=(8, 6))\\\\n\\\",\\n+    \\\"    sns.barplot(x=importances, y=feature_names)\\\\n\\\",\\n+    \\\"    plt.title(\\\\\\\"Feature Importances\\\\\\\")\\\\n\\\",\\n+    \\\"    plt.xlabel(\\\\\\\"Importance\\\\\\\")\\\\n\\\",\\n+    \\\"    plt.ylabel(\\\\\\\"Feature\\\\\\\")\\\\n\\\",\\n+    \\\"    plt.tight_layout()\\\\n\\\",\\n+    \\\"    plt.savefig(fi_path)\\\\n\\\",\\n+    \\\"    mlflow.log_artifact(fi_path)\\\\n\\\",\\n+    \\\"    plt.close()\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# 2) Multi-class ROC Curves\\\\n\\\",\\n+    \\\"# Binarize labels for one-vs-rest\\\\n\\\",\\n+    \\\"    classes = np.unique(y_test)\\\\n\\\",\\n+    \\\"    y_test_bin = label_binarize(y_test, classes=classes)\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    for idx, cls in enumerate(classes):\\\\n\\\",\\n+    \\\"        disp = RocCurveDisplay.from_predictions(\\\\n\\\",\\n+    \\\"            y_test_bin[:, idx], \\\\n\\\",\\n+    \\\"            y_proba[:, idx],\\\\n\\\",\\n+    \\\"            name=f\\\\\\\"ROC for class {cls}\\\\\\\"\\\\n\\\",\\n+    \\\"        )\\\\n\\\",\\n+    \\\"        roc_path = os.path.join(plot_dir, f\\\\\\\"roc_curve_cls_{cls}.png\\\\\\\")\\\\n\\\",\\n+    \\\"        disp.figure_.savefig(roc_path)\\\\n\\\",\\n+    \\\"        mlflow.log_artifact(roc_path)\\\\n\\\",\\n+    \\\"        plt.close(disp.figure_)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # 3) Multi-class Precision-Recall Curves\\\\n\\\",\\n+    \\\"    for idx, cls in enumerate(classes):\\\\n\\\",\\n+    \\\"        disp = PrecisionRecallDisplay.from_predictions(\\\\n\\\",\\n+    \\\"            y_test_bin[:, idx], \\\\n\\\",\\n+    \\\"            y_proba[:, idx],\\\\n\\\",\\n+    \\\"            name=f\\\\\\\"PR curve for class {cls}\\\\\\\"\\\\n\\\",\\n+    \\\"        )\\\\n\\\",\\n+    \\\"        pr_path = os.path.join(plot_dir, f\\\\\\\"pr_curve_cls_{cls}.png\\\\\\\")\\\\n\\\",\\n+    \\\"        disp.figure_.savefig(pr_path)\\\\n\\\",\\n+    \\\"        mlflow.log_artifact(pr_path)\\\\n\\\",\\n+    \\\"        plt.close(disp.figure_)\\\\n\\\",\\n+    \\\"        \\\\n\\\",\\n+    \\\"    # \\u2705 Confusion Matrix Plot\\\\n\\\",\\n+    \\\"    cm_path = os.path.join(plot_dir, \\\\\\\"confusion_matrix.png\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    cm = confusion_matrix(y_test, y_pred)\\\\n\\\",\\n+    \\\"    plt.figure(figsize=(6, 6))\\\\n\\\",\\n+    \\\"    sns.heatmap(cm, annot=True, fmt=\\\\\\\"d\\\\\\\", cmap=\\\\\\\"Blues\\\\\\\")\\\\n\\\",\\n+    \\\"    plt.title(\\\\\\\"Confusion Matrix\\\\\\\")\\\\n\\\",\\n+    \\\"    plt.xlabel(\\\\\\\"Predicted\\\\\\\")\\\\n\\\",\\n+    \\\"    plt.ylabel(\\\\\\\"Actual\\\\\\\")\\\\n\\\",\\n+    \\\"    plt.savefig(cm_path)\\\\n\\\",\\n+    \\\"    mlflow.log_artifact(cm_path)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # \\u2705 SHAP Summary\\\\n\\\",\\n+    \\\"    shap_path = os.path.join(plot_dir, \\\\\\\"shap_summary.png\\\\\\\")\\\\n\\\",\\n+    \\\"    explainer = shap.TreeExplainer(model)\\\\n\\\",\\n+    \\\"    shap_values = explainer.shap_values(X_test)\\\\n\\\",\\n+    \\\"    shap.summary_plot(shap_values, X_test, show=False)\\\\n\\\",\\n+    \\\"    plt.savefig(shap_path)\\\\n\\\",\\n+    \\\"    mlflow.log_artifact(shap_path)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    # \\u2500\\u2500\\u2500 1) Build a .pkl filename (you can include your model_name for clarity)\\\\n\\\",\\n+    \\\"    pkl_path = f\\\\\\\"Trained_models/{model_name}.pkl\\\\\\\"\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    # \\u2500\\u2500\\u2500 2) Serialize your trained model to disk\\\\n\\\",\\n+    \\\"    with open(pkl_path, \\\\\\\"wb\\\\\\\") as f:\\\\n\\\",\\n+    \\\"        pickle.dump(model, f)\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    # \\u2500\\u2500\\u2500 3) Log that pickle file as an MLflow artifact\\\\n\\\",\\n+    \\\"    #     It will appear under Artifacts \\u2192 models/RandomForest_Iris_vYYYYMMDD_HHMMSS.pkl\\\\n\\\",\\n+    \\\"    mlflow.log_artifact(pkl_path, artifact_path=model_name)\\\\n\\\",\\n+    \\\"        \\\\n\\\",\\n+    \\\"    def get_latest_commit_hash(repo_path=\\\\\\\".\\\\\\\"):\\\\n\\\",\\n+    \\\"        # returns the full SHA of HEAD\\\\n\\\",\\n+    \\\"        res = subprocess.run(\\\\n\\\",\\n+    \\\"            [\\\\\\\"git\\\\\\\", \\\\\\\"-C\\\\\\\", repo_path, \\\\\\\"rev-parse\\\\\\\", \\\\\\\"HEAD\\\\\\\"],\\\\n\\\",\\n+    \\\"            capture_output=True, text=True, check=True)\\\\n\\\",\\n+    \\\"        \\\\n\\\",\\n+    \\\"        return res.stdout.strip()\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    def get_remote_url(repo_path=\\\\\\\".\\\\\\\", remote=\\\\\\\"origin\\\\\\\"):\\\\n\\\",\\n+    \\\"        # returns something like git@github.com:user/repo.git or https://...\\\\n\\\",\\n+    \\\"        res = subprocess.run(\\\\n\\\",\\n+    \\\"            [\\\\\\\"git\\\\\\\", \\\\\\\"-C\\\\\\\", repo_path, \\\\\\\"config\\\\\\\", \\\\\\\"--get\\\\\\\", f\\\\\\\"remote.{remote}.url\\\\\\\"],\\\\n\\\",\\n+    \\\"            capture_output=True, text=True, check=True\\\\n\\\",\\n+    \\\"        )\\\\n\\\",\\n+    \\\"        return res.stdout.strip()\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    def make_commit_link(remote_url, commit_hash):\\\\n\\\",\\n+    \\\"        # handle GitHub/GitLab convention; strip \\u201c.git\\u201d if present\\\\n\\\",\\n+    \\\"        base = remote_url.rstrip(\\\\\\\".git\\\\\\\")\\\\n\\\",\\n+    \\\"        # if SSH form (git@github.com:owner/repo), convert to https\\\\n\\\",\\n+    \\\"        if base.startswith(\\\\\\\"git@\\\\\\\"):\\\\n\\\",\\n+    \\\"            base = base.replace(\\\\\\\":\\\\\\\", \\\\\\\"/\\\\\\\").replace(\\\\\\\"git@\\\\\\\", \\\\\\\"https://\\\\\\\")\\\\n\\\",\\n+    \\\"        return f\\\\\\\"{base}/commit/{commit_hash}\\\\\\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    def simple_commit_and_push_and_log(repo_path=\\\\\\\".\\\\\\\", message=\\\\\\\"Auto commit\\\\\\\", remote=\\\\\\\"origin\\\\\\\", branch=\\\\\\\"main\\\\\\\"):\\\\n\\\",\\n+    \\\"    # 1) Check for changes\\\\n\\\",\\n+    \\\"        status = subprocess.run(\\\\n\\\",\\n+    \\\"            [\\\\\\\"git\\\\\\\", \\\\\\\"-C\\\\\\\", repo_path, \\\\\\\"status\\\\\\\", \\\\\\\"--porcelain\\\\\\\"],\\\\n\\\",\\n+    \\\"            capture_output=True, text=True\\\\n\\\",\\n+    \\\"        )\\\\n\\\",\\n+    \\\"        if not status.stdout.strip():\\\\n\\\",\\n+    \\\"            print(\\\\\\\"\\ud83d\\udfe1 No changes to commit.\\\\\\\")\\\\n\\\",\\n+    \\\"            return None, None\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"        # 2) Stage everything\\\\n\\\",\\n+    \\\"        add = subprocess.run(\\\\n\\\",\\n+    \\\"            [\\\\\\\"git\\\\\\\", \\\\\\\"-C\\\\\\\", repo_path, \\\\\\\"add\\\\\\\", \\\\\\\"--all\\\\\\\"],\\\\n\\\",\\n+    \\\"            capture_output=True, text=True\\\\n\\\",\\n+    \\\"        )\\\\n\\\",\\n+    \\\"        if add.returncode:\\\\n\\\",\\n+    \\\"            print(\\\\\\\"\\u274c git add failed:\\\\\\\\n\\\\\\\", add.stderr)\\\\n\\\",\\n+    \\\"            return None, None\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"        # 3) Commit\\\\n\\\",\\n+    \\\"        commit = subprocess.run(\\\\n\\\",\\n+    \\\"            [\\\\\\\"git\\\\\\\", \\\\\\\"-C\\\\\\\", repo_path, \\\\\\\"commit\\\\\\\", \\\\\\\"-m\\\\\\\", message],\\\\n\\\",\\n+    \\\"            capture_output=True, text=True\\\\n\\\",\\n+    \\\"        )\\\\n\\\",\\n+    \\\"        if commit.returncode:\\\\n\\\",\\n+    \\\"            print(\\\\\\\"\\u274c git commit failed:\\\\\\\\n\\\\\\\", commit.stderr)\\\\n\\\",\\n+    \\\"            return None, None\\\\n\\\",\\n+    \\\"        print(\\\\\\\"\\u2705 Commit successful.\\\\\\\")\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"        # 4) Push\\\\n\\\",\\n+    \\\"        push = subprocess.run(\\\\n\\\",\\n+    \\\"            [\\\\\\\"git\\\\\\\", \\\\\\\"-C\\\\\\\", repo_path, \\\\\\\"push\\\\\\\", \\\\\\\"-u\\\\\\\", remote, branch],\\\\n\\\",\\n+    \\\"            capture_output=True, text=True\\\\n\\\",\\n+    \\\"        )\\\\n\\\",\\n+    \\\"        if push.returncode:\\\\n\\\",\\n+    \\\"            print(\\\\\\\"\\u274c git push failed:\\\\\\\\n\\\\\\\", push.stderr)\\\\n\\\",\\n+    \\\"        else:\\\\n\\\",\\n+    \\\"            print(\\\\\\\"\\ud83d\\ude80 Push successful.\\\\\\\")\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"        # 5) Retrieve hash & remote URL\\\\n\\\",\\n+    \\\"        sha = get_latest_commit_hash(repo_path)\\\\n\\\",\\n+    \\\"        url = get_remote_url(repo_path, remote)\\\\n\\\",\\n+    \\\"        link = make_commit_link(url, sha)\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"        return sha, link\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"      \\\\n\\\",\\n+    \\\"    sha, link = simple_commit_and_push_and_log(\\\\n\\\",\\n+    \\\"        repo_path=\\\\\\\".\\\\\\\",\\\\n\\\",\\n+    \\\"        message=\\\\\\\"Auto commit after successful training\\\\\\\"\\\\n\\\",\\n+    \\\"    )\\\\n\\\",\\n+    \\\"    if sha and link:\\\\n\\\",\\n+    \\\"        diff_text = subprocess.check_output(\\\\n\\\",\\n+    \\\"            [\\\\\\\"git\\\\\\\", \\\\\\\"-C\\\\\\\", \\\\\\\".\\\\\\\", \\\\\\\"diff\\\\\\\", previous_commit_hash, sha],\\\\n\\\",\\n+    \\\"            encoding=\\\\\\\"utf-8\\\\\\\",\\\\n\\\",\\n+    \\\"            errors=\\\\\\\"ignore\\\\\\\"    # or \\\\\\\"replace\\\\\\\"\\\\n\\\",\\n+    \\\"        )\\\\n\\\",\\n+    \\\"                \\\\n\\\",\\n+    \\\"        # 1) Get your repo\\u2019s remote URL and normalize to HTTPS\\\\n\\\",\\n+    \\\"        remote_url = subprocess.check_output(\\\\n\\\",\\n+    \\\"            [\\\\\\\"git\\\\\\\", \\\\\\\"config\\\\\\\", \\\\\\\"--get\\\\\\\", \\\\\\\"remote.origin.url\\\\\\\"],\\\\n\\\",\\n+    \\\"            text=True\\\\n\\\",\\n+    \\\"        ).strip().rstrip(\\\\\\\".git\\\\\\\")\\\\n\\\",\\n+    \\\"        if remote_url.startswith(\\\\\\\"git@\\\\\\\"):\\\\n\\\",\\n+    \\\"            # git@github.com:owner/repo.git \\u2192 https://github.com/owner/repo\\\\n\\\",\\n+    \\\"            remote_url = remote_url.replace(\\\\\\\":\\\\\\\", \\\\\\\"/\\\\\\\").replace(\\\\\\\"git@\\\\\\\", \\\\\\\"https://\\\\\\\")\\\\n\\\",\\n+    \\\"        \\\\n\\\",\\n+    \\\"        # 2) Build commit URLs\\\\n\\\",\\n+    \\\"        previous_commit_url  = f\\\\\\\"{remote_url}/commit/{previous_commit_hash}\\\\\\\"\\\\n\\\",\\n+    \\\"        current_commit_url = f\\\\\\\"{remote_url}/commit/{sha}\\\\\\\"\\\\n\\\",\\n+    \\\"        diff_data = {\\\\n\\\",\\n+    \\\"            \\\\\\\"previous_commit\\\\\\\":  previous_commit_hash,\\\\n\\\",\\n+    \\\"            \\\\\\\"previous_commit_url\\\\\\\":previous_commit_url,\\\\n\\\",\\n+    \\\"            \\\\\\\"current_commit_url\\\\\\\":current_commit_url,\\\\n\\\",\\n+    \\\"            \\\\\\\"current_commit\\\\\\\": sha,\\\\n\\\",\\n+    \\\"            \\\\\\\"diff\\\\\\\": diff_text\\\\n\\\",\\n+    \\\"        }\\\\n\\\",\\n+    \\\"        mlflow.log_dict(\\\\n\\\",\\n+    \\\"            diff_data,\\\\n\\\",\\n+    \\\"            artifact_file=\\\\\\\"commit_diff.json\\\\\\\"\\\\n\\\",\\n+    \\\"        )\\\\n\\\",\\n+    \\\"        mlflow.set_tag(\\\\\\\"git_previous_commit_hash\\\\\\\", previous_commit_hash)\\\\n\\\",\\n+    \\\"        mlflow.set_tag(\\\\\\\"git_current_commit_hash\\\\\\\", sha)\\\\n\\\",\\n+    \\\"        mlflow.set_tag(\\\\\\\"git__current_commit_url\\\\\\\", link) \\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    client   = MlflowClient()\\\\n\\\",\\n+    \\\"    run_id    = run.info.run_id\\\\n\\\",\\n+    \\\"    run_info  = client.get_run(run_id).info\\\\n\\\",\\n+    \\\"    run_data  = client.get_run(run_id).data\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    # 1) params, metrics, tags\\\\n\\\",\\n+    \\\"    params  = dict(run_data.params)\\\\n\\\",\\n+    \\\"    metrics = dict(run_data.metrics)\\\\n\\\",\\n+    \\\"    tags    = dict(run_data.tags)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # (4) List artifacts under a specific subfolder\\\\n\\\",\\n+    \\\"    run_meta     = client.get_run(run_id).info\\\\n\\\",\\n+    \\\"    artifact_uri = run_meta.artifact_uri  # base URI for all artifacts\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    artifact_meta = []\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    def _gather(path=\\\\\\\"\\\\\\\"):\\\\n\\\",\\n+    \\\"        for af in client.list_artifacts(run_id, path):\\\\n\\\",\\n+    \\\"            # If it\\u2019s a directory, recurse\\\\n\\\",\\n+    \\\"            if af.is_dir:\\\\n\\\",\\n+    \\\"                _gather(af.path)\\\\n\\\",\\n+    \\\"                continue\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"            rel_path = af.path\\\\n\\\",\\n+    \\\"            uri      = f\\\\\\\"{artifact_uri}/{rel_path}\\\\\\\"\\\\n\\\",\\n+    \\\"            lower    = rel_path.lower()\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"            # 1) Text files \\u2192 download & embed contents\\\\n\\\",\\n+    \\\"            if lower.endswith((\\\\\\\".json\\\\\\\", \\\\\\\".txt\\\\\\\", \\\\\\\".patch\\\\\\\")):\\\\n\\\",\\n+    \\\"                local = client.download_artifacts(run_id, rel_path)\\\\n\\\",\\n+    \\\"                with open(local, \\\\\\\"r\\\\\\\", encoding=\\\\\\\"utf-8\\\\\\\") as f:\\\\n\\\",\\n+    \\\"                    content = f.read()\\\\n\\\",\\n+    \\\"                artifact_meta.append({\\\\n\\\",\\n+    \\\"                    \\\\\\\"path\\\\\\\":    rel_path,\\\\n\\\",\\n+    \\\"                    \\\\\\\"type\\\\\\\":    \\\\\\\"text\\\\\\\",\\\\n\\\",\\n+    \\\"                    \\\\\\\"content\\\\\\\": content\\\\n\\\",\\n+    \\\"                })\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"            # 2) Images \\u2192 surface a clickable URI\\\\n\\\",\\n+    \\\"            elif lower.endswith((\\\\\\\".png\\\\\\\", \\\\\\\".jpg\\\\\\\", \\\\\\\".jpeg\\\\\\\", \\\\\\\".svg\\\\\\\")):\\\\n\\\",\\n+    \\\"                artifact_meta.append({\\\\n\\\",\\n+    \\\"                    \\\\\\\"path\\\\\\\": rel_path,\\\\n\\\",\\n+    \\\"                    \\\\\\\"type\\\\\\\": \\\\\\\"image\\\\\\\",\\\\n\\\",\\n+    \\\"                    \\\\\\\"uri\\\\\\\":  uri\\\\n\\\",\\n+    \\\"                })\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"            # 3) Everything else \\u2192 just link\\\\n\\\",\\n+    \\\"            else:\\\\n\\\",\\n+    \\\"                artifact_meta.append({\\\\n\\\",\\n+    \\\"                    \\\\\\\"path\\\\\\\": rel_path,\\\\n\\\",\\n+    \\\"                    \\\\\\\"type\\\\\\\": \\\\\\\"other\\\\\\\",\\\\n\\\",\\n+    \\\"                    \\\\\\\"uri\\\\\\\":  uri\\\\n\\\",\\n+    \\\"                })\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    # Run the gather\\\\n\\\",\\n+    \\\"    _gather()\\\\n\\\",\\n+    \\\"     \\\\n\\\",\\n+    \\\"    summary = {\\\\n\\\",\\n+    \\\"        \\\\\\\"run_id\\\\\\\":         run_id,\\\\n\\\",\\n+    \\\"        \\\\\\\"run_name\\\\\\\": run_info.run_name,\\\\n\\\",\\n+    \\\"        \\\\\\\"experiment_id\\\\\\\":  run_info.experiment_id,\\\\n\\\",\\n+    \\\"        \\\\\\\"start_time\\\\\\\":     run_info.start_time,\\\\n\\\",\\n+    \\\"        \\\\\\\"end_time\\\\\\\":       run_info.end_time,\\\\n\\\",\\n+    \\\"        \\\\\\\"params\\\\\\\":         params,\\\\n\\\",\\n+    \\\"        \\\\\\\"metrics\\\\\\\":        metrics,\\\\n\\\",\\n+    \\\"        \\\\\\\"tags\\\\\\\":           tags,\\\\n\\\",\\n+    \\\"        \\\\\\\"artifacts\\\\\\\":      artifact_meta\\\\n\\\",\\n+    \\\"    }\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # 1) Determine notebook directory (where your .ipynb lives)\\\\n\\\",\\n+    \\\"    notebook_dir = os.getcwd()\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    # \\u2705 Create a subdirectory inside MODEL_PROVENANCE for the model\\\\n\\\",\\n+    \\\"    summary_dir = os.path.join(os.getcwd(), \\\\\\\"MODEL_PROVENANCE\\\\\\\", model_name)\\\\n\\\",\\n+    \\\"    os.makedirs(summary_dir, exist_ok=True)\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"   # 2) Pick a filename based on your model_name\\\\n\\\",\\n+    \\\"    summary_filename   = f\\\\\\\"{model_name}_run_summary.json\\\\\\\"\\\\n\\\",\\n+    \\\"    summary_local_path = os.path.join(summary_dir, summary_filename)\\\\n\\\",\\n+    \\\"   # 3) Write the JSON locally\\\\n\\\",\\n+    \\\"    with open(summary_local_path, \\\\\\\"w\\\\\\\", encoding=\\\\\\\"utf-8\\\\\\\") as f:\\\\n\\\",\\n+    \\\"        json.dump(summary, f, indent=2)\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    # 4) (Optional) Mirror it into MLflow artifacts under a single folder\\\\n\\\",\\n+    \\\"    mlflow.log_artifact(summary_local_path, artifact_path=\\\\\\\"run_summaries\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    mlflow.end_run()\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"d0c4e1b2-9fa9-4606-8128-6ac66b5c6e78\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"what does it create: \\\\n\\\",\\n+    \\\"lable_mapping in the current dir\\\\n\\\",\\n+    \\\"provenence file :REPO/notebooks/RQ_notebooks/MODEL_PROVENANCE/RandomForest_Iris_v20250425_120045_run_summary.json\\\\n\\\",\\n+    \\\"plots based on run:REPO/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120045/shap_summary.png\\\\n\\\",\\n+    \\\"mlrun:REPO/notebooks/RQ_notebooks/mlrunlogs/mlflow.db/615223710259862608/5d1fa0fc65af47128f3200628b1afaea\\\\n\\\",\\n+    \\\"trained model:REPO/notebooks/RQ_notebooks/Trained_models/RandomForest_Iris_v20250425_120852.pkl\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"7a5e3bbb-0288-47d0-9dc4-2855d7e4801a\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"1. Standards-compliant export (JSON-LD + Turtle)\\\\n\\\",\\n+    \\\"I already have your plain run_summary.json , wrap it in a JSON-LD context that maps your fields into PROV-O terms, then use rdflib to emit Turtle:\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": null,\\n+   \\\"id\\\": \\\"28ed1cfb-930a-4f17-a48f-30e4cffb7f3e\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [],\\n+   \\\"source\\\": [\\n+    \\\"import json\\\\n\\\",\\n+    \\\"import pandas as pd\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# Load the JSON file\\\\n\\\",\\n+    \\\"json_path = \\\\\\\"/mnt/data/REPO/notebooks/RQ_notebooks/MODEL_PROVENANCE/RandomForest_Iris_v20250425_125653/RandomForest_Iris_v20250425_125653_run_summary.json\\\\\\\"\\\\n\\\",\\n+    \\\"with open(json_path, \\\\\\\"r\\\\\\\", encoding=\\\\\\\"utf-8\\\\\\\") as file:\\\\n\\\",\\n+    \\\"    data = json.load(file)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# Extract justification tags\\\\n\\\",\\n+    \\\"justifications = {\\\\n\\\",\\n+    \\\"    k: v for k, v in data.get(\\\\\\\"tags\\\\\\\", {}).items()\\\\n\\\",\\n+    \\\"    if k.startswith(\\\\\\\"justification_\\\\\\\")\\\\n\\\",\\n+    \\\"}\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# Create a DataFrame\\\\n\\\",\\n+    \\\"justification_df = pd.DataFrame([\\\\n\\\",\\n+    \\\"    {\\\\\\\"Decision\\\\\\\": k.replace(\\\\\\\"justification_\\\\\\\", \\\\\\\"\\\\\\\"), \\\\\\\"Justification\\\\\\\": v}\\\\n\\\",\\n+    \\\"    for k, v in justifications.items()\\\\n\\\",\\n+    \\\"])\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"import ace_tools as tools; tools.display_dataframe_to_user(name=\\\\\\\"Researcher Justifications\\\\\\\", dataframe=justification_df)\\\\n\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 66,\\n+   \\\"id\\\": \\\"5cf88da4-69f8-4982-a594-28cf25e4f79a\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"Converted RandomForest_Iris_v20250425_121328_run_summary.json \\u2192 RandomForest_Iris_v20250425_121328.jsonld, RandomForest_Iris_v20250425_121328.ttl\\\\n\\\"\\n+     ]\\n+    }\\n+   ],\\n+   \\\"source\\\": [\\n+    \\\"\\\\n\\\",\\n+    \\\"def iso8601(ms):\\\\n\\\",\\n+    \\\"    \\\\\\\"\\\\\\\"\\\\\\\"Convert milliseconds since epoch to ISO8601 UTC.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\",\\n+    \\\"    return datetime.fromtimestamp(ms / 1000, tz=timezone.utc).isoformat()\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"for json_path in glob.glob(\\\\\\\"MODEL_PROVENANCE/*/*_run_summary.json\\\\\\\"):\\\\n\\\",\\n+    \\\"    basename   = os.path.basename(json_path)\\\\n\\\",\\n+    \\\"    model_name = basename.rsplit(\\\\\\\"_run_summary.json\\\\\\\", 1)[0]\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    with open(json_path, \\\\\\\"r\\\\\\\", encoding=\\\\\\\"utf-8\\\\\\\") as f:\\\\n\\\",\\n+    \\\"        summary = json.load(f)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    #\\u2013\\u2013 Minimal override context: keep all your flat fields as-is,\\\\n\\\",\\n+    \\\"    #\\u2013\\u2013 and only map the actual PROV terms to their IRIs.\\\\n\\\",\\n+    \\\"    ctx = {\\\\n\\\",\\n+    \\\"        # keep these flat\\\\n\\\",\\n+    \\\"        \\\\\\\"run_id\\\\\\\":       { \\\\\\\"@id\\\\\\\": \\\\\\\"run_id\\\\\\\" },\\\\n\\\",\\n+    \\\"        \\\\\\\"run_name\\\\\\\":     { \\\\\\\"@id\\\\\\\": \\\\\\\"run_name\\\\\\\" },\\\\n\\\",\\n+    \\\"        \\\\\\\"experiment_id\\\\\\\":{ \\\\\\\"@id\\\\\\\": \\\\\\\"experiment_id\\\\\\\" },\\\\n\\\",\\n+    \\\"        \\\\\\\"params\\\\\\\":       { \\\\\\\"@id\\\\\\\": \\\\\\\"params\\\\\\\" },\\\\n\\\",\\n+    \\\"        \\\\\\\"metrics\\\\\\\":      { \\\\\\\"@id\\\\\\\": \\\\\\\"metrics\\\\\\\" },\\\\n\\\",\\n+    \\\"        \\\\\\\"artifacts\\\\\\\":    { \\\\\\\"@id\\\\\\\": \\\\\\\"artifacts\\\\\\\" },\\\\n\\\",\\n+    \\\"        \\\\\\\"tags\\\\\\\":         { \\\\\\\"@id\\\\\\\": \\\\\\\"tags\\\\\\\" },\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"        # provenance namespace\\\\n\\\",\\n+    \\\"        \\\\\\\"prov\\\\\\\": \\\\\\\"http://www.w3.org/ns/prov#\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"xsd\\\\\\\":  \\\\\\\"http://www.w3.org/2001/XMLSchema#\\\\\\\",\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"        # map your timestamp fields into PROV\\\\n\\\",\\n+    \\\"        \\\\\\\"start_time\\\\\\\": { \\\\\\\"@id\\\\\\\": \\\\\\\"prov:startedAtTime\\\\\\\", \\\\\\\"@type\\\\\\\": \\\\\\\"xsd:dateTime\\\\\\\" },\\\\n\\\",\\n+    \\\"        \\\\\\\"end_time\\\\\\\":   { \\\\\\\"@id\\\\\\\": \\\\\\\"prov:endedAtTime\\\\\\\",   \\\\\\\"@type\\\\\\\": \\\\\\\"xsd:dateTime\\\\\\\" },\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"        # PROV-used/generated\\\\n\\\",\\n+    \\\"        \\\\\\\"used\\\\\\\":      { \\\\\\\"@id\\\\\\\": \\\\\\\"prov:used\\\\\\\",      \\\\\\\"@type\\\\\\\": \\\\\\\"@id\\\\\\\" },\\\\n\\\",\\n+    \\\"        \\\\\\\"generated\\\\\\\": { \\\\\\\"@id\\\\\\\": \\\\\\\"prov:generated\\\\\\\", \\\\\\\"@type\\\\\\\": \\\\\\\"@id\\\\\\\" },\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"        # JSON-LD boilerplate\\\\n\\\",\\n+    \\\"        \\\\\\\"@id\\\\\\\":   \\\\\\\"@id\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"@type\\\\\\\": \\\\\\\"@type\\\\\\\"\\\\n\\\",\\n+    \\\"    }\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    #\\u2013\\u2013 Build JSON-LD document, re-using your original keys verbatim\\\\n\\\",\\n+    \\\"    doc = {\\\\n\\\",\\n+    \\\"        \\\\\\\"@context\\\\\\\":      ctx,\\\\n\\\",\\n+    \\\"        \\\\\\\"run_id\\\\\\\":        summary[\\\\\\\"run_id\\\\\\\"],\\\\n\\\",\\n+    \\\"        \\\\\\\"run_name\\\\\\\":      summary.get(\\\\\\\"run_name\\\\\\\"),\\\\n\\\",\\n+    \\\"        \\\\\\\"experiment_id\\\\\\\": summary.get(\\\\\\\"experiment_id\\\\\\\"),\\\\n\\\",\\n+    \\\"        \\\\\\\"params\\\\\\\":        summary.get(\\\\\\\"params\\\\\\\", {}),\\\\n\\\",\\n+    \\\"        \\\\\\\"metrics\\\\\\\":       summary.get(\\\\\\\"metrics\\\\\\\", {}),\\\\n\\\",\\n+    \\\"        \\\\\\\"artifacts\\\\\\\":     summary.get(\\\\\\\"artifacts\\\\\\\", []),\\\\n\\\",\\n+    \\\"        \\\\\\\"tags\\\\\\\":          summary.get(\\\\\\\"tags\\\\\\\", {}),\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"        # PROV fields:\\\\n\\\",\\n+    \\\"        \\\\\\\"start_time\\\\\\\": iso8601(summary[\\\\\\\"start_time\\\\\\\"])\\\\n\\\",\\n+    \\\"    }\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    if summary.get(\\\\\\\"end_time\\\\\\\") is not None:\\\\n\\\",\\n+    \\\"        doc[\\\\\\\"end_time\\\\\\\"] = iso8601(summary[\\\\\\\"end_time\\\\\\\"])\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # for used/generated, just point at your dataset/model URIs\\\\n\\\",\\n+    \\\"    # (or blank-node them if you prefer richer structure)\\\\n\\\",\\n+    \\\"    doc[\\\\\\\"used\\\\\\\"] = summary.get(\\\\\\\"tags\\\\\\\", {}).get(\\\\\\\"dataset_uri\\\\\\\") or []\\\\n\\\",\\n+    \\\"    doc[\\\\\\\"generated\\\\\\\"] = [\\\\n\\\",\\n+    \\\"        art.get(\\\\\\\"uri\\\\\\\") or art.get(\\\\\\\"path\\\\\\\")\\\\n\\\",\\n+    \\\"        for art in summary.get(\\\\\\\"artifacts\\\\\\\", [])\\\\n\\\",\\n+    \\\"    ]\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    #\\u2013\\u2013 write JSON-LD\\\\n\\\",\\n+    \\\"    out_jsonld = os.path.join(\\\\\\\"MODEL_PROVENANCE\\\\\\\", model_name, f\\\\\\\"{model_name}.jsonld\\\\\\\")\\\\n\\\",\\n+    \\\"    with open(out_jsonld, \\\\\\\"w\\\\\\\", encoding=\\\\\\\"utf-8\\\\\\\") as f:\\\\n\\\",\\n+    \\\"        json.dump(doc, f, indent=2)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    #\\u2013\\u2013 parse & serialize to Turtle\\\\n\\\",\\n+    \\\"    g = Graph().parse(data=json.dumps(doc), format=\\\\\\\"json-ld\\\\\\\")\\\\n\\\",\\n+    \\\"    out_ttl = os.path.join(\\\\\\\"MODEL_PROVENANCE\\\\\\\", model_name, f\\\\\\\"{model_name}.ttl\\\\\\\")\\\\n\\\",\\n+    \\\"    g.serialize(destination=out_ttl, format=\\\\\\\"turtle\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    print(f\\\\\\\"Converted {basename} \\u2192 {os.path.basename(out_jsonld)}, {os.path.basename(out_ttl)}\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"83d6d524-01da-4f20-8131-0d4a3ac005e2\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"This code programatically, finds diff between generated Json file and created JsonLD and .TTL file to make it easier to understand if there is any discrepency\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 67,\\n+   \\\"id\\\": \\\"77a420c0-230d-41c0-9b63-f3dbbca1e670\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"== JSON-LD vs TTL ==\\\\n\\\",\\n+      \\\"Change summary:\\\\n\\\",\\n+      \\\"type\\\\n\\\",\\n+      \\\"changed    1 \\\\n\\\",\\n+      \\\"\\\\n\\\",\\n+      \\\"First 10 \\u2018changed\\u2019 entries:\\\\n\\\",\\n+      \\\"Top-level adds/removes:\\\\n\\\",\\n+      \\\"Empty DataFrame\\\\n\\\",\\n+      \\\"Columns: [path, type, a, b]\\\\n\\\",\\n+      \\\"Index: []\\\\n\\\",\\n+      \\\"\\\\n\\\",\\n+      \\\"== JSON vs JSON-LD ==\\\\n\\\",\\n+      \\\"Change summary:\\\\n\\\",\\n+      \\\"type\\\\n\\\",\\n+      \\\"added      3\\\\n\\\",\\n+      \\\"removed    1\\\\n\\\",\\n+      \\\"changed    1 \\\\n\\\",\\n+      \\\"\\\\n\\\",\\n+      \\\"First 10 \\u2018changed\\u2019 entries:\\\\n\\\",\\n+      \\\"Top-level adds/removes:\\\\n\\\",\\n+      \\\"Empty DataFrame\\\\n\\\",\\n+      \\\"Columns: [path, type, a, b]\\\\n\\\",\\n+      \\\"Index: []\\\\n\\\"\\n+     ]\\n+    }\\n+   ],\\n+   \\\"source\\\": [\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"def load_as_dict(path):\\\\n\\\",\\n+    \\\"    if path.endswith((\\\\\\\".ttl\\\\\\\", \\\\\\\".turtle\\\\\\\")):\\\\n\\\",\\n+    \\\"        g = Graph()\\\\n\\\",\\n+    \\\"        g.parse(path, format=\\\\\\\"turtle\\\\\\\")\\\\n\\\",\\n+    \\\"        # normalize to JSON-LD dict\\\\n\\\",\\n+    \\\"        return json.loads(g.serialize(format=\\\\\\\"json-ld\\\\\\\", indent=2))\\\\n\\\",\\n+    \\\"    else:\\\\n\\\",\\n+    \\\"        with open(path, encoding=\\\\\\\"utf-8\\\\\\\") as f:\\\\n\\\",\\n+    \\\"            return json.load(f)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"def compare_json(a, b, path=\\\\\\\"\\\\\\\"):\\\\n\\\",\\n+    \\\"    diffs = []\\\\n\\\",\\n+    \\\"    if isinstance(a, dict) and isinstance(b, dict):\\\\n\\\",\\n+    \\\"        all_keys = set(a) | set(b)\\\\n\\\",\\n+    \\\"        for k in all_keys:\\\\n\\\",\\n+    \\\"            new_path = f\\\\\\\"{path}/{k}\\\\\\\" if path else k\\\\n\\\",\\n+    \\\"            if k not in a:\\\\n\\\",\\n+    \\\"                diffs.append({\\\\\\\"path\\\\\\\": new_path, \\\\\\\"type\\\\\\\": \\\\\\\"added\\\\\\\",   \\\\\\\"a\\\\\\\": None,    \\\\\\\"b\\\\\\\": b[k]})\\\\n\\\",\\n+    \\\"            elif k not in b:\\\\n\\\",\\n+    \\\"                diffs.append({\\\\\\\"path\\\\\\\": new_path, \\\\\\\"type\\\\\\\": \\\\\\\"removed\\\\\\\", \\\\\\\"a\\\\\\\": a[k],   \\\\\\\"b\\\\\\\": None})\\\\n\\\",\\n+    \\\"            else:\\\\n\\\",\\n+    \\\"                diffs.extend(compare_json(a[k], b[k], new_path))\\\\n\\\",\\n+    \\\"    elif isinstance(a, list) and isinstance(b, list):\\\\n\\\",\\n+    \\\"        for i, (ia, ib) in enumerate(zip(a, b)):\\\\n\\\",\\n+    \\\"            diffs.extend(compare_json(ia, ib, f\\\\\\\"{path}[{i}]\\\\\\\"))\\\\n\\\",\\n+    \\\"        # handle length mismatches\\\\n\\\",\\n+    \\\"        if len(a) < len(b):\\\\n\\\",\\n+    \\\"            for i in range(len(a), len(b)):\\\\n\\\",\\n+    \\\"                diffs.append({\\\\\\\"path\\\\\\\": f\\\\\\\"{path}[{i}]\\\\\\\", \\\\\\\"type\\\\\\\": \\\\\\\"added\\\\\\\",   \\\\\\\"a\\\\\\\": None,  \\\\\\\"b\\\\\\\": b[i]})\\\\n\\\",\\n+    \\\"        elif len(a) > len(b):\\\\n\\\",\\n+    \\\"            for i in range(len(b), len(a)):\\\\n\\\",\\n+    \\\"                diffs.append({\\\\\\\"path\\\\\\\": f\\\\\\\"{path}[{i}]\\\\\\\", \\\\\\\"type\\\\\\\": \\\\\\\"removed\\\\\\\", \\\\\\\"a\\\\\\\": a[i],  \\\\\\\"b\\\\\\\": None})\\\\n\\\",\\n+    \\\"    else:\\\\n\\\",\\n+    \\\"        if a != b:\\\\n\\\",\\n+    \\\"            diffs.append({\\\\\\\"path\\\\\\\": path, \\\\\\\"type\\\\\\\": \\\\\\\"changed\\\\\\\", \\\\\\\"a\\\\\\\": a, \\\\\\\"b\\\\\\\": b})\\\\n\\\",\\n+    \\\"    return diffs\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# --- Usage example -----------------------------------------------\\\\n\\\",\\n+    \\\"# REPO/notebooks/RQ_notebooks/MODEL_PROVENANCE/RandomForest_Iris_v20250425_121328/RandomForest_Iris_v20250425_121328_run_summary.json\\\\n\\\",\\n+    \\\"# # Compare JSON-LD vs Turtle:\\\\n\\\",\\n+    \\\"# a = load_as_dict(\\\\\\\"MODEL_PROVENANCE/RandomForest_Iris_v20250423_230422_run_summary.json\\\\\\\")\\\\n\\\",\\n+    \\\"# b = load_as_dict(\\\\\\\"MODEL_PROVENANCE/RandomForest_Iris_v20250423_230422.ttl\\\\\\\")\\\\n\\\",\\n+    \\\"# diffs_jsonld_vs_ttl = compare_json(a, b)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# # Compare JSON vs JSON-LD:\\\\n\\\",\\n+    \\\"# c = load_as_dict(\\\\\\\"MODEL_PROVENANCE/RandomForest_Iris_v20250423_230422_run_summary.json\\\\\\\")\\\\n\\\",\\n+    \\\"# d = load_as_dict(\\\\\\\"MODEL_PROVENANCE/RandomForest_Iris_v20250423_230422.jsonld\\\\\\\")\\\\n\\\",\\n+    \\\"# diffs_json_vs_jsonld = compare_json(c, d)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# Define base directory\\\\n\\\",\\n+    \\\"base_dir = os.path.join(\\\\\\\"MODEL_PROVENANCE\\\\\\\", model_name)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# Build full paths for the files to compare\\\\n\\\",\\n+    \\\"summary_json    = os.path.join(base_dir, f\\\\\\\"{model_name}_run_summary.json\\\\\\\")\\\\n\\\",\\n+    \\\"turtle_file     = os.path.join(base_dir, f\\\\\\\"{model_name}.ttl\\\\\\\")\\\\n\\\",\\n+    \\\"jsonld_file     = os.path.join(base_dir, f\\\\\\\"{model_name}.jsonld\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# Load files\\\\n\\\",\\n+    \\\"a = load_as_dict(summary_json)\\\\n\\\",\\n+    \\\"b = load_as_dict(turtle_file)\\\\n\\\",\\n+    \\\"c = load_as_dict(summary_json)\\\\n\\\",\\n+    \\\"d = load_as_dict(jsonld_file)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# Perform comparisons\\\\n\\\",\\n+    \\\"diffs_jsonld_vs_ttl = compare_json(a, b)\\\\n\\\",\\n+    \\\"diffs_json_vs_jsonld = compare_json(c, d)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# Build DataFrames for interactive inspection\\\\n\\\",\\n+    \\\"df1 = pd.DataFrame(diffs_jsonld_vs_ttl)\\\\n\\\",\\n+    \\\"df2 = pd.DataFrame(diffs_json_vs_jsonld)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# --- Summaries & Filtering ---------------------------------------\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"def summarize_and_preview(df, preview_n=10):\\\\n\\\",\\n+    \\\"    print(\\\\\\\"Change summary:\\\\\\\")\\\\n\\\",\\n+    \\\"    print(df['type'].value_counts().to_string(), \\\\\\\"\\\\\\\\n\\\\\\\")\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    print(f\\\\\\\"First {preview_n} \\u2018changed\\u2019 entries:\\\\\\\")\\\\n\\\",\\n+    \\\"    # print(df[df['type']==\\\\\\\"changed\\\\\\\"].head(preview_n).to_string(index=False), \\\\\\\"\\\\\\\\n\\\\\\\")\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    # Top\\u2010level (one slash) adds/removes\\\\n\\\",\\n+    \\\"    top = df[df['path'].str.count(\\\\\\\"/\\\\\\\") == 1]\\\\n\\\",\\n+    \\\"    print(\\\\\\\"Top-level adds/removes:\\\\\\\")\\\\n\\\",\\n+    \\\"    print(top[top['type'].isin(['added','removed'])].to_string(index=False))\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"print(\\\\\\\"== JSON-LD vs TTL ==\\\\\\\")\\\\n\\\",\\n+    \\\"summarize_and_preview(df1)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"print(\\\\\\\"\\\\\\\\n== JSON vs JSON-LD ==\\\\\\\")\\\\n\\\",\\n+    \\\"summarize_and_preview(df2)\\\\n\\\",\\n+    \\\"\\\\n\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 68,\\n+   \\\"id\\\": \\\"41af9d6e-c683-45f9-bac1-296611b4d0b9\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"Removed in JSON-LD comparison:\\\\n\\\",\\n+      \\\"    path\\\\n\\\",\\n+      \\\"end_time\\\\n\\\",\\n+      \\\"\\\\n\\\",\\n+      \\\"Added in JSON-LD comparison:\\\\n\\\",\\n+      \\\"     path\\\\n\\\",\\n+      \\\" @context\\\\n\\\",\\n+      \\\"     used\\\\n\\\",\\n+      \\\"generated\\\\n\\\"\\n+     ]\\n+    }\\n+   ],\\n+   \\\"source\\\": [\\n+    \\\"# show all the removed paths (in JSON but not in JSON-LD)\\\\n\\\",\\n+    \\\"print(\\\\\\\"Removed in JSON-LD comparison:\\\\\\\")\\\\n\\\",\\n+    \\\"print(df2[df2['type']==\\\\\\\"removed\\\\\\\"][['path']].to_string(index=False))\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# show all the added paths (in JSON-LD but not in JSON)\\\\n\\\",\\n+    \\\"print(\\\\\\\"\\\\\\\\nAdded in JSON-LD comparison:\\\\\\\")\\\\n\\\",\\n+    \\\"print(df2[df2['type']==\\\\\\\"added\\\\\\\"][['path']].to_string(index=False))\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 69,\\n+   \\\"id\\\": \\\"f0d6f92a-5cd9-4c78-9c2a-0cd3247137c6\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"Removed in .ttl comparison:\\\\n\\\",\\n+      \\\"Empty DataFrame\\\\n\\\",\\n+      \\\"Columns: [path]\\\\n\\\",\\n+      \\\"Index: []\\\\n\\\",\\n+      \\\"\\\\n\\\",\\n+      \\\"Added in .ttl comparison:\\\\n\\\",\\n+      \\\"Empty DataFrame\\\\n\\\",\\n+      \\\"Columns: [path]\\\\n\\\",\\n+      \\\"Index: []\\\\n\\\"\\n+     ]\\n+    }\\n+   ],\\n+   \\\"source\\\": [\\n+    \\\"# show all the removed paths (in JSON but not in JSON-LD)\\\\n\\\",\\n+    \\\"print(\\\\\\\"Removed in .ttl comparison:\\\\\\\")\\\\n\\\",\\n+    \\\"print(df1[df1['type']==\\\\\\\"removed\\\\\\\"][['path']].to_string(index=False))\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# show all the added paths (in JSON-LD but not in JSON)\\\\n\\\",\\n+    \\\"print(\\\\\\\"\\\\\\\\nAdded in .ttl comparison:\\\\\\\")\\\\n\\\",\\n+    \\\"print(df1[df1['type']==\\\\\\\"added\\\\\\\"][['path']].to_string(index=False))\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"69efd0d0-9277-4efa-88cf-d2fd1b90d74c\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"Checks for completeness and mapping and time taken, needs work #TODO\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 70,\\n+   \\\"id\\\": \\\"165a13eb-7679-4f4c-b346-24f25da72cce\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\\\n\\\",\\n+      \\\"0/0 runs passed completeness checks (0.0%).\\\\n\\\",\\n+      \\\"\\\\n\\\",\\n+      \\\"Mapping integrity: 0/0 runs have zero diffs \\u2014 0.0%\\\\n\\\",\\n+      \\\"Overall quality score: 0.0%\\\\n\\\",\\n+      \\\"\\\\n\\\",\\n+      \\\"Benchmarking train_and_log() overhead:\\\\n\\\",\\n+      \\\"  \\u2022 No MLflow : 0.502s\\\\n\\\",\\n+      \\\"  \\u2022 With MLflow: 0.601s\\\\n\\\"\\n+     ]\\n+    }\\n+   ],\\n+   \\\"source\\\": [\\n+    \\\"\\\\n\\\",\\n+    \\\"# \\u2500\\u2500 User configuration \\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# Which keys must appear in every run_summary.json?\\\\n\\\",\\n+    \\\"REQUIRED_TOPLEVEL = {\\\\n\\\",\\n+    \\\"    \\\\\\\"run_id\\\\\\\", \\\\\\\"start_time\\\\\\\", \\\\\\\"end_time\\\\\\\",\\\\n\\\",\\n+    \\\"    \\\\\\\"params\\\\\\\", \\\\\\\"metrics\\\\\\\", \\\\\\\"tags\\\\\\\", \\\\\\\"artifacts\\\\\\\"\\\\n\\\",\\n+    \\\"}\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# A couple of sub-fields we also want to spot-check:\\\\n\\\",\\n+    \\\"REQUIRED_PARAMS  = {\\\\\\\"random_state\\\\\\\"}\\\\n\\\",\\n+    \\\"REQUIRED_METRICS = {\\\\\\\"accuracy\\\\\\\"}\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"JSON_SUMMARIES = glob.glob(\\\\\\\"MODEL_PROVENANCE/*_run_summary.json\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# \\u2500\\u2500 Helpers \\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"def iso8601(ms):\\\\n\\\",\\n+    \\\"    return datetime.fromtimestamp(ms/1000, tz=timezone.utc).isoformat()\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"def load_json(path):\\\\n\\\",\\n+    \\\"    with open(path, \\\\\\\"r\\\\\\\", encoding=\\\\\\\"utf-8\\\\\\\") as f:\\\\n\\\",\\n+    \\\"        return json.load(f)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"def write_json(path, obj):\\\\n\\\",\\n+    \\\"    with open(path, \\\\\\\"w\\\\\\\", encoding=\\\\\\\"utf-8\\\\\\\") as f:\\\\n\\\",\\n+    \\\"        json.dump(obj, f, indent=2)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"def convert_to_jsonld_and_ttl(summary, basename):\\\\n\\\",\\n+    \\\"    # build @context\\\\n\\\",\\n+    \\\"    ctx = {\\\\n\\\",\\n+    \\\"        \\\\\\\"prov\\\\\\\":    \\\\\\\"http://www.w3.org/ns/prov#\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"xsd\\\\\\\":     \\\\\\\"http://www.w3.org/2001/XMLSchema#\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"run\\\\\\\":     \\\\\\\"prov:Activity\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"start\\\\\\\":   \\\\\\\"prov:startedAtTime\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"end\\\\\\\":     \\\\\\\"prov:endedAtTime\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"used\\\\\\\":    \\\\\\\"prov:used\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"gen\\\\\\\":     \\\\\\\"prov:generated\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"param\\\\\\\":   \\\\\\\"prov:hadParameter\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"metric\\\\\\\":  \\\\\\\"prov:hadQuality\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"entity\\\\\\\":  \\\\\\\"prov:Entity\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"label\\\\\\\":   \\\\\\\"prov:label\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"value\\\\\\\":   \\\\\\\"prov:value\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"version\\\\\\\": \\\\\\\"prov:hadRevision\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"id\\\\\\\":      \\\\\\\"@id\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"type\\\\\\\":    \\\\\\\"@type\\\\\\\"\\\\n\\\",\\n+    \\\"    }\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    jsonld = {\\\\n\\\",\\n+    \\\"        \\\\\\\"@context\\\\\\\": ctx,\\\\n\\\",\\n+    \\\"        \\\\\\\"@id\\\\\\\":      f\\\\\\\"urn:run:{summary['run_id']}\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"@type\\\\\\\":    \\\\\\\"run\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"start\\\\\\\": {\\\\n\\\",\\n+    \\\"            \\\\\\\"@type\\\\\\\":  \\\\\\\"xsd:dateTime\\\\\\\",\\\\n\\\",\\n+    \\\"            \\\\\\\"@value\\\\\\\": iso8601(summary[\\\\\\\"start_time\\\\\\\"])\\\\n\\\",\\n+    \\\"        }\\\\n\\\",\\n+    \\\"    }\\\\n\\\",\\n+    \\\"    if summary.get(\\\\\\\"end_time\\\\\\\") is not None:\\\\n\\\",\\n+    \\\"        jsonld[\\\\\\\"end\\\\\\\"] = {\\\\n\\\",\\n+    \\\"            \\\\\\\"@type\\\\\\\":  \\\\\\\"xsd:dateTime\\\\\\\",\\\\n\\\",\\n+    \\\"            \\\\\\\"@value\\\\\\\": iso8601(summary[\\\\\\\"end_time\\\\\\\"])\\\\n\\\",\\n+    \\\"        }\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # params\\\\n\\\",\\n+    \\\"    jsonld[\\\\\\\"param\\\\\\\"] = [\\\\n\\\",\\n+    \\\"        {\\\\\\\"@type\\\\\\\":\\\\\\\"entity\\\\\\\",\\\\\\\"label\\\\\\\":k,\\\\\\\"value\\\\\\\":str(v)}\\\\n\\\",\\n+    \\\"        for k,v in summary.get(\\\\\\\"params\\\\\\\",{}).items()\\\\n\\\",\\n+    \\\"    ]\\\\n\\\",\\n+    \\\"    # metrics\\\\n\\\",\\n+    \\\"    jsonld[\\\\\\\"metric\\\\\\\"] = [\\\\n\\\",\\n+    \\\"        {\\\\\\\"@type\\\\\\\":\\\\\\\"entity\\\\\\\",\\\\\\\"label\\\\\\\":k,\\\\n\\\",\\n+    \\\"         \\\\\\\"value\\\\\\\":{\\\\\\\"@type\\\\\\\":\\\\\\\"xsd:decimal\\\\\\\",\\\\\\\"@value\\\\\\\":v}}\\\\n\\\",\\n+    \\\"        for k,v in summary.get(\\\\\\\"metrics\\\\\\\",{}).items()\\\\n\\\",\\n+    \\\"    ]\\\\n\\\",\\n+    \\\"    # artifacts\\\\n\\\",\\n+    \\\"    jsonld[\\\\\\\"gen\\\\\\\"] = [\\\\n\\\",\\n+    \\\"        {\\\\n\\\",\\n+    \\\"            \\\\\\\"@type\\\\\\\":\\\\\\\"entity\\\\\\\",\\\\n\\\",\\n+    \\\"            \\\\\\\"label\\\\\\\": art.get(\\\\\\\"path\\\\\\\") or art.get(\\\\\\\"label\\\\\\\"),\\\\n\\\",\\n+    \\\"            \\\\\\\"prov:location\\\\\\\": (\\\\n\\\",\\n+    \\\"                art.get(\\\\\\\"uri\\\\\\\")\\\\n\\\",\\n+    \\\"                or (art.get(\\\\\\\"content\\\\\\\",\\\\\\\"\\\\\\\")[:30]+\\\\\\\"\\u2026\\\\\\\")\\\\n\\\",\\n+    \\\"                if isinstance(art.get(\\\\\\\"content\\\\\\\"),str)\\\\n\\\",\\n+    \\\"                else \\\\\\\"\\\\\\\"\\\\n\\\",\\n+    \\\"            )\\\\n\\\",\\n+    \\\"        }\\\\n\\\",\\n+    \\\"        for art in summary.get(\\\\\\\"artifacts\\\\\\\",[])\\\\n\\\",\\n+    \\\"    ]\\\\n\\\",\\n+    \\\"    # dataset used\\\\n\\\",\\n+    \\\"    jsonld[\\\\\\\"used\\\\\\\"] = {\\\\n\\\",\\n+    \\\"        \\\\\\\"@type\\\\\\\":\\\\\\\"entity\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"label\\\\\\\": summary[\\\\\\\"tags\\\\\\\"].get(\\\\\\\"dataset_name\\\\\\\"),\\\\n\\\",\\n+    \\\"        \\\\\\\"version\\\\\\\": summary[\\\\\\\"tags\\\\\\\"].get(\\\\\\\"dataset_version\\\\\\\")\\\\n\\\",\\n+    \\\"    }\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # write JSON-LD\\\\n\\\",\\n+    \\\"    out_jsonld = f\\\\\\\"MODEL_PROVENANCE/{basename}.jsonld\\\\\\\"\\\\n\\\",\\n+    \\\"    write_json(out_jsonld, jsonld)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # serialize TTL\\\\n\\\",\\n+    \\\"    g = Graph().parse(data=json.dumps(jsonld), format=\\\\\\\"json-ld\\\\\\\")\\\\n\\\",\\n+    \\\"    out_ttl = f\\\\\\\"MODEL_PROVENANCE/{basename}.ttl\\\\\\\"\\\\n\\\",\\n+    \\\"    g.serialize(destination=out_ttl, format=\\\\\\\"turtle\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    return out_jsonld, out_ttl\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"def normalize_jsonld(js):\\\\n\\\",\\n+    \\\"    \\\\\\\"\\\\\\\"\\\\\\\"Simple deep-sort so compare_json doesn\\u2019t trip over ordering.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\",\\n+    \\\"    if isinstance(js, dict):\\\\n\\\",\\n+    \\\"        return {k: normalize_jsonld(js[k]) for k in sorted(js)}\\\\n\\\",\\n+    \\\"    if isinstance(js, list):\\\\n\\\",\\n+    \\\"        return sorted((normalize_jsonld(el) for el in js),\\\\n\\\",\\n+    \\\"                      key=lambda x: json.dumps(x, sort_keys=True))\\\\n\\\",\\n+    \\\"    return js\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"def diff_roundtrip(orig_json, jsonld_path, ttl_path):\\\\n\\\",\\n+    \\\"    orig = load_json(orig_json)\\\\n\\\",\\n+    \\\"    ld   = load_json(jsonld_path)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # parse TTL back to JSON-LD\\\\n\\\",\\n+    \\\"    g = Graph().parse(ttl_path, format=\\\\\\\"turtle\\\\\\\")\\\\n\\\",\\n+    \\\"    ttl_as_ld = json.loads(g.serialize(format=\\\\\\\"json-ld\\\\\\\"))\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # normalize\\\\n\\\",\\n+    \\\"    nl = normalize_jsonld(ld)\\\\n\\\",\\n+    \\\"    nt = normalize_jsonld(ttl_as_ld)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    return {\\\\n\\\",\\n+    \\\"        \\\\\\\"orig_vs_jsonld\\\\\\\":   compare_json(orig, ld),\\\\n\\\",\\n+    \\\"        \\\\\\\"jsonld_vs_ttl_ld\\\\\\\": compare_json(nl, nt)\\\\n\\\",\\n+    \\\"    }\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# \\u2500\\u2500 Main flow \\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"def main():\\\\n\\\",\\n+    \\\"    ok = 0\\\\n\\\",\\n+    \\\"    total = len(JSON_SUMMARIES)\\\\n\\\",\\n+    \\\"    missing_reports = []\\\\n\\\",\\n+    \\\"    cases = {}  # store diff results per run\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    for js_path in JSON_SUMMARIES:\\\\n\\\",\\n+    \\\"        summary = load_json(js_path)\\\\n\\\",\\n+    \\\"        base    = os.path.basename(js_path).split(\\\\\\\"_run_summary.json\\\\\\\")[0]\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"        # 1) completeness check\\\\n\\\",\\n+    \\\"        if not REQUIRED_TOPLEVEL.issubset(summary):\\\\n\\\",\\n+    \\\"            missing = REQUIRED_TOPLEVEL - set(summary)\\\\n\\\",\\n+    \\\"            missing_reports.append((js_path, f\\\\\\\"missing fields {missing}\\\\\\\"))\\\\n\\\",\\n+    \\\"            continue\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"        if not (REQUIRED_PARAMS <= summary[\\\\\\\"params\\\\\\\"].keys()):\\\\n\\\",\\n+    \\\"            missing_reports.append((js_path, f\\\\\\\"params missing {REQUIRED_PARAMS - summary['params'].keys()}\\\\\\\"))\\\\n\\\",\\n+    \\\"            continue\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"        if not (REQUIRED_METRICS <= summary[\\\\\\\"metrics\\\\\\\"].keys()):\\\\n\\\",\\n+    \\\"            missing_reports.append((js_path, f\\\\\\\"metrics missing {REQUIRED_METRICS - summary['metrics'].keys()}\\\\\\\"))\\\\n\\\",\\n+    \\\"            continue\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"        ok += 1\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"        # 2) convert\\\\n\\\",\\n+    \\\"        jsonld_path, ttl_path = convert_to_jsonld_and_ttl(summary, base)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"        # 3) diff\\\\n\\\",\\n+    \\\"        diffs = diff_roundtrip(js_path, jsonld_path, ttl_path)\\\\n\\\",\\n+    \\\"        cases[base] = diffs\\\\n\\\",\\n+    \\\"        print(f\\\\\\\"\\\\\\\\n\\u2500\\u2500 {base} diffs \\u2500\\u2500\\\\\\\")\\\\n\\\",\\n+    \\\"        print(\\\\\\\"  \\u2022 JSON \\u2192 JSON-LD:\\\\\\\", len(diffs[\\\\\\\"orig_vs_jsonld\\\\\\\"]), \\\\\\\"differences\\\\\\\")\\\\n\\\",\\n+    \\\"        print(\\\\\\\"  \\u2022 JSON-LD \\u2192 TTL \\u2192 JSON-LD:\\\\\\\", len(diffs[\\\\\\\"jsonld_vs_ttl_ld\\\\\\\"]), \\\\\\\"differences\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # 4) completeness summary\\\\n\\\",\\n+    \\\"    completeness_pct = (100 * ok / total) if total else 0\\\\n\\\",\\n+    \\\"    print(f\\\\\\\"\\\\\\\\n{ok}/{total} runs passed completeness checks ({completeness_pct:.1f}%).\\\\\\\")\\\\n\\\",\\n+    \\\"    if missing_reports:\\\\n\\\",\\n+    \\\"        print(\\\\\\\"\\\\\\\\nFailures:\\\\\\\")\\\\n\\\",\\n+    \\\"        for path, reason in missing_reports:\\\\n\\\",\\n+    \\\"            print(f\\\\\\\" \\u2022 {path}: {reason}\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # 5) integrity check\\\\n\\\",\\n+    \\\"    total_runs = len(cases)\\\\n\\\",\\n+    \\\"    zero_diff_runs = sum(\\\\n\\\",\\n+    \\\"        1\\\\n\\\",\\n+    \\\"        for diffs in cases.values()\\\\n\\\",\\n+    \\\"        if not diffs[\\\\\\\"orig_vs_jsonld\\\\\\\"] and not diffs[\\\\\\\"jsonld_vs_ttl_ld\\\\\\\"]\\\\n\\\",\\n+    \\\"    )\\\\n\\\",\\n+    \\\"    integrity_pct = (100 * zero_diff_runs / total_runs) if total_runs else 0\\\\n\\\",\\n+    \\\"    print(f\\\\\\\"\\\\\\\\nMapping integrity: {zero_diff_runs}/{total_runs} runs have zero diffs \\u2014 {integrity_pct:.1f}%\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # 6) overall quality score\\\\n\\\",\\n+    \\\"    overall_score = (completeness_pct + integrity_pct) / 2\\\\n\\\",\\n+    \\\"    print(f\\\\\\\"Overall quality score: {overall_score:.1f}%\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # 7) Benchmark your training fn\\\\n\\\",\\n+    \\\"    print(\\\\\\\"\\\\\\\\nBenchmarking train_and_log() overhead:\\\\\\\")\\\\n\\\",\\n+    \\\"    def train_and_log(use_mlflow=False):\\\\n\\\",\\n+    \\\"        # \\u2190 your real instrumentation + fit logic here\\\\n\\\",\\n+    \\\"        time.sleep(0.5 + (0.1 if use_mlflow else 0))  # stub\\\\n\\\",\\n+    \\\"        return\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    for flag in (False, True):\\\\n\\\",\\n+    \\\"        start = time.time()\\\\n\\\",\\n+    \\\"        train_and_log(use_mlflow=flag)\\\\n\\\",\\n+    \\\"        elapsed = time.time() - start\\\\n\\\",\\n+    \\\"        label = \\\\\\\"With MLflow\\\\\\\" if flag else \\\\\\\"No MLflow\\\\\\\"\\\\n\\\",\\n+    \\\"        print(f\\\\\\\"  \\u2022 {label:10s}: {elapsed:.3f}s\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"if __name__ == \\\\\\\"__main__\\\\\\\":\\\\n\\\",\\n+    \\\"    main()\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"5883f673-371e-415e-a73e-5c9c88b56fb1\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"RQ2  implementation\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 72,\\n+   \\\"id\\\": \\\"6d07ac1c-ea80-4787-bcb9-da047d12167d\\\",\\n+   \\\"metadata\\\": {\\n+    \\\"scrolled\\\": true\\n+   },\\n+   \\\"outputs\\\": [\\n+    {\\n+     \\\"data\\\": {\\n+      \\\"text/plain\\\": [\\n+       \\\"Index(['run_id', 'param_bootstrap', 'param_ccp_alpha', 'param_class_weight',\\\\n\\\",\\n+       \\\"       'param_columns_raw', 'param_criterion', 'param_database.description',\\\\n\\\",\\n+       \\\"       'param_database.id', 'param_database.name', 'param_database.owner',\\\\n\\\",\\n+       \\\"       'param_dataset.authors', 'param_dataset.doi', 'param_dataset.published',\\\\n\\\",\\n+       \\\"       'param_dataset.publisher', 'param_dataset.title',\\\\n\\\",\\n+       \\\"       'param_dropped_columns', 'param_feature_names',\\\\n\\\",\\n+       \\\"       'param_matplotlib_version', 'param_max_depth', 'param_max_features',\\\\n\\\",\\n+       \\\"       'param_max_leaf_nodes', 'param_max_samples',\\\\n\\\",\\n+       \\\"       'param_min_impurity_decrease', 'param_min_samples_leaf',\\\\n\\\",\\n+       \\\"       'param_min_samples_split', 'param_min_weight_fraction_leaf',\\\\n\\\",\\n+       \\\"       'param_numpy_version', 'param_n_estimators', 'param_n_features',\\\\n\\\",\\n+       \\\"       'param_n_features_final', 'param_n_jobs', 'param_n_records',\\\\n\\\",\\n+       \\\"       'param_n_test_samples', 'param_n_train_samples', 'param_oob_score',\\\\n\\\",\\n+       \\\"       'param_os_platform', 'param_pandas_version', 'param_python_version',\\\\n\\\",\\n+       \\\"       'param_random_state', 'param_retrieval_time', 'param_seaborn_version',\\\\n\\\",\\n+       \\\"       'param_shap_version', 'param_sklearn_version', 'param_test_size',\\\\n\\\",\\n+       \\\"       'param_verbose', 'param_warm_start', 'metric_accuracy',\\\\n\\\",\\n+       \\\"       'metric_accuracy_score_X_test', 'metric_dbrepo.num_deletes',\\\\n\\\",\\n+       \\\"       'metric_dbrepo.num_inserts', 'metric_dbrepo.row_count_end',\\\\n\\\",\\n+       \\\"       'metric_dbrepo.row_count_start', 'metric_f1_macro',\\\\n\\\",\\n+       \\\"       'metric_f1_score_X_test', 'metric_precision_macro',\\\\n\\\",\\n+       \\\"       'metric_precision_score_X_test', 'metric_recall_macro',\\\\n\\\",\\n+       \\\"       'metric_recall_score_X_test', 'metric_roc_auc',\\\\n\\\",\\n+       \\\"       'metric_roc_auc_score_X_test', 'metric_training_accuracy_score',\\\\n\\\",\\n+       \\\"       'metric_training_f1_score', 'metric_training_log_loss',\\\\n\\\",\\n+       \\\"       'metric_training_precision_score', 'metric_training_recall_score',\\\\n\\\",\\n+       \\\"       'metric_training_roc_auc', 'metric_training_score', 'tag_dataset_id',\\\\n\\\",\\n+       \\\"       'tag_dataset_name', 'tag_dataset_version', 'tag_data_source',\\\\n\\\",\\n+       \\\"       'tag_dbrepo.admin_email', 'tag_dbrepo.base_url',\\\\n\\\",\\n+       \\\"       'tag_dbrepo.granularity', 'tag_dbrepo.protocol_version',\\\\n\\\",\\n+       \\\"       'tag_dbrepo.repository_name', 'tag_dbrepo.table_last_modified',\\\\n\\\",\\n+       \\\"       'tag_estimator_class', 'tag_estimator_name',\\\\n\\\",\\n+       \\\"       'tag_git_current_commit_hash', 'tag_git_previous_commit_hash',\\\\n\\\",\\n+       \\\"       'tag_git__current_commit_url', 'tag_mlflow.log-model.history',\\\\n\\\",\\n+       \\\"       'tag_mlflow.runName', 'tag_mlflow.source.name',\\\\n\\\",\\n+       \\\"       'tag_mlflow.source.type', 'tag_mlflow.user', 'tag_model_name',\\\\n\\\",\\n+       \\\"       'tag_notebook_name', 'tag_target_name', 'tag_training_end_time',\\\\n\\\",\\n+       \\\"       'tag_training_start_time'],\\\\n\\\",\\n+       \\\"      dtype='object')\\\"\\n+      ]\\n+     },\\n+     \\\"execution_count\\\": 72,\\n+     \\\"metadata\\\": {},\\n+     \\\"output_type\\\": \\\"execute_result\\\"\\n+    }\\n+   ],\\n+   \\\"source\\\": [\\n+    \\\"\\\\n\\\",\\n+    \\\"# Load all run summary JSON files\\\\n\\\",\\n+    \\\"files = glob.glob(\\\\\\\"MODEL_PROVENANCE/*/*_run_summary.json\\\\\\\")\\\\n\\\",\\n+    \\\"rows = []\\\\n\\\",\\n+    \\\"for f in files:\\\\n\\\",\\n+    \\\"    with open(f) as fh:\\\\n\\\",\\n+    \\\"        summary = json.load(fh)\\\\n\\\",\\n+    \\\"    # Flatten parameters and metrics\\\\n\\\",\\n+    \\\"    row = {\\\\\\\"run_id\\\\\\\": summary[\\\\\\\"run_id\\\\\\\"]}\\\\n\\\",\\n+    \\\"    row.update({f\\\\\\\"param_{k}\\\\\\\": v for k, v in summary.get(\\\\\\\"params\\\\\\\", {}).items()})\\\\n\\\",\\n+    \\\"    row.update({f\\\\\\\"metric_{k}\\\\\\\": v for k, v in summary.get(\\\\\\\"metrics\\\\\\\", {}).items()})\\\\n\\\",\\n+    \\\"    row.update({f\\\\\\\"tag_{k}\\\\\\\": v for k, v in summary.get(\\\\\\\"tags\\\\\\\", {}).items()})\\\\n\\\",\\n+    \\\"    rows.append(row)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# Create DataFrame\\\\n\\\",\\n+    \\\"df = pd.DataFrame(rows)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# Display the DataFrame\\\\n\\\",\\n+    \\\"df.columns\\\\n\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"ba148da6-6ce5-45cf-a985-f164a53c969b\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"1) Tracing preprocessing steps\\\\n\\\",\\n+    \\\":\\\\n\\\",\\n+    \\\"Here are the top 4 Iris\\u2010focused preprocessing\\u2010tracing use cases I\\u2019d tackle first:\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"Reconstruct a run\\u2019s exact preprocessing\\\\n\\\",\\n+    \\\"Fetch a run\\u2019s run_id, columns_raw, dropped_columns, feature_names and test_size so you can replay the exact data pull & split.\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"Feature\\u2010drop impact analysis\\\\n\\\",\\n+    \\\"Identify runs where one or more measurements (e.g. petalwidthcm) were dropped and compare their test accuracies.\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"Best feature subset discovery\\\\n\\\",\\n+    \\\"Group runs by which features they used (sepals only vs petals only vs both) and rank them by test F1 or accuracy.\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"Common steps in high-accuracy runs\\\\n\\\",\\n+    \\\"Filter for runs with accuracy_score_X_test \\u2265 0.95 and list the shared preprocessing settings (dropped columns, test_size, etc.).\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 73,\\n+   \\\"id\\\": \\\"6e147555-afbf-4bba-b6da-7e90ff391920\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [\\n+    {\\n+     \\\"name\\\": \\\"stderr\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"2025/04/25 12:23:44 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'df84c36b36cc4ebd90a999db3ebc4ad4', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"[{'run_id': '28f01e38b7f04d2f948fe21f57f41d0c', 'param_dataset.title': 'Scikit-Learn Iris', 'param_columns_raw': \\\\\\\"['id', 'sepallengthcm', 'sepalwidthcm', 'petallengthcm', 'petalwidthcm', 'species']\\\\\\\", 'param_dropped_columns': \\\\\\\"['id']\\\\\\\", 'param_feature_names': \\\\\\\"['sepallengthcm', 'sepalwidthcm', 'petallengthcm', 'petalwidthcm']\\\\\\\", 'param_dataset.authors': '[\\\\\\\"Marshall Michael\\\\\\\"]', 'param_dataset.doi': '10.5281/ZENODO.1404173', 'param_dataset.published': '2018-8-27', 'param_test_size': '0.2', 'param_criterion': 'entropy', 'param_max_depth': '12', 'param_max_leaf_nodes': 'None', 'param_max_samples': 'None', 'metric_accuracy': 1.0, 'metric_f1_macro': 1.0, 'metric_roc_auc': 1.0}]\\\\n\\\",\\n+      \\\"[]\\\\n\\\",\\n+      \\\"[{'param_dropped_columns': \\\\\\\"['id']\\\\\\\", 'param_test_size': '0.2', 'param_feature_names': \\\\\\\"['sepallengthcm', 'sepalwidthcm', 'petallengthcm', 'petalwidthcm']\\\\\\\"}]\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"data\\\": {\\n+      \\\"application/vnd.jupyter.widget-view+json\\\": {\\n+       \\\"model_id\\\": \\\"d931b602947d4db8872f254d48e22027\\\",\\n+       \\\"version_major\\\": 2,\\n+       \\\"version_minor\\\": 0\\n+      },\\n+      \\\"text/plain\\\": [\\n+       \\\"Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]\\\"\\n+      ]\\n+     },\\n+     \\\"metadata\\\": {},\\n+     \\\"output_type\\\": \\\"display_data\\\"\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stderr\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"2025/04/25 12:23:52 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '41261519e1a643c5b1335701aee1bf95', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"{'features': ['sepallengthcm', 'sepalwidthcm'], 'accuracy': 0.7666666666666667}\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"data\\\": {\\n+      \\\"application/vnd.jupyter.widget-view+json\\\": {\\n+       \\\"model_id\\\": \\\"83ff1224205a4a8eb0c351a7f299dd93\\\",\\n+       \\\"version_major\\\": 2,\\n+       \\\"version_minor\\\": 0\\n+      },\\n+      \\\"text/plain\\\": [\\n+       \\\"Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]\\\"\\n+      ]\\n+     },\\n+     \\\"metadata\\\": {},\\n+     \\\"output_type\\\": \\\"display_data\\\"\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stderr\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"2025/04/25 12:23:58 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'e0955d231fa6488e9339086b5845064c', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"data\\\": {\\n+      \\\"application/vnd.jupyter.widget-view+json\\\": {\\n+       \\\"model_id\\\": \\\"1eaa6c141e064593b73b6c72ce0b00cf\\\",\\n+       \\\"version_major\\\": 2,\\n+       \\\"version_minor\\\": 0\\n+      },\\n+      \\\"text/plain\\\": [\\n+       \\\"Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]\\\"\\n+      ]\\n+     },\\n+     \\\"metadata\\\": {},\\n+     \\\"output_type\\\": \\\"display_data\\\"\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stderr\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"2025/04/25 12:24:04 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '21d299b426ac42a0ad799604e9e7ff88', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"{'dropped_feature': 'petallengthcm', 'baseline_acc': 1.0, 'dropped_acc': 0.9666666666666667, 'impact': 0.033333333333333326}\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"data\\\": {\\n+      \\\"application/vnd.jupyter.widget-view+json\\\": {\\n+       \\\"model_id\\\": \\\"4c04ce12f62f49a29f48509b1483f16b\\\",\\n+       \\\"version_major\\\": 2,\\n+       \\\"version_minor\\\": 0\\n+      },\\n+      \\\"text/plain\\\": [\\n+       \\\"Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]\\\"\\n+      ]\\n+     },\\n+     \\\"metadata\\\": {},\\n+     \\\"output_type\\\": \\\"display_data\\\"\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stderr\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"2025/04/25 12:24:10 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '8ca4591a1b53402f854187104d1e7ee0', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"data\\\": {\\n+      \\\"application/vnd.jupyter.widget-view+json\\\": {\\n+       \\\"model_id\\\": \\\"66bf06c45648410daa144c12f85658c6\\\",\\n+       \\\"version_major\\\": 2,\\n+       \\\"version_minor\\\": 0\\n+      },\\n+      \\\"text/plain\\\": [\\n+       \\\"Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]\\\"\\n+      ]\\n+     },\\n+     \\\"metadata\\\": {},\\n+     \\\"output_type\\\": \\\"display_data\\\"\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stderr\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"2025/04/25 12:24:16 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '0c8a66e5e4b244f9a6a8e9fa02d26828', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"data\\\": {\\n+      \\\"application/vnd.jupyter.widget-view+json\\\": {\\n+       \\\"model_id\\\": \\\"0d71b6d9b58d4e5a9db241baeaa79d53\\\",\\n+       \\\"version_major\\\": 2,\\n+       \\\"version_minor\\\": 0\\n+      },\\n+      \\\"text/plain\\\": [\\n+       \\\"Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]\\\"\\n+      ]\\n+     },\\n+     \\\"metadata\\\": {},\\n+     \\\"output_type\\\": \\\"display_data\\\"\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stderr\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"2025/04/25 12:24:22 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '53994143a51e481abd23e988be2466b1', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"data\\\": {\\n+      \\\"application/vnd.jupyter.widget-view+json\\\": {\\n+       \\\"model_id\\\": \\\"3fa13db4a66940d59cf37a30cb7a3cbc\\\",\\n+       \\\"version_major\\\": 2,\\n+       \\\"version_minor\\\": 0\\n+      },\\n+      \\\"text/plain\\\": [\\n+       \\\"Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]\\\"\\n+      ]\\n+     },\\n+     \\\"metadata\\\": {},\\n+     \\\"output_type\\\": \\\"display_data\\\"\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stderr\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"2025/04/25 12:24:28 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '35588f1cd8c34ce28770848de714d3c4', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"data\\\": {\\n+      \\\"application/vnd.jupyter.widget-view+json\\\": {\\n+       \\\"model_id\\\": \\\"273c026f2e0b464f98090472792b3a87\\\",\\n+       \\\"version_major\\\": 2,\\n+       \\\"version_minor\\\": 0\\n+      },\\n+      \\\"text/plain\\\": [\\n+       \\\"Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]\\\"\\n+      ]\\n+     },\\n+     \\\"metadata\\\": {},\\n+     \\\"output_type\\\": \\\"display_data\\\"\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"[{'dropped_feature': 'sepallengthcm', 'baseline_acc': 1.0, 'dropped_acc': 1.0, 'impact': 0.0}, {'dropped_feature': 'sepalwidthcm', 'baseline_acc': 1.0, 'dropped_acc': 1.0, 'impact': 0.0}, {'dropped_feature': 'petallengthcm', 'baseline_acc': 1.0, 'dropped_acc': 0.9666666666666667, 'impact': 0.0333}, {'dropped_feature': 'petalwidthcm', 'baseline_acc': 1.0, 'dropped_acc': 0.9666666666666667, 'impact': 0.0333}]\\\\n\\\"\\n+     ]\\n+    }\\n+   ],\\n+   \\\"source\\\": [\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# Helper to get the \\u201cofficial\\u201d feature_names from your summary DF\\\\n\\\",\\n+    \\\"def _get_all_features(df):\\\\n\\\",\\n+    \\\"    # assumes every row has the same param_feature_names\\\\n\\\",\\n+    \\\"    raw = df.loc[0, 'param_feature_names']\\\\n\\\",\\n+    \\\"    return ast.literal_eval(raw)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# Train & eval RF on just these columns of Iris\\\\n\\\",\\n+    \\\"def evaluate_subset(features, test_size=0.2, random_state=42, n_estimators=200):\\\\n\\\",\\n+    \\\"    iris = load_iris()\\\\n\\\",\\n+    \\\"    X = pd.DataFrame(iris.data, columns=iris.feature_names)\\\\n\\\",\\n+    \\\"    # map sklearn\\u2019s names to your param names, e.g. \\\\\\\"sepal length (cm)\\\\\\\" \\u2192 \\\\\\\"sepallengthcm\\\\\\\"\\\\n\\\",\\n+    \\\"    canon = _get_all_features(df)\\\\n\\\",\\n+    \\\"    mapping = dict(zip(iris.feature_names, canon))\\\\n\\\",\\n+    \\\"    X = X.rename(columns=mapping)\\\\n\\\",\\n+    \\\"    X_sub = X[features]\\\\n\\\",\\n+    \\\"    y = iris.target\\\\n\\\",\\n+    \\\"    Xtr, Xte, ytr, yte = train_test_split(X_sub, y, test_size=test_size, random_state=random_state)\\\\n\\\",\\n+    \\\"    m = RandomForestClassifier(n_estimators=n_estimators, random_state=random_state)\\\\n\\\",\\n+    \\\"    m.fit(Xtr, ytr)\\\\n\\\",\\n+    \\\"    return accuracy_score(yte, m.predict(Xte))\\\\n\\\",\\n+    \\\"def trace_preprocessing(df, run_id=None):\\\\n\\\",\\n+    \\\"    cols = ['run_id',\\\\n\\\",\\n+    \\\"            'param_dataset.title',\\\\n\\\",\\n+    \\\"            'param_columns_raw',\\\\n\\\",\\n+    \\\"            'param_dropped_columns',\\\\n\\\",\\n+    \\\"            'param_feature_names',\\\\n\\\",\\n+    \\\"            'param_dataset.authors', 'param_dataset.doi', 'param_dataset.published',\\\\n\\\",\\n+    \\\"            'param_test_size',\\\\n\\\",\\n+    \\\"            'param_criterion',\\\\n\\\",\\n+    \\\"            'param_max_depth','param_max_leaf_nodes', 'param_max_samples',\\\\n\\\",\\n+    \\\"           'metric_accuracy','metric_f1_macro','metric_roc_auc']\\\\n\\\",\\n+    \\\"    if run_id is None:\\\\n\\\",\\n+    \\\"        subset = df.loc[:, cols]\\\\n\\\",\\n+    \\\"    else:\\\\n\\\",\\n+    \\\"        subset = df.loc[df['run_id'] == run_id, cols]\\\\n\\\",\\n+    \\\"    return subset.to_dict(orient='records')\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"def drop_impact(df, feature, **_):\\\\n\\\",\\n+    \\\"    all_feats = _get_all_features(df)\\\\n\\\",\\n+    \\\"    baseline = evaluate_subset(all_feats)\\\\n\\\",\\n+    \\\"    without = [f for f in all_feats if f!=feature]\\\\n\\\",\\n+    \\\"    dropped = evaluate_subset(without)\\\\n\\\",\\n+    \\\"    return {\\\\n\\\",\\n+    \\\"      'dropped_feature': feature,\\\\n\\\",\\n+    \\\"      'baseline_acc': baseline,\\\\n\\\",\\n+    \\\"      'dropped_acc': dropped,\\\\n\\\",\\n+    \\\"      'impact': baseline - dropped\\\\n\\\",\\n+    \\\"    }\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"def drop_impact_all(df: pd.DataFrame) -> List[Dict[str, Any]]:\\\\n\\\",\\n+    \\\"    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\",\\n+    \\\"    Compute drop-impact for every feature in the dataset.\\\\n\\\",\\n+    \\\"    Returns list of dicts with dropped_feature, baseline_acc, dropped_acc, impact.\\\\n\\\",\\n+    \\\"    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\",\\n+    \\\"    feats = _get_all_features(df)\\\\n\\\",\\n+    \\\"    baseline = evaluate_subset(feats)\\\\n\\\",\\n+    \\\"    summary = []\\\\n\\\",\\n+    \\\"    for feat in feats:\\\\n\\\",\\n+    \\\"        without = [f for f in feats if f != feat]\\\\n\\\",\\n+    \\\"        acc = evaluate_subset(without)\\\\n\\\",\\n+    \\\"        summary.append({\\\\n\\\",\\n+    \\\"            'dropped_feature': feat,\\\\n\\\",\\n+    \\\"            'baseline_acc': baseline,\\\\n\\\",\\n+    \\\"            'dropped_acc': acc,\\\\n\\\",\\n+    \\\"            'impact': round(baseline - acc, 4)\\\\n\\\",\\n+    \\\"        })\\\\n\\\",\\n+    \\\"    return summary\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"def best_feature_subset(df, features, **_):\\\\n\\\",\\n+    \\\"    acc = evaluate_subset(features)\\\\n\\\",\\n+    \\\"    return {'features': features, 'accuracy': acc}\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"def common_high_accuracy(df: pd.DataFrame, threshold: float = 0.95) -> List[Dict[str, Any]]:\\\\n\\\",\\n+    \\\"    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\",\\n+    \\\"    Filter runs with test accuracy >= threshold and list unique shared preprocessing settings.\\\\n\\\",\\n+    \\\"    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\",\\n+    \\\"    high = df[df['metric_accuracy_score_X_test'] >= threshold]\\\\n\\\",\\n+    \\\"    cols = ['param_dropped_columns', 'param_test_size', 'param_feature_names']\\\\n\\\",\\n+    \\\"    return high[cols].drop_duplicates().to_dict(orient='records')\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# --------------------------------------------\\\\n\\\",\\n+    \\\"# Use Case Registry with parameter order for minimal input\\\\n\\\",\\n+    \\\"# --------------------------------------------\\\\n\\\",\\n+    \\\"USE_CASES = {\\\\n\\\",\\n+    \\\"    'trace_preprocessing': {\\\\n\\\",\\n+    \\\"        'func': trace_preprocessing,\\\\n\\\",\\n+    \\\"        'required_params': [],            # none strictly required\\\\n\\\",\\n+    \\\"        'optional_params': ['run_id'],    # run_id can be supplied or not\\\\n\\\",\\n+    \\\"    },\\\\n\\\",\\n+    \\\"    'drop_impact': {\\\\n\\\",\\n+    \\\"        'func': drop_impact,\\\\n\\\",\\n+    \\\"        'required_params': ['feature'],\\\\n\\\",\\n+    \\\"        'optional_params': [],\\\\n\\\",\\n+    \\\"    },\\\\n\\\",\\n+    \\\"     'drop_impact_all': {\\\\n\\\",\\n+    \\\"        'func': drop_impact_all,\\\\n\\\",\\n+    \\\"        'required_params': [],\\\\n\\\",\\n+    \\\"        'optional_params': [],\\\\n\\\",\\n+    \\\"    },\\\\n\\\",\\n+    \\\"    'best_feature_subset': {\\\\n\\\",\\n+    \\\"        'func': best_feature_subset,\\\\n\\\",\\n+    \\\"        'required_params': ['features'],\\\\n\\\",\\n+    \\\"        'optional_params': [],\\\\n\\\",\\n+    \\\"    },\\\\n\\\",\\n+    \\\"    'common_high_accuracy': {\\\\n\\\",\\n+    \\\"        'func': common_high_accuracy,\\\\n\\\",\\n+    \\\"        'required_params': ['threshold'],\\\\n\\\",\\n+    \\\"        'optional_params': [],\\\\n\\\",\\n+    \\\"    },\\\\n\\\",\\n+    \\\"}\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"def call_use_case(df, use_case_name, **kwargs):\\\\n\\\",\\n+    \\\"    if use_case_name not in USE_CASES:\\\\n\\\",\\n+    \\\"        raise ValueError(f\\\\\\\"Unknown use case: {use_case_name}\\\\\\\")\\\\n\\\",\\n+    \\\"    case = USE_CASES[use_case_name]\\\\n\\\",\\n+    \\\"    func = case['func']\\\\n\\\",\\n+    \\\"    # check required\\\\n\\\",\\n+    \\\"    missing = [p for p in case['required_params'] if p not in kwargs]\\\\n\\\",\\n+    \\\"    if missing:\\\\n\\\",\\n+    \\\"        raise ValueError(f\\\\\\\"{use_case_name} missing required params: {missing}\\\\\\\")\\\\n\\\",\\n+    \\\"    # build args\\\\n\\\",\\n+    \\\"    args = {p: kwargs[p] for p in case['required_params']}\\\\n\\\",\\n+    \\\"    for p in case['optional_params']:\\\\n\\\",\\n+    \\\"        args[p] = kwargs.get(p)\\\\n\\\",\\n+    \\\"    return func(df, **args)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# --------------------------------------------\\\\n\\\",\\n+    \\\"# Example Usage\\\\n\\\",\\n+    \\\"# --------------------------------------------\\\\n\\\",\\n+    \\\"if __name__ == '__main__':\\\\n\\\",\\n+    \\\"   # # 1) trace_preprocessing for all runs\\\\n\\\",\\n+    \\\"    print(call_use_case(df, 'trace_preprocessing'))\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    # 2) trace_preprocessing for a single run_id\\\\n\\\",\\n+    \\\"    print(call_use_case(df, 'trace_preprocessing', run_id='361daa12f99f4129a06cd20b78dd6fa7'))\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # 5) common_high_accuracy\\\\n\\\",\\n+    \\\"    print(call_use_case(df, 'common_high_accuracy', threshold=0.99))\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # 4) Best\\u2010subset on just sepals:\\\\n\\\",\\n+    \\\"    print(call_use_case(df, 'best_feature_subset', features=['sepallengthcm','sepalwidthcm']))\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # 3) Drop\\u2010impact for \\u201cpetallengthcm\\u201d:\\\\n\\\",\\n+    \\\"    print(call_use_case(df, 'drop_impact', feature='petallengthcm'))\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    print(call_use_case(df, 'drop_impact_all'))  # summary for all features\\\\n\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"96f912d6-0e84-4155-858a-9668bef63f6e\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\" \\u2022 Detecting models trained with deprecated code versions\\\\n\\\",\\n+    \\\" \\u2022 Mapping models to specific datasets used during training\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 74,\\n+   \\\"id\\\": \\\"34a02c9a-5459-478f-a3c5-7f7a58ff22b0\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"[{'param_dataset.doi': '10.5281/ZENODO.1404173',\\\\n\\\",\\n+      \\\"  'param_dataset.published': '2018-8-27',\\\\n\\\",\\n+      \\\"  'param_dataset.publisher': 'Zenodo',\\\\n\\\",\\n+      \\\"  'param_dataset.title': 'Scikit-Learn Iris',\\\\n\\\",\\n+      \\\"  'run_id': '28f01e38b7f04d2f948fe21f57f41d0c',\\\\n\\\",\\n+      \\\"  'tag_model_name': 'RandomForest_Iris_v20250425_121328'}]\\\\n\\\"\\n+     ]\\n+    }\\n+   ],\\n+   \\\"source\\\": [\\n+    \\\"\\\\n\\\",\\n+    \\\"def detect_deprecated_code(df: pd.DataFrame, deprecated_commits: List[str], **_) -> List[Dict[str, Any]]:\\\\n\\\",\\n+    \\\"    # we know the column is called tag_git_current_commit_hash\\\\n\\\",\\n+    \\\"    commit_col = 'tag_git_current_commit_hash'\\\\n\\\",\\n+    \\\"    if commit_col not in df.columns:\\\\n\\\",\\n+    \\\"        raise KeyError(f\\\\\\\"Missing {commit_col} in DataFrame\\\\\\\")\\\\n\\\",\\n+    \\\"    out = df[df[commit_col].isin(deprecated_commits)]\\\\n\\\",\\n+    \\\"    # include run_id and notebook/runName for context\\\\n\\\",\\n+    \\\"    cols = ['run_id', commit_col, 'tag_notebook_name', 'tag_mlflow.runName']\\\\n\\\",\\n+    \\\"    # drop any that don\\u2019t exist\\\\n\\\",\\n+    \\\"    cols = [c for c in cols if c in df.columns]\\\\n\\\",\\n+    \\\"    return out[cols].to_dict(orient='records')\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"def map_model_dataset(df: pd.DataFrame, **_) -> List[Dict[str, Any]]:\\\\n\\\",\\n+    \\\"    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\",\\n+    \\\"    For each run, return its model name (or run_id) alongside the dataset\\\\n\\\",\\n+    \\\"    title, DOI, published date and publisher.\\\\n\\\",\\n+    \\\"    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\",\\n+    \\\"    # pick whichever model-name column you have\\\\n\\\",\\n+    \\\"    model_col = 'tag_model_name' if 'tag_model_name' in df.columns else 'param_model_name'\\\\n\\\",\\n+    \\\"    cols = [\\\\n\\\",\\n+    \\\"        'run_id',\\\\n\\\",\\n+    \\\"        model_col,\\\\n\\\",\\n+    \\\"        'param_dataset.title',\\\\n\\\",\\n+    \\\"        'param_dataset.doi',\\\\n\\\",\\n+    \\\"        'param_dataset.published',\\\\n\\\",\\n+    \\\"        'param_dataset.publisher'\\\\n\\\",\\n+    \\\"    ]\\\\n\\\",\\n+    \\\"    # filter out any columns that don\\u2019t actually exist\\\\n\\\",\\n+    \\\"    cols = [c for c in cols if c in df.columns]\\\\n\\\",\\n+    \\\"    return df[cols].to_dict(orient='records')\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# --------------------------------------------\\\\n\\\",\\n+    \\\"# Extend Use-Case Registry\\\\n\\\",\\n+    \\\"# --------------------------------------------\\\\n\\\",\\n+    \\\"USE_CASES.update({\\\\n\\\",\\n+    \\\"    'detect_deprecated_code': {\\\\n\\\",\\n+    \\\"        'func': detect_deprecated_code,\\\\n\\\",\\n+    \\\"        'required_params': ['deprecated_commits'],\\\\n\\\",\\n+    \\\"        'optional_params': []\\\\n\\\",\\n+    \\\"    },\\\\n\\\",\\n+    \\\"    'map_model_dataset': {\\\\n\\\",\\n+    \\\"        'func': map_model_dataset,\\\\n\\\",\\n+    \\\"        'required_params': [],\\\\n\\\",\\n+    \\\"        'optional_params': []\\\\n\\\",\\n+    \\\"    },\\\\n\\\",\\n+    \\\"})\\\\n\\\",\\n+    \\\"# 1) Detect runs on deprecated commits:\\\\n\\\",\\n+    \\\"deprecated = [\\\\n\\\",\\n+    \\\"    \\\\\\\"a07434af4f547af2daab044d6873eb7081162293\\\\\\\",\\\\n\\\",\\n+    \\\"    \\\\\\\"d329c92495e196ec0f39fbb19dfdd367131a77d9\\\\\\\"\\\\n\\\",\\n+    \\\"]\\\\n\\\",\\n+    \\\"# print(call_use_case(df, \\\\\\\"detect_deprecated_code\\\\\\\", deprecated_commits=deprecated))\\\\n\\\",\\n+    \\\"pprint(call_use_case(df, 'map_model_dataset'))\\\\n\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"c52607ad-5849-4a2d-97ef-e8fc1ca16dc7\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"Goal: Notify collaborators who have forked the GitHub repo if their fork is outdated (i.e., behind the current commit used to train a model).\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"f29c8ad9-00bb-4c1e-ac3b-ee6861991acd\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"\\ud83e\\udde0 What We Need\\\\n\\\",\\n+    \\\"Current training run\\u2019s Git commit hash\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"GitHub API to fetch all forks of your repo\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"Compare each fork\\u2019s main or master branch head commit\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"Create an issue on their fork or on your repo tagging them if they\\u2019re behind\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"c72bed50-fb56-442d-a21e-bb7991892d07\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\": Notify via issues on your own repo\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 75,\\n+   \\\"id\\\": \\\"852f147c-9d0a-4d7f-a4ab-545d1e2375fb\\\",\\n+   \\\"metadata\\\": {\\n+    \\\"scrolled\\\": true\\n+   },\\n+   \\\"outputs\\\": [\\n+    {\\n+     \\\"name\\\": \\\"stdin\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"Do you want to notify collaborators whose forks are behind? (y/N):  N\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"No action taken.\\\\n\\\"\\n+     ]\\n+    }\\n+   ],\\n+   \\\"source\\\": [\\n+    \\\"def notify_outdated_forks():\\\\n\\\",\\n+    \\\"    load_dotenv()\\\\n\\\",\\n+    \\\"    token     = os.getenv(\\\\\\\"THESIS_TOKEN\\\\\\\")\\\\n\\\",\\n+    \\\"    owner     = \\\\\\\"reema-dass26\\\\\\\"\\\\n\\\",\\n+    \\\"    repo      = \\\\\\\"REPO\\\\\\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    if not token:\\\\n\\\",\\n+    \\\"        print(\\\\\\\"\\u26a0\\ufe0f GITHUB_TOKEN not set.\\\\\\\")\\\\n\\\",\\n+    \\\"        return\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    headers = {\\\\n\\\",\\n+    \\\"        \\\\\\\"Authorization\\\\\\\": f\\\\\\\"token {token}\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"Accept\\\\\\\":        \\\\\\\"application/vnd.github.v3+json\\\\\\\"\\\\n\\\",\\n+    \\\"    }\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # 1) Get latest upstream commit\\\\n\\\",\\n+    \\\"    main_commits = requests.get(\\\\n\\\",\\n+    \\\"        f\\\\\\\"https://api.github.com/repos/{owner}/{repo}/commits\\\\\\\",\\\\n\\\",\\n+    \\\"        headers=headers,\\\\n\\\",\\n+    \\\"        params={\\\\\\\"per_page\\\\\\\": 1}\\\\n\\\",\\n+    \\\"    )\\\\n\\\",\\n+    \\\"    main_commits.raise_for_status()\\\\n\\\",\\n+    \\\"    new_commit_hash = main_commits.json()[0][\\\\\\\"sha\\\\\\\"]\\\\n\\\",\\n+    \\\"    print(f\\\\\\\"Latest upstream commit: {new_commit_hash}\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # 2) List forks\\\\n\\\",\\n+    \\\"    forks_resp = requests.get(f\\\\\\\"https://api.github.com/repos/{owner}/{repo}/forks\\\\\\\", headers=headers)\\\\n\\\",\\n+    \\\"    forks_resp.raise_for_status()\\\\n\\\",\\n+    \\\"    forks = forks_resp.json()\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # 3) Compare each fork\\\\n\\\",\\n+    \\\"    outdated = []\\\\n\\\",\\n+    \\\"    for fork in forks:\\\\n\\\",\\n+    \\\"        fork_owner = fork[\\\\\\\"owner\\\\\\\"][\\\\\\\"login\\\\\\\"]\\\\n\\\",\\n+    \\\"        fork_comm = requests.get(\\\\n\\\",\\n+    \\\"            fork[\\\\\\\"url\\\\\\\"] + \\\\\\\"/commits\\\\\\\",\\\\n\\\",\\n+    \\\"            headers=headers,\\\\n\\\",\\n+    \\\"            params={\\\\\\\"per_page\\\\\\\": 1}\\\\n\\\",\\n+    \\\"        )\\\\n\\\",\\n+    \\\"        if fork_comm.status_code != 200:\\\\n\\\",\\n+    \\\"            print(f\\\\\\\"\\u00a0\\u00a0\\u2013 could not fetch commits for {fork_owner}, skipping.\\\\\\\")\\\\n\\\",\\n+    \\\"            continue\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"        fork_sha = fork_comm.json()[0][\\\\\\\"sha\\\\\\\"]\\\\n\\\",\\n+    \\\"        if fork_sha != new_commit_hash:\\\\n\\\",\\n+    \\\"            outdated.append(f\\\\\\\"@{fork_owner}\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # 4) Open an issue if any are behind\\\\n\\\",\\n+    \\\"    if outdated:\\\\n\\\",\\n+    \\\"        title = \\\\\\\"\\ud83d\\udd14 Notification: Your fork is behind the latest commit\\\\\\\"\\\\n\\\",\\n+    \\\"        body  = (\\\\n\\\",\\n+    \\\"            f\\\\\\\"Hi {' '.join(outdated)},\\\\\\\\n\\\\\\\\n\\\\\\\"\\\\n\\\",\\n+    \\\"            f\\\\\\\"The main repository has been updated to commit `{new_commit_hash}`.\\\\\\\\n\\\\\\\"\\\\n\\\",\\n+    \\\"            \\\\\\\"Please consider pulling the latest changes to stay in sync.\\\\\\\\n\\\\\\\\n\\\\\\\"\\\\n\\\",\\n+    \\\"            \\\\\\\"Thanks!\\\\\\\"\\\\n\\\",\\n+    \\\"        )\\\\n\\\",\\n+    \\\"        issues_url = f\\\\\\\"https://api.github.com/repos/{owner}/{repo}/issues\\\\\\\"\\\\n\\\",\\n+    \\\"        resp = requests.post(\\\\n\\\",\\n+    \\\"        issues_url,\\\\n\\\",\\n+    \\\"        headers=headers,\\\\n\\\",\\n+    \\\"        json={\\\\\\\"title\\\\\\\": title, \\\\\\\"body\\\\\\\": body}\\\\n\\\",\\n+    \\\"    )\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # DEBUGGING OUTPUT\\\\n\\\",\\n+    \\\"    print(f\\\\\\\"\\u2192 POST {issues_url}\\\\\\\")\\\\n\\\",\\n+    \\\"    print(\\\\\\\"\\u2192 Status code:\\\\\\\", resp.status_code)\\\\n\\\",\\n+    \\\"    print(\\\\\\\"\\u2192 Response headers:\\\\\\\", resp.headers)\\\\n\\\",\\n+    \\\"    try:\\\\n\\\",\\n+    \\\"        data = resp.json()\\\\n\\\",\\n+    \\\"        print(\\\\\\\"\\u2192 Response JSON:\\\\\\\", data)\\\\n\\\",\\n+    \\\"        print(\\\\\\\"\\u2192 html_url field:\\\\\\\", data.get(\\\\\\\"html_url\\\\\\\"))\\\\n\\\",\\n+    \\\"    except ValueError:\\\\n\\\",\\n+    \\\"        print(\\\\\\\"\\u2192 No JSON response body; raw text:\\\\\\\", resp.text)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"if __name__ == \\\\\\\"__main__\\\\\\\":\\\\n\\\",\\n+    \\\"    answer = input(\\\\\\\"Do you want to notify collaborators whose forks are behind? (y/N): \\\\\\\").strip().lower()\\\\n\\\",\\n+    \\\"    if answer in (\\\\\\\"y\\\\\\\", \\\\\\\"yes\\\\\\\"):\\\\n\\\",\\n+    \\\"        notify_outdated_forks()\\\\n\\\",\\n+    \\\"    else:\\\\n\\\",\\n+    \\\"        print(\\\\\\\"No action taken.\\\\\\\")\\\\n\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"cda31f16-fbe9-40ce-ac1b-9ebc898c8820\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"INVENIO INTEGRETION to upload the necessary files and publish\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": null,\\n+   \\\"id\\\": \\\"c2e5a7fc-3b03-45c8-bc90-817ea5ba7352\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [],\\n+   \\\"source\\\": [\\n+    \\\"############################################################################################\\\\n\\\",\\n+    \\\"# TEST CODE FOR INVENIO INTEGRETION\\\\n\\\",\\n+    \\\"#############################################################################################\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# API_BASE = \\\\\\\"https://127.0.0.1:5000\\\\\\\"\\\\n\\\",\\n+    \\\"# TOKEN    = \\\\\\\"8LnqJuz3TsBHffnDJ3isPLHYHtRbWrC0M667Nb5haEbnXpWqGbFRyfDApymr\\\\\\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# # 1) Test read\\u2010scope by listing records (no size param or size=1)\\\\n\\\",\\n+    \\\"# resp = requests.get(\\\\n\\\",\\n+    \\\"#     f\\\\\\\"{API_BASE}/api/records\\\\\\\",\\\\n\\\",\\n+    \\\"#     headers={\\\\\\\"Authorization\\\\\\\": f\\\\\\\"Bearer {TOKEN}\\\\\\\"},\\\\n\\\",\\n+    \\\"#     verify=False\\\\n\\\",\\n+    \\\"# )\\\\n\\\",\\n+    \\\"# print(resp.status_code)\\\\n\\\",\\n+    \\\"# # should be 200 and a JSON page of records\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# # or explicitly:\\\\n\\\",\\n+    \\\"# resp = requests.get(\\\\n\\\",\\n+    \\\"#     f\\\\\\\"{API_BASE}/api/records?size=1\\\\\\\",\\\\n\\\",\\n+    \\\"#     headers={\\\\\\\"Authorization\\\\\\\": f\\\\\\\"Bearer {TOKEN}\\\\\\\"},\\\\n\\\",\\n+    \\\"#     verify=False\\\\n\\\",\\n+    \\\"# )\\\\n\\\",\\n+    \\\"# print(resp.status_code, resp.json())\\\\n\\\",\\n+    \\\"# #################################################################################################\\\\n\\\",\\n+    \\\"# API_BASE = \\\\\\\"https://127.0.0.1:5000\\\\\\\"\\\\n\\\",\\n+    \\\"# TOKEN    = \\\\\\\"8LnqJuz3TsBHffnDJ3isPLHYHtRbWrC0M667Nb5haEbnXpWqGbFRyfDApymr\\\\\\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# resp = requests.options(\\\\n\\\",\\n+    \\\"#     f\\\\\\\"{API_BASE}/api/records\\\\\\\",\\\\n\\\",\\n+    \\\"#     headers={\\\\\\\"Authorization\\\\\\\": f\\\\\\\"Bearer {TOKEN}\\\\\\\"},\\\\n\\\",\\n+    \\\"#     verify=False\\\\n\\\",\\n+    \\\"# )\\\\n\\\",\\n+    \\\"# print(\\\\\\\"Allowed methods:\\\\\\\", resp.headers.get(\\\\\\\"Allow\\\\\\\"))\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": null,\\n+   \\\"id\\\": \\\"7e5b2cc5-ecf3-4e13-8cac-47f57f12cbdd\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [],\\n+   \\\"source\\\": [\\n+    \\\"\\\\n\\\",\\n+    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n+    \\\"# Configuration\\\\n\\\",\\n+    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n+    \\\"API_BASE   = \\\\\\\"https://127.0.0.1:5000\\\\\\\"\\\\n\\\",\\n+    \\\"TOKEN      = \\\\\\\"8LnqJuz3TsBHffnDJ3isPLHYHtRbWrC0M667Nb5haEbnXpWqGbFRyfDApymr\\\\\\\"\\\\n\\\",\\n+    \\\"VERIFY_SSL = False  # only for self\\u2010signed dev\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"HEADERS_JSON = {\\\\n\\\",\\n+    \\\"    \\\\\\\"Accept\\\\\\\":        \\\\\\\"application/json\\\\\\\",\\\\n\\\",\\n+    \\\"    \\\\\\\"Content-Type\\\\\\\":  \\\\\\\"application/json\\\\\\\",\\\\n\\\",\\n+    \\\"    \\\\\\\"Authorization\\\\\\\": f\\\\\\\"Bearer {TOKEN}\\\\\\\",\\\\n\\\",\\n+    \\\"}\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"HEADERS_OCTET = {\\\\n\\\",\\n+    \\\"    \\\\\\\"Content-Type\\\\\\\":  \\\\\\\"application/octet-stream\\\\\\\",\\\\n\\\",\\n+    \\\"    \\\\\\\"Authorization\\\\\\\": f\\\\\\\"Bearer {TOKEN}\\\\\\\",\\\\n\\\",\\n+    \\\"}\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# The folders you want to walk & upload:\\\\n\\\",\\n+    \\\"TO_UPLOAD = [\\\\\\\"Trained_models\\\\\\\", \\\\\\\"plots\\\\\\\", \\\\\\\"MODEL_PROVENANCE\\\\\\\"]\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n+    \\\"# 1) Create draft with ALL required metadata\\\\n\\\",\\n+    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n+    \\\"def create_draft():\\\\n\\\",\\n+    \\\"    payload = {\\\\n\\\",\\n+    \\\"  \\\\\\\"metadata\\\\\\\": {\\\\n\\\",\\n+    \\\"    \\\\\\\"title\\\\\\\":            \\\\\\\"RandomForest Iris Model Artifacts\\\\\\\",\\\\n\\\",\\n+    \\\"    \\\\\\\"creators\\\\\\\": [ {\\\\n\\\",\\n+    \\\"      \\\\\\\"person_or_org\\\\\\\": {\\\\n\\\",\\n+    \\\"        \\\\\\\"type\\\\\\\":        \\\\\\\"personal\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"given_name\\\\\\\":  \\\\\\\"Reema\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"family_name\\\\\\\": \\\\\\\"Dass\\\\\\\"\\\\n\\\",\\n+    \\\"      }\\\\n\\\",\\n+    \\\"    } ],\\\\n\\\",\\n+    \\\"    \\\\\\\"publication_date\\\\\\\": \\\\\\\"2025-04-24\\\\\\\",\\\\n\\\",\\n+    \\\"    \\\\\\\"resource_type\\\\\\\":    { \\\\\\\"id\\\\\\\": \\\\\\\"software\\\\\\\" },\\\\n\\\",\\n+    \\\"    \\\\\\\"access\\\\\\\": {\\\\n\\\",\\n+    \\\"      \\\\\\\"record\\\\\\\": \\\\\\\"public\\\\\\\",\\\\n\\\",\\n+    \\\"      \\\\\\\"files\\\\\\\":  \\\\\\\"public\\\\\\\"\\\\n\\\",\\n+    \\\"    }\\\\n\\\",\\n+    \\\"  }\\\\n\\\",\\n+    \\\"}\\\\n\\\",\\n+    \\\"    r = requests.post(f\\\\\\\"{API_BASE}/api/records\\\\\\\",\\\\n\\\",\\n+    \\\"                      headers=HEADERS_JSON,\\\\n\\\",\\n+    \\\"                      json=payload,\\\\n\\\",\\n+    \\\"                      verify=VERIFY_SSL)\\\\n\\\",\\n+    \\\"    r.raise_for_status()\\\\n\\\",\\n+    \\\"    draft = r.json()\\\\n\\\",\\n+    \\\"    print(\\\\\\\"\\u2705 Draft created:\\\\\\\", draft[\\\\\\\"id\\\\\\\"])\\\\n\\\",\\n+    \\\"    return draft[\\\\\\\"id\\\\\\\"], draft[\\\\\\\"links\\\\\\\"]\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n+    \\\"# 2) Register, upload and commit a single file\\\\n\\\",\\n+    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n+    \\\"def upload_and_commit(links, key, path):\\\\n\\\",\\n+    \\\"    # 2a) register the filename in the draft\\\\n\\\",\\n+    \\\"    r1 = requests.post(links[\\\\\\\"files\\\\\\\"],\\\\n\\\",\\n+    \\\"                       headers=HEADERS_JSON,\\\\n\\\",\\n+    \\\"                       json=[{\\\\\\\"key\\\\\\\": key}],\\\\n\\\",\\n+    \\\"                       verify=VERIFY_SSL)\\\\n\\\",\\n+    \\\"    r1.raise_for_status()\\\\n\\\",\\n+    \\\"    entry = next(e for e in r1.json()[\\\\\\\"entries\\\\\\\"] if e[\\\\\\\"key\\\\\\\"] == key)\\\\n\\\",\\n+    \\\"    file_links = entry[\\\\\\\"links\\\\\\\"]\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # 2b) upload the bytes\\\\n\\\",\\n+    \\\"    with open(path, \\\\\\\"rb\\\\\\\") as fp:\\\\n\\\",\\n+    \\\"        r2 = requests.put(file_links[\\\\\\\"content\\\\\\\"],\\\\n\\\",\\n+    \\\"                          headers=HEADERS_OCTET,\\\\n\\\",\\n+    \\\"                          data=fp,\\\\n\\\",\\n+    \\\"                          verify=VERIFY_SSL)\\\\n\\\",\\n+    \\\"    r2.raise_for_status()\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # 2c) commit the upload\\\\n\\\",\\n+    \\\"    r3 = requests.post(file_links[\\\\\\\"commit\\\\\\\"],\\\\n\\\",\\n+    \\\"                       headers=HEADERS_JSON,\\\\n\\\",\\n+    \\\"                       verify=VERIFY_SSL)\\\\n\\\",\\n+    \\\"    r3.raise_for_status()\\\\n\\\",\\n+    \\\"    print(f\\\\\\\"  \\u2022 Uploaded {key}\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n+    \\\"# 3) Walk each folder and upload every file\\\\n\\\",\\n+    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n+    \\\"def upload_folder(links):\\\\n\\\",\\n+    \\\"    for folder in TO_UPLOAD:\\\\n\\\",\\n+    \\\"        if not os.path.isdir(folder):\\\\n\\\",\\n+    \\\"            print(f\\\\\\\"\\u26a0\\ufe0f Skipping missing folder {folder}\\\\\\\")\\\\n\\\",\\n+    \\\"            continue\\\\n\\\",\\n+    \\\"        base = os.path.dirname(folder) or folder\\\\n\\\",\\n+    \\\"        for root, _, files in os.walk(folder):\\\\n\\\",\\n+    \\\"            for fn in files:\\\\n\\\",\\n+    \\\"                local = os.path.join(root, fn)\\\\n\\\",\\n+    \\\"                # create a POSIX\\u2010style key preserving subfolders\\\\n\\\",\\n+    \\\"                key = os.path.relpath(local, start=base).replace(os.sep, \\\\\\\"/\\\\\\\")\\\\n\\\",\\n+    \\\"                upload_and_commit(links, key, local)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n+    \\\"# 4) Publish the draft\\\\n\\\",\\n+    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n+    \\\"def publish(links):\\\\n\\\",\\n+    \\\"    r = requests.post(links[\\\\\\\"publish\\\\\\\"],\\\\n\\\",\\n+    \\\"                      headers=HEADERS_JSON,\\\\n\\\",\\n+    \\\"                      verify=VERIFY_SSL)\\\\n\\\",\\n+    \\\"    if not r.ok:\\\\n\\\",\\n+    \\\"        print(\\\\\\\"\\u274c Publish failed:\\\\\\\", r.status_code, r.text)\\\\n\\\",\\n+    \\\"        try: print(r.json())\\\\n\\\",\\n+    \\\"        except: pass\\\\n\\\",\\n+    \\\"        r.raise_for_status()\\\\n\\\",\\n+    \\\"    print(\\\\\\\"\\u2705 Published:\\\\\\\", r.json()[\\\\\\\"id\\\\\\\"])\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n+    \\\"# 5) Fetch metadata and save to a file\\\\n\\\",\\n+    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n+    \\\"def fetch_metadata(record_id):\\\\n\\\",\\n+    \\\"    r = requests.get(f\\\\\\\"{API_BASE}/api/records/{record_id}\\\\\\\",\\\\n\\\",\\n+    \\\"                     headers=HEADERS_JSON,\\\\n\\\",\\n+    \\\"                     verify=VERIFY_SSL)\\\\n\\\",\\n+    \\\"    r.raise_for_status()\\\\n\\\",\\n+    \\\"    metadata = r.json()\\\\n\\\",\\n+    \\\"    print(\\\\\\\"\\u2705 Metadata fetched successfully\\\\\\\")\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    # Save the metadata to a file\\\\n\\\",\\n+    \\\"    with open(f\\\\\\\"metadata_{record_id}.json\\\\\\\", \\\\\\\"w\\\\\\\") as f:\\\\n\\\",\\n+    \\\"        json.dump(metadata, f, indent=4)\\\\n\\\",\\n+    \\\"    print(f\\\\\\\"\\u2705 Metadata saved as metadata_{record_id}.json\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n+    \\\"# Main\\\\n\\\",\\n+    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n+    \\\"if __name__ == \\\\\\\"__main__\\\\\\\":\\\\n\\\",\\n+    \\\"    recid, links = create_draft()\\\\n\\\",\\n+    \\\"    upload_folder(links)\\\\n\\\",\\n+    \\\"    publish(links)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # Fetch and save metadata after publishing\\\\n\\\",\\n+    \\\"    print(fetch_metadata(recid))\\\\n\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"2f7423f2-0ff3-4104-913e-50eeb32d9d0f\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"METADATA EXTRACTION FROM INVENIO:\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": null,\\n+   \\\"id\\\": \\\"0013878b-37da-4a22-9586-3773531bfd01\\\",\\n+   \\\"metadata\\\": {\\n+    \\\"scrolled\\\": true\\n+   },\\n+   \\\"outputs\\\": [],\\n+   \\\"source\\\": [\\n+    \\\"\\\\n\\\",\\n+    \\\"# Function to dynamically extract and structure metadata from the original JSON\\\\n\\\",\\n+    \\\"def extract_metadata(metadata):\\\\n\\\",\\n+    \\\"    # Debug: Check if metadata is loaded correctly\\\\n\\\",\\n+    \\\"    print(\\\\\\\"Debug: Metadata loaded successfully\\\\\\\")\\\\n\\\",\\n+    \\\"    print(metadata.get(\\\\\\\"id\\\\\\\", \\\\\\\"\\\\\\\"))  # Check if 'id' is being fetched\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # Check if the required fields are in the metadata\\\\n\\\",\\n+    \\\"    print(\\\\\\\"Debug: Extracting fields from metadata...\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    extracted_data = {\\\\n\\\",\\n+    \\\"        \\\\\\\"invenio_metadata\\\\\\\": {\\\\n\\\",\\n+    \\\"            \\\\\\\"id\\\\\\\": metadata.get(\\\\\\\"id\\\\\\\", \\\\\\\"\\\\\\\"),\\\\n\\\",\\n+    \\\"            \\\\\\\"title\\\\\\\": metadata.get(\\\\\\\"metadata\\\\\\\", {}).get(\\\\\\\"title\\\\\\\", \\\\\\\"\\\\\\\"),\\\\n\\\",\\n+    \\\"            \\\\\\\"creator\\\\\\\": \\\\\\\", \\\\\\\".join([creator[\\\\\\\"person_or_org\\\\\\\"].get(\\\\\\\"name\\\\\\\", \\\\\\\"\\\\\\\") for creator in metadata.get(\\\\\\\"metadata\\\\\\\", {}).get(\\\\\\\"creators\\\\\\\", [])]),\\\\n\\\",\\n+    \\\"            \\\\\\\"publication_date\\\\\\\": metadata.get(\\\\\\\"metadata\\\\\\\", {}).get(\\\\\\\"publication_date\\\\\\\", \\\\\\\"\\\\\\\"),\\\\n\\\",\\n+    \\\"            \\\\\\\"files\\\\\\\": [],  # Initialize 'files' as a list\\\\n\\\",\\n+    \\\"            \\\\\\\"pids\\\\\\\": metadata.get(\\\\\\\"pids\\\\\\\", {}),\\\\n\\\",\\n+    \\\"            \\\\\\\"version_info\\\\\\\": metadata.get(\\\\\\\"versions\\\\\\\", {}),\\\\n\\\",\\n+    \\\"            \\\\\\\"status\\\\\\\": metadata.get(\\\\\\\"status\\\\\\\", \\\\\\\"\\\\\\\"),\\\\n\\\",\\n+    \\\"            \\\\\\\"views\\\\\\\": metadata.get(\\\\\\\"stats\\\\\\\", {}).get(\\\\\\\"this_version\\\\\\\", {}).get(\\\\\\\"views\\\\\\\", 0),\\\\n\\\",\\n+    \\\"            \\\\\\\"downloads\\\\\\\": metadata.get(\\\\\\\"stats\\\\\\\", {}).get(\\\\\\\"this_version\\\\\\\", {}).get(\\\\\\\"downloads\\\\\\\", 0),\\\\n\\\",\\n+    \\\"        }\\\\n\\\",\\n+    \\\"    }\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # Extract file details from the metadata\\\\n\\\",\\n+    \\\"    for key, file_info in metadata.get(\\\\\\\"files\\\\\\\", {}).get(\\\\\\\"entries\\\\\\\", {}).items():\\\\n\\\",\\n+    \\\"        file_detail = {\\\\n\\\",\\n+    \\\"            \\\\\\\"key\\\\\\\": key,\\\\n\\\",\\n+    \\\"            \\\\\\\"url\\\\\\\": file_info[\\\\\\\"links\\\\\\\"].get(\\\\\\\"content\\\\\\\", \\\\\\\"\\\\\\\"),\\\\n\\\",\\n+    \\\"            \\\\\\\"size\\\\\\\": file_info.get(\\\\\\\"size\\\\\\\", 0),\\\\n\\\",\\n+    \\\"            \\\\\\\"mimetype\\\\\\\": file_info.get(\\\\\\\"mimetype\\\\\\\", \\\\\\\"\\\\\\\"),\\\\n\\\",\\n+    \\\"            \\\\\\\"checksum\\\\\\\": file_info.get(\\\\\\\"checksum\\\\\\\", \\\\\\\"\\\\\\\"),\\\\n\\\",\\n+    \\\"            \\\\\\\"metadata\\\\\\\": file_info.get(\\\\\\\"metadata\\\\\\\", {}),\\\\n\\\",\\n+    \\\"        }\\\\n\\\",\\n+    \\\"        extracted_data[\\\\\\\"invenio_metadata\\\\\\\"][\\\\\\\"files\\\\\\\"].append(file_detail)  # Append to the 'files' list\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    return extracted_data\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# Load the original metadata from the JSON file (replace with your actual file path)\\\\n\\\",\\n+    \\\"with open('metadata_p8a8y-1bn93.json', 'r') as f: \\\\n\\\",\\n+    \\\"    original_metadata = json.load(f)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# Debugging: print out the first part of the original metadata to verify its structure\\\\n\\\",\\n+    \\\"print(\\\\\\\"Debug: Original Metadata (start):\\\\\\\", json.dumps(original_metadata, indent=4)[:1000])  # Print only the start for review\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# Extract relevant details dynamically\\\\n\\\",\\n+    \\\"extracted_metadata = extract_metadata(original_metadata)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# Debugging: print the extracted metadata to verify it's correct\\\\n\\\",\\n+    \\\"print(\\\\\\\"Debug: Extracted Metadata:\\\\\\\", json.dumps(extracted_metadata, indent=4))\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# Load the existing JSON file (replace with your actual file path)\\\\n\\\",\\n+    \\\"with open('MODEL_PROVENANCE/RandomForest_Iris_v20250424_111946_run_summary.json', 'r') as f:\\\\n\\\",\\n+    \\\"    existing_metadata = json.load(f)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# Add the extracted metadata as a new node\\\\n\\\",\\n+    \\\"existing_metadata.update(extracted_metadata)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# Save the updated metadata back to the file\\\\n\\\",\\n+    \\\"with open('updated_metadata.json', 'w') as f:\\\\n\\\",\\n+    \\\"    json.dump(existing_metadata, f, indent=4)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"print(\\\\\\\"\\u2705 New dynamic metadata added successfully!\\\\\\\")\\\\n\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": null,\\n+   \\\"id\\\": \\\"38a807a7-6ecd-4ea7-93ac-78c0f853825c\\\",\\n+   \\\"metadata\\\": {\\n+    \\\"scrolled\\\": true\\n+   },\\n+   \\\"outputs\\\": [],\\n+   \\\"source\\\": [\\n+    \\\"# import mlflow\\\\n\\\",\\n+    \\\"# import mlflow.sklearn\\\\n\\\",\\n+    \\\"# from sklearn.datasets import load_iris\\\\n\\\",\\n+    \\\"# from sklearn.ensemble import RandomForestClassifier\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# X, y = load_iris(return_X_y=True)\\\\n\\\",\\n+    \\\"# mlflow.sklearn.autolog()\\\\n\\\",\\n+    \\\"# with mlflow.start_run() as run:\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"#     model = RandomForestClassifier(**hyperparams)\\\\n\\\",\\n+    \\\"#     model.fit(X_train, y_train)\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": null,\\n+   \\\"id\\\": \\\"570fa169-a5e2-47b3-b7f5-44f9577f22ad\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [],\\n+   \\\"source\\\": []\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": null,\\n+   \\\"id\\\": \\\"f67b7a46-a70d-44ea-976c-322a1a795311\\\",\\n+   \\\"metadata\\\": {\\n+    \\\"scrolled\\\": true\\n+   },\\n+   \\\"outputs\\\": [],\\n+   \\\"source\\\": []\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": null,\\n+   \\\"id\\\": \\\"4211bdef-5785-472d-8ea5-0bc24a3faf3c\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [],\\n+   \\\"source\\\": []\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": null,\\n+   \\\"id\\\": \\\"9d4d71f2-ef66-4e04-9d9b-c4b381d45590\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [],\\n+   \\\"source\\\": []\\n+  }\\n+ ],\\n+ \\\"metadata\\\": {\\n+  \\\"kernelspec\\\": {\\n+   \\\"display_name\\\": \\\"Python 3 (ipykernel)\\\",\\n+   \\\"language\\\": \\\"python\\\",\\n+   \\\"name\\\": \\\"python3\\\"\\n+  },\\n+  \\\"language_info\\\": {\\n+   \\\"codemirror_mode\\\": {\\n+    \\\"name\\\": \\\"ipython\\\",\\n+    \\\"version\\\": 3\\n+   },\\n+   \\\"file_extension\\\": \\\".py\\\",\\n+   \\\"mimetype\\\": \\\"text/x-python\\\",\\n+   \\\"name\\\": \\\"python\\\",\\n+   \\\"nbconvert_exporter\\\": \\\"python\\\",\\n+   \\\"pygments_lexer\\\": \\\"ipython3\\\",\\n+   \\\"version\\\": \\\"3.11.5\\\"\\n+  }\\n+ },\\n+ \\\"nbformat\\\": 4,\\n+ \\\"nbformat_minor\\\": 5\\n+}\\ndiff --git a/notebooks/RQ_notebooks/RQ1_updated-Copy1.ipynb b/notebooks/RQ_notebooks/RQ1_updated-Copy1.ipynb\\ndeleted file mode 100644\\nindex 3a07d0e..0000000\\n--- a/notebooks/RQ_notebooks/RQ1_updated-Copy1.ipynb\\n+++ /dev/null\\n@@ -1,4255 +0,0 @@\\n-{\\n- \\\"cells\\\": [\\n-  {\\n-   \\\"cell_type\\\": \\\"code\\\",\\n-   \\\"execution_count\\\": 1,\\n-   \\\"id\\\": \\\"12fa6f59-927c-4003-964f-83e53793fd36\\\",\\n-   \\\"metadata\\\": {\\n-    \\\"scrolled\\\": true\\n-   },\\n-   \\\"outputs\\\": [],\\n-   \\\"source\\\": [\\n-    \\\"# TODO: atm the mlflow autolog isnt capturing metrics n params\\\\n\\\",\\n-    \\\"# and sklearn.autolog throws error( posted the issue on github)\\\\n\\\",\\n-    \\\"# Ideally, I should be able to fetch most of the imp detail via MLFLOW AUTOLOG. will check that later in time\\\\n\\\",\\n-    \\\"#============================\\\\n\\\",\\n-    \\\"# \\ud83e\\udde0 MLflow Autologging\\\\n\\\",\\n-    \\\"# ============================\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# mlflow.autolog(log_input_examples=True, log_model_signatures=True)\\\\n\\\",\\n-    \\\"# mlflow.sklearn.autolog() \\\\n\\\",\\n-    \\\"# mlflow.sklearn.autolog(\\\\n\\\",\\n-    \\\"#     log_input_examples=True,\\\\n\\\",\\n-    \\\"#     log_model_signatures=True,\\\\n\\\",\\n-    \\\"#     log_post_training_metrics=True,        # calls model.score() \\u2192 accuracy\\\\n\\\",\\n-    \\\"#     disable_for_unsupported_versions=True,  # skips if versions still wonky\\\\n\\\",\\n-    \\\"#     exclusive=True                          # only patch the sklearn integration\\\\n\\\",\\n-    \\\"# )\\\"\\n-   ]\\n-  },\\n-  {\\n-   \\\"cell_type\\\": \\\"markdown\\\",\\n-   \\\"id\\\": \\\"61d4d6b8-34a9-47b5-974d-5927c0ee2256\\\",\\n-   \\\"metadata\\\": {},\\n-   \\\"source\\\": [\\n-    \\\"DBREPO INTEGRETION\\\"\\n-   ]\\n-  },\\n-  {\\n-   \\\"cell_type\\\": \\\"code\\\",\\n-   \\\"execution_count\\\": 88,\\n-   \\\"id\\\": \\\"8e3570e2-9a60-45b4-8653-28060071e728\\\",\\n-   \\\"metadata\\\": {\\n-    \\\"scrolled\\\": true\\n-   },\\n-   \\\"outputs\\\": [\\n-    {\\n-     \\\"name\\\": \\\"stdout\\\",\\n-     \\\"output_type\\\": \\\"stream\\\",\\n-     \\\"text\\\": [\\n-      \\\"API Response: [{'id': '1', 'sepallengthcm': '5.100000000000000000', 'sepalwidthcm': '3.500000000000000000', 'petallengthcm': '1.400000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '2', 'sepallengthcm': '4.900000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '1.400000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '3', 'sepallengthcm': '4.700000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '1.300000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '4', 'sepallengthcm': '4.600000000000000000', 'sepalwidthcm': '3.100000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '5', 'sepallengthcm': '5.000000000000000000', 'sepalwidthcm': '3.600000000000000000', 'petallengthcm': '1.400000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '6', 'sepallengthcm': '5.400000000000000000', 'sepalwidthcm': '3.900000000000000000', 'petallengthcm': '1.700000000000000000', 'petalwidthcm': '0.400000000000000000', 'species': 'Iris-setosa'}, {'id': '7', 'sepallengthcm': '4.600000000000000000', 'sepalwidthcm': '3.400000000000000000', 'petallengthcm': '1.400000000000000000', 'petalwidthcm': '0.300000000000000000', 'species': 'Iris-setosa'}, {'id': '8', 'sepallengthcm': '5.000000000000000000', 'sepalwidthcm': '3.400000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '9', 'sepallengthcm': '4.400000000000000000', 'sepalwidthcm': '2.900000000000000000', 'petallengthcm': '1.400000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '10', 'sepallengthcm': '4.900000000000000000', 'sepalwidthcm': '3.100000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.100000000000000000', 'species': 'Iris-setosa'}, {'id': '11', 'sepallengthcm': '5.400000000000000000', 'sepalwidthcm': '3.700000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '12', 'sepallengthcm': '4.800000000000000000', 'sepalwidthcm': '3.400000000000000000', 'petallengthcm': '1.600000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '13', 'sepallengthcm': '4.800000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '1.400000000000000000', 'petalwidthcm': '0.100000000000000000', 'species': 'Iris-setosa'}, {'id': '14', 'sepallengthcm': '4.300000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '1.100000000000000000', 'petalwidthcm': '0.100000000000000000', 'species': 'Iris-setosa'}, {'id': '15', 'sepallengthcm': '5.800000000000000000', 'sepalwidthcm': '4.000000000000000000', 'petallengthcm': '1.200000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '16', 'sepallengthcm': '5.700000000000000000', 'sepalwidthcm': '4.400000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.400000000000000000', 'species': 'Iris-setosa'}, {'id': '17', 'sepallengthcm': '5.400000000000000000', 'sepalwidthcm': '3.900000000000000000', 'petallengthcm': '1.300000000000000000', 'petalwidthcm': '0.400000000000000000', 'species': 'Iris-setosa'}, {'id': '18', 'sepallengthcm': '5.100000000000000000', 'sepalwidthcm': '3.500000000000000000', 'petallengthcm': '1.400000000000000000', 'petalwidthcm': '0.300000000000000000', 'species': 'Iris-setosa'}, {'id': '19', 'sepallengthcm': '5.700000000000000000', 'sepalwidthcm': '3.800000000000000000', 'petallengthcm': '1.700000000000000000', 'petalwidthcm': '0.300000000000000000', 'species': 'Iris-setosa'}, {'id': '20', 'sepallengthcm': '5.100000000000000000', 'sepalwidthcm': '3.800000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.300000000000000000', 'species': 'Iris-setosa'}, {'id': '21', 'sepallengthcm': '5.400000000000000000', 'sepalwidthcm': '3.400000000000000000', 'petallengthcm': '1.700000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '22', 'sepallengthcm': '5.100000000000000000', 'sepalwidthcm': '3.700000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.400000000000000000', 'species': 'Iris-setosa'}, {'id': '23', 'sepallengthcm': '4.600000000000000000', 'sepalwidthcm': '3.600000000000000000', 'petallengthcm': '1.000000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '24', 'sepallengthcm': '5.100000000000000000', 'sepalwidthcm': '3.300000000000000000', 'petallengthcm': '1.700000000000000000', 'petalwidthcm': '0.500000000000000000', 'species': 'Iris-setosa'}, {'id': '25', 'sepallengthcm': '4.800000000000000000', 'sepalwidthcm': '3.400000000000000000', 'petallengthcm': '1.900000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '26', 'sepallengthcm': '5.000000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '1.600000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '27', 'sepallengthcm': '5.000000000000000000', 'sepalwidthcm': '3.400000000000000000', 'petallengthcm': '1.600000000000000000', 'petalwidthcm': '0.400000000000000000', 'species': 'Iris-setosa'}, {'id': '28', 'sepallengthcm': '5.200000000000000000', 'sepalwidthcm': '3.500000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '29', 'sepallengthcm': '5.200000000000000000', 'sepalwidthcm': '3.400000000000000000', 'petallengthcm': '1.400000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '30', 'sepallengthcm': '4.700000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '1.600000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '31', 'sepallengthcm': '4.800000000000000000', 'sepalwidthcm': '3.100000000000000000', 'petallengthcm': '1.600000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '32', 'sepallengthcm': '5.400000000000000000', 'sepalwidthcm': '3.400000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.400000000000000000', 'species': 'Iris-setosa'}, {'id': '33', 'sepallengthcm': '5.200000000000000000', 'sepalwidthcm': '4.100000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.100000000000000000', 'species': 'Iris-setosa'}, {'id': '34', 'sepallengthcm': '5.500000000000000000', 'sepalwidthcm': '4.200000000000000000', 'petallengthcm': '1.400000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '35', 'sepallengthcm': '4.900000000000000000', 'sepalwidthcm': '3.100000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.100000000000000000', 'species': 'Iris-setosa'}, {'id': '36', 'sepallengthcm': '5.000000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '1.200000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '37', 'sepallengthcm': '5.500000000000000000', 'sepalwidthcm': '3.500000000000000000', 'petallengthcm': '1.300000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '38', 'sepallengthcm': '4.900000000000000000', 'sepalwidthcm': '3.100000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.100000000000000000', 'species': 'Iris-setosa'}, {'id': '39', 'sepallengthcm': '4.400000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '1.300000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '40', 'sepallengthcm': '5.100000000000000000', 'sepalwidthcm': '3.400000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '41', 'sepallengthcm': '5.000000000000000000', 'sepalwidthcm': '3.500000000000000000', 'petallengthcm': '1.300000000000000000', 'petalwidthcm': '0.300000000000000000', 'species': 'Iris-setosa'}, {'id': '42', 'sepallengthcm': '4.500000000000000000', 'sepalwidthcm': '2.300000000000000000', 'petallengthcm': '1.300000000000000000', 'petalwidthcm': '0.300000000000000000', 'species': 'Iris-setosa'}, {'id': '43', 'sepallengthcm': '4.400000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '1.300000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '44', 'sepallengthcm': '5.000000000000000000', 'sepalwidthcm': '3.500000000000000000', 'petallengthcm': '1.600000000000000000', 'petalwidthcm': '0.600000000000000000', 'species': 'Iris-setosa'}, {'id': '45', 'sepallengthcm': '5.100000000000000000', 'sepalwidthcm': '3.800000000000000000', 'petallengthcm': '1.900000000000000000', 'petalwidthcm': '0.400000000000000000', 'species': 'Iris-setosa'}, {'id': '46', 'sepallengthcm': '4.800000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '1.400000000000000000', 'petalwidthcm': '0.300000000000000000', 'species': 'Iris-setosa'}, {'id': '47', 'sepallengthcm': '5.100000000000000000', 'sepalwidthcm': '3.800000000000000000', 'petallengthcm': '1.600000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '48', 'sepallengthcm': '4.600000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '1.400000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '49', 'sepallengthcm': '5.300000000000000000', 'sepalwidthcm': '3.700000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '50', 'sepallengthcm': '5.000000000000000000', 'sepalwidthcm': '3.300000000000000000', 'petallengthcm': '1.400000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '51', 'sepallengthcm': '7.000000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '4.700000000000000000', 'petalwidthcm': '1.400000000000000000', 'species': 'Iris-versicolor'}, {'id': '52', 'sepallengthcm': '6.400000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '4.500000000000000000', 'petalwidthcm': '1.500000000000000000', 'species': 'Iris-versicolor'}, {'id': '53', 'sepallengthcm': '6.900000000000000000', 'sepalwidthcm': '3.100000000000000000', 'petallengthcm': '4.900000000000000000', 'petalwidthcm': '1.500000000000000000', 'species': 'Iris-versicolor'}, {'id': '54', 'sepallengthcm': '5.500000000000000000', 'sepalwidthcm': '2.300000000000000000', 'petallengthcm': '4.000000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '55', 'sepallengthcm': '6.500000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '4.600000000000000000', 'petalwidthcm': '1.500000000000000000', 'species': 'Iris-versicolor'}, {'id': '56', 'sepallengthcm': '5.700000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '4.500000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '57', 'sepallengthcm': '6.300000000000000000', 'sepalwidthcm': '3.300000000000000000', 'petallengthcm': '4.700000000000000000', 'petalwidthcm': '1.600000000000000000', 'species': 'Iris-versicolor'}, {'id': '58', 'sepallengthcm': '4.900000000000000000', 'sepalwidthcm': '2.400000000000000000', 'petallengthcm': '3.300000000000000000', 'petalwidthcm': '1.000000000000000000', 'species': 'Iris-versicolor'}, {'id': '59', 'sepallengthcm': '6.600000000000000000', 'sepalwidthcm': '2.900000000000000000', 'petallengthcm': '4.600000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '60', 'sepallengthcm': '5.200000000000000000', 'sepalwidthcm': '2.700000000000000000', 'petallengthcm': '3.900000000000000000', 'petalwidthcm': '1.400000000000000000', 'species': 'Iris-versicolor'}, {'id': '61', 'sepallengthcm': '5.000000000000000000', 'sepalwidthcm': '2.000000000000000000', 'petallengthcm': '3.500000000000000000', 'petalwidthcm': '1.000000000000000000', 'species': 'Iris-versicolor'}, {'id': '62', 'sepallengthcm': '5.900000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '4.200000000000000000', 'petalwidthcm': '1.500000000000000000', 'species': 'Iris-versicolor'}, {'id': '63', 'sepallengthcm': '6.000000000000000000', 'sepalwidthcm': '2.200000000000000000', 'petallengthcm': '4.000000000000000000', 'petalwidthcm': '1.000000000000000000', 'species': 'Iris-versicolor'}, {'id': '64', 'sepallengthcm': '6.100000000000000000', 'sepalwidthcm': '2.900000000000000000', 'petallengthcm': '4.700000000000000000', 'petalwidthcm': '1.400000000000000000', 'species': 'Iris-versicolor'}, {'id': '65', 'sepallengthcm': '5.600000000000000000', 'sepalwidthcm': '2.900000000000000000', 'petallengthcm': '3.600000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '66', 'sepallengthcm': '6.700000000000000000', 'sepalwidthcm': '3.100000000000000000', 'petallengthcm': '4.400000000000000000', 'petalwidthcm': '1.400000000000000000', 'species': 'Iris-versicolor'}, {'id': '67', 'sepallengthcm': '5.600000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '4.500000000000000000', 'petalwidthcm': '1.500000000000000000', 'species': 'Iris-versicolor'}, {'id': '68', 'sepallengthcm': '5.800000000000000000', 'sepalwidthcm': '2.700000000000000000', 'petallengthcm': '4.100000000000000000', 'petalwidthcm': '1.000000000000000000', 'species': 'Iris-versicolor'}, {'id': '69', 'sepallengthcm': '6.200000000000000000', 'sepalwidthcm': '2.200000000000000000', 'petallengthcm': '4.500000000000000000', 'petalwidthcm': '1.500000000000000000', 'species': 'Iris-versicolor'}, {'id': '70', 'sepallengthcm': '5.600000000000000000', 'sepalwidthcm': '2.500000000000000000', 'petallengthcm': '3.900000000000000000', 'petalwidthcm': '1.100000000000000000', 'species': 'Iris-versicolor'}, {'id': '71', 'sepallengthcm': '5.900000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '4.800000000000000000', 'petalwidthcm': '1.800000000000000000', 'species': 'Iris-versicolor'}, {'id': '72', 'sepallengthcm': '6.100000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '4.000000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '73', 'sepallengthcm': '6.300000000000000000', 'sepalwidthcm': '2.500000000000000000', 'petallengthcm': '4.900000000000000000', 'petalwidthcm': '1.500000000000000000', 'species': 'Iris-versicolor'}, {'id': '74', 'sepallengthcm': '6.100000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '4.700000000000000000', 'petalwidthcm': '1.200000000000000000', 'species': 'Iris-versicolor'}, {'id': '75', 'sepallengthcm': '6.400000000000000000', 'sepalwidthcm': '2.900000000000000000', 'petallengthcm': '4.300000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '76', 'sepallengthcm': '6.600000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '4.400000000000000000', 'petalwidthcm': '1.400000000000000000', 'species': 'Iris-versicolor'}, {'id': '77', 'sepallengthcm': '6.800000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '4.800000000000000000', 'petalwidthcm': '1.400000000000000000', 'species': 'Iris-versicolor'}, {'id': '78', 'sepallengthcm': '6.700000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '5.000000000000000000', 'petalwidthcm': '1.700000000000000000', 'species': 'Iris-versicolor'}, {'id': '79', 'sepallengthcm': '6.000000000000000000', 'sepalwidthcm': '2.900000000000000000', 'petallengthcm': '4.500000000000000000', 'petalwidthcm': '1.500000000000000000', 'species': 'Iris-versicolor'}, {'id': '80', 'sepallengthcm': '5.700000000000000000', 'sepalwidthcm': '2.600000000000000000', 'petallengthcm': '3.500000000000000000', 'petalwidthcm': '1.000000000000000000', 'species': 'Iris-versicolor'}, {'id': '81', 'sepallengthcm': '5.500000000000000000', 'sepalwidthcm': '2.400000000000000000', 'petallengthcm': '3.800000000000000000', 'petalwidthcm': '1.100000000000000000', 'species': 'Iris-versicolor'}, {'id': '82', 'sepallengthcm': '5.500000000000000000', 'sepalwidthcm': '2.400000000000000000', 'petallengthcm': '3.700000000000000000', 'petalwidthcm': '1.000000000000000000', 'species': 'Iris-versicolor'}, {'id': '83', 'sepallengthcm': '5.800000000000000000', 'sepalwidthcm': '2.700000000000000000', 'petallengthcm': '3.900000000000000000', 'petalwidthcm': '1.200000000000000000', 'species': 'Iris-versicolor'}, {'id': '84', 'sepallengthcm': '6.000000000000000000', 'sepalwidthcm': '2.700000000000000000', 'petallengthcm': '5.100000000000000000', 'petalwidthcm': '1.600000000000000000', 'species': 'Iris-versicolor'}, {'id': '85', 'sepallengthcm': '5.400000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '4.500000000000000000', 'petalwidthcm': '1.500000000000000000', 'species': 'Iris-versicolor'}, {'id': '86', 'sepallengthcm': '6.000000000000000000', 'sepalwidthcm': '3.400000000000000000', 'petallengthcm': '4.500000000000000000', 'petalwidthcm': '1.600000000000000000', 'species': 'Iris-versicolor'}, {'id': '87', 'sepallengthcm': '6.700000000000000000', 'sepalwidthcm': '3.100000000000000000', 'petallengthcm': '4.700000000000000000', 'petalwidthcm': '1.500000000000000000', 'species': 'Iris-versicolor'}, {'id': '88', 'sepallengthcm': '6.300000000000000000', 'sepalwidthcm': '2.300000000000000000', 'petallengthcm': '4.400000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '89', 'sepallengthcm': '5.600000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '4.100000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '90', 'sepallengthcm': '5.500000000000000000', 'sepalwidthcm': '2.500000000000000000', 'petallengthcm': '4.000000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '91', 'sepallengthcm': '5.500000000000000000', 'sepalwidthcm': '2.600000000000000000', 'petallengthcm': '4.400000000000000000', 'petalwidthcm': '1.200000000000000000', 'species': 'Iris-versicolor'}, {'id': '92', 'sepallengthcm': '6.100000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '4.600000000000000000', 'petalwidthcm': '1.400000000000000000', 'species': 'Iris-versicolor'}, {'id': '93', 'sepallengthcm': '5.800000000000000000', 'sepalwidthcm': '2.600000000000000000', 'petallengthcm': '4.000000000000000000', 'petalwidthcm': '1.200000000000000000', 'species': 'Iris-versicolor'}, {'id': '94', 'sepallengthcm': '5.000000000000000000', 'sepalwidthcm': '2.300000000000000000', 'petallengthcm': '3.300000000000000000', 'petalwidthcm': '1.000000000000000000', 'species': 'Iris-versicolor'}, {'id': '95', 'sepallengthcm': '5.600000000000000000', 'sepalwidthcm': '2.700000000000000000', 'petallengthcm': '4.200000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '96', 'sepallengthcm': '5.700000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '4.200000000000000000', 'petalwidthcm': '1.200000000000000000', 'species': 'Iris-versicolor'}, {'id': '97', 'sepallengthcm': '5.700000000000000000', 'sepalwidthcm': '2.900000000000000000', 'petallengthcm': '4.200000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '98', 'sepallengthcm': '6.200000000000000000', 'sepalwidthcm': '2.900000000000000000', 'petallengthcm': '4.300000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '99', 'sepallengthcm': '5.100000000000000000', 'sepalwidthcm': '2.500000000000000000', 'petallengthcm': '3.000000000000000000', 'petalwidthcm': '1.100000000000000000', 'species': 'Iris-versicolor'}, {'id': '100', 'sepallengthcm': '5.700000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '4.100000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '101', 'sepallengthcm': '6.300000000000000000', 'sepalwidthcm': '3.300000000000000000', 'petallengthcm': '6.000000000000000000', 'petalwidthcm': '2.500000000000000000', 'species': 'Iris-virginica'}, {'id': '102', 'sepallengthcm': '5.800000000000000000', 'sepalwidthcm': '2.700000000000000000', 'petallengthcm': '5.100000000000000000', 'petalwidthcm': '1.900000000000000000', 'species': 'Iris-virginica'}, {'id': '103', 'sepallengthcm': '7.100000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '5.900000000000000000', 'petalwidthcm': '2.100000000000000000', 'species': 'Iris-virginica'}, {'id': '104', 'sepallengthcm': '6.300000000000000000', 'sepalwidthcm': '2.900000000000000000', 'petallengthcm': '5.600000000000000000', 'petalwidthcm': '1.800000000000000000', 'species': 'Iris-virginica'}, {'id': '105', 'sepallengthcm': '6.500000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '5.800000000000000000', 'petalwidthcm': '2.200000000000000000', 'species': 'Iris-virginica'}, {'id': '106', 'sepallengthcm': '7.600000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '6.600000000000000000', 'petalwidthcm': '2.100000000000000000', 'species': 'Iris-virginica'}, {'id': '107', 'sepallengthcm': '4.900000000000000000', 'sepalwidthcm': '2.500000000000000000', 'petallengthcm': '4.500000000000000000', 'petalwidthcm': '1.700000000000000000', 'species': 'Iris-virginica'}, {'id': '108', 'sepallengthcm': '7.300000000000000000', 'sepalwidthcm': '2.900000000000000000', 'petallengthcm': '6.300000000000000000', 'petalwidthcm': '1.800000000000000000', 'species': 'Iris-virginica'}, {'id': '109', 'sepallengthcm': '6.700000000000000000', 'sepalwidthcm': '2.500000000000000000', 'petallengthcm': '5.800000000000000000', 'petalwidthcm': '1.800000000000000000', 'species': 'Iris-virginica'}, {'id': '110', 'sepallengthcm': '7.200000000000000000', 'sepalwidthcm': '3.600000000000000000', 'petallengthcm': '6.100000000000000000', 'petalwidthcm': '2.500000000000000000', 'species': 'Iris-virginica'}, {'id': '111', 'sepallengthcm': '6.500000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '5.100000000000000000', 'petalwidthcm': '2.000000000000000000', 'species': 'Iris-virginica'}, {'id': '112', 'sepallengthcm': '6.400000000000000000', 'sepalwidthcm': '2.700000000000000000', 'petallengthcm': '5.300000000000000000', 'petalwidthcm': '1.900000000000000000', 'species': 'Iris-virginica'}, {'id': '113', 'sepallengthcm': '6.800000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '5.500000000000000000', 'petalwidthcm': '2.100000000000000000', 'species': 'Iris-virginica'}, {'id': '114', 'sepallengthcm': '5.700000000000000000', 'sepalwidthcm': '2.500000000000000000', 'petallengthcm': '5.000000000000000000', 'petalwidthcm': '2.000000000000000000', 'species': 'Iris-virginica'}, {'id': '115', 'sepallengthcm': '5.800000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '5.100000000000000000', 'petalwidthcm': '2.400000000000000000', 'species': 'Iris-virginica'}, {'id': '116', 'sepallengthcm': '6.400000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '5.300000000000000000', 'petalwidthcm': '2.300000000000000000', 'species': 'Iris-virginica'}, {'id': '117', 'sepallengthcm': '6.500000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '5.500000000000000000', 'petalwidthcm': '1.800000000000000000', 'species': 'Iris-virginica'}, {'id': '118', 'sepallengthcm': '7.700000000000000000', 'sepalwidthcm': '3.800000000000000000', 'petallengthcm': '6.700000000000000000', 'petalwidthcm': '2.200000000000000000', 'species': 'Iris-virginica'}, {'id': '119', 'sepallengthcm': '7.700000000000000000', 'sepalwidthcm': '2.600000000000000000', 'petallengthcm': '6.900000000000000000', 'petalwidthcm': '2.300000000000000000', 'species': 'Iris-virginica'}, {'id': '120', 'sepallengthcm': '6.000000000000000000', 'sepalwidthcm': '2.200000000000000000', 'petallengthcm': '5.000000000000000000', 'petalwidthcm': '1.500000000000000000', 'species': 'Iris-virginica'}, {'id': '121', 'sepallengthcm': '6.900000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '5.700000000000000000', 'petalwidthcm': '2.300000000000000000', 'species': 'Iris-virginica'}, {'id': '122', 'sepallengthcm': '5.600000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '4.900000000000000000', 'petalwidthcm': '2.000000000000000000', 'species': 'Iris-virginica'}, {'id': '123', 'sepallengthcm': '7.700000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '6.700000000000000000', 'petalwidthcm': '2.000000000000000000', 'species': 'Iris-virginica'}, {'id': '124', 'sepallengthcm': '6.300000000000000000', 'sepalwidthcm': '2.700000000000000000', 'petallengthcm': '4.900000000000000000', 'petalwidthcm': '1.800000000000000000', 'species': 'Iris-virginica'}, {'id': '125', 'sepallengthcm': '6.700000000000000000', 'sepalwidthcm': '3.300000000000000000', 'petallengthcm': '5.700000000000000000', 'petalwidthcm': '2.100000000000000000', 'species': 'Iris-virginica'}, {'id': '126', 'sepallengthcm': '7.200000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '6.000000000000000000', 'petalwidthcm': '1.800000000000000000', 'species': 'Iris-virginica'}, {'id': '127', 'sepallengthcm': '6.200000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '4.800000000000000000', 'petalwidthcm': '1.800000000000000000', 'species': 'Iris-virginica'}, {'id': '128', 'sepallengthcm': '6.100000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '4.900000000000000000', 'petalwidthcm': '1.800000000000000000', 'species': 'Iris-virginica'}, {'id': '129', 'sepallengthcm': '6.400000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '5.600000000000000000', 'petalwidthcm': '2.100000000000000000', 'species': 'Iris-virginica'}, {'id': '130', 'sepallengthcm': '7.200000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '5.800000000000000000', 'petalwidthcm': '1.600000000000000000', 'species': 'Iris-virginica'}, {'id': '131', 'sepallengthcm': '7.400000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '6.100000000000000000', 'petalwidthcm': '1.900000000000000000', 'species': 'Iris-virginica'}, {'id': '132', 'sepallengthcm': '7.900000000000000000', 'sepalwidthcm': '3.800000000000000000', 'petallengthcm': '6.400000000000000000', 'petalwidthcm': '2.000000000000000000', 'species': 'Iris-virginica'}, {'id': '133', 'sepallengthcm': '6.400000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '5.600000000000000000', 'petalwidthcm': '2.200000000000000000', 'species': 'Iris-virginica'}, {'id': '134', 'sepallengthcm': '6.300000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '5.100000000000000000', 'petalwidthcm': '1.500000000000000000', 'species': 'Iris-virginica'}, {'id': '135', 'sepallengthcm': '6.100000000000000000', 'sepalwidthcm': '2.600000000000000000', 'petallengthcm': '5.600000000000000000', 'petalwidthcm': '1.400000000000000000', 'species': 'Iris-virginica'}, {'id': '136', 'sepallengthcm': '7.700000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '6.100000000000000000', 'petalwidthcm': '2.300000000000000000', 'species': 'Iris-virginica'}, {'id': '137', 'sepallengthcm': '6.300000000000000000', 'sepalwidthcm': '3.400000000000000000', 'petallengthcm': '5.600000000000000000', 'petalwidthcm': '2.400000000000000000', 'species': 'Iris-virginica'}, {'id': '138', 'sepallengthcm': '6.400000000000000000', 'sepalwidthcm': '3.100000000000000000', 'petallengthcm': '5.500000000000000000', 'petalwidthcm': '1.800000000000000000', 'species': 'Iris-virginica'}, {'id': '139', 'sepallengthcm': '6.000000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '4.800000000000000000', 'petalwidthcm': '1.800000000000000000', 'species': 'Iris-virginica'}, {'id': '140', 'sepallengthcm': '6.900000000000000000', 'sepalwidthcm': '3.100000000000000000', 'petallengthcm': '5.400000000000000000', 'petalwidthcm': '2.100000000000000000', 'species': 'Iris-virginica'}, {'id': '141', 'sepallengthcm': '6.700000000000000000', 'sepalwidthcm': '3.100000000000000000', 'petallengthcm': '5.600000000000000000', 'petalwidthcm': '2.400000000000000000', 'species': 'Iris-virginica'}, {'id': '142', 'sepallengthcm': '6.900000000000000000', 'sepalwidthcm': '3.100000000000000000', 'petallengthcm': '5.100000000000000000', 'petalwidthcm': '2.300000000000000000', 'species': 'Iris-virginica'}, {'id': '143', 'sepallengthcm': '5.800000000000000000', 'sepalwidthcm': '2.700000000000000000', 'petallengthcm': '5.100000000000000000', 'petalwidthcm': '1.900000000000000000', 'species': 'Iris-virginica'}, {'id': '144', 'sepallengthcm': '6.800000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '5.900000000000000000', 'petalwidthcm': '2.300000000000000000', 'species': 'Iris-virginica'}, {'id': '145', 'sepallengthcm': '6.700000000000000000', 'sepalwidthcm': '3.300000000000000000', 'petallengthcm': '5.700000000000000000', 'petalwidthcm': '2.500000000000000000', 'species': 'Iris-virginica'}, {'id': '146', 'sepallengthcm': '6.700000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '5.200000000000000000', 'petalwidthcm': '2.300000000000000000', 'species': 'Iris-virginica'}, {'id': '147', 'sepallengthcm': '6.300000000000000000', 'sepalwidthcm': '2.500000000000000000', 'petallengthcm': '5.000000000000000000', 'petalwidthcm': '1.900000000000000000', 'species': 'Iris-virginica'}, {'id': '148', 'sepallengthcm': '6.500000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '5.200000000000000000', 'petalwidthcm': '2.000000000000000000', 'species': 'Iris-virginica'}, {'id': '149', 'sepallengthcm': '6.200000000000000000', 'sepalwidthcm': '3.400000000000000000', 'petallengthcm': '5.400000000000000000', 'petalwidthcm': '2.300000000000000000', 'species': 'Iris-virginica'}, {'id': '150', 'sepallengthcm': '5.900000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '5.100000000000000000', 'petalwidthcm': '1.800000000000000000', 'species': 'Iris-virginica'}]\\\\n\\\",\\n-      \\\"<built-in method count of list object at 0x000001EF7FA4E400>\\\\n\\\"\\n-     ]\\n-    }\\n-   ],\\n-   \\\"source\\\": [\\n-    \\\"import requests\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# API endpoint URL\\\\n\\\",\\n-    \\\"API_URL = \\\\\\\"http://localhost/api/database/c3a42d17-42b7-43c9-a504-2363fb4c9c8d/table/5315e7da-64fb-4fdb-b493-95b4138c765f/data?size=100000&page=0\\\\\\\"\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# Define the headers\\\\n\\\",\\n-    \\\"headers = {\\\\n\\\",\\n-    \\\"    \\\\\\\"Accept\\\\\\\": \\\\\\\"application/json\\\\\\\"  # Specify the expected response format\\\\n\\\",\\n-    \\\"}\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"try:\\\\n\\\",\\n-    \\\"    # Send a GET request to the API with the Accept header\\\\n\\\",\\n-    \\\"    response = requests.get(API_URL, headers=headers)\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    # Check if the request was successful\\\\n\\\",\\n-    \\\"    if response.status_code == 200:\\\\n\\\",\\n-    \\\"        # Parse the JSON response\\\\n\\\",\\n-    \\\"        dataset = response.json()\\\\n\\\",\\n-    \\\"        print(\\\\\\\"API Response:\\\\\\\", dataset)\\\\n\\\",\\n-    \\\"        print( dataset.count)\\\\n\\\",\\n-    \\\"    else:\\\\n\\\",\\n-    \\\"        print(f\\\\\\\"Error: Received status code {response.status_code}\\\\\\\")\\\\n\\\",\\n-    \\\"        print(\\\\\\\"Response content:\\\\\\\", response.text)\\\\n\\\",\\n-    \\\"       \\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"except requests.exceptions.RequestException as e:\\\\n\\\",\\n-    \\\"    print(f\\\\\\\"Request failed: {e}\\\\\\\")\\\\n\\\"\\n-   ]\\n-  },\\n-  {\\n-   \\\"cell_type\\\": \\\"markdown\\\",\\n-   \\\"id\\\": \\\"09557f94-325c-4bd6-882a-069a9e3c5ecd\\\",\\n-   \\\"metadata\\\": {},\\n-   \\\"source\\\": [\\n-    \\\"replacing dynamic fetching of data while i integrete invenio\\\"\\n-   ]\\n-  },\\n-  {\\n-   \\\"cell_type\\\": \\\"code\\\",\\n-   \\\"execution_count\\\": 90,\\n-   \\\"id\\\": \\\"ce6e020d-cb80-49ec-8bcc-687b1e08885c\\\",\\n-   \\\"metadata\\\": {},\\n-   \\\"outputs\\\": [],\\n-   \\\"source\\\": [\\n-    \\\"# 2a. Save raw JSON\\\\n\\\",\\n-    \\\"# with open(\\\\\\\"iris_data.json\\\\\\\", \\\\\\\"w\\\\\\\") as f:\\\\n\\\",\\n-    \\\"#     json.dump(dataset, f, indent=2)\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# 1. Read the JSON file\\\\n\\\",\\n-    \\\"with open(\\\\\\\"iris_data.json\\\\\\\", \\\\\\\"r\\\\\\\") as f:\\\\n\\\",\\n-    \\\"    dataset = json.load(f)\\\\n\\\",\\n-    \\\"\\\\n\\\"\\n-   ]\\n-  },\\n-  {\\n-   \\\"cell_type\\\": \\\"markdown\\\",\\n-   \\\"id\\\": \\\"a6c6007a-2126-4b1a-90ee-3326eb39a362\\\",\\n-   \\\"metadata\\\": {},\\n-   \\\"source\\\": [\\n-    \\\"Metadata fetching from db repo\\\"\\n-   ]\\n-  },\\n-  {\\n-   \\\"cell_type\\\": \\\"code\\\",\\n-   \\\"execution_count\\\": 3,\\n-   \\\"id\\\": \\\"abe912e7-bf9b-4bbd-8e43-6046745ade3f\\\",\\n-   \\\"metadata\\\": {\\n-    \\\"scrolled\\\": true\\n-   },\\n-   \\\"outputs\\\": [],\\n-   \\\"source\\\": [\\n-    \\\"import requests\\\\n\\\",\\n-    \\\"import mlflow\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"DB_API = \\\\\\\"http://localhost/api/database/{db_id}\\\\\\\"\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"def fetch_db_metadata(db_id: str) -> dict:\\\\n\\\",\\n-    \\\"    url = DB_API.format(db_id=db_id)\\\\n\\\",\\n-    \\\"    resp = requests.get(url)\\\\n\\\",\\n-    \\\"    resp.raise_for_status()\\\\n\\\",\\n-    \\\"    return resp.json()\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"def log_db_metadata(db_meta: dict):\\\\n\\\",\\n-    \\\"    # 1) core DB fields as params\\\\n\\\",\\n-    \\\"    mlflow.log_param(\\\\\\\"database.id\\\\\\\",          db_meta[\\\\\\\"id\\\\\\\"])\\\\n\\\",\\n-    \\\"    mlflow.log_param(\\\\\\\"database.name\\\\\\\",        db_meta[\\\\\\\"name\\\\\\\"])\\\\n\\\",\\n-    \\\"    mlflow.log_param(\\\\\\\"database.description\\\\\\\", db_meta.get(\\\\\\\"description\\\\\\\",\\\\\\\"\\\\\\\"))\\\\n\\\",\\n-    \\\"    owner = db_meta[\\\\\\\"tables\\\\\\\"][0][\\\\\\\"owner\\\\\\\"][\\\\\\\"username\\\\\\\"]\\\\n\\\",\\n-    \\\"    mlflow.log_param(\\\\\\\"database.owner\\\\\\\",       owner)\\\\n\\\"\\n-   ]\\n-  },\\n-  {\\n-   \\\"cell_type\\\": \\\"code\\\",\\n-   \\\"execution_count\\\": 4,\\n-   \\\"id\\\": \\\"296f307e-e01b-477a-9406-92cab9f2d7bf\\\",\\n-   \\\"metadata\\\": {},\\n-   \\\"outputs\\\": [\\n-    {\\n-     \\\"name\\\": \\\"stdout\\\",\\n-     \\\"output_type\\\": \\\"stream\\\",\\n-     \\\"text\\\": [\\n-      \\\"<ns0:OAI-PMH xmlns:ns0=\\\\\\\"http://www.openarchives.org/OAI/2.0/\\\\\\\" xmlns:xsi=\\\\\\\"http://www.w3.org/2001/XMLSchema-instance\\\\\\\" xsi:schemaLocation=\\\\\\\"http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd\\\\\\\">\\\\n\\\",\\n-      \\\"    <ns0:responseDate>2025-04-23T20:56:28Z</ns0:responseDate>\\\\n\\\",\\n-      \\\"    <ns0:request verb=\\\\\\\"Identify\\\\\\\">https://localhost/api/oai</ns0:request>\\\\n\\\",\\n-      \\\"    <ns0:Identify>\\\\n\\\",\\n-      \\\"    <ns0:repositoryName>Database Repository</ns0:repositoryName>\\\\n\\\",\\n-      \\\"    <ns0:baseURL>http://localhost</ns0:baseURL>\\\\n\\\",\\n-      \\\"    <ns0:protocolVersion>2.0</ns0:protocolVersion>\\\\n\\\",\\n-      \\\"    <ns0:adminEmail>noreply@localhost</ns0:adminEmail>\\\\n\\\",\\n-      \\\"    <ns0:earliestDatestamp />\\\\n\\\",\\n-      \\\"    <ns0:deletedRecord>persistent</ns0:deletedRecord>\\\\n\\\",\\n-      \\\"    <ns0:granularity>YYYY-MM-DDThh:mm:ssZ</ns0:granularity>\\\\n\\\",\\n-      \\\"</ns0:Identify>\\\\n\\\",\\n-      \\\"</ns0:OAI-PMH>\\\\n\\\"\\n-     ]\\n-    }\\n-   ],\\n-   \\\"source\\\": [\\n-    \\\"import requests\\\\n\\\",\\n-    \\\"import xml.etree.ElementTree as ET\\\\n\\\",\\n-    \\\"import urllib.parse\\\\n\\\",\\n-    \\\"import mlflow, requests, json\\\\n\\\",\\n-    \\\"import pandas as pd\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# 1) Fetch your database metadata\\\\n\\\",\\n-    \\\"db_url = \\\\\\\"http://localhost/api/database/c3a42d17-42b7-43c9-a504-2363fb4c9c8d\\\\\\\"\\\\n\\\",\\n-    \\\"db_resp = requests.get(db_url)\\\\n\\\",\\n-    \\\"db_resp.raise_for_status()\\\\n\\\",\\n-    \\\"db_data = db_resp.json()\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"db_id  = db_data[\\\\\\\"id\\\\\\\"]\\\\n\\\",\\n-    \\\"tbl_id = db_data[\\\\\\\"tables\\\\\\\"][0][\\\\\\\"id\\\\\\\"]\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# 2) Build the OAI-PMH URL, URL-encoding the `set` param\\\\n\\\",\\n-    \\\"set_param   = f\\\\\\\"Databases/{db_id}/Tables/{tbl_id}\\\\\\\"\\\\n\\\",\\n-    \\\"encoded_set = urllib.parse.quote(set_param, safe=\\\\\\\"\\\\\\\")\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"oai_url = (\\\\n\\\",\\n-    \\\"    \\\\\\\"http://localhost/api/oai\\\\\\\"\\\\n\\\",\\n-    \\\"    f\\\\\\\"?metadataPrefix=oai_dc\\\\\\\"\\\\n\\\",\\n-    \\\"    f\\\\\\\"&from=2025-03-01\\\\\\\"\\\\n\\\",\\n-    \\\"    f\\\\\\\"&until=2025-03-07\\\\\\\"\\\\n\\\",\\n-    \\\"    f\\\\\\\"&set={encoded_set}\\\\\\\"\\\\n\\\",\\n-    \\\"    f\\\\\\\"&resumptionToken=string\\\\\\\"\\\\n\\\",\\n-    \\\"    f\\\\\\\"&fromDate=2025-03-07T19%3A35%3A51.476Z\\\\\\\"\\\\n\\\",\\n-    \\\"    f\\\\\\\"&untilDate=2025-03-07T19%3A35%3A51.476Z\\\\\\\"\\\\n\\\",\\n-    \\\"    f\\\\\\\"&parametersString=string\\\\\\\"\\\\n\\\",\\n-    \\\")\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# 3) Call and parse\\\\n\\\",\\n-    \\\"try:\\\\n\\\",\\n-    \\\"    resp = requests.get(oai_url)\\\\n\\\",\\n-    \\\"    resp.raise_for_status()\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    if \\\\\\\"xml\\\\\\\" in resp.headers.get(\\\\\\\"Content-Type\\\\\\\", \\\\\\\"\\\\\\\"):\\\\n\\\",\\n-    \\\"        root = ET.fromstring(resp.text)\\\\n\\\",\\n-    \\\"        print(ET.tostring(root, encoding=\\\\\\\"utf-8\\\\\\\").decode())\\\\n\\\",\\n-    \\\"    else:\\\\n\\\",\\n-    \\\"        print(\\\\\\\"Non-XML response:\\\\\\\", resp.headers.get(\\\\\\\"Content-Type\\\\\\\"), resp.text)\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"except requests.exceptions.RequestException as e:\\\\n\\\",\\n-    \\\"    print(\\\\\\\"Request failed:\\\\\\\", e)\\\\n\\\"\\n-   ]\\n-  },\\n-  {\\n-   \\\"cell_type\\\": \\\"code\\\",\\n-   \\\"execution_count\\\": 5,\\n-   \\\"id\\\": \\\"61cc99ab-4a5c-4142-8725-e7c940673ffd\\\",\\n-   \\\"metadata\\\": {},\\n-   \\\"outputs\\\": [],\\n-   \\\"source\\\": [\\n-    \\\"import xml.etree.ElementTree as ET\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# \\u2026after you fetch & parse your XML into `root`\\u2026\\\\n\\\",\\n-    \\\"ns = {\\\\\\\"oai\\\\\\\": \\\\\\\"http://www.openarchives.org/OAI/2.0/\\\\\\\"}\\\\n\\\",\\n-    \\\"repo_name   = root.findtext(\\\\\\\"oai:Identify/oai:repositoryName\\\\\\\",   namespaces=ns)\\\\n\\\",\\n-    \\\"base_url    = root.findtext(\\\\\\\"oai:Identify/oai:baseURL\\\\\\\",          namespaces=ns)\\\\n\\\",\\n-    \\\"protocol    = root.findtext(\\\\\\\"oai:Identify/oai:protocolVersion\\\\\\\",  namespaces=ns)\\\\n\\\",\\n-    \\\"admin_email = root.findtext(\\\\\\\"oai:Identify/oai:adminEmail\\\\\\\",       namespaces=ns)\\\\n\\\",\\n-    \\\"gran        = root.findtext(\\\\\\\"oai:Identify/oai:granularity\\\\\\\",      namespaces=ns)\\\\n\\\"\\n-   ]\\n-  },\\n-  {\\n-   \\\"cell_type\\\": \\\"markdown\\\",\\n-   \\\"id\\\": \\\"74214aa7-c12f-414e-9feb-094a366b855b\\\",\\n-   \\\"metadata\\\": {},\\n-   \\\"source\\\": [\\n-    \\\"History Logging\\\"\\n-   ]\\n-  },\\n-  {\\n-   \\\"cell_type\\\": \\\"code\\\",\\n-   \\\"execution_count\\\": 6,\\n-   \\\"id\\\": \\\"e9c74e9b-c9b0-4b4a-82eb-2a6e56456508\\\",\\n-   \\\"metadata\\\": {},\\n-   \\\"outputs\\\": [\\n-    {\\n-     \\\"name\\\": \\\"stdout\\\",\\n-     \\\"output_type\\\": \\\"stream\\\",\\n-     \\\"text\\\": [\\n-      \\\"API Response: [{'timestamp': '2025-04-23T20:42:29.501Z', 'event': 'insert', 'total': 150}]\\\\n\\\"\\n-     ]\\n-    }\\n-   ],\\n-   \\\"source\\\": [\\n-    \\\"url = \\\\\\\"http://localhost/api/database/c3a42d17-42b7-43c9-a504-2363fb4c9c8d/table/5315e7da-64fb-4fdb-b493-95b4138c765f/history\\\\\\\"\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"try:\\\\n\\\",\\n-    \\\"    # Send a GET request to the API\\\\n\\\",\\n-    \\\"    response = requests.get(url)\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    # Check if the request was successful\\\\n\\\",\\n-    \\\"    if response.status_code == 200:\\\\n\\\",\\n-    \\\"        # Parse the JSON response\\\\n\\\",\\n-    \\\"        data = response.json()\\\\n\\\",\\n-    \\\"        print(\\\\\\\"API Response:\\\\\\\", data)\\\\n\\\",\\n-    \\\"    else:\\\\n\\\",\\n-    \\\"        print(f\\\\\\\"Error: Received status code {response.status_code}\\\\\\\")\\\\n\\\",\\n-    \\\"        print(\\\\\\\"Response content:\\\\\\\", response.text)\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"except requests.exceptions.RequestException as e:\\\\n\\\",\\n-    \\\"    print(f\\\\\\\"Request failed: {e}\\\\\\\")\\\"\\n-   ]\\n-  },\\n-  {\\n-   \\\"cell_type\\\": \\\"code\\\",\\n-   \\\"execution_count\\\": 7,\\n-   \\\"id\\\": \\\"3630c954-5ad2-4759-b9a0-fa6e20e184ef\\\",\\n-   \\\"metadata\\\": {},\\n-   \\\"outputs\\\": [],\\n-   \\\"source\\\": [\\n-    \\\"first   = data[0]\\\\n\\\",\\n-    \\\"last    = data[-1]\\\\n\\\",\\n-    \\\"count_0 = first[\\\\\\\"total\\\\\\\"]    # e.g. 149\\\\n\\\",\\n-    \\\"count_N = last[\\\\\\\"total\\\\\\\"]     # e.g. 149 again, or changed\\\\n\\\",\\n-    \\\"ts_last = last[\\\\\\\"timestamp\\\\\\\"]  # e.g. \\\\\\\"2025-03-28T17:42:38.058Z\\\\\\\"\\\\n\\\",\\n-    \\\"n_insert = sum(1 for ev in data if ev[\\\\\\\"event\\\\\\\"]==\\\\\\\"insert\\\\\\\")\\\\n\\\",\\n-    \\\"n_delete = sum(1 for ev in data if ev[\\\\\\\"event\\\\\\\"]==\\\\\\\"delete\\\\\\\")\\\\n\\\",\\n-    \\\"history = response.json()\\\\n\\\",\\n-    \\\"first, last = history[0], history[-1]\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# summary stats\\\\n\\\",\\n-    \\\"count_start = first[\\\\\\\"total\\\\\\\"]\\\\n\\\",\\n-    \\\"count_end   = last[\\\\\\\"total\\\\\\\"]\\\\n\\\",\\n-    \\\"ts_last     = last[\\\\\\\"timestamp\\\\\\\"]\\\\n\\\",\\n-    \\\"n_insert    = sum(1 for ev in history if ev[\\\\\\\"event\\\\\\\"]==\\\\\\\"insert\\\\\\\")\\\\n\\\",\\n-    \\\"n_delete    = sum(1 for ev in history if ev[\\\\\\\"event\\\\\\\"]==\\\\\\\"delete\\\\\\\")\\\"\\n-   ]\\n-  },\\n-  {\\n-   \\\"cell_type\\\": \\\"markdown\\\",\\n-   \\\"id\\\": \\\"1afd5dad-72d5-42e1-a0fa-b7bd3455937b\\\",\\n-   \\\"metadata\\\": {},\\n-   \\\"source\\\": [\\n-    \\\"Dataset metadata fetching from ZONEDO or any public dataset repositories to gain more details\\\"\\n-   ]\\n-  },\\n-  {\\n-   \\\"cell_type\\\": \\\"code\\\",\\n-   \\\"execution_count\\\": 40,\\n-   \\\"id\\\": \\\"a7fa122a-c6e5-4b38-842a-dc81590a1f46\\\",\\n-   \\\"metadata\\\": {},\\n-   \\\"outputs\\\": [],\\n-   \\\"source\\\": [\\n-    \\\"\\\\n\\\",\\n-    \\\"def fetch_and_log_dataset_metadata_nested(doi_url: str):\\\\n\\\",\\n-    \\\"    # 1) fetch the CSL+JSON\\\\n\\\",\\n-    \\\"    headers = {\\\\\\\"Accept\\\\\\\": \\\\\\\"application/vnd.citationstyles.csl+json\\\\\\\"}\\\\n\\\",\\n-    \\\"    r = requests.get(doi_url, headers=headers); r.raise_for_status()\\\\n\\\",\\n-    \\\"    meta = r.json()\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    # 2) pull out what you care about\\\\n\\\",\\n-    \\\"    authors = [f\\\\\\\"{a.get('family','')} {a.get('given','')}\\\\\\\".strip()\\\\n\\\",\\n-    \\\"               for a in meta.get(\\\\\\\"author\\\\\\\", [])]\\\\n\\\",\\n-    \\\"    pubdate = \\\\\\\"-\\\\\\\".join(str(x) for x in meta.get(\\\\\\\"issued\\\\\\\",{}).get(\\\\\\\"date-parts\\\\\\\",[[]])[0])\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    # 3) assemble one nested dict\\\\n\\\",\\n-    \\\"    public_datasetRepository_metadata = {\\\\n\\\",\\n-    \\\"      \\\\\\\"zenodo\\\\\\\": {\\\\n\\\",\\n-    \\\"        \\\\\\\"title\\\\\\\":     meta.get(\\\\\\\"title\\\\\\\"),\\\\n\\\",\\n-    \\\"        \\\\\\\"doi\\\\\\\":       meta.get(\\\\\\\"DOI\\\\\\\"),\\\\n\\\",\\n-    \\\"        \\\\\\\"authors\\\\\\\":   authors,\\\\n\\\",\\n-    \\\"        \\\\\\\"published\\\\\\\": pubdate,\\\\n\\\",\\n-    \\\"        \\\\\\\"publisher\\\\\\\": meta.get(\\\\\\\"publisher\\\\\\\"),\\\\n\\\",\\n-    \\\"      },\\\\n\\\",\\n-    \\\"   \\\\n\\\",\\n-    \\\"    }\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"      # 4) log it as a single JSON artifact\\\\n\\\",\\n-    \\\"    mlflow.log_dict(public_datasetRepository_metadata,\\\\n\\\",\\n-    \\\"                \\\\\\\"public_datasetRepository_metadata.json\\\\\\\")\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    # 2) Flatten and log the important bits as params:\\\\n\\\",\\n-    \\\"    z = public_datasetRepository_metadata[\\\\\\\"zenodo\\\\\\\"]\\\\n\\\",\\n-    \\\"    \\\\n\\\",\\n-    \\\"    mlflow.log_param(\\\\\\\"dataset.title\\\\\\\",     z[\\\\\\\"title\\\\\\\"])\\\\n\\\",\\n-    \\\"    mlflow.log_param(\\\\\\\"dataset.doi\\\\\\\",       z[\\\\\\\"doi\\\\\\\"])\\\\n\\\",\\n-    \\\"    mlflow.log_param(\\\\\\\"dataset.authors\\\\\\\",   json.dumps(z[\\\\\\\"authors\\\\\\\"]))\\\\n\\\",\\n-    \\\"    mlflow.log_param(\\\\\\\"dataset.published\\\\\\\", z[\\\\\\\"published\\\\\\\"])\\\\n\\\",\\n-    \\\"    mlflow.log_param(\\\\\\\"dataset.publisher\\\\\\\", z[\\\\\\\"publisher\\\\\\\"])\\\\n\\\",\\n-    \\\"    \\\\n\\\",\\n-    \\\"   \\\"\\n-   ]\\n-  },\\n-  {\\n-   \\\"cell_type\\\": \\\"markdown\\\",\\n-   \\\"id\\\": \\\"9832d0df-af0a-4eee-90d0-fab926e03e85\\\",\\n-   \\\"metadata\\\": {},\\n-   \\\"source\\\": [\\n-    \\\"DATA PREPROCESSING\\\"\\n-   ]\\n-  },\\n-  {\\n-   \\\"cell_type\\\": \\\"code\\\",\\n-   \\\"execution_count\\\": 91,\\n-   \\\"id\\\": \\\"77402d80-22d1-4bed-9489-768958c3e9fa\\\",\\n-   \\\"metadata\\\": {},\\n-   \\\"outputs\\\": [],\\n-   \\\"source\\\": [\\n-    \\\"# \\u2500\\u2500 2) Load into a DataFrame \\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\\\n\\\",\\n-    \\\"df = pd.DataFrame(dataset)\\\"\\n-   ]\\n-  },\\n-  {\\n-   \\\"cell_type\\\": \\\"code\\\",\\n-   \\\"execution_count\\\": 92,\\n-   \\\"id\\\": \\\"01309a7b-53d2-4df4-b334-0f0db8b03333\\\",\\n-   \\\"metadata\\\": {},\\n-   \\\"outputs\\\": [\\n-    {\\n-     \\\"name\\\": \\\"stdout\\\",\\n-     \\\"output_type\\\": \\\"stream\\\",\\n-     \\\"text\\\": [\\n-      \\\"Shapes: (150, 4) (150,)\\\\n\\\"\\n-     ]\\n-    }\\n-   ],\\n-   \\\"source\\\": [\\n-    \\\"target_col = df.columns[-1]      # e.g. \\\\\\\"species\\\\\\\"\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# 2) extract y as the Series of labels\\\\n\\\",\\n-    \\\"y = df[target_col]               # length == n_samples\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# 3) build X by dropping just that one column\\\\n\\\",\\n-    \\\"X = df.drop(columns=[target_col])\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# 4) drop any ID column (case-insensitive)\\\\n\\\",\\n-    \\\"id_cols = [c for c in X.columns if c.lower() == \\\\\\\"id\\\\\\\"]\\\\n\\\",\\n-    \\\"if id_cols:\\\\n\\\",\\n-    \\\"    X = X.drop(columns=id_cols)\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# 5) coerce numeric where possible\\\\n\\\",\\n-    \\\"for c in X.columns:\\\\n\\\",\\n-    \\\"    try:\\\\n\\\",\\n-    \\\"        X[c] = pd.to_numeric(X[c])\\\\n\\\",\\n-    \\\"    except Exception:\\\\n\\\",\\n-    \\\"        pass\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"print(\\\\\\\"Shapes:\\\\\\\", X.shape, y.shape)\\\\n\\\",\\n-    \\\"# \\u2192 (150, 4) (150,)\\\\n\\\",\\n-    \\\"\\\\n\\\"\\n-   ]\\n-  },\\n-  {\\n-   \\\"cell_type\\\": \\\"code\\\",\\n-   \\\"execution_count\\\": 93,\\n-   \\\"id\\\": \\\"11f5126d-6a03-48c6-9ecf-39ed0d43688c\\\",\\n-   \\\"metadata\\\": {},\\n-   \\\"outputs\\\": [\\n-    {\\n-     \\\"name\\\": \\\"stdout\\\",\\n-     \\\"output_type\\\": \\\"stream\\\",\\n-     \\\"text\\\": [\\n-      \\\"Classes: ['Iris-setosa' 'Iris-versicolor' 'Iris-virginica']\\\\n\\\"\\n-     ]\\n-    },\\n-    {\\n-     \\\"data\\\": {\\n-      \\\"text/plain\\\": [\\n-       \\\"array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\\\\n\\\",\\n-       \\\"       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\\\\n\\\",\\n-       \\\"       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\\\\n\\\",\\n-       \\\"       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\\\\n\\\",\\n-       \\\"       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\\\\n\\\",\\n-       \\\"       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\\\\n\\\",\\n-       \\\"       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\\\"\\n-      ]\\n-     },\\n-     \\\"execution_count\\\": 93,\\n-     \\\"metadata\\\": {},\\n-     \\\"output_type\\\": \\\"execute_result\\\"\\n-    }\\n-   ],\\n-   \\\"source\\\": [\\n-    \\\"from sklearn.preprocessing import LabelEncoder\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"le = LabelEncoder()\\\\n\\\",\\n-    \\\"y = le.fit_transform(y)  \\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# now y_enc is a 1d numpy array of ints 0,1,2\\\\n\\\",\\n-    \\\"print(\\\\\\\"Classes:\\\\\\\", le.classes_)  \\\\n\\\",\\n-    \\\"y\\\"\\n-   ]\\n-  },\\n-  {\\n-   \\\"cell_type\\\": \\\"code\\\",\\n-   \\\"execution_count\\\": 103,\\n-   \\\"id\\\": \\\"68d0a924-c65f-4a44-a5cc-bbb32d17e96f\\\",\\n-   \\\"metadata\\\": {},\\n-   \\\"outputs\\\": [],\\n-   \\\"source\\\": [\\n-    \\\"# \\u2500\\u2500 4) Cast feature columns to numeric where possible \\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\\\n\\\",\\n-    \\\"for col in X.columns:\\\\n\\\",\\n-    \\\"    try:\\\\n\\\",\\n-    \\\"        X[col] = pd.to_numeric(X[col])   # no errors=\\\\\\\"ignore\\\\\\\"\\\\n\\\",\\n-    \\\"    except ValueError:\\\\n\\\",\\n-    \\\"        # if it can\\u2019t be cast, just leave it as-is\\\\n\\\",\\n-    \\\"        pass\\\\n\\\"\\n-   ]\\n-  },\\n-  {\\n-   \\\"cell_type\\\": \\\"code\\\",\\n-   \\\"execution_count\\\": 104,\\n-   \\\"id\\\": \\\"e17f39ce-3322-4626-83a6-079d304bbc04\\\",\\n-   \\\"metadata\\\": {},\\n-   \\\"outputs\\\": [],\\n-   \\\"source\\\": [\\n-    \\\"# \\u2500\\u2500 5) Drop any \\u201cid\\u201d column (case-insensitive) \\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\\\n\\\",\\n-    \\\"dropped = [c for c in X.columns if c.lower() == \\\\\\\"id\\\\\\\"]\\\\n\\\",\\n-    \\\"X = X.drop(columns=dropped, errors=\\\\\\\"ignore\\\\\\\")\\\"\\n-   ]\\n-  },\\n-  {\\n-   \\\"cell_type\\\": \\\"code\\\",\\n-   \\\"execution_count\\\": 55,\\n-   \\\"id\\\": \\\"46f00853-206c-4fd1-b627-38115ae95a0f\\\",\\n-   \\\"metadata\\\": {\\n-    \\\"scrolled\\\": true\\n-   },\\n-   \\\"outputs\\\": [],\\n-   \\\"source\\\": [\\n-    \\\"# RQ1.2: Model Provenance Tracking in Jupyter Notebook using MLflow\\\\n\\\",\\n-    \\\"# Updated with automatic logging of environment, Git, model config, and FAIR-aligned metadata\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# ============================\\\\n\\\",\\n-    \\\"# \\u2699\\ufe0f Install Dependencies (if needed in Colab)\\\\n\\\",\\n-    \\\"# ============================\\\\n\\\",\\n-    \\\"# !pip install mlflow scikit-learn pandas numpy matplotlib seaborn shap requests GitPython\\\\n\\\",\\n-    \\\"\\\\n\\\"\\n-   ]\\n-  },\\n-  {\\n-   \\\"cell_type\\\": \\\"code\\\",\\n-   \\\"execution_count\\\": 56,\\n-   \\\"id\\\": \\\"3475b9b8-173d-4b5b-8913-de384dc60e67\\\",\\n-   \\\"metadata\\\": {},\\n-   \\\"outputs\\\": [],\\n-   \\\"source\\\": [\\n-    \\\"# !pip install --upgrade threadpoolctl\\\\n\\\",\\n-    \\\"# !pip install setuptools\\\\n\\\",\\n-    \\\"# !pip install ace_tools \\\\n\\\"\\n-   ]\\n-  },\\n-  {\\n-   \\\"cell_type\\\": \\\"code\\\",\\n-   \\\"execution_count\\\": 57,\\n-   \\\"id\\\": \\\"64674a5d-93d3-4557-8f5a-2c1babfcfb2a\\\",\\n-   \\\"metadata\\\": {},\\n-   \\\"outputs\\\": [],\\n-   \\\"source\\\": [\\n-    \\\"# ============================\\\\n\\\",\\n-    \\\"# \\ud83d\\udce6 Imports\\\\n\\\",\\n-    \\\"# ============================\\\\n\\\",\\n-    \\\"import os\\\\n\\\",\\n-    \\\"import time\\\\n\\\",\\n-    \\\"import json\\\\n\\\",\\n-    \\\"import psutil\\\\n\\\",\\n-    \\\"import platform\\\\n\\\",\\n-    \\\"import git\\\\n\\\",\\n-    \\\"from git import Repo\\\\n\\\",\\n-    \\\"from git import Repo, GitCommandError\\\\n\\\",\\n-    \\\"import mlflow\\\\n\\\",\\n-    \\\"import requests\\\\n\\\",\\n-    \\\"import shap\\\\n\\\",\\n-    \\\"import pandas as pd\\\\n\\\",\\n-    \\\"import numpy as np\\\\n\\\",\\n-    \\\"import sklearn\\\\n\\\",\\n-    \\\"import subprocess\\\\n\\\",\\n-    \\\"import seaborn as sns\\\\n\\\",\\n-    \\\"from git import Repo, GitCommandError\\\\n\\\",\\n-    \\\"import matplotlib\\\\n\\\",\\n-    \\\"import matplotlib.pyplot as plt\\\\n\\\",\\n-    \\\"import mlflow.sklearn\\\\n\\\",\\n-    \\\"from dotenv import load_dotenv\\\\n\\\",\\n-    \\\"from datetime import datetime\\\\n\\\",\\n-    \\\"# import setuptools\\\\n\\\",\\n-    \\\"from sklearn.ensemble import RandomForestClassifier\\\\n\\\",\\n-    \\\"from sklearn.model_selection import train_test_split\\\\n\\\",\\n-    \\\"from sklearn.metrics import (\\\\n\\\",\\n-    \\\"    accuracy_score, roc_auc_score, confusion_matrix,\\\\n\\\",\\n-    \\\"    precision_score, recall_score, f1_score, roc_curve\\\\n\\\",\\n-    \\\")\\\\n\\\",\\n-    \\\"from mlflow import MlflowClient\\\\n\\\",\\n-    \\\"from sklearn.metrics import (\\\\n\\\",\\n-    \\\"    accuracy_score,\\\\n\\\",\\n-    \\\"    roc_auc_score,\\\\n\\\",\\n-    \\\"    precision_score,\\\\n\\\",\\n-    \\\"    recall_score,\\\\n\\\",\\n-    \\\"    f1_score,\\\\n\\\",\\n-    \\\"    RocCurveDisplay,\\\\n\\\",\\n-    \\\"    PrecisionRecallDisplay,\\\\n\\\",\\n-    \\\")\\\\n\\\",\\n-    \\\"from sklearn.preprocessing import label_binarize\\\\n\\\",\\n-    \\\"import numpy as np\\\\n\\\",\\n-    \\\"import pickle\\\\n\\\"\\n-   ]\\n-  },\\n-  {\\n-   \\\"cell_type\\\": \\\"code\\\",\\n-   \\\"execution_count\\\": 205,\\n-   \\\"id\\\": \\\"cbe91ec0-6447-4586-b7cc-2c1f74d4218f\\\",\\n-   \\\"metadata\\\": {},\\n-   \\\"outputs\\\": [],\\n-   \\\"source\\\": [\\n-    \\\"# ============================\\\\n\\\",\\n-    \\\"# \\ud83d\\udcc2 Setup MLflow\\\\n\\\",\\n-    \\\"# ============================\\\\n\\\",\\n-    \\\"project_dir = os.getcwd()\\\\n\\\",\\n-    \\\"mlflow.set_tracking_uri(\\\\\\\"mlrunlogs/mlflow.db\\\\\\\")\\\\n\\\",\\n-    \\\"mlflow.set_experiment(\\\\\\\"RandomForest-Iris-CSV\\\\\\\")\\\\n\\\",\\n-    \\\"# mlflow.sklearn.autolog()\\\"\\n-   ]\\n-  },\\n-  {\\n-   \\\"cell_type\\\": \\\"code\\\",\\n-   \\\"execution_count\\\": 59,\\n-   \\\"id\\\": \\\"838dd233-25dc-4725-974d-4da89c257782\\\",\\n-   \\\"metadata\\\": {},\\n-   \\\"outputs\\\": [],\\n-   \\\"source\\\": [\\n-    \\\"# ============================\\\\n\\\",\\n-    \\\"# \\ud83d\\udd04 Git Commit Hash\\\\n\\\",\\n-    \\\"# ============================\\\\n\\\",\\n-    \\\"repo_dir = \\\\\\\"C:/Users/reema/REPO\\\\\\\"\\\\n\\\",\\n-    \\\"previous_commit_repo = git.Repo(repo_dir)\\\\n\\\",\\n-    \\\"previous_commit_hash = previous_commit_repo.head.object.hexsha\\\"\\n-   ]\\n-  },\\n-  {\\n-   \\\"cell_type\\\": \\\"code\\\",\\n-   \\\"execution_count\\\": 60,\\n-   \\\"id\\\": \\\"9668451f-4352-4bdc-8b6b-bbe49074212a\\\",\\n-   \\\"metadata\\\": {},\\n-   \\\"outputs\\\": [\\n-    {\\n-     \\\"name\\\": \\\"stderr\\\",\\n-     \\\"output_type\\\": \\\"stream\\\",\\n-     \\\"text\\\": [\\n-      \\\"2025/04/23 23:01:41 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\\\\n\\\",\\n-      \\\"2025/04/23 23:01:41 INFO mlflow.tracking.fluent: Autologging successfully enabled for statsmodels.\\\\n\\\"\\n-     ]\\n-    }\\n-   ],\\n-   \\\"source\\\": [\\n-    \\\"# \\u2500\\u2500\\u2500 0) Make threadpoolctl safe so MLflow\\u2019s autologger won\\u2019t crash \\u2500\\u2500\\u2500\\\\n\\\",\\n-    \\\"try:\\\\n\\\",\\n-    \\\"    import threadpoolctl\\\\n\\\",\\n-    \\\"    _orig = threadpoolctl.threadpool_info\\\\n\\\",\\n-    \\\"    def _safe_threadpool_info(*args, **kwargs):\\\\n\\\",\\n-    \\\"        try:\\\\n\\\",\\n-    \\\"            return _orig(*args, **kwargs)\\\\n\\\",\\n-    \\\"        except Exception:\\\\n\\\",\\n-    \\\"            return []\\\\n\\\",\\n-    \\\"    threadpoolctl.threadpool_info = _safe_threadpool_info\\\\n\\\",\\n-    \\\"except ImportError:\\\\n\\\",\\n-    \\\"    pass  # if threadpoolctl isn\\u2019t installed, autolog will skip unsupported versions\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# \\u2500\\u2500\\u2500 1) Enable generic autolog (will auto-patch sklearn under the hood) \\u2500\\u2500\\u2500\\\\n\\\",\\n-    \\\"import mlflow\\\\n\\\",\\n-    \\\"mlflow.autolog(\\\\n\\\",\\n-    \\\"    log_input_examples=True,\\\\n\\\",\\n-    \\\"    log_model_signatures=True\\\\n\\\",\\n-    \\\")\\\"\\n-   ]\\n-  },\\n-  {\\n-   \\\"cell_type\\\": \\\"code\\\",\\n-   \\\"execution_count\\\": 206,\\n-   \\\"id\\\": \\\"14c62f08-a116-4060-9689-f69968e9f240\\\",\\n-   \\\"metadata\\\": {\\n-    \\\"scrolled\\\": true\\n-   },\\n-   \\\"outputs\\\": [\\n-    {\\n-     \\\"ename\\\": \\\"ConnectionError\\\",\\n-     \\\"evalue\\\": \\\"HTTPConnectionPool(host='localhost', port=80): Max retries exceeded with url: /api/database/c3a42d17-42b7-43c9-a504-2363fb4c9c8d (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001EF2D576A10>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))\\\",\\n-     \\\"output_type\\\": \\\"error\\\",\\n-     \\\"traceback\\\": [\\n-      \\\"\\\\u001b[1;31m---------------------------------------------------------------------------\\\\u001b[0m\\\",\\n-      \\\"\\\\u001b[1;31mConnectionRefusedError\\\\u001b[0m                    Traceback (most recent call last)\\\",\\n-      \\\"File \\\\u001b[1;32m~\\\\\\\\anaconda3\\\\\\\\Lib\\\\\\\\site-packages\\\\\\\\urllib3\\\\\\\\connection.py:174\\\\u001b[0m, in \\\\u001b[0;36mHTTPConnection._new_conn\\\\u001b[1;34m(self)\\\\u001b[0m\\\\n\\\\u001b[0;32m    173\\\\u001b[0m \\\\u001b[38;5;28;01mtry\\\\u001b[39;00m:\\\\n\\\\u001b[1;32m--> 174\\\\u001b[0m     conn \\\\u001b[38;5;241m=\\\\u001b[39m \\\\u001b[43mconnection\\\\u001b[49m\\\\u001b[38;5;241;43m.\\\\u001b[39;49m\\\\u001b[43mcreate_connection\\\\u001b[49m\\\\u001b[43m(\\\\u001b[49m\\\\n\\\\u001b[0;32m    175\\\\u001b[0m \\\\u001b[43m        \\\\u001b[49m\\\\u001b[43m(\\\\u001b[49m\\\\u001b[38;5;28;43mself\\\\u001b[39;49m\\\\u001b[38;5;241;43m.\\\\u001b[39;49m\\\\u001b[43m_dns_host\\\\u001b[49m\\\\u001b[43m,\\\\u001b[49m\\\\u001b[43m \\\\u001b[49m\\\\u001b[38;5;28;43mself\\\\u001b[39;49m\\\\u001b[38;5;241;43m.\\\\u001b[39;49m\\\\u001b[43mport\\\\u001b[49m\\\\u001b[43m)\\\\u001b[49m\\\\u001b[43m,\\\\u001b[49m\\\\u001b[43m \\\\u001b[49m\\\\u001b[38;5;28;43mself\\\\u001b[39;49m\\\\u001b[38;5;241;43m.\\\\u001b[39;49m\\\\u001b[43mtimeout\\\\u001b[49m\\\\u001b[43m,\\\\u001b[49m\\\\u001b[43m \\\\u001b[49m\\\\u001b[38;5;241;43m*\\\\u001b[39;49m\\\\u001b[38;5;241;43m*\\\\u001b[39;49m\\\\u001b[43mextra_kw\\\\u001b[49m\\\\n\\\\u001b[0;32m    176\\\\u001b[0m \\\\u001b[43m    \\\\u001b[49m\\\\u001b[43m)\\\\u001b[49m\\\\n\\\\u001b[0;32m    178\\\\u001b[0m \\\\u001b[38;5;28;01mexcept\\\\u001b[39;00m SocketTimeout:\\\\n\\\",\\n-      \\\"File \\\\u001b[1;32m~\\\\\\\\anaconda3\\\\\\\\Lib\\\\\\\\site-packages\\\\\\\\urllib3\\\\\\\\util\\\\\\\\connection.py:95\\\\u001b[0m, in \\\\u001b[0;36mcreate_connection\\\\u001b[1;34m(address, timeout, source_address, socket_options)\\\\u001b[0m\\\\n\\\\u001b[0;32m     94\\\\u001b[0m \\\\u001b[38;5;28;01mif\\\\u001b[39;00m err \\\\u001b[38;5;129;01mis\\\\u001b[39;00m \\\\u001b[38;5;129;01mnot\\\\u001b[39;00m \\\\u001b[38;5;28;01mNone\\\\u001b[39;00m:\\\\n\\\\u001b[1;32m---> 95\\\\u001b[0m     \\\\u001b[38;5;28;01mraise\\\\u001b[39;00m err\\\\n\\\\u001b[0;32m     97\\\\u001b[0m \\\\u001b[38;5;28;01mraise\\\\u001b[39;00m socket\\\\u001b[38;5;241m.\\\\u001b[39merror(\\\\u001b[38;5;124m\\\\\\\"\\\\u001b[39m\\\\u001b[38;5;124mgetaddrinfo returns an empty list\\\\u001b[39m\\\\u001b[38;5;124m\\\\\\\"\\\\u001b[39m)\\\\n\\\",\\n-      \\\"File \\\\u001b[1;32m~\\\\\\\\anaconda3\\\\\\\\Lib\\\\\\\\site-packages\\\\\\\\urllib3\\\\\\\\util\\\\\\\\connection.py:85\\\\u001b[0m, in \\\\u001b[0;36mcreate_connection\\\\u001b[1;34m(address, timeout, source_address, socket_options)\\\\u001b[0m\\\\n\\\\u001b[0;32m     84\\\\u001b[0m     sock\\\\u001b[38;5;241m.\\\\u001b[39mbind(source_address)\\\\n\\\\u001b[1;32m---> 85\\\\u001b[0m sock\\\\u001b[38;5;241m.\\\\u001b[39mconnect(sa)\\\\n\\\\u001b[0;32m     86\\\\u001b[0m \\\\u001b[38;5;28;01mreturn\\\\u001b[39;00m sock\\\\n\\\",\\n-      \\\"\\\\u001b[1;31mConnectionRefusedError\\\\u001b[0m: [WinError 10061] No connection could be made because the target machine actively refused it\\\",\\n-      \\\"\\\\nDuring handling of the above exception, another exception occurred:\\\\n\\\",\\n-      \\\"\\\\u001b[1;31mNewConnectionError\\\\u001b[0m                        Traceback (most recent call last)\\\",\\n-      \\\"File \\\\u001b[1;32m~\\\\\\\\anaconda3\\\\\\\\Lib\\\\\\\\site-packages\\\\\\\\urllib3\\\\\\\\connectionpool.py:714\\\\u001b[0m, in \\\\u001b[0;36mHTTPConnectionPool.urlopen\\\\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\\\\u001b[0m\\\\n\\\\u001b[0;32m    713\\\\u001b[0m \\\\u001b[38;5;66;03m# Make the request on the httplib connection object.\\\\u001b[39;00m\\\\n\\\\u001b[1;32m--> 714\\\\u001b[0m httplib_response \\\\u001b[38;5;241m=\\\\u001b[39m \\\\u001b[38;5;28;43mself\\\\u001b[39;49m\\\\u001b[38;5;241;43m.\\\\u001b[39;49m\\\\u001b[43m_make_request\\\\u001b[49m\\\\u001b[43m(\\\\u001b[49m\\\\n\\\\u001b[0;32m    715\\\\u001b[0m \\\\u001b[43m    \\\\u001b[49m\\\\u001b[43mconn\\\\u001b[49m\\\\u001b[43m,\\\\u001b[49m\\\\n\\\\u001b[0;32m    716\\\\u001b[0m \\\\u001b[43m    \\\\u001b[49m\\\\u001b[43mmethod\\\\u001b[49m\\\\u001b[43m,\\\\u001b[49m\\\\n\\\\u001b[0;32m    717\\\\u001b[0m \\\\u001b[43m    \\\\u001b[49m\\\\u001b[43murl\\\\u001b[49m\\\\u001b[43m,\\\\u001b[49m\\\\n\\\\u001b[0;32m    718\\\\u001b[0m \\\\u001b[43m    \\\\u001b[49m\\\\u001b[43mtimeout\\\\u001b[49m\\\\u001b[38;5;241;43m=\\\\u001b[39;49m\\\\u001b[43mtimeout_obj\\\\u001b[49m\\\\u001b[43m,\\\\u001b[49m\\\\n\\\\u001b[0;32m    719\\\\u001b[0m \\\\u001b[43m    \\\\u001b[49m\\\\u001b[43mbody\\\\u001b[49m\\\\u001b[38;5;241;43m=\\\\u001b[39;49m\\\\u001b[43mbody\\\\u001b[49m\\\\u001b[43m,\\\\u001b[49m\\\\n\\\\u001b[0;32m    720\\\\u001b[0m \\\\u001b[43m    \\\\u001b[49m\\\\u001b[43mheaders\\\\u001b[49m\\\\u001b[38;5;241;43m=\\\\u001b[39;49m\\\\u001b[43mheaders\\\\u001b[49m\\\\u001b[43m,\\\\u001b[49m\\\\n\\\\u001b[0;32m    721\\\\u001b[0m \\\\u001b[43m    \\\\u001b[49m\\\\u001b[43mchunked\\\\u001b[49m\\\\u001b[38;5;241;43m=\\\\u001b[39;49m\\\\u001b[43mchunked\\\\u001b[49m\\\\u001b[43m,\\\\u001b[49m\\\\n\\\\u001b[0;32m    722\\\\u001b[0m \\\\u001b[43m\\\\u001b[49m\\\\u001b[43m)\\\\u001b[49m\\\\n\\\\u001b[0;32m    724\\\\u001b[0m \\\\u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\\\\u001b[39;00m\\\\n\\\\u001b[0;32m    725\\\\u001b[0m \\\\u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\\\\u001b[39;00m\\\\n\\\\u001b[0;32m    726\\\\u001b[0m \\\\u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\\\\u001b[39;00m\\\\n\\\\u001b[0;32m    727\\\\u001b[0m \\\\u001b[38;5;66;03m# mess.\\\\u001b[39;00m\\\\n\\\",\\n-      \\\"File \\\\u001b[1;32m~\\\\\\\\anaconda3\\\\\\\\Lib\\\\\\\\site-packages\\\\\\\\urllib3\\\\\\\\connectionpool.py:415\\\\u001b[0m, in \\\\u001b[0;36mHTTPConnectionPool._make_request\\\\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\\\\u001b[0m\\\\n\\\\u001b[0;32m    414\\\\u001b[0m     \\\\u001b[38;5;28;01melse\\\\u001b[39;00m:\\\\n\\\\u001b[1;32m--> 415\\\\u001b[0m         \\\\u001b[43mconn\\\\u001b[49m\\\\u001b[38;5;241;43m.\\\\u001b[39;49m\\\\u001b[43mrequest\\\\u001b[49m\\\\u001b[43m(\\\\u001b[49m\\\\u001b[43mmethod\\\\u001b[49m\\\\u001b[43m,\\\\u001b[49m\\\\u001b[43m \\\\u001b[49m\\\\u001b[43murl\\\\u001b[49m\\\\u001b[43m,\\\\u001b[49m\\\\u001b[43m \\\\u001b[49m\\\\u001b[38;5;241;43m*\\\\u001b[39;49m\\\\u001b[38;5;241;43m*\\\\u001b[39;49m\\\\u001b[43mhttplib_request_kw\\\\u001b[49m\\\\u001b[43m)\\\\u001b[49m\\\\n\\\\u001b[0;32m    417\\\\u001b[0m \\\\u001b[38;5;66;03m# We are swallowing BrokenPipeError (errno.EPIPE) since the server is\\\\u001b[39;00m\\\\n\\\\u001b[0;32m    418\\\\u001b[0m \\\\u001b[38;5;66;03m# legitimately able to close the connection after sending a valid response.\\\\u001b[39;00m\\\\n\\\\u001b[0;32m    419\\\\u001b[0m \\\\u001b[38;5;66;03m# With this behaviour, the received response is still readable.\\\\u001b[39;00m\\\\n\\\",\\n-      \\\"File \\\\u001b[1;32m~\\\\\\\\anaconda3\\\\\\\\Lib\\\\\\\\site-packages\\\\\\\\urllib3\\\\\\\\connection.py:244\\\\u001b[0m, in \\\\u001b[0;36mHTTPConnection.request\\\\u001b[1;34m(self, method, url, body, headers)\\\\u001b[0m\\\\n\\\\u001b[0;32m    243\\\\u001b[0m     headers[\\\\u001b[38;5;124m\\\\\\\"\\\\u001b[39m\\\\u001b[38;5;124mUser-Agent\\\\u001b[39m\\\\u001b[38;5;124m\\\\\\\"\\\\u001b[39m] \\\\u001b[38;5;241m=\\\\u001b[39m _get_default_user_agent()\\\\n\\\\u001b[1;32m--> 244\\\\u001b[0m \\\\u001b[38;5;28;43msuper\\\\u001b[39;49m\\\\u001b[43m(\\\\u001b[49m\\\\u001b[43mHTTPConnection\\\\u001b[49m\\\\u001b[43m,\\\\u001b[49m\\\\u001b[43m \\\\u001b[49m\\\\u001b[38;5;28;43mself\\\\u001b[39;49m\\\\u001b[43m)\\\\u001b[49m\\\\u001b[38;5;241;43m.\\\\u001b[39;49m\\\\u001b[43mrequest\\\\u001b[49m\\\\u001b[43m(\\\\u001b[49m\\\\u001b[43mmethod\\\\u001b[49m\\\\u001b[43m,\\\\u001b[49m\\\\u001b[43m \\\\u001b[49m\\\\u001b[43murl\\\\u001b[49m\\\\u001b[43m,\\\\u001b[49m\\\\u001b[43m \\\\u001b[49m\\\\u001b[43mbody\\\\u001b[49m\\\\u001b[38;5;241;43m=\\\\u001b[39;49m\\\\u001b[43mbody\\\\u001b[49m\\\\u001b[43m,\\\\u001b[49m\\\\u001b[43m \\\\u001b[49m\\\\u001b[43mheaders\\\\u001b[49m\\\\u001b[38;5;241;43m=\\\\u001b[39;49m\\\\u001b[43mheaders\\\\u001b[49m\\\\u001b[43m)\\\\u001b[49m\\\\n\\\",\\n-      \\\"File \\\\u001b[1;32m~\\\\\\\\anaconda3\\\\\\\\Lib\\\\\\\\http\\\\\\\\client.py:1286\\\\u001b[0m, in \\\\u001b[0;36mHTTPConnection.request\\\\u001b[1;34m(self, method, url, body, headers, encode_chunked)\\\\u001b[0m\\\\n\\\\u001b[0;32m   1285\\\\u001b[0m \\\\u001b[38;5;250m\\\\u001b[39m\\\\u001b[38;5;124;03m\\\\\\\"\\\\\\\"\\\\\\\"Send a complete request to the server.\\\\\\\"\\\\\\\"\\\\\\\"\\\\u001b[39;00m\\\\n\\\\u001b[1;32m-> 1286\\\\u001b[0m \\\\u001b[38;5;28;43mself\\\\u001b[39;49m\\\\u001b[38;5;241;43m.\\\\u001b[39;49m\\\\u001b[43m_send_request\\\\u001b[49m\\\\u001b[43m(\\\\u001b[49m\\\\u001b[43mmethod\\\\u001b[49m\\\\u001b[43m,\\\\u001b[49m\\\\u001b[43m \\\\u001b[49m\\\\u001b[43murl\\\\u001b[49m\\\\u001b[43m,\\\\u001b[49m\\\\u001b[43m \\\\u001b[49m\\\\u001b[43mbody\\\\u001b[49m\\\\u001b[43m,\\\\u001b[49m\\\\u001b[43m \\\\u001b[49m\\\\u001b[43mheaders\\\\u001b[49m\\\\u001b[43m,\\\\u001b[49m\\\\u001b[43m \\\\u001b[49m\\\\u001b[43mencode_chunked\\\\u001b[49m\\\\u001b[43m)\\\\u001b[49m\\\\n\\\",\\n-      \\\"File \\\\u001b[1;32m~\\\\\\\\anaconda3\\\\\\\\Lib\\\\\\\\http\\\\\\\\client.py:1332\\\\u001b[0m, in \\\\u001b[0;36mHTTPConnection._send_request\\\\u001b[1;34m(self, method, url, body, headers, encode_chunked)\\\\u001b[0m\\\\n\\\\u001b[0;32m   1331\\\\u001b[0m     body \\\\u001b[38;5;241m=\\\\u001b[39m _encode(body, \\\\u001b[38;5;124m'\\\\u001b[39m\\\\u001b[38;5;124mbody\\\\u001b[39m\\\\u001b[38;5;124m'\\\\u001b[39m)\\\\n\\\\u001b[1;32m-> 1332\\\\u001b[0m \\\\u001b[38;5;28;43mself\\\\u001b[39;49m\\\\u001b[38;5;241;43m.\\\\u001b[39;49m\\\\u001b[43mendheaders\\\\u001b[49m\\\\u001b[43m(\\\\u001b[49m\\\\u001b[43mbody\\\\u001b[49m\\\\u001b[43m,\\\\u001b[49m\\\\u001b[43m \\\\u001b[49m\\\\u001b[43mencode_chunked\\\\u001b[49m\\\\u001b[38;5;241;43m=\\\\u001b[39;49m\\\\u001b[43mencode_chunked\\\\u001b[49m\\\\u001b[43m)\\\\u001b[49m\\\\n\\\",\\n-      \\\"File \\\\u001b[1;32m~\\\\\\\\anaconda3\\\\\\\\Lib\\\\\\\\http\\\\\\\\client.py:1281\\\\u001b[0m, in \\\\u001b[0;36mHTTPConnection.endheaders\\\\u001b[1;34m(self, message_body, encode_chunked)\\\\u001b[0m\\\\n\\\\u001b[0;32m   1280\\\\u001b[0m     \\\\u001b[38;5;28;01mraise\\\\u001b[39;00m CannotSendHeader()\\\\n\\\\u001b[1;32m-> 1281\\\\u001b[0m \\\\u001b[38;5;28;43mself\\\\u001b[39;49m\\\\u001b[38;5;241;43m.\\\\u001b[39;49m\\\\u001b[43m_send_output\\\\u001b[49m\\\\u001b[43m(\\\\u001b[49m\\\\u001b[43mmessage_body\\\\u001b[49m\\\\u001b[43m,\\\\u001b[49m\\\\u001b[43m \\\\u001b[49m\\\\u001b[43mencode_chunked\\\\u001b[49m\\\\u001b[38;5;241;43m=\\\\u001b[39;49m\\\\u001b[43mencode_chunked\\\\u001b[49m\\\\u001b[43m)\\\\u001b[49m\\\\n\\\",\\n-      \\\"File \\\\u001b[1;32m~\\\\\\\\anaconda3\\\\\\\\Lib\\\\\\\\http\\\\\\\\client.py:1041\\\\u001b[0m, in \\\\u001b[0;36mHTTPConnection._send_output\\\\u001b[1;34m(self, message_body, encode_chunked)\\\\u001b[0m\\\\n\\\\u001b[0;32m   1040\\\\u001b[0m \\\\u001b[38;5;28;01mdel\\\\u001b[39;00m \\\\u001b[38;5;28mself\\\\u001b[39m\\\\u001b[38;5;241m.\\\\u001b[39m_buffer[:]\\\\n\\\\u001b[1;32m-> 1041\\\\u001b[0m \\\\u001b[38;5;28;43mself\\\\u001b[39;49m\\\\u001b[38;5;241;43m.\\\\u001b[39;49m\\\\u001b[43msend\\\\u001b[49m\\\\u001b[43m(\\\\u001b[49m\\\\u001b[43mmsg\\\\u001b[49m\\\\u001b[43m)\\\\u001b[49m\\\\n\\\\u001b[0;32m   1043\\\\u001b[0m \\\\u001b[38;5;28;01mif\\\\u001b[39;00m message_body \\\\u001b[38;5;129;01mis\\\\u001b[39;00m \\\\u001b[38;5;129;01mnot\\\\u001b[39;00m \\\\u001b[38;5;28;01mNone\\\\u001b[39;00m:\\\\n\\\\u001b[0;32m   1044\\\\u001b[0m \\\\n\\\\u001b[0;32m   1045\\\\u001b[0m     \\\\u001b[38;5;66;03m# create a consistent interface to message_body\\\\u001b[39;00m\\\\n\\\",\\n-      \\\"File \\\\u001b[1;32m~\\\\\\\\anaconda3\\\\\\\\Lib\\\\\\\\http\\\\\\\\client.py:979\\\\u001b[0m, in \\\\u001b[0;36mHTTPConnection.send\\\\u001b[1;34m(self, data)\\\\u001b[0m\\\\n\\\\u001b[0;32m    978\\\\u001b[0m \\\\u001b[38;5;28;01mif\\\\u001b[39;00m \\\\u001b[38;5;28mself\\\\u001b[39m\\\\u001b[38;5;241m.\\\\u001b[39mauto_open:\\\\n\\\\u001b[1;32m--> 979\\\\u001b[0m     \\\\u001b[38;5;28;43mself\\\\u001b[39;49m\\\\u001b[38;5;241;43m.\\\\u001b[39;49m\\\\u001b[43mconnect\\\\u001b[49m\\\\u001b[43m(\\\\u001b[49m\\\\u001b[43m)\\\\u001b[49m\\\\n\\\\u001b[0;32m    980\\\\u001b[0m \\\\u001b[38;5;28;01melse\\\\u001b[39;00m:\\\\n\\\",\\n-      \\\"File \\\\u001b[1;32m~\\\\\\\\anaconda3\\\\\\\\Lib\\\\\\\\site-packages\\\\\\\\urllib3\\\\\\\\connection.py:205\\\\u001b[0m, in \\\\u001b[0;36mHTTPConnection.connect\\\\u001b[1;34m(self)\\\\u001b[0m\\\\n\\\\u001b[0;32m    204\\\\u001b[0m \\\\u001b[38;5;28;01mdef\\\\u001b[39;00m \\\\u001b[38;5;21mconnect\\\\u001b[39m(\\\\u001b[38;5;28mself\\\\u001b[39m):\\\\n\\\\u001b[1;32m--> 205\\\\u001b[0m     conn \\\\u001b[38;5;241m=\\\\u001b[39m \\\\u001b[38;5;28;43mself\\\\u001b[39;49m\\\\u001b[38;5;241;43m.\\\\u001b[39;49m\\\\u001b[43m_new_conn\\\\u001b[49m\\\\u001b[43m(\\\\u001b[49m\\\\u001b[43m)\\\\u001b[49m\\\\n\\\\u001b[0;32m    206\\\\u001b[0m     \\\\u001b[38;5;28mself\\\\u001b[39m\\\\u001b[38;5;241m.\\\\u001b[39m_prepare_conn(conn)\\\\n\\\",\\n-      \\\"File \\\\u001b[1;32m~\\\\\\\\anaconda3\\\\\\\\Lib\\\\\\\\site-packages\\\\\\\\urllib3\\\\\\\\connection.py:186\\\\u001b[0m, in \\\\u001b[0;36mHTTPConnection._new_conn\\\\u001b[1;34m(self)\\\\u001b[0m\\\\n\\\\u001b[0;32m    185\\\\u001b[0m \\\\u001b[38;5;28;01mexcept\\\\u001b[39;00m SocketError \\\\u001b[38;5;28;01mas\\\\u001b[39;00m e:\\\\n\\\\u001b[1;32m--> 186\\\\u001b[0m     \\\\u001b[38;5;28;01mraise\\\\u001b[39;00m NewConnectionError(\\\\n\\\\u001b[0;32m    187\\\\u001b[0m         \\\\u001b[38;5;28mself\\\\u001b[39m, \\\\u001b[38;5;124m\\\\\\\"\\\\u001b[39m\\\\u001b[38;5;124mFailed to establish a new connection: \\\\u001b[39m\\\\u001b[38;5;132;01m%s\\\\u001b[39;00m\\\\u001b[38;5;124m\\\\\\\"\\\\u001b[39m \\\\u001b[38;5;241m%\\\\u001b[39m e\\\\n\\\\u001b[0;32m    188\\\\u001b[0m     )\\\\n\\\\u001b[0;32m    190\\\\u001b[0m \\\\u001b[38;5;28;01mreturn\\\\u001b[39;00m conn\\\\n\\\",\\n-      \\\"\\\\u001b[1;31mNewConnectionError\\\\u001b[0m: <urllib3.connection.HTTPConnection object at 0x000001EF2D576A10>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it\\\",\\n-      \\\"\\\\nDuring handling of the above exception, another exception occurred:\\\\n\\\",\\n-      \\\"\\\\u001b[1;31mMaxRetryError\\\\u001b[0m                             Traceback (most recent call last)\\\",\\n-      \\\"File \\\\u001b[1;32m~\\\\\\\\anaconda3\\\\\\\\Lib\\\\\\\\site-packages\\\\\\\\requests\\\\\\\\adapters.py:486\\\\u001b[0m, in \\\\u001b[0;36mHTTPAdapter.send\\\\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\\\\u001b[0m\\\\n\\\\u001b[0;32m    485\\\\u001b[0m \\\\u001b[38;5;28;01mtry\\\\u001b[39;00m:\\\\n\\\\u001b[1;32m--> 486\\\\u001b[0m     resp \\\\u001b[38;5;241m=\\\\u001b[39m \\\\u001b[43mconn\\\\u001b[49m\\\\u001b[38;5;241;43m.\\\\u001b[39;49m\\\\u001b[43murlopen\\\\u001b[49m\\\\u001b[43m(\\\\u001b[49m\\\\n\\\\u001b[0;32m    487\\\\u001b[0m \\\\u001b[43m        \\\\u001b[49m\\\\u001b[43mmethod\\\\u001b[49m\\\\u001b[38;5;241;43m=\\\\u001b[39;49m\\\\u001b[43mrequest\\\\u001b[49m\\\\u001b[38;5;241;43m.\\\\u001b[39;49m\\\\u001b[43mmethod\\\\u001b[49m\\\\u001b[43m,\\\\u001b[49m\\\\n\\\\u001b[0;32m    488\\\\u001b[0m \\\\u001b[43m        \\\\u001b[49m\\\\u001b[43murl\\\\u001b[49m\\\\u001b[38;5;241;43m=\\\\u001b[39;49m\\\\u001b[43murl\\\\u001b[49m\\\\u001b[43m,\\\\u001b[49m\\\\n\\\\u001b[0;32m    489\\\\u001b[0m \\\\u001b[43m        \\\\u001b[49m\\\\u001b[43mbody\\\\u001b[49m\\\\u001b[38;5;241;43m=\\\\u001b[39;49m\\\\u001b[43mrequest\\\\u001b[49m\\\\u001b[38;5;241;43m.\\\\u001b[39;49m\\\\u001b[43mbody\\\\u001b[49m\\\\u001b[43m,\\\\u001b[49m\\\\n\\\\u001b[0;32m    490\\\\u001b[0m \\\\u001b[43m        \\\\u001b[49m\\\\u001b[43mheaders\\\\u001b[49m\\\\u001b[38;5;241;43m=\\\\u001b[39;49m\\\\u001b[43mrequest\\\\u001b[49m\\\\u001b[38;5;241;43m.\\\\u001b[39;49m\\\\u001b[43mheaders\\\\u001b[49m\\\\u001b[43m,\\\\u001b[49m\\\\n\\\\u001b[0;32m    491\\\\u001b[0m \\\\u001b[43m        \\\\u001b[49m\\\\u001b[43mredirect\\\\u001b[49m\\\\u001b[38;5;241;43m=\\\\u001b[39;49m\\\\u001b[38;5;28;43;01mFalse\\\\u001b[39;49;00m\\\\u001b[43m,\\\\u001b[49m\\\\n\\\\u001b[0;32m    492\\\\u001b[0m \\\\u001b[43m        \\\\u001b[49m\\\\u001b[43massert_same_host\\\\u001b[49m\\\\u001b[38;5;241;43m=\\\\u001b[39;49m\\\\u001b[38;5;28;43;01mFalse\\\\u001b[39;49;00m\\\\u001b[43m,\\\\u001b[49m\\\\n\\\\u001b[0;32m    493\\\\u001b[0m \\\\u001b[43m        \\\\u001b[49m\\\\u001b[43mpreload_content\\\\u001b[49m\\\\u001b[38;5;241;43m=\\\\u001b[39;49m\\\\u001b[38;5;28;43;01mFalse\\\\u001b[39;49;00m\\\\u001b[43m,\\\\u001b[49m\\\\n\\\\u001b[0;32m    494\\\\u001b[0m \\\\u001b[43m        \\\\u001b[49m\\\\u001b[43mdecode_content\\\\u001b[49m\\\\u001b[38;5;241;43m=\\\\u001b[39;49m\\\\u001b[38;5;28;43;01mFalse\\\\u001b[39;49;00m\\\\u001b[43m,\\\\u001b[49m\\\\n\\\\u001b[0;32m    495\\\\u001b[0m \\\\u001b[43m        \\\\u001b[49m\\\\u001b[43mretries\\\\u001b[49m\\\\u001b[38;5;241;43m=\\\\u001b[39;49m\\\\u001b[38;5;28;43mself\\\\u001b[39;49m\\\\u001b[38;5;241;43m.\\\\u001b[39;49m\\\\u001b[43mmax_retries\\\\u001b[49m\\\\u001b[43m,\\\\u001b[49m\\\\n\\\\u001b[0;32m    496\\\\u001b[0m \\\\u001b[43m        \\\\u001b[49m\\\\u001b[43mtimeout\\\\u001b[49m\\\\u001b[38;5;241;43m=\\\\u001b[39;49m\\\\u001b[43mtimeout\\\\u001b[49m\\\\u001b[43m,\\\\u001b[49m\\\\n\\\\u001b[0;32m    497\\\\u001b[0m \\\\u001b[43m        \\\\u001b[49m\\\\u001b[43mchunked\\\\u001b[49m\\\\u001b[38;5;241;43m=\\\\u001b[39;49m\\\\u001b[43mchunked\\\\u001b[49m\\\\u001b[43m,\\\\u001b[49m\\\\n\\\\u001b[0;32m    498\\\\u001b[0m \\\\u001b[43m    \\\\u001b[49m\\\\u001b[43m)\\\\u001b[49m\\\\n\\\\u001b[0;32m    500\\\\u001b[0m \\\\u001b[38;5;28;01mexcept\\\\u001b[39;00m (ProtocolError, \\\\u001b[38;5;167;01mOSError\\\\u001b[39;00m) \\\\u001b[38;5;28;01mas\\\\u001b[39;00m err:\\\\n\\\",\\n-      \\\"File \\\\u001b[1;32m~\\\\\\\\anaconda3\\\\\\\\Lib\\\\\\\\site-packages\\\\\\\\urllib3\\\\\\\\connectionpool.py:798\\\\u001b[0m, in \\\\u001b[0;36mHTTPConnectionPool.urlopen\\\\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\\\\u001b[0m\\\\n\\\\u001b[0;32m    796\\\\u001b[0m     e \\\\u001b[38;5;241m=\\\\u001b[39m ProtocolError(\\\\u001b[38;5;124m\\\\\\\"\\\\u001b[39m\\\\u001b[38;5;124mConnection aborted.\\\\u001b[39m\\\\u001b[38;5;124m\\\\\\\"\\\\u001b[39m, e)\\\\n\\\\u001b[1;32m--> 798\\\\u001b[0m retries \\\\u001b[38;5;241m=\\\\u001b[39m \\\\u001b[43mretries\\\\u001b[49m\\\\u001b[38;5;241;43m.\\\\u001b[39;49m\\\\u001b[43mincrement\\\\u001b[49m\\\\u001b[43m(\\\\u001b[49m\\\\n\\\\u001b[0;32m    799\\\\u001b[0m \\\\u001b[43m    \\\\u001b[49m\\\\u001b[43mmethod\\\\u001b[49m\\\\u001b[43m,\\\\u001b[49m\\\\u001b[43m \\\\u001b[49m\\\\u001b[43murl\\\\u001b[49m\\\\u001b[43m,\\\\u001b[49m\\\\u001b[43m \\\\u001b[49m\\\\u001b[43merror\\\\u001b[49m\\\\u001b[38;5;241;43m=\\\\u001b[39;49m\\\\u001b[43me\\\\u001b[49m\\\\u001b[43m,\\\\u001b[49m\\\\u001b[43m \\\\u001b[49m\\\\u001b[43m_pool\\\\u001b[49m\\\\u001b[38;5;241;43m=\\\\u001b[39;49m\\\\u001b[38;5;28;43mself\\\\u001b[39;49m\\\\u001b[43m,\\\\u001b[49m\\\\u001b[43m \\\\u001b[49m\\\\u001b[43m_stacktrace\\\\u001b[49m\\\\u001b[38;5;241;43m=\\\\u001b[39;49m\\\\u001b[43msys\\\\u001b[49m\\\\u001b[38;5;241;43m.\\\\u001b[39;49m\\\\u001b[43mexc_info\\\\u001b[49m\\\\u001b[43m(\\\\u001b[49m\\\\u001b[43m)\\\\u001b[49m\\\\u001b[43m[\\\\u001b[49m\\\\u001b[38;5;241;43m2\\\\u001b[39;49m\\\\u001b[43m]\\\\u001b[49m\\\\n\\\\u001b[0;32m    800\\\\u001b[0m \\\\u001b[43m\\\\u001b[49m\\\\u001b[43m)\\\\u001b[49m\\\\n\\\\u001b[0;32m    801\\\\u001b[0m retries\\\\u001b[38;5;241m.\\\\u001b[39msleep()\\\\n\\\",\\n-      \\\"File \\\\u001b[1;32m~\\\\\\\\anaconda3\\\\\\\\Lib\\\\\\\\site-packages\\\\\\\\urllib3\\\\\\\\util\\\\\\\\retry.py:592\\\\u001b[0m, in \\\\u001b[0;36mRetry.increment\\\\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\\\\u001b[0m\\\\n\\\\u001b[0;32m    591\\\\u001b[0m \\\\u001b[38;5;28;01mif\\\\u001b[39;00m new_retry\\\\u001b[38;5;241m.\\\\u001b[39mis_exhausted():\\\\n\\\\u001b[1;32m--> 592\\\\u001b[0m     \\\\u001b[38;5;28;01mraise\\\\u001b[39;00m MaxRetryError(_pool, url, error \\\\u001b[38;5;129;01mor\\\\u001b[39;00m ResponseError(cause))\\\\n\\\\u001b[0;32m    594\\\\u001b[0m log\\\\u001b[38;5;241m.\\\\u001b[39mdebug(\\\\u001b[38;5;124m\\\\\\\"\\\\u001b[39m\\\\u001b[38;5;124mIncremented Retry for (url=\\\\u001b[39m\\\\u001b[38;5;124m'\\\\u001b[39m\\\\u001b[38;5;132;01m%s\\\\u001b[39;00m\\\\u001b[38;5;124m'\\\\u001b[39m\\\\u001b[38;5;124m): \\\\u001b[39m\\\\u001b[38;5;132;01m%r\\\\u001b[39;00m\\\\u001b[38;5;124m\\\\\\\"\\\\u001b[39m, url, new_retry)\\\\n\\\",\\n-      \\\"\\\\u001b[1;31mMaxRetryError\\\\u001b[0m: HTTPConnectionPool(host='localhost', port=80): Max retries exceeded with url: /api/database/c3a42d17-42b7-43c9-a504-2363fb4c9c8d (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001EF2D576A10>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))\\\",\\n-      \\\"\\\\nDuring handling of the above exception, another exception occurred:\\\\n\\\",\\n-      \\\"\\\\u001b[1;31mConnectionError\\\\u001b[0m                           Traceback (most recent call last)\\\",\\n-      \\\"Cell \\\\u001b[1;32mIn[206], line 16\\\\u001b[0m\\\\n\\\\u001b[0;32m     11\\\\u001b[0m   \\\\u001b[38;5;66;03m# 4) log it as a single JSON artifact\\\\u001b[39;00m\\\\n\\\\u001b[0;32m     12\\\\u001b[0m \\\\u001b[38;5;66;03m# mlflow.log_dict(public_datasetRepository_metadata, \\\\\\\"public_datasetRepository_metadata.json\\\\\\\")\\\\u001b[39;00m\\\\n\\\\u001b[0;32m     13\\\\u001b[0m \\\\n\\\\u001b[0;32m     14\\\\u001b[0m \\\\u001b[38;5;66;03m#Datasbase info logging\\\\u001b[39;00m\\\\n\\\\u001b[0;32m     15\\\\u001b[0m db_id \\\\u001b[38;5;241m=\\\\u001b[39m \\\\u001b[38;5;124m\\\\\\\"\\\\u001b[39m\\\\u001b[38;5;124mc3a42d17-42b7-43c9-a504-2363fb4c9c8d\\\\u001b[39m\\\\u001b[38;5;124m\\\\\\\"\\\\u001b[39m\\\\n\\\\u001b[1;32m---> 16\\\\u001b[0m db_meta \\\\u001b[38;5;241m=\\\\u001b[39m \\\\u001b[43mfetch_db_metadata\\\\u001b[49m\\\\u001b[43m(\\\\u001b[49m\\\\u001b[43mdb_id\\\\u001b[49m\\\\u001b[43m)\\\\u001b[49m\\\\n\\\\u001b[0;32m     17\\\\u001b[0m log_db_metadata(db_meta)\\\\n\\\\u001b[0;32m     19\\\\u001b[0m \\\\u001b[38;5;66;03m#OAI metadata logging from api endpoint\\\\u001b[39;00m\\\\n\\\\u001b[0;32m     20\\\\u001b[0m \\\\u001b[38;5;66;03m# log as tags\\\\u001b[39;00m\\\\n\\\",\\n-      \\\"Cell \\\\u001b[1;32mIn[3], line 8\\\\u001b[0m, in \\\\u001b[0;36mfetch_db_metadata\\\\u001b[1;34m(db_id)\\\\u001b[0m\\\\n\\\\u001b[0;32m      6\\\\u001b[0m \\\\u001b[38;5;28;01mdef\\\\u001b[39;00m \\\\u001b[38;5;21mfetch_db_metadata\\\\u001b[39m(db_id: \\\\u001b[38;5;28mstr\\\\u001b[39m) \\\\u001b[38;5;241m-\\\\u001b[39m\\\\u001b[38;5;241m>\\\\u001b[39m \\\\u001b[38;5;28mdict\\\\u001b[39m:\\\\n\\\\u001b[0;32m      7\\\\u001b[0m     url \\\\u001b[38;5;241m=\\\\u001b[39m DB_API\\\\u001b[38;5;241m.\\\\u001b[39mformat(db_id\\\\u001b[38;5;241m=\\\\u001b[39mdb_id)\\\\n\\\\u001b[1;32m----> 8\\\\u001b[0m     resp \\\\u001b[38;5;241m=\\\\u001b[39m \\\\u001b[43mrequests\\\\u001b[49m\\\\u001b[38;5;241;43m.\\\\u001b[39;49m\\\\u001b[43mget\\\\u001b[49m\\\\u001b[43m(\\\\u001b[49m\\\\u001b[43murl\\\\u001b[49m\\\\u001b[43m)\\\\u001b[49m\\\\n\\\\u001b[0;32m      9\\\\u001b[0m     resp\\\\u001b[38;5;241m.\\\\u001b[39mraise_for_status()\\\\n\\\\u001b[0;32m     10\\\\u001b[0m     \\\\u001b[38;5;28;01mreturn\\\\u001b[39;00m resp\\\\u001b[38;5;241m.\\\\u001b[39mjson()\\\\n\\\",\\n-      \\\"File \\\\u001b[1;32m~\\\\\\\\anaconda3\\\\\\\\Lib\\\\\\\\site-packages\\\\\\\\requests\\\\\\\\api.py:73\\\\u001b[0m, in \\\\u001b[0;36mget\\\\u001b[1;34m(url, params, **kwargs)\\\\u001b[0m\\\\n\\\\u001b[0;32m     62\\\\u001b[0m \\\\u001b[38;5;28;01mdef\\\\u001b[39;00m \\\\u001b[38;5;21mget\\\\u001b[39m(url, params\\\\u001b[38;5;241m=\\\\u001b[39m\\\\u001b[38;5;28;01mNone\\\\u001b[39;00m, \\\\u001b[38;5;241m*\\\\u001b[39m\\\\u001b[38;5;241m*\\\\u001b[39mkwargs):\\\\n\\\\u001b[0;32m     63\\\\u001b[0m \\\\u001b[38;5;250m    \\\\u001b[39m\\\\u001b[38;5;124mr\\\\u001b[39m\\\\u001b[38;5;124;03m\\\\\\\"\\\\\\\"\\\\\\\"Sends a GET request.\\\\u001b[39;00m\\\\n\\\\u001b[0;32m     64\\\\u001b[0m \\\\n\\\\u001b[0;32m     65\\\\u001b[0m \\\\u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\\\\u001b[39;00m\\\\n\\\\u001b[1;32m   (...)\\\\u001b[0m\\\\n\\\\u001b[0;32m     70\\\\u001b[0m \\\\u001b[38;5;124;03m    :rtype: requests.Response\\\\u001b[39;00m\\\\n\\\\u001b[0;32m     71\\\\u001b[0m \\\\u001b[38;5;124;03m    \\\\\\\"\\\\\\\"\\\\\\\"\\\\u001b[39;00m\\\\n\\\\u001b[1;32m---> 73\\\\u001b[0m     \\\\u001b[38;5;28;01mreturn\\\\u001b[39;00m \\\\u001b[43mrequest\\\\u001b[49m\\\\u001b[43m(\\\\u001b[49m\\\\u001b[38;5;124;43m\\\\\\\"\\\\u001b[39;49m\\\\u001b[38;5;124;43mget\\\\u001b[39;49m\\\\u001b[38;5;124;43m\\\\\\\"\\\\u001b[39;49m\\\\u001b[43m,\\\\u001b[49m\\\\u001b[43m \\\\u001b[49m\\\\u001b[43murl\\\\u001b[49m\\\\u001b[43m,\\\\u001b[49m\\\\u001b[43m \\\\u001b[49m\\\\u001b[43mparams\\\\u001b[49m\\\\u001b[38;5;241;43m=\\\\u001b[39;49m\\\\u001b[43mparams\\\\u001b[49m\\\\u001b[43m,\\\\u001b[49m\\\\u001b[43m \\\\u001b[49m\\\\u001b[38;5;241;43m*\\\\u001b[39;49m\\\\u001b[38;5;241;43m*\\\\u001b[39;49m\\\\u001b[43mkwargs\\\\u001b[49m\\\\u001b[43m)\\\\u001b[49m\\\\n\\\",\\n-      \\\"File \\\\u001b[1;32m~\\\\\\\\anaconda3\\\\\\\\Lib\\\\\\\\site-packages\\\\\\\\requests\\\\\\\\api.py:59\\\\u001b[0m, in \\\\u001b[0;36mrequest\\\\u001b[1;34m(method, url, **kwargs)\\\\u001b[0m\\\\n\\\\u001b[0;32m     55\\\\u001b[0m \\\\u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\\\\u001b[39;00m\\\\n\\\\u001b[0;32m     56\\\\u001b[0m \\\\u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\\\\u001b[39;00m\\\\n\\\\u001b[0;32m     57\\\\u001b[0m \\\\u001b[38;5;66;03m# cases, and look like a memory leak in others.\\\\u001b[39;00m\\\\n\\\\u001b[0;32m     58\\\\u001b[0m \\\\u001b[38;5;28;01mwith\\\\u001b[39;00m sessions\\\\u001b[38;5;241m.\\\\u001b[39mSession() \\\\u001b[38;5;28;01mas\\\\u001b[39;00m session:\\\\n\\\\u001b[1;32m---> 59\\\\u001b[0m     \\\\u001b[38;5;28;01mreturn\\\\u001b[39;00m \\\\u001b[43msession\\\\u001b[49m\\\\u001b[38;5;241;43m.\\\\u001b[39;49m\\\\u001b[43mrequest\\\\u001b[49m\\\\u001b[43m(\\\\u001b[49m\\\\u001b[43mmethod\\\\u001b[49m\\\\u001b[38;5;241;43m=\\\\u001b[39;49m\\\\u001b[43mmethod\\\\u001b[49m\\\\u001b[43m,\\\\u001b[49m\\\\u001b[43m \\\\u001b[49m\\\\u001b[43murl\\\\u001b[49m\\\\u001b[38;5;241;43m=\\\\u001b[39;49m\\\\u001b[43murl\\\\u001b[49m\\\\u001b[43m,\\\\u001b[49m\\\\u001b[43m \\\\u001b[49m\\\\u001b[38;5;241;43m*\\\\u001b[39;49m\\\\u001b[38;5;241;43m*\\\\u001b[39;49m\\\\u001b[43mkwargs\\\\u001b[49m\\\\u001b[43m)\\\\u001b[49m\\\\n\\\",\\n-      \\\"File \\\\u001b[1;32m~\\\\\\\\anaconda3\\\\\\\\Lib\\\\\\\\site-packages\\\\\\\\requests\\\\\\\\sessions.py:589\\\\u001b[0m, in \\\\u001b[0;36mSession.request\\\\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\\\\u001b[0m\\\\n\\\\u001b[0;32m    584\\\\u001b[0m send_kwargs \\\\u001b[38;5;241m=\\\\u001b[39m {\\\\n\\\\u001b[0;32m    585\\\\u001b[0m     \\\\u001b[38;5;124m\\\\\\\"\\\\u001b[39m\\\\u001b[38;5;124mtimeout\\\\u001b[39m\\\\u001b[38;5;124m\\\\\\\"\\\\u001b[39m: timeout,\\\\n\\\\u001b[0;32m    586\\\\u001b[0m     \\\\u001b[38;5;124m\\\\\\\"\\\\u001b[39m\\\\u001b[38;5;124mallow_redirects\\\\u001b[39m\\\\u001b[38;5;124m\\\\\\\"\\\\u001b[39m: allow_redirects,\\\\n\\\\u001b[0;32m    587\\\\u001b[0m }\\\\n\\\\u001b[0;32m    588\\\\u001b[0m send_kwargs\\\\u001b[38;5;241m.\\\\u001b[39mupdate(settings)\\\\n\\\\u001b[1;32m--> 589\\\\u001b[0m resp \\\\u001b[38;5;241m=\\\\u001b[39m \\\\u001b[38;5;28;43mself\\\\u001b[39;49m\\\\u001b[38;5;241;43m.\\\\u001b[39;49m\\\\u001b[43msend\\\\u001b[49m\\\\u001b[43m(\\\\u001b[49m\\\\u001b[43mprep\\\\u001b[49m\\\\u001b[43m,\\\\u001b[49m\\\\u001b[43m \\\\u001b[49m\\\\u001b[38;5;241;43m*\\\\u001b[39;49m\\\\u001b[38;5;241;43m*\\\\u001b[39;49m\\\\u001b[43msend_kwargs\\\\u001b[49m\\\\u001b[43m)\\\\u001b[49m\\\\n\\\\u001b[0;32m    591\\\\u001b[0m \\\\u001b[38;5;28;01mreturn\\\\u001b[39;00m resp\\\\n\\\",\\n-      \\\"File \\\\u001b[1;32m~\\\\\\\\anaconda3\\\\\\\\Lib\\\\\\\\site-packages\\\\\\\\requests\\\\\\\\sessions.py:703\\\\u001b[0m, in \\\\u001b[0;36mSession.send\\\\u001b[1;34m(self, request, **kwargs)\\\\u001b[0m\\\\n\\\\u001b[0;32m    700\\\\u001b[0m start \\\\u001b[38;5;241m=\\\\u001b[39m preferred_clock()\\\\n\\\\u001b[0;32m    702\\\\u001b[0m \\\\u001b[38;5;66;03m# Send the request\\\\u001b[39;00m\\\\n\\\\u001b[1;32m--> 703\\\\u001b[0m r \\\\u001b[38;5;241m=\\\\u001b[39m \\\\u001b[43madapter\\\\u001b[49m\\\\u001b[38;5;241;43m.\\\\u001b[39;49m\\\\u001b[43msend\\\\u001b[49m\\\\u001b[43m(\\\\u001b[49m\\\\u001b[43mrequest\\\\u001b[49m\\\\u001b[43m,\\\\u001b[49m\\\\u001b[43m \\\\u001b[49m\\\\u001b[38;5;241;43m*\\\\u001b[39;49m\\\\u001b[38;5;241;43m*\\\\u001b[39;49m\\\\u001b[43mkwargs\\\\u001b[49m\\\\u001b[43m)\\\\u001b[49m\\\\n\\\\u001b[0;32m    705\\\\u001b[0m \\\\u001b[38;5;66;03m# Total elapsed time of the request (approximately)\\\\u001b[39;00m\\\\n\\\\u001b[0;32m    706\\\\u001b[0m elapsed \\\\u001b[38;5;241m=\\\\u001b[39m preferred_clock() \\\\u001b[38;5;241m-\\\\u001b[39m start\\\\n\\\",\\n-      \\\"File \\\\u001b[1;32m~\\\\\\\\anaconda3\\\\\\\\Lib\\\\\\\\site-packages\\\\\\\\requests\\\\\\\\adapters.py:519\\\\u001b[0m, in \\\\u001b[0;36mHTTPAdapter.send\\\\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\\\\u001b[0m\\\\n\\\\u001b[0;32m    515\\\\u001b[0m     \\\\u001b[38;5;28;01mif\\\\u001b[39;00m \\\\u001b[38;5;28misinstance\\\\u001b[39m(e\\\\u001b[38;5;241m.\\\\u001b[39mreason, _SSLError):\\\\n\\\\u001b[0;32m    516\\\\u001b[0m         \\\\u001b[38;5;66;03m# This branch is for urllib3 v1.22 and later.\\\\u001b[39;00m\\\\n\\\\u001b[0;32m    517\\\\u001b[0m         \\\\u001b[38;5;28;01mraise\\\\u001b[39;00m SSLError(e, request\\\\u001b[38;5;241m=\\\\u001b[39mrequest)\\\\n\\\\u001b[1;32m--> 519\\\\u001b[0m     \\\\u001b[38;5;28;01mraise\\\\u001b[39;00m \\\\u001b[38;5;167;01mConnectionError\\\\u001b[39;00m(e, request\\\\u001b[38;5;241m=\\\\u001b[39mrequest)\\\\n\\\\u001b[0;32m    521\\\\u001b[0m \\\\u001b[38;5;28;01mexcept\\\\u001b[39;00m ClosedPoolError \\\\u001b[38;5;28;01mas\\\\u001b[39;00m e:\\\\n\\\\u001b[0;32m    522\\\\u001b[0m     \\\\u001b[38;5;28;01mraise\\\\u001b[39;00m \\\\u001b[38;5;167;01mConnectionError\\\\u001b[39;00m(e, request\\\\u001b[38;5;241m=\\\\u001b[39mrequest)\\\\n\\\",\\n-      \\\"\\\\u001b[1;31mConnectionError\\\\u001b[0m: HTTPConnectionPool(host='localhost', port=80): Max retries exceeded with url: /api/database/c3a42d17-42b7-43c9-a504-2363fb4c9c8d (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001EF2D576A10>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))\\\"\\n-     ]\\n-    }\\n-   ],\\n-   \\\"source\\\": [\\n-    \\\"\\\\n\\\",\\n-    \\\"# ============================\\\\n\\\",\\n-    \\\"# \\ud83d\\ude80 Start MLflow Run CURRENT BACKUP\\\\n\\\",\\n-    \\\"# ============================\\\\n\\\",\\n-    \\\"with mlflow.start_run() as run:\\\\n\\\",\\n-    \\\"    ##########################\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    meta = fetch_and_log_dataset_metadata_nested(\\\\n\\\",\\n-    \\\"            \\\\\\\"https://doi.org/10.5281/zenodo.1404173\\\\\\\",\\\\n\\\",\\n-    \\\"           \\\\n\\\",\\n-    \\\"        )\\\\n\\\",\\n-    \\\"      # 4) log it as a single JSON artifact\\\\n\\\",\\n-    \\\"    # mlflow.log_dict(public_datasetRepository_metadata, \\\\\\\"public_datasetRepository_metadata.json\\\\\\\")\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    #Datasbase info logging\\\\n\\\",\\n-    \\\"    db_id = \\\\\\\"c3a42d17-42b7-43c9-a504-2363fb4c9c8d\\\\\\\"\\\\n\\\",\\n-    \\\"    db_meta = fetch_db_metadata(db_id)\\\\n\\\",\\n-    \\\"    log_db_metadata(db_meta)\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    #OAI metadata logging from api endpoint\\\\n\\\",\\n-    \\\"    # log as tags\\\\n\\\",\\n-    \\\"    mlflow.set_tag(\\\\\\\"dbrepo.repository_name\\\\\\\", repo_name)\\\\n\\\",\\n-    \\\"    mlflow.set_tag(\\\\\\\"dbrepo.base_url\\\\\\\",       base_url)\\\\n\\\",\\n-    \\\"    mlflow.set_tag(\\\\\\\"dbrepo.protocol_version\\\\\\\", protocol)\\\\n\\\",\\n-    \\\"    mlflow.set_tag(\\\\\\\"dbrepo.admin_email\\\\\\\",     admin_email)\\\\n\\\",\\n-    \\\"    mlflow.set_tag(\\\\\\\"dbrepo.granularity\\\\\\\",     gran)\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    #From history API logging\\\\n\\\",\\n-    \\\"    # provenance tags\\\\n\\\",\\n-    \\\"    mlflow.set_tag(\\\\\\\"dbrepo.table_last_modified\\\\\\\", ts_last)\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    # row-count metrics\\\\n\\\",\\n-    \\\"    mlflow.log_metric(\\\\\\\"dbrepo.row_count_start\\\\\\\", count_start)\\\\n\\\",\\n-    \\\"    mlflow.log_metric(\\\\\\\"dbrepo.row_count_end\\\\\\\",   count_end)\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    # change-event metrics\\\\n\\\",\\n-    \\\"    mlflow.log_metric(\\\\\\\"dbrepo.num_inserts\\\\\\\", n_insert)\\\\n\\\",\\n-    \\\"    mlflow.log_metric(\\\\\\\"dbrepo.num_deletes\\\\\\\", n_delete)\\\\n\\\",\\n-    \\\"    \\\\n\\\",\\n-    \\\"    # 2) Capture raw metadata\\\\n\\\",\\n-    \\\"    mlflow.set_tag(\\\\\\\"data_source\\\\\\\", API_URL)\\\\n\\\",\\n-    \\\"    mlflow.log_param(\\\\\\\"retrieval_time\\\\\\\", datetime.utcnow().isoformat())\\\\n\\\",\\n-    \\\"    mlflow.log_param(\\\\\\\"n_records\\\\\\\", len(df))\\\\n\\\",\\n-    \\\"    mlflow.log_param(\\\\\\\"columns_raw\\\\\\\", df.columns.tolist())\\\\n\\\",\\n-    \\\"    mlflow.log_param(\\\\\\\"dropped_columns\\\\\\\", id_cols)\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    # 4) Post\\u2010processing metadata\\\\n\\\",\\n-    \\\"    mlflow.log_param(\\\\\\\"n_features_final\\\\\\\", X.shape[1])\\\\n\\\",\\n-    \\\"    mlflow.log_param(\\\\\\\"feature_names\\\\\\\", X.columns.tolist())\\\\n\\\",\\n-    \\\"    mlflow.set_tag(\\\\\\\"target_name\\\\\\\", y)\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    #Lable encoding\\\\n\\\",\\n-    \\\"    label_map = { int(idx): cls for idx, cls in enumerate(le.classes_) }\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    with open(\\\\\\\"label_mapping.json\\\\\\\", \\\\\\\"w\\\\\\\") as fp:\\\\n\\\",\\n-    \\\"        json.dump(label_map, fp, indent=2)\\\\n\\\",\\n-    \\\"    mlflow.log_artifact(\\\\\\\"label_mapping.json\\\\\\\")\\\\n\\\",\\n-    \\\"   \\\\n\\\",\\n-    \\\"    ts = datetime.now().strftime(\\\\\\\"%Y%m%d_%H%M%S\\\\\\\")\\\\n\\\",\\n-    \\\"    model_name = f\\\\\\\"RandomForest_Iris_v{ts}\\\\\\\"\\\\n\\\",\\n-    \\\"    mlflow.set_tag(\\\\\\\"model_name\\\\\\\",model_name)\\\\n\\\",\\n-    \\\"    \\\\n\\\",\\n-    \\\"    train_start_ts = datetime.now().isoformat()\\\\n\\\",\\n-    \\\"    mlflow.set_tag(\\\\\\\"training_start_time\\\\\\\", train_start_ts)\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    test_size    = 0.2\\\\n\\\",\\n-    \\\"    random_state = 42\\\\n\\\",\\n-    \\\"    # \\ud83d\\udcc8 Model Training\\\\n\\\",\\n-    \\\"    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\\\\n\\\",\\n-    \\\"    \\\\n\\\",\\n-    \\\"    # \\u2500\\u2500 2) Log dataset split params \\u2500\\u2500\\\\n\\\",\\n-    \\\"    mlflow.log_param(\\\\\\\"test_size\\\\\\\", test_size)\\\\n\\\",\\n-    \\\"    mlflow.log_param(\\\\\\\"random_state\\\\\\\", random_state)\\\\n\\\",\\n-    \\\"    mlflow.log_param(\\\\\\\"n_train_samples\\\\\\\", X_train.shape[0])\\\\n\\\",\\n-    \\\"    mlflow.log_param(\\\\\\\"n_test_samples\\\\\\\",  X_test.shape[0])\\\\n\\\",\\n-    \\\"    mlflow.log_param(\\\\\\\"n_features\\\\\\\",      X_train.shape[1])\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"     # 1) Define a more complex hyperparameter dict\\\\n\\\",\\n-    \\\"    hyperparams = {\\\\n\\\",\\n-    \\\"        \\\\\\\"n_estimators\\\\\\\":       200,\\\\n\\\",\\n-    \\\"        \\\\\\\"criterion\\\\\\\":          \\\\\\\"entropy\\\\\\\",\\\\n\\\",\\n-    \\\"        \\\\\\\"max_depth\\\\\\\":          12,\\\\n\\\",\\n-    \\\"        \\\\\\\"min_samples_split\\\\\\\":  5,\\\\n\\\",\\n-    \\\"        \\\\\\\"min_samples_leaf\\\\\\\":   2,\\\\n\\\",\\n-    \\\"        \\\\\\\"max_features\\\\\\\":       \\\\\\\"sqrt\\\\\\\",\\\\n\\\",\\n-    \\\"        \\\\\\\"bootstrap\\\\\\\":          True,\\\\n\\\",\\n-    \\\"        \\\\\\\"oob_score\\\\\\\":          False,\\\\n\\\",\\n-    \\\"        \\\\\\\"class_weight\\\\\\\":       None,\\\\n\\\",\\n-    \\\"        \\\\\\\"random_state\\\\\\\":       42,\\\\n\\\",\\n-    \\\"        \\\\\\\"verbose\\\\\\\":            1,\\\\n\\\",\\n-    \\\"        \\\\\\\"n_jobs\\\\\\\":             -1\\\\n\\\",\\n-    \\\"    }\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    # 2) Log them ALL at once\\\\n\\\",\\n-    \\\"    mlflow.log_params(hyperparams)\\\\n\\\",\\n-    \\\"    model = RandomForestClassifier(**hyperparams)\\\\n\\\",\\n-    \\\"    model.fit(X_train, y_train)\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    train_end_ts = datetime.now().isoformat()\\\\n\\\",\\n-    \\\"    mlflow.set_tag(\\\\\\\"training_end_time\\\\\\\", train_end_ts)\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"     # \\u2500\\u2500 6) Predict & log metrics \\u2500\\u2500\\\\n\\\",\\n-    \\\"    y_pred = model.predict(X_test)\\\\n\\\",\\n-    \\\"    y_proba = model.predict_proba(X_test)\\\\n\\\",\\n-    \\\"    acc = accuracy_score(y_test, y_pred)\\\\n\\\",\\n-    \\\"    auc = roc_auc_score(y_test, y_proba, multi_class=\\\\\\\"ovr\\\\\\\")\\\\n\\\",\\n-    \\\"    prec = precision_score(y_test, y_pred, average=\\\\\\\"macro\\\\\\\")\\\\n\\\",\\n-    \\\"    rec  = recall_score(y_test,    y_pred, average=\\\\\\\"macro\\\\\\\")\\\\n\\\",\\n-    \\\"    f1   = f1_score(y_test,      y_pred, average=\\\\\\\"macro\\\\\\\")\\\\n\\\",\\n-    \\\"    \\\\n\\\",\\n-    \\\"    mlflow.log_metric(\\\\\\\"precision_macro\\\\\\\", prec)\\\\n\\\",\\n-    \\\"    mlflow.log_metric(\\\\\\\"recall_macro\\\\\\\",    rec)\\\\n\\\",\\n-    \\\"    mlflow.log_metric(\\\\\\\"f1_macro\\\\\\\",        f1)\\\\n\\\",\\n-    \\\"    mlflow.log_metric(\\\\\\\"accuracy\\\\\\\", acc)\\\\n\\\",\\n-    \\\"    mlflow.log_metric(\\\\\\\"roc_auc\\\\\\\",   auc)\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    # \\u2705 Log Environment Automatically\\\\n\\\",\\n-    \\\"    mlflow.log_params({\\\\n\\\",\\n-    \\\"        \\\\\\\"python_version\\\\\\\": platform.python_version(),\\\\n\\\",\\n-    \\\"        \\\\\\\"os_platform\\\\\\\": f\\\\\\\"{platform.system()} {platform.release()}\\\\\\\",\\\\n\\\",\\n-    \\\"        \\\\\\\"sklearn_version\\\\\\\": sklearn.__version__,\\\\n\\\",\\n-    \\\"        \\\\\\\"pandas_version\\\\\\\": pd.__version__,\\\\n\\\",\\n-    \\\"        \\\\\\\"numpy_version\\\\\\\": np.__version__,\\\\n\\\",\\n-    \\\"        \\\\\\\"matplotlib_version\\\\\\\": matplotlib.__version__,\\\\n\\\",\\n-    \\\"        \\\\\\\"seaborn_version\\\\\\\": sns.__version__,\\\\n\\\",\\n-    \\\"        \\\\\\\"shap_version\\\\\\\": shap.__version__,\\\\n\\\",\\n-    \\\"    })\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    # \\u2705 Git and Notebook Metadata\\\\n\\\",\\n-    \\\"    mlflow.set_tag(\\\\\\\"notebook_name\\\\\\\", \\\\\\\"RQ1.ipynb\\\\\\\")\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    # \\u2705 Dataset Metadata Tags\\\\n\\\",\\n-    \\\"    mlflow.set_tag(\\\\\\\"dataset_name\\\\\\\", \\\\\\\"Iris\\\\\\\") #TODO\\\\n\\\",\\n-    \\\"    mlflow.set_tag(\\\\\\\"dataset_version\\\\\\\", \\\\\\\"1.0.0\\\\\\\") #TODO\\\\n\\\",\\n-    \\\"    mlflow.set_tag(\\\\\\\"dataset_id\\\\\\\", \\\\\\\"iris_local\\\\\\\") #TODO\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    # \\u2500\\u2500\\u2500 2) Create a folder for this run\\u2019s plots \\u2500\\u2500\\u2500\\\\n\\\",\\n-    \\\"    plot_dir = os.path.join(\\\\\\\"plots\\\\\\\", model_name)\\\\n\\\",\\n-    \\\"    os.makedirs(plot_dir, exist_ok=True)\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    # 1) Feature Importance Bar Chart\\\\n\\\",\\n-    \\\"    importances = model.feature_importances_\\\\n\\\",\\n-    \\\"    # if X_train is a DataFrame, grab column names; otherwise auto-name them f0,f1,...\\\\n\\\",\\n-    \\\"    try:\\\\n\\\",\\n-    \\\"        feature_names = X_train.columns\\\\n\\\",\\n-    \\\"    except AttributeError:\\\\n\\\",\\n-    \\\"        feature_names = [f\\\\\\\"f{i}\\\\\\\" for i in range(X_train.shape[1])]\\\\n\\\",\\n-    \\\"    fi_path = os.path.join(plot_dir, \\\\\\\"feature_importances.png\\\\\\\")\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    plt.figure(figsize=(8, 6))\\\\n\\\",\\n-    \\\"    sns.barplot(x=importances, y=feature_names)\\\\n\\\",\\n-    \\\"    plt.title(\\\\\\\"Feature Importances\\\\\\\")\\\\n\\\",\\n-    \\\"    plt.xlabel(\\\\\\\"Importance\\\\\\\")\\\\n\\\",\\n-    \\\"    plt.ylabel(\\\\\\\"Feature\\\\\\\")\\\\n\\\",\\n-    \\\"    plt.tight_layout()\\\\n\\\",\\n-    \\\"    plt.savefig(fi_path)\\\\n\\\",\\n-    \\\"    mlflow.log_artifact(fi_path)\\\\n\\\",\\n-    \\\"    plt.close()\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# 2) Multi-class ROC Curves\\\\n\\\",\\n-    \\\"# Binarize labels for one-vs-rest\\\\n\\\",\\n-    \\\"    classes = np.unique(y_test)\\\\n\\\",\\n-    \\\"    y_test_bin = label_binarize(y_test, classes=classes)\\\\n\\\",\\n-    \\\"    \\\\n\\\",\\n-    \\\"    for idx, cls in enumerate(classes):\\\\n\\\",\\n-    \\\"        disp = RocCurveDisplay.from_predictions(\\\\n\\\",\\n-    \\\"            y_test_bin[:, idx], \\\\n\\\",\\n-    \\\"            y_proba[:, idx],\\\\n\\\",\\n-    \\\"            name=f\\\\\\\"ROC for class {cls}\\\\\\\"\\\\n\\\",\\n-    \\\"        )\\\\n\\\",\\n-    \\\"        roc_path = os.path.join(plot_dir, f\\\\\\\"roc_curve_cls_{cls}.png\\\\\\\")\\\\n\\\",\\n-    \\\"        disp.figure_.savefig(roc_path)\\\\n\\\",\\n-    \\\"        mlflow.log_artifact(roc_path)\\\\n\\\",\\n-    \\\"        plt.close(disp.figure_)\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    # 3) Multi-class Precision-Recall Curves\\\\n\\\",\\n-    \\\"    for idx, cls in enumerate(classes):\\\\n\\\",\\n-    \\\"        disp = PrecisionRecallDisplay.from_predictions(\\\\n\\\",\\n-    \\\"            y_test_bin[:, idx], \\\\n\\\",\\n-    \\\"            y_proba[:, idx],\\\\n\\\",\\n-    \\\"            name=f\\\\\\\"PR curve for class {cls}\\\\\\\"\\\\n\\\",\\n-    \\\"        )\\\\n\\\",\\n-    \\\"        pr_path = os.path.join(plot_dir, f\\\\\\\"pr_curve_cls_{cls}.png\\\\\\\")\\\\n\\\",\\n-    \\\"        disp.figure_.savefig(pr_path)\\\\n\\\",\\n-    \\\"        mlflow.log_artifact(pr_path)\\\\n\\\",\\n-    \\\"        plt.close(disp.figure_)\\\\n\\\",\\n-    \\\"        \\\\n\\\",\\n-    \\\"    # \\u2705 Confusion Matrix Plot\\\\n\\\",\\n-    \\\"    cm_path = os.path.join(plot_dir, \\\\\\\"confusion_matrix.png\\\\\\\")\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    cm = confusion_matrix(y_test, y_pred)\\\\n\\\",\\n-    \\\"    plt.figure(figsize=(6, 6))\\\\n\\\",\\n-    \\\"    sns.heatmap(cm, annot=True, fmt=\\\\\\\"d\\\\\\\", cmap=\\\\\\\"Blues\\\\\\\")\\\\n\\\",\\n-    \\\"    plt.title(\\\\\\\"Confusion Matrix\\\\\\\")\\\\n\\\",\\n-    \\\"    plt.xlabel(\\\\\\\"Predicted\\\\\\\")\\\\n\\\",\\n-    \\\"    plt.ylabel(\\\\\\\"Actual\\\\\\\")\\\\n\\\",\\n-    \\\"    plt.savefig(cm_path)\\\\n\\\",\\n-    \\\"    mlflow.log_artifact(cm_path)\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    # \\u2705 SHAP Summary\\\\n\\\",\\n-    \\\"    shap_path = os.path.join(plot_dir, \\\\\\\"shap_summary.png\\\\\\\")\\\\n\\\",\\n-    \\\"    explainer = shap.TreeExplainer(model)\\\\n\\\",\\n-    \\\"    shap_values = explainer.shap_values(X_test)\\\\n\\\",\\n-    \\\"    shap.summary_plot(shap_values, X_test, show=False)\\\\n\\\",\\n-    \\\"    plt.savefig(shap_path)\\\\n\\\",\\n-    \\\"    mlflow.log_artifact(shap_path)\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    \\\\n\\\",\\n-    \\\"    # \\u2500\\u2500\\u2500 1) Build a .pkl filename (you can include your model_name for clarity)\\\\n\\\",\\n-    \\\"    pkl_path = f\\\\\\\"{model_name}.pkl\\\\\\\"\\\\n\\\",\\n-    \\\"    \\\\n\\\",\\n-    \\\"    # \\u2500\\u2500\\u2500 2) Serialize your trained model to disk\\\\n\\\",\\n-    \\\"    with open(pkl_path, \\\\\\\"wb\\\\\\\") as f:\\\\n\\\",\\n-    \\\"        pickle.dump(model, f)\\\\n\\\",\\n-    \\\"    \\\\n\\\",\\n-    \\\"    # \\u2500\\u2500\\u2500 3) Log that pickle file as an MLflow artifact\\\\n\\\",\\n-    \\\"    #     It will appear under Artifacts \\u2192 models/RandomForest_Iris_vYYYYMMDD_HHMMSS.pkl\\\\n\\\",\\n-    \\\"    mlflow.log_artifact(pkl_path, artifact_path=model_name)\\\\n\\\",\\n-    \\\"        \\\\n\\\",\\n-    \\\"    def get_latest_commit_hash(repo_path=\\\\\\\".\\\\\\\"):\\\\n\\\",\\n-    \\\"        # returns the full SHA of HEAD\\\\n\\\",\\n-    \\\"        res = subprocess.run(\\\\n\\\",\\n-    \\\"            [\\\\\\\"git\\\\\\\", \\\\\\\"-C\\\\\\\", repo_path, \\\\\\\"rev-parse\\\\\\\", \\\\\\\"HEAD\\\\\\\"],\\\\n\\\",\\n-    \\\"            capture_output=True, text=True, check=True)\\\\n\\\",\\n-    \\\"        \\\\n\\\",\\n-    \\\"        return res.stdout.strip()\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    def get_remote_url(repo_path=\\\\\\\".\\\\\\\", remote=\\\\\\\"origin\\\\\\\"):\\\\n\\\",\\n-    \\\"        # returns something like git@github.com:user/repo.git or https://...\\\\n\\\",\\n-    \\\"        res = subprocess.run(\\\\n\\\",\\n-    \\\"            [\\\\\\\"git\\\\\\\", \\\\\\\"-C\\\\\\\", repo_path, \\\\\\\"config\\\\\\\", \\\\\\\"--get\\\\\\\", f\\\\\\\"remote.{remote}.url\\\\\\\"],\\\\n\\\",\\n-    \\\"            capture_output=True, text=True, check=True\\\\n\\\",\\n-    \\\"        )\\\\n\\\",\\n-    \\\"        return res.stdout.strip()\\\\n\\\",\\n-    \\\"    \\\\n\\\",\\n-    \\\"    def make_commit_link(remote_url, commit_hash):\\\\n\\\",\\n-    \\\"        # handle GitHub/GitLab convention; strip \\u201c.git\\u201d if present\\\\n\\\",\\n-    \\\"        base = remote_url.rstrip(\\\\\\\".git\\\\\\\")\\\\n\\\",\\n-    \\\"        # if SSH form (git@github.com:owner/repo), convert to https\\\\n\\\",\\n-    \\\"        if base.startswith(\\\\\\\"git@\\\\\\\"):\\\\n\\\",\\n-    \\\"            base = base.replace(\\\\\\\":\\\\\\\", \\\\\\\"/\\\\\\\").replace(\\\\\\\"git@\\\\\\\", \\\\\\\"https://\\\\\\\")\\\\n\\\",\\n-    \\\"        return f\\\\\\\"{base}/commit/{commit_hash}\\\\\\\"\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    \\\\n\\\",\\n-    \\\"    def simple_commit_and_push_and_log(repo_path=\\\\\\\".\\\\\\\", message=\\\\\\\"Auto commit\\\\\\\", remote=\\\\\\\"origin\\\\\\\", branch=\\\\\\\"main\\\\\\\"):\\\\n\\\",\\n-    \\\"    # 1) Check for changes\\\\n\\\",\\n-    \\\"        status = subprocess.run(\\\\n\\\",\\n-    \\\"            [\\\\\\\"git\\\\\\\", \\\\\\\"-C\\\\\\\", repo_path, \\\\\\\"status\\\\\\\", \\\\\\\"--porcelain\\\\\\\"],\\\\n\\\",\\n-    \\\"            capture_output=True, text=True\\\\n\\\",\\n-    \\\"        )\\\\n\\\",\\n-    \\\"        if not status.stdout.strip():\\\\n\\\",\\n-    \\\"            print(\\\\\\\"\\ud83d\\udfe1 No changes to commit.\\\\\\\")\\\\n\\\",\\n-    \\\"            return None, None\\\\n\\\",\\n-    \\\"    \\\\n\\\",\\n-    \\\"        # 2) Stage everything\\\\n\\\",\\n-    \\\"        add = subprocess.run(\\\\n\\\",\\n-    \\\"            [\\\\\\\"git\\\\\\\", \\\\\\\"-C\\\\\\\", repo_path, \\\\\\\"add\\\\\\\", \\\\\\\"--all\\\\\\\"],\\\\n\\\",\\n-    \\\"            capture_output=True, text=True\\\\n\\\",\\n-    \\\"        )\\\\n\\\",\\n-    \\\"        if add.returncode:\\\\n\\\",\\n-    \\\"            print(\\\\\\\"\\u274c git add failed:\\\\\\\\n\\\\\\\", add.stderr)\\\\n\\\",\\n-    \\\"            return None, None\\\\n\\\",\\n-    \\\"    \\\\n\\\",\\n-    \\\"        # 3) Commit\\\\n\\\",\\n-    \\\"        commit = subprocess.run(\\\\n\\\",\\n-    \\\"            [\\\\\\\"git\\\\\\\", \\\\\\\"-C\\\\\\\", repo_path, \\\\\\\"commit\\\\\\\", \\\\\\\"-m\\\\\\\", message],\\\\n\\\",\\n-    \\\"            capture_output=True, text=True\\\\n\\\",\\n-    \\\"        )\\\\n\\\",\\n-    \\\"        if commit.returncode:\\\\n\\\",\\n-    \\\"            print(\\\\\\\"\\u274c git commit failed:\\\\\\\\n\\\\\\\", commit.stderr)\\\\n\\\",\\n-    \\\"            return None, None\\\\n\\\",\\n-    \\\"        print(\\\\\\\"\\u2705 Commit successful.\\\\\\\")\\\\n\\\",\\n-    \\\"    \\\\n\\\",\\n-    \\\"        # 4) Push\\\\n\\\",\\n-    \\\"        push = subprocess.run(\\\\n\\\",\\n-    \\\"            [\\\\\\\"git\\\\\\\", \\\\\\\"-C\\\\\\\", repo_path, \\\\\\\"push\\\\\\\", \\\\\\\"-u\\\\\\\", remote, branch],\\\\n\\\",\\n-    \\\"            capture_output=True, text=True\\\\n\\\",\\n-    \\\"        )\\\\n\\\",\\n-    \\\"        if push.returncode:\\\\n\\\",\\n-    \\\"            print(\\\\\\\"\\u274c git push failed:\\\\\\\\n\\\\\\\", push.stderr)\\\\n\\\",\\n-    \\\"        else:\\\\n\\\",\\n-    \\\"            print(\\\\\\\"\\ud83d\\ude80 Push successful.\\\\\\\")\\\\n\\\",\\n-    \\\"    \\\\n\\\",\\n-    \\\"        # 5) Retrieve hash & remote URL\\\\n\\\",\\n-    \\\"        sha = get_latest_commit_hash(repo_path)\\\\n\\\",\\n-    \\\"        url = get_remote_url(repo_path, remote)\\\\n\\\",\\n-    \\\"        link = make_commit_link(url, sha)\\\\n\\\",\\n-    \\\"    \\\\n\\\",\\n-    \\\"        return sha, link\\\\n\\\",\\n-    \\\"    \\\\n\\\",\\n-    \\\"      \\\\n\\\",\\n-    \\\"    sha, link = simple_commit_and_push_and_log(\\\\n\\\",\\n-    \\\"        repo_path=\\\\\\\".\\\\\\\",\\\\n\\\",\\n-    \\\"        message=\\\\\\\"Auto commit after successful training\\\\\\\"\\\\n\\\",\\n-    \\\"    )\\\\n\\\",\\n-    \\\"    if sha and link:\\\\n\\\",\\n-    \\\"        diff_text = subprocess.check_output(\\\\n\\\",\\n-    \\\"            [\\\\\\\"git\\\\\\\", \\\\\\\"-C\\\\\\\", \\\\\\\".\\\\\\\", \\\\\\\"diff\\\\\\\", previous_commit_hash, sha],\\\\n\\\",\\n-    \\\"            encoding=\\\\\\\"utf-8\\\\\\\",\\\\n\\\",\\n-    \\\"            errors=\\\\\\\"ignore\\\\\\\"    # or \\\\\\\"replace\\\\\\\"\\\\n\\\",\\n-    \\\"        )\\\\n\\\",\\n-    \\\"                \\\\n\\\",\\n-    \\\"        # 1) Get your repo\\u2019s remote URL and normalize to HTTPS\\\\n\\\",\\n-    \\\"        remote_url = subprocess.check_output(\\\\n\\\",\\n-    \\\"            [\\\\\\\"git\\\\\\\", \\\\\\\"config\\\\\\\", \\\\\\\"--get\\\\\\\", \\\\\\\"remote.origin.url\\\\\\\"],\\\\n\\\",\\n-    \\\"            text=True\\\\n\\\",\\n-    \\\"        ).strip().rstrip(\\\\\\\".git\\\\\\\")\\\\n\\\",\\n-    \\\"        if remote_url.startswith(\\\\\\\"git@\\\\\\\"):\\\\n\\\",\\n-    \\\"            # git@github.com:owner/repo.git \\u2192 https://github.com/owner/repo\\\\n\\\",\\n-    \\\"            remote_url = remote_url.replace(\\\\\\\":\\\\\\\", \\\\\\\"/\\\\\\\").replace(\\\\\\\"git@\\\\\\\", \\\\\\\"https://\\\\\\\")\\\\n\\\",\\n-    \\\"        \\\\n\\\",\\n-    \\\"        # 2) Build commit URLs\\\\n\\\",\\n-    \\\"        previous_commit_url  = f\\\\\\\"{remote_url}/commit/{previous_commit_hash}\\\\\\\"\\\\n\\\",\\n-    \\\"        current_commit_url = f\\\\\\\"{remote_url}/commit/{sha}\\\\\\\"\\\\n\\\",\\n-    \\\"        diff_data = {\\\\n\\\",\\n-    \\\"            \\\\\\\"previous_commit\\\\\\\":  previous_commit_hash,\\\\n\\\",\\n-    \\\"            \\\\\\\"previous_commit_url\\\\\\\":previous_commit_url,\\\\n\\\",\\n-    \\\"            \\\\\\\"current_commit_url\\\\\\\":current_commit_url,\\\\n\\\",\\n-    \\\"            \\\\\\\"current_commit\\\\\\\": sha,\\\\n\\\",\\n-    \\\"            \\\\\\\"diff\\\\\\\": diff_text\\\\n\\\",\\n-    \\\"        }\\\\n\\\",\\n-    \\\"        mlflow.log_dict(\\\\n\\\",\\n-    \\\"            diff_data,\\\\n\\\",\\n-    \\\"            artifact_file=\\\\\\\"commit_diff.json\\\\\\\"\\\\n\\\",\\n-    \\\"        )\\\\n\\\",\\n-    \\\"        mlflow.set_tag(\\\\\\\"git_previous_commit_hash\\\\\\\", previous_commit_hash)\\\\n\\\",\\n-    \\\"        mlflow.set_tag(\\\\\\\"git_current_commit_hash\\\\\\\", sha)\\\\n\\\",\\n-    \\\"        mlflow.set_tag(\\\\\\\"git__current_commit_url\\\\\\\", link) \\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    client   = MlflowClient()\\\\n\\\",\\n-    \\\"    run_id    = run.info.run_id\\\\n\\\",\\n-    \\\"    run_info  = client.get_run(run_id).info\\\\n\\\",\\n-    \\\"    run_data  = client.get_run(run_id).data\\\\n\\\",\\n-    \\\"    \\\\n\\\",\\n-    \\\"    # 1) params, metrics, tags\\\\n\\\",\\n-    \\\"    params  = dict(run_data.params)\\\\n\\\",\\n-    \\\"    metrics = dict(run_data.metrics)\\\\n\\\",\\n-    \\\"    tags    = dict(run_data.tags)\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    # (4) List artifacts under a specific subfolder\\\\n\\\",\\n-    \\\"    # artifact_paths = [af.path for af in client.list_artifacts(run_id)]\\\\n\\\",\\n-    \\\"    run_meta     = client.get_run(run_id).info\\\\n\\\",\\n-    \\\"    artifact_uri = run_meta.artifact_uri  # base URI for all artifacts\\\\n\\\",\\n-    \\\"    \\\\n\\\",\\n-    \\\"    artifact_meta = []\\\\n\\\",\\n-    \\\"    \\\\n\\\",\\n-    \\\"    def _gather(path=\\\\\\\"\\\\\\\"):\\\\n\\\",\\n-    \\\"        for af in client.list_artifacts(run_id, path):\\\\n\\\",\\n-    \\\"            # If it\\u2019s a directory, recurse\\\\n\\\",\\n-    \\\"            if af.is_dir:\\\\n\\\",\\n-    \\\"                _gather(af.path)\\\\n\\\",\\n-    \\\"                continue\\\\n\\\",\\n-    \\\"    \\\\n\\\",\\n-    \\\"            rel_path = af.path\\\\n\\\",\\n-    \\\"            uri      = f\\\\\\\"{artifact_uri}/{rel_path}\\\\\\\"\\\\n\\\",\\n-    \\\"            lower    = rel_path.lower()\\\\n\\\",\\n-    \\\"    \\\\n\\\",\\n-    \\\"            # 1) Text files \\u2192 download & embed contents\\\\n\\\",\\n-    \\\"            if lower.endswith((\\\\\\\".json\\\\\\\", \\\\\\\".txt\\\\\\\", \\\\\\\".patch\\\\\\\")):\\\\n\\\",\\n-    \\\"                local = client.download_artifacts(run_id, rel_path)\\\\n\\\",\\n-    \\\"                with open(local, \\\\\\\"r\\\\\\\", encoding=\\\\\\\"utf-8\\\\\\\") as f:\\\\n\\\",\\n-    \\\"                    content = f.read()\\\\n\\\",\\n-    \\\"                artifact_meta.append({\\\\n\\\",\\n-    \\\"                    \\\\\\\"path\\\\\\\":    rel_path,\\\\n\\\",\\n-    \\\"                    \\\\\\\"type\\\\\\\":    \\\\\\\"text\\\\\\\",\\\\n\\\",\\n-    \\\"                    \\\\\\\"content\\\\\\\": content\\\\n\\\",\\n-    \\\"                })\\\\n\\\",\\n-    \\\"    \\\\n\\\",\\n-    \\\"            # 2) Images \\u2192 surface a clickable URI\\\\n\\\",\\n-    \\\"            elif lower.endswith((\\\\\\\".png\\\\\\\", \\\\\\\".jpg\\\\\\\", \\\\\\\".jpeg\\\\\\\", \\\\\\\".svg\\\\\\\")):\\\\n\\\",\\n-    \\\"                artifact_meta.append({\\\\n\\\",\\n-    \\\"                    \\\\\\\"path\\\\\\\": rel_path,\\\\n\\\",\\n-    \\\"                    \\\\\\\"type\\\\\\\": \\\\\\\"image\\\\\\\",\\\\n\\\",\\n-    \\\"                    \\\\\\\"uri\\\\\\\":  uri\\\\n\\\",\\n-    \\\"                })\\\\n\\\",\\n-    \\\"    \\\\n\\\",\\n-    \\\"            # 3) Everything else \\u2192 just link\\\\n\\\",\\n-    \\\"            else:\\\\n\\\",\\n-    \\\"                artifact_meta.append({\\\\n\\\",\\n-    \\\"                    \\\\\\\"path\\\\\\\": rel_path,\\\\n\\\",\\n-    \\\"                    \\\\\\\"type\\\\\\\": \\\\\\\"other\\\\\\\",\\\\n\\\",\\n-    \\\"                    \\\\\\\"uri\\\\\\\":  uri\\\\n\\\",\\n-    \\\"                })\\\\n\\\",\\n-    \\\"    \\\\n\\\",\\n-    \\\"    # Run the gather\\\\n\\\",\\n-    \\\"    _gather()\\\\n\\\",\\n-    \\\"     \\\\n\\\",\\n-    \\\"    summary = {\\\\n\\\",\\n-    \\\"        \\\\\\\"run_id\\\\\\\":         run_id,\\\\n\\\",\\n-    \\\"        \\\\\\\"run_name\\\\\\\": run_info.run_name,\\\\n\\\",\\n-    \\\"        \\\\\\\"experiment_id\\\\\\\":  run_info.experiment_id,\\\\n\\\",\\n-    \\\"        \\\\\\\"start_time\\\\\\\":     run_info.start_time,\\\\n\\\",\\n-    \\\"        \\\\\\\"end_time\\\\\\\":       run_info.end_time,\\\\n\\\",\\n-    \\\"        \\\\\\\"params\\\\\\\":         params,\\\\n\\\",\\n-    \\\"        \\\\\\\"metrics\\\\\\\":        metrics,\\\\n\\\",\\n-    \\\"        \\\\\\\"tags\\\\\\\":           tags,\\\\n\\\",\\n-    \\\"        \\\\\\\"artifacts\\\\\\\":      artifact_meta\\\\n\\\",\\n-    \\\"    }\\\\n\\\",\\n-    \\\"    # 1) Create (or reuse) a base folder for run summaries\\\\n\\\",\\n-    \\\"    base_dir = \\\\\\\"run_summaries\\\\\\\"\\\\n\\\",\\n-    \\\"    os.makedirs(base_dir, exist_ok=True)\\\\n\\\",\\n-    \\\"    \\\\n\\\",\\n-    \\\"   # 2) Pick next numeric folder\\\\n\\\",\\n-    \\\"    existing = [\\\\n\\\",\\n-    \\\"        d for d in os.listdir(base_dir)\\\\n\\\",\\n-    \\\"        if os.path.isdir(os.path.join(base_dir, d)) and d.isdigit()\\\\n\\\",\\n-    \\\"    ]\\\\n\\\",\\n-    \\\"    next_num = max(map(int, existing), default=0) + 1\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    # 1) Determine notebook directory (where your .ipynb lives)\\\\n\\\",\\n-    \\\"    notebook_dir = os.getcwd()\\\\n\\\",\\n-    \\\"    \\\\n\\\",\\n-    \\\"    # 2) Create a subfolder for this model\\\\n\\\",\\n-    \\\"    summary_dir = os.path.join(os.getcwd(), \\\\\\\"MODEL_PROVENANCE\\\\\\\")\\\\n\\\",\\n-    \\\"    os.makedirs(summary_dir, exist_ok=True)\\\\n\\\",\\n-    \\\"    \\\\n\\\",\\n-    \\\"   # 2) Pick a filename based on your model_name\\\\n\\\",\\n-    \\\"    summary_filename   = f\\\\\\\"{model_name}_run_summary.json\\\\\\\"\\\\n\\\",\\n-    \\\"    summary_local_path = os.path.join(summary_dir, summary_filename)\\\\n\\\",\\n-    \\\"   # 3) Write the JSON locally\\\\n\\\",\\n-    \\\"    with open(summary_local_path, \\\\\\\"w\\\\\\\", encoding=\\\\\\\"utf-8\\\\\\\") as f:\\\\n\\\",\\n-    \\\"        json.dump(summary, f, indent=2)\\\\n\\\",\\n-    \\\"    \\\\n\\\",\\n-    \\\"    # 4) (Optional) Mirror it into MLflow artifacts under a single folder\\\\n\\\",\\n-    \\\"    mlflow.log_artifact(summary_local_path, artifact_path=\\\\\\\"run_summaries\\\\\\\")\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    mlflow.end_run()\\\"\\n-   ]\\n-  },\\n-  {\\n-   \\\"cell_type\\\": \\\"code\\\",\\n-   \\\"execution_count\\\": null,\\n-   \\\"id\\\": \\\"461eca1d-e33c-4398-835a-64f9ea850469\\\",\\n-   \\\"metadata\\\": {},\\n-   \\\"outputs\\\": [],\\n-   \\\"source\\\": [\\n-    \\\"# !pip install rdflib\\\"\\n-   ]\\n-  },\\n-  {\\n-   \\\"cell_type\\\": \\\"markdown\\\",\\n-   \\\"id\\\": \\\"7a5e3bbb-0288-47d0-9dc4-2855d7e4801a\\\",\\n-   \\\"metadata\\\": {},\\n-   \\\"source\\\": [\\n-    \\\"1. Standards-compliant export (JSON-LD + Turtle)\\\\n\\\",\\n-    \\\"I already have your plain run_summary.json , wrap it in a JSON-LD context that maps your fields into PROV-O terms, then use rdflib to emit Turtle:\\\"\\n-   ]\\n-  },\\n-  {\\n-   \\\"cell_type\\\": \\\"code\\\",\\n-   \\\"execution_count\\\": 66,\\n-   \\\"id\\\": \\\"5cf88da4-69f8-4982-a594-28cf25e4f79a\\\",\\n-   \\\"metadata\\\": {},\\n-   \\\"outputs\\\": [\\n-    {\\n-     \\\"name\\\": \\\"stdout\\\",\\n-     \\\"output_type\\\": \\\"stream\\\",\\n-     \\\"text\\\": [\\n-      \\\"Converted RandomForest_Iris_v20250423_230422_run_summary.json \\u2192 RandomForest_Iris_v20250423_230422.jsonld, RandomForest_Iris_v20250423_230422.ttl\\\\n\\\"\\n-     ]\\n-    }\\n-   ],\\n-   \\\"source\\\": [\\n-    \\\"import os\\\\n\\\",\\n-    \\\"import json\\\\n\\\",\\n-    \\\"import glob\\\\n\\\",\\n-    \\\"from datetime import datetime, timezone\\\\n\\\",\\n-    \\\"from rdflib import Graph\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"def iso8601(ms):\\\\n\\\",\\n-    \\\"    \\\\\\\"\\\\\\\"\\\\\\\"Convert milliseconds since epoch to ISO8601 UTC.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\",\\n-    \\\"    return datetime.fromtimestamp(ms / 1000, tz=timezone.utc).isoformat()\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"for json_path in glob.glob(\\\\\\\"MODEL_PROVENANCE/*_run_summary.json\\\\\\\"):\\\\n\\\",\\n-    \\\"    basename   = os.path.basename(json_path)\\\\n\\\",\\n-    \\\"    model_name = basename.rsplit(\\\\\\\"_run_summary.json\\\\\\\", 1)[0]\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    with open(json_path, \\\\\\\"r\\\\\\\", encoding=\\\\\\\"utf-8\\\\\\\") as f:\\\\n\\\",\\n-    \\\"        summary = json.load(f)\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    #\\u2013\\u2013 Minimal override context: keep all your flat fields as-is,\\\\n\\\",\\n-    \\\"    #\\u2013\\u2013 and only map the actual PROV terms to their IRIs.\\\\n\\\",\\n-    \\\"    ctx = {\\\\n\\\",\\n-    \\\"        # keep these flat\\\\n\\\",\\n-    \\\"        \\\\\\\"run_id\\\\\\\":       { \\\\\\\"@id\\\\\\\": \\\\\\\"run_id\\\\\\\" },\\\\n\\\",\\n-    \\\"        \\\\\\\"run_name\\\\\\\":     { \\\\\\\"@id\\\\\\\": \\\\\\\"run_name\\\\\\\" },\\\\n\\\",\\n-    \\\"        \\\\\\\"experiment_id\\\\\\\":{ \\\\\\\"@id\\\\\\\": \\\\\\\"experiment_id\\\\\\\" },\\\\n\\\",\\n-    \\\"        \\\\\\\"params\\\\\\\":       { \\\\\\\"@id\\\\\\\": \\\\\\\"params\\\\\\\" },\\\\n\\\",\\n-    \\\"        \\\\\\\"metrics\\\\\\\":      { \\\\\\\"@id\\\\\\\": \\\\\\\"metrics\\\\\\\" },\\\\n\\\",\\n-    \\\"        \\\\\\\"artifacts\\\\\\\":    { \\\\\\\"@id\\\\\\\": \\\\\\\"artifacts\\\\\\\" },\\\\n\\\",\\n-    \\\"        \\\\\\\"tags\\\\\\\":         { \\\\\\\"@id\\\\\\\": \\\\\\\"tags\\\\\\\" },\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"        # provenance namespace\\\\n\\\",\\n-    \\\"        \\\\\\\"prov\\\\\\\": \\\\\\\"http://www.w3.org/ns/prov#\\\\\\\",\\\\n\\\",\\n-    \\\"        \\\\\\\"xsd\\\\\\\":  \\\\\\\"http://www.w3.org/2001/XMLSchema#\\\\\\\",\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"        # map your timestamp fields into PROV\\\\n\\\",\\n-    \\\"        \\\\\\\"start_time\\\\\\\": { \\\\\\\"@id\\\\\\\": \\\\\\\"prov:startedAtTime\\\\\\\", \\\\\\\"@type\\\\\\\": \\\\\\\"xsd:dateTime\\\\\\\" },\\\\n\\\",\\n-    \\\"        \\\\\\\"end_time\\\\\\\":   { \\\\\\\"@id\\\\\\\": \\\\\\\"prov:endedAtTime\\\\\\\",   \\\\\\\"@type\\\\\\\": \\\\\\\"xsd:dateTime\\\\\\\" },\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"        # PROV-used/generated\\\\n\\\",\\n-    \\\"        \\\\\\\"used\\\\\\\":      { \\\\\\\"@id\\\\\\\": \\\\\\\"prov:used\\\\\\\",      \\\\\\\"@type\\\\\\\": \\\\\\\"@id\\\\\\\" },\\\\n\\\",\\n-    \\\"        \\\\\\\"generated\\\\\\\": { \\\\\\\"@id\\\\\\\": \\\\\\\"prov:generated\\\\\\\", \\\\\\\"@type\\\\\\\": \\\\\\\"@id\\\\\\\" },\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"        # JSON-LD boilerplate\\\\n\\\",\\n-    \\\"        \\\\\\\"@id\\\\\\\":   \\\\\\\"@id\\\\\\\",\\\\n\\\",\\n-    \\\"        \\\\\\\"@type\\\\\\\": \\\\\\\"@type\\\\\\\"\\\\n\\\",\\n-    \\\"    }\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    #\\u2013\\u2013 Build JSON-LD document, re-using your original keys verbatim\\\\n\\\",\\n-    \\\"    doc = {\\\\n\\\",\\n-    \\\"        \\\\\\\"@context\\\\\\\":      ctx,\\\\n\\\",\\n-    \\\"        \\\\\\\"run_id\\\\\\\":        summary[\\\\\\\"run_id\\\\\\\"],\\\\n\\\",\\n-    \\\"        \\\\\\\"run_name\\\\\\\":      summary.get(\\\\\\\"run_name\\\\\\\"),\\\\n\\\",\\n-    \\\"        \\\\\\\"experiment_id\\\\\\\": summary.get(\\\\\\\"experiment_id\\\\\\\"),\\\\n\\\",\\n-    \\\"        \\\\\\\"params\\\\\\\":        summary.get(\\\\\\\"params\\\\\\\", {}),\\\\n\\\",\\n-    \\\"        \\\\\\\"metrics\\\\\\\":       summary.get(\\\\\\\"metrics\\\\\\\", {}),\\\\n\\\",\\n-    \\\"        \\\\\\\"artifacts\\\\\\\":     summary.get(\\\\\\\"artifacts\\\\\\\", []),\\\\n\\\",\\n-    \\\"        \\\\\\\"tags\\\\\\\":          summary.get(\\\\\\\"tags\\\\\\\", {}),\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"        # PROV fields:\\\\n\\\",\\n-    \\\"        \\\\\\\"start_time\\\\\\\": iso8601(summary[\\\\\\\"start_time\\\\\\\"])\\\\n\\\",\\n-    \\\"    }\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    if summary.get(\\\\\\\"end_time\\\\\\\") is not None:\\\\n\\\",\\n-    \\\"        doc[\\\\\\\"end_time\\\\\\\"] = iso8601(summary[\\\\\\\"end_time\\\\\\\"])\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    # for used/generated, just point at your dataset/model URIs\\\\n\\\",\\n-    \\\"    # (or blank-node them if you prefer richer structure)\\\\n\\\",\\n-    \\\"    doc[\\\\\\\"used\\\\\\\"] = summary.get(\\\\\\\"tags\\\\\\\", {}).get(\\\\\\\"dataset_uri\\\\\\\") or []\\\\n\\\",\\n-    \\\"    doc[\\\\\\\"generated\\\\\\\"] = [\\\\n\\\",\\n-    \\\"        art.get(\\\\\\\"uri\\\\\\\") or art.get(\\\\\\\"path\\\\\\\")\\\\n\\\",\\n-    \\\"        for art in summary.get(\\\\\\\"artifacts\\\\\\\", [])\\\\n\\\",\\n-    \\\"    ]\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    #\\u2013\\u2013 write JSON-LD\\\\n\\\",\\n-    \\\"    out_jsonld = os.path.join(\\\\\\\"MODEL_PROVENANCE\\\\\\\", f\\\\\\\"{model_name}.jsonld\\\\\\\")\\\\n\\\",\\n-    \\\"    with open(out_jsonld, \\\\\\\"w\\\\\\\", encoding=\\\\\\\"utf-8\\\\\\\") as f:\\\\n\\\",\\n-    \\\"        json.dump(doc, f, indent=2)\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    #\\u2013\\u2013 parse & serialize to Turtle\\\\n\\\",\\n-    \\\"    g = Graph().parse(data=json.dumps(doc), format=\\\\\\\"json-ld\\\\\\\")\\\\n\\\",\\n-    \\\"    out_ttl = os.path.join(\\\\\\\"MODEL_PROVENANCE\\\\\\\", f\\\\\\\"{model_name}.ttl\\\\\\\")\\\\n\\\",\\n-    \\\"    g.serialize(destination=out_ttl, format=\\\\\\\"turtle\\\\\\\")\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    print(f\\\\\\\"Converted {basename} \\u2192 {os.path.basename(out_jsonld)}, {os.path.basename(out_ttl)}\\\\\\\")\\\\n\\\",\\n-    \\\"\\\\n\\\"\\n-   ]\\n-  },\\n-  {\\n-   \\\"cell_type\\\": \\\"markdown\\\",\\n-   \\\"id\\\": \\\"83d6d524-01da-4f20-8131-0d4a3ac005e2\\\",\\n-   \\\"metadata\\\": {},\\n-   \\\"source\\\": [\\n-    \\\"This code programatically, finds diff between generated Json file and created JsonLD and .TTL file to make it easier to understand if there is any discrepency\\\"\\n-   ]\\n-  },\\n-  {\\n-   \\\"cell_type\\\": \\\"code\\\",\\n-   \\\"execution_count\\\": 68,\\n-   \\\"id\\\": \\\"77a420c0-230d-41c0-9b63-f3dbbca1e670\\\",\\n-   \\\"metadata\\\": {},\\n-   \\\"outputs\\\": [\\n-    {\\n-     \\\"name\\\": \\\"stdout\\\",\\n-     \\\"output_type\\\": \\\"stream\\\",\\n-     \\\"text\\\": [\\n-      \\\"== JSON-LD vs TTL ==\\\\n\\\",\\n-      \\\"Change summary:\\\\n\\\",\\n-      \\\"type\\\\n\\\",\\n-      \\\"changed    1 \\\\n\\\",\\n-      \\\"\\\\n\\\",\\n-      \\\"First 10 \\u2018changed\\u2019 entries:\\\\n\\\",\\n-      \\\"Top-level adds/removes:\\\\n\\\",\\n-      \\\"Empty DataFrame\\\\n\\\",\\n-      \\\"Columns: [path, type, a, b]\\\\n\\\",\\n-      \\\"Index: []\\\\n\\\",\\n-      \\\"\\\\n\\\",\\n-      \\\"== JSON vs JSON-LD ==\\\\n\\\",\\n-      \\\"Change summary:\\\\n\\\",\\n-      \\\"type\\\\n\\\",\\n-      \\\"added      3\\\\n\\\",\\n-      \\\"changed    1\\\\n\\\",\\n-      \\\"removed    1 \\\\n\\\",\\n-      \\\"\\\\n\\\",\\n-      \\\"First 10 \\u2018changed\\u2019 entries:\\\\n\\\",\\n-      \\\"Top-level adds/removes:\\\\n\\\",\\n-      \\\"Empty DataFrame\\\\n\\\",\\n-      \\\"Columns: [path, type, a, b]\\\\n\\\",\\n-      \\\"Index: []\\\\n\\\"\\n-     ]\\n-    }\\n-   ],\\n-   \\\"source\\\": [\\n-    \\\"import json\\\\n\\\",\\n-    \\\"from rdflib import Graph\\\\n\\\",\\n-    \\\"import pandas as pd\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"def load_as_dict(path):\\\\n\\\",\\n-    \\\"    if path.endswith((\\\\\\\".ttl\\\\\\\", \\\\\\\".turtle\\\\\\\")):\\\\n\\\",\\n-    \\\"        g = Graph()\\\\n\\\",\\n-    \\\"        g.parse(path, format=\\\\\\\"turtle\\\\\\\")\\\\n\\\",\\n-    \\\"        # normalize to JSON-LD dict\\\\n\\\",\\n-    \\\"        return json.loads(g.serialize(format=\\\\\\\"json-ld\\\\\\\", indent=2))\\\\n\\\",\\n-    \\\"    else:\\\\n\\\",\\n-    \\\"        with open(path, encoding=\\\\\\\"utf-8\\\\\\\") as f:\\\\n\\\",\\n-    \\\"            return json.load(f)\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"def compare_json(a, b, path=\\\\\\\"\\\\\\\"):\\\\n\\\",\\n-    \\\"    diffs = []\\\\n\\\",\\n-    \\\"    if isinstance(a, dict) and isinstance(b, dict):\\\\n\\\",\\n-    \\\"        all_keys = set(a) | set(b)\\\\n\\\",\\n-    \\\"        for k in all_keys:\\\\n\\\",\\n-    \\\"            new_path = f\\\\\\\"{path}/{k}\\\\\\\" if path else k\\\\n\\\",\\n-    \\\"            if k not in a:\\\\n\\\",\\n-    \\\"                diffs.append({\\\\\\\"path\\\\\\\": new_path, \\\\\\\"type\\\\\\\": \\\\\\\"added\\\\\\\",   \\\\\\\"a\\\\\\\": None,    \\\\\\\"b\\\\\\\": b[k]})\\\\n\\\",\\n-    \\\"            elif k not in b:\\\\n\\\",\\n-    \\\"                diffs.append({\\\\\\\"path\\\\\\\": new_path, \\\\\\\"type\\\\\\\": \\\\\\\"removed\\\\\\\", \\\\\\\"a\\\\\\\": a[k],   \\\\\\\"b\\\\\\\": None})\\\\n\\\",\\n-    \\\"            else:\\\\n\\\",\\n-    \\\"                diffs.extend(compare_json(a[k], b[k], new_path))\\\\n\\\",\\n-    \\\"    elif isinstance(a, list) and isinstance(b, list):\\\\n\\\",\\n-    \\\"        for i, (ia, ib) in enumerate(zip(a, b)):\\\\n\\\",\\n-    \\\"            diffs.extend(compare_json(ia, ib, f\\\\\\\"{path}[{i}]\\\\\\\"))\\\\n\\\",\\n-    \\\"        # handle length mismatches\\\\n\\\",\\n-    \\\"        if len(a) < len(b):\\\\n\\\",\\n-    \\\"            for i in range(len(a), len(b)):\\\\n\\\",\\n-    \\\"                diffs.append({\\\\\\\"path\\\\\\\": f\\\\\\\"{path}[{i}]\\\\\\\", \\\\\\\"type\\\\\\\": \\\\\\\"added\\\\\\\",   \\\\\\\"a\\\\\\\": None,  \\\\\\\"b\\\\\\\": b[i]})\\\\n\\\",\\n-    \\\"        elif len(a) > len(b):\\\\n\\\",\\n-    \\\"            for i in range(len(b), len(a)):\\\\n\\\",\\n-    \\\"                diffs.append({\\\\\\\"path\\\\\\\": f\\\\\\\"{path}[{i}]\\\\\\\", \\\\\\\"type\\\\\\\": \\\\\\\"removed\\\\\\\", \\\\\\\"a\\\\\\\": a[i],  \\\\\\\"b\\\\\\\": None})\\\\n\\\",\\n-    \\\"    else:\\\\n\\\",\\n-    \\\"        if a != b:\\\\n\\\",\\n-    \\\"            diffs.append({\\\\\\\"path\\\\\\\": path, \\\\\\\"type\\\\\\\": \\\\\\\"changed\\\\\\\", \\\\\\\"a\\\\\\\": a, \\\\\\\"b\\\\\\\": b})\\\\n\\\",\\n-    \\\"    return diffs\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# --- Usage example -----------------------------------------------\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# Compare JSON-LD vs Turtle:\\\\n\\\",\\n-    \\\"a = load_as_dict(\\\\\\\"MODEL_PROVENANCE/RandomForest_Iris_v20250423_230422_run_summary.json\\\\\\\")\\\\n\\\",\\n-    \\\"b = load_as_dict(\\\\\\\"MODEL_PROVENANCE/RandomForest_Iris_v20250423_230422.ttl\\\\\\\")\\\\n\\\",\\n-    \\\"diffs_jsonld_vs_ttl = compare_json(a, b)\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# Compare JSON vs JSON-LD:\\\\n\\\",\\n-    \\\"c = load_as_dict(\\\\\\\"MODEL_PROVENANCE/RandomForest_Iris_v20250423_230422_run_summary.json\\\\\\\")\\\\n\\\",\\n-    \\\"d = load_as_dict(\\\\\\\"MODEL_PROVENANCE/RandomForest_Iris_v20250423_230422.jsonld\\\\\\\")\\\\n\\\",\\n-    \\\"diffs_json_vs_jsonld = compare_json(c, d)\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# Build DataFrames for interactive inspection\\\\n\\\",\\n-    \\\"df1 = pd.DataFrame(diffs_jsonld_vs_ttl)\\\\n\\\",\\n-    \\\"df2 = pd.DataFrame(diffs_json_vs_jsonld)\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# --- Summaries & Filtering ---------------------------------------\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"def summarize_and_preview(df, preview_n=10):\\\\n\\\",\\n-    \\\"    print(\\\\\\\"Change summary:\\\\\\\")\\\\n\\\",\\n-    \\\"    print(df['type'].value_counts().to_string(), \\\\\\\"\\\\\\\\n\\\\\\\")\\\\n\\\",\\n-    \\\"    \\\\n\\\",\\n-    \\\"    print(f\\\\\\\"First {preview_n} \\u2018changed\\u2019 entries:\\\\\\\")\\\\n\\\",\\n-    \\\"    # print(df[df['type']==\\\\\\\"changed\\\\\\\"].head(preview_n).to_string(index=False), \\\\\\\"\\\\\\\\n\\\\\\\")\\\\n\\\",\\n-    \\\"    \\\\n\\\",\\n-    \\\"    # Top\\u2010level (one slash) adds/removes\\\\n\\\",\\n-    \\\"    top = df[df['path'].str.count(\\\\\\\"/\\\\\\\") == 1]\\\\n\\\",\\n-    \\\"    print(\\\\\\\"Top-level adds/removes:\\\\\\\")\\\\n\\\",\\n-    \\\"    print(top[top['type'].isin(['added','removed'])].to_string(index=False))\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"print(\\\\\\\"== JSON-LD vs TTL ==\\\\\\\")\\\\n\\\",\\n-    \\\"summarize_and_preview(df1)\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"print(\\\\\\\"\\\\\\\\n== JSON vs JSON-LD ==\\\\\\\")\\\\n\\\",\\n-    \\\"summarize_and_preview(df2)\\\\n\\\",\\n-    \\\"\\\\n\\\"\\n-   ]\\n-  },\\n-  {\\n-   \\\"cell_type\\\": \\\"code\\\",\\n-   \\\"execution_count\\\": 69,\\n-   \\\"id\\\": \\\"41af9d6e-c683-45f9-bac1-296611b4d0b9\\\",\\n-   \\\"metadata\\\": {},\\n-   \\\"outputs\\\": [\\n-    {\\n-     \\\"name\\\": \\\"stdout\\\",\\n-     \\\"output_type\\\": \\\"stream\\\",\\n-     \\\"text\\\": [\\n-      \\\"Removed in JSON-LD comparison:\\\\n\\\",\\n-      \\\"    path\\\\n\\\",\\n-      \\\"end_time\\\\n\\\",\\n-      \\\"\\\\n\\\",\\n-      \\\"Added in JSON-LD comparison:\\\\n\\\",\\n-      \\\"     path\\\\n\\\",\\n-      \\\" @context\\\\n\\\",\\n-      \\\"generated\\\\n\\\",\\n-      \\\"     used\\\\n\\\"\\n-     ]\\n-    }\\n-   ],\\n-   \\\"source\\\": [\\n-    \\\"# show all the removed paths (in JSON but not in JSON-LD)\\\\n\\\",\\n-    \\\"print(\\\\\\\"Removed in JSON-LD comparison:\\\\\\\")\\\\n\\\",\\n-    \\\"print(df2[df2['type']==\\\\\\\"removed\\\\\\\"][['path']].to_string(index=False))\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# show all the added paths (in JSON-LD but not in JSON)\\\\n\\\",\\n-    \\\"print(\\\\\\\"\\\\\\\\nAdded in JSON-LD comparison:\\\\\\\")\\\\n\\\",\\n-    \\\"print(df2[df2['type']==\\\\\\\"added\\\\\\\"][['path']].to_string(index=False))\\\"\\n-   ]\\n-  },\\n-  {\\n-   \\\"cell_type\\\": \\\"code\\\",\\n-   \\\"execution_count\\\": 70,\\n-   \\\"id\\\": \\\"f0d6f92a-5cd9-4c78-9c2a-0cd3247137c6\\\",\\n-   \\\"metadata\\\": {},\\n-   \\\"outputs\\\": [\\n-    {\\n-     \\\"name\\\": \\\"stdout\\\",\\n-     \\\"output_type\\\": \\\"stream\\\",\\n-     \\\"text\\\": [\\n-      \\\"Removed in .ttl comparison:\\\\n\\\",\\n-      \\\"Empty DataFrame\\\\n\\\",\\n-      \\\"Columns: [path]\\\\n\\\",\\n-      \\\"Index: []\\\\n\\\",\\n-      \\\"\\\\n\\\",\\n-      \\\"Added in .ttl comparison:\\\\n\\\",\\n-      \\\"Empty DataFrame\\\\n\\\",\\n-      \\\"Columns: [path]\\\\n\\\",\\n-      \\\"Index: []\\\\n\\\"\\n-     ]\\n-    }\\n-   ],\\n-   \\\"source\\\": [\\n-    \\\"# show all the removed paths (in JSON but not in JSON-LD)\\\\n\\\",\\n-    \\\"print(\\\\\\\"Removed in .ttl comparison:\\\\\\\")\\\\n\\\",\\n-    \\\"print(df1[df1['type']==\\\\\\\"removed\\\\\\\"][['path']].to_string(index=False))\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# show all the added paths (in JSON-LD but not in JSON)\\\\n\\\",\\n-    \\\"print(\\\\\\\"\\\\\\\\nAdded in .ttl comparison:\\\\\\\")\\\\n\\\",\\n-    \\\"print(df1[df1['type']==\\\\\\\"added\\\\\\\"][['path']].to_string(index=False))\\\"\\n-   ]\\n-  },\\n-  {\\n-   \\\"cell_type\\\": \\\"markdown\\\",\\n-   \\\"id\\\": \\\"69efd0d0-9277-4efa-88cf-d2fd1b90d74c\\\",\\n-   \\\"metadata\\\": {},\\n-   \\\"source\\\": [\\n-    \\\"Checks for completeness and mapping and time taken, needs work #TODO\\\"\\n-   ]\\n-  },\\n-  {\\n-   \\\"cell_type\\\": \\\"code\\\",\\n-   \\\"execution_count\\\": 71,\\n-   \\\"id\\\": \\\"165a13eb-7679-4f4c-b346-24f25da72cce\\\",\\n-   \\\"metadata\\\": {},\\n-   \\\"outputs\\\": [\\n-    {\\n-     \\\"name\\\": \\\"stdout\\\",\\n-     \\\"output_type\\\": \\\"stream\\\",\\n-     \\\"text\\\": [\\n-      \\\"\\\\n\\\",\\n-      \\\"\\u2500\\u2500 RandomForest_Iris_v20250423_230422 diffs \\u2500\\u2500\\\\n\\\",\\n-      \\\"  \\u2022 JSON \\u2192 JSON-LD: 17 differences\\\\n\\\",\\n-      \\\"  \\u2022 JSON-LD \\u2192 TTL \\u2192 JSON-LD: 1 differences\\\\n\\\",\\n-      \\\"\\\\n\\\",\\n-      \\\"1/1 runs passed completeness checks (100.0%).\\\\n\\\",\\n-      \\\"\\\\n\\\",\\n-      \\\"Mapping integrity: 0/1 runs have zero diffs \\u2014 0.0%\\\\n\\\",\\n-      \\\"Overall quality score: 50.0%\\\\n\\\",\\n-      \\\"\\\\n\\\",\\n-      \\\"Benchmarking train_and_log() overhead:\\\\n\\\",\\n-      \\\"  \\u2022 No MLflow : 0.501s\\\\n\\\",\\n-      \\\"  \\u2022 With MLflow: 0.601s\\\\n\\\"\\n-     ]\\n-    }\\n-   ],\\n-   \\\"source\\\": [\\n-    \\\"import os\\\\n\\\",\\n-    \\\"import glob\\\\n\\\",\\n-    \\\"import json\\\\n\\\",\\n-    \\\"import time\\\\n\\\",\\n-    \\\"from datetime import datetime, timezone\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"from rdflib import Graph\\\\n\\\",\\n-    \\\"# from your_compare_module import compare_json  # \\u2190 your existing compare_json()\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# \\u2500\\u2500 User configuration \\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# Which keys must appear in every run_summary.json?\\\\n\\\",\\n-    \\\"REQUIRED_TOPLEVEL = {\\\\n\\\",\\n-    \\\"    \\\\\\\"run_id\\\\\\\", \\\\\\\"start_time\\\\\\\", \\\\\\\"end_time\\\\\\\",\\\\n\\\",\\n-    \\\"    \\\\\\\"params\\\\\\\", \\\\\\\"metrics\\\\\\\", \\\\\\\"tags\\\\\\\", \\\\\\\"artifacts\\\\\\\"\\\\n\\\",\\n-    \\\"}\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# A couple of sub-fields we also want to spot-check:\\\\n\\\",\\n-    \\\"REQUIRED_PARAMS  = {\\\\\\\"random_state\\\\\\\"}\\\\n\\\",\\n-    \\\"REQUIRED_METRICS = {\\\\\\\"accuracy\\\\\\\"}\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"JSON_SUMMARIES = glob.glob(\\\\\\\"MODEL_PROVENANCE/*_run_summary.json\\\\\\\")\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# \\u2500\\u2500 Helpers \\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"def iso8601(ms):\\\\n\\\",\\n-    \\\"    return datetime.fromtimestamp(ms/1000, tz=timezone.utc).isoformat()\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"def load_json(path):\\\\n\\\",\\n-    \\\"    with open(path, \\\\\\\"r\\\\\\\", encoding=\\\\\\\"utf-8\\\\\\\") as f:\\\\n\\\",\\n-    \\\"        return json.load(f)\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"def write_json(path, obj):\\\\n\\\",\\n-    \\\"    with open(path, \\\\\\\"w\\\\\\\", encoding=\\\\\\\"utf-8\\\\\\\") as f:\\\\n\\\",\\n-    \\\"        json.dump(obj, f, indent=2)\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"def convert_to_jsonld_and_ttl(summary, basename):\\\\n\\\",\\n-    \\\"    # build @context\\\\n\\\",\\n-    \\\"    ctx = {\\\\n\\\",\\n-    \\\"        \\\\\\\"prov\\\\\\\":    \\\\\\\"http://www.w3.org/ns/prov#\\\\\\\",\\\\n\\\",\\n-    \\\"        \\\\\\\"xsd\\\\\\\":     \\\\\\\"http://www.w3.org/2001/XMLSchema#\\\\\\\",\\\\n\\\",\\n-    \\\"        \\\\\\\"run\\\\\\\":     \\\\\\\"prov:Activity\\\\\\\",\\\\n\\\",\\n-    \\\"        \\\\\\\"start\\\\\\\":   \\\\\\\"prov:startedAtTime\\\\\\\",\\\\n\\\",\\n-    \\\"        \\\\\\\"end\\\\\\\":     \\\\\\\"prov:endedAtTime\\\\\\\",\\\\n\\\",\\n-    \\\"        \\\\\\\"used\\\\\\\":    \\\\\\\"prov:used\\\\\\\",\\\\n\\\",\\n-    \\\"        \\\\\\\"gen\\\\\\\":     \\\\\\\"prov:generated\\\\\\\",\\\\n\\\",\\n-    \\\"        \\\\\\\"param\\\\\\\":   \\\\\\\"prov:hadParameter\\\\\\\",\\\\n\\\",\\n-    \\\"        \\\\\\\"metric\\\\\\\":  \\\\\\\"prov:hadQuality\\\\\\\",\\\\n\\\",\\n-    \\\"        \\\\\\\"entity\\\\\\\":  \\\\\\\"prov:Entity\\\\\\\",\\\\n\\\",\\n-    \\\"        \\\\\\\"label\\\\\\\":   \\\\\\\"prov:label\\\\\\\",\\\\n\\\",\\n-    \\\"        \\\\\\\"value\\\\\\\":   \\\\\\\"prov:value\\\\\\\",\\\\n\\\",\\n-    \\\"        \\\\\\\"version\\\\\\\": \\\\\\\"prov:hadRevision\\\\\\\",\\\\n\\\",\\n-    \\\"        \\\\\\\"id\\\\\\\":      \\\\\\\"@id\\\\\\\",\\\\n\\\",\\n-    \\\"        \\\\\\\"type\\\\\\\":    \\\\\\\"@type\\\\\\\"\\\\n\\\",\\n-    \\\"    }\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    jsonld = {\\\\n\\\",\\n-    \\\"        \\\\\\\"@context\\\\\\\": ctx,\\\\n\\\",\\n-    \\\"        \\\\\\\"@id\\\\\\\":      f\\\\\\\"urn:run:{summary['run_id']}\\\\\\\",\\\\n\\\",\\n-    \\\"        \\\\\\\"@type\\\\\\\":    \\\\\\\"run\\\\\\\",\\\\n\\\",\\n-    \\\"        \\\\\\\"start\\\\\\\": {\\\\n\\\",\\n-    \\\"            \\\\\\\"@type\\\\\\\":  \\\\\\\"xsd:dateTime\\\\\\\",\\\\n\\\",\\n-    \\\"            \\\\\\\"@value\\\\\\\": iso8601(summary[\\\\\\\"start_time\\\\\\\"])\\\\n\\\",\\n-    \\\"        }\\\\n\\\",\\n-    \\\"    }\\\\n\\\",\\n-    \\\"    if summary.get(\\\\\\\"end_time\\\\\\\") is not None:\\\\n\\\",\\n-    \\\"        jsonld[\\\\\\\"end\\\\\\\"] = {\\\\n\\\",\\n-    \\\"            \\\\\\\"@type\\\\\\\":  \\\\\\\"xsd:dateTime\\\\\\\",\\\\n\\\",\\n-    \\\"            \\\\\\\"@value\\\\\\\": iso8601(summary[\\\\\\\"end_time\\\\\\\"])\\\\n\\\",\\n-    \\\"        }\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    # params\\\\n\\\",\\n-    \\\"    jsonld[\\\\\\\"param\\\\\\\"] = [\\\\n\\\",\\n-    \\\"        {\\\\\\\"@type\\\\\\\":\\\\\\\"entity\\\\\\\",\\\\\\\"label\\\\\\\":k,\\\\\\\"value\\\\\\\":str(v)}\\\\n\\\",\\n-    \\\"        for k,v in summary.get(\\\\\\\"params\\\\\\\",{}).items()\\\\n\\\",\\n-    \\\"    ]\\\\n\\\",\\n-    \\\"    # metrics\\\\n\\\",\\n-    \\\"    jsonld[\\\\\\\"metric\\\\\\\"] = [\\\\n\\\",\\n-    \\\"        {\\\\\\\"@type\\\\\\\":\\\\\\\"entity\\\\\\\",\\\\\\\"label\\\\\\\":k,\\\\n\\\",\\n-    \\\"         \\\\\\\"value\\\\\\\":{\\\\\\\"@type\\\\\\\":\\\\\\\"xsd:decimal\\\\\\\",\\\\\\\"@value\\\\\\\":v}}\\\\n\\\",\\n-    \\\"        for k,v in summary.get(\\\\\\\"metrics\\\\\\\",{}).items()\\\\n\\\",\\n-    \\\"    ]\\\\n\\\",\\n-    \\\"    # artifacts\\\\n\\\",\\n-    \\\"    jsonld[\\\\\\\"gen\\\\\\\"] = [\\\\n\\\",\\n-    \\\"        {\\\\n\\\",\\n-    \\\"            \\\\\\\"@type\\\\\\\":\\\\\\\"entity\\\\\\\",\\\\n\\\",\\n-    \\\"            \\\\\\\"label\\\\\\\": art.get(\\\\\\\"path\\\\\\\") or art.get(\\\\\\\"label\\\\\\\"),\\\\n\\\",\\n-    \\\"            \\\\\\\"prov:location\\\\\\\": (\\\\n\\\",\\n-    \\\"                art.get(\\\\\\\"uri\\\\\\\")\\\\n\\\",\\n-    \\\"                or (art.get(\\\\\\\"content\\\\\\\",\\\\\\\"\\\\\\\")[:30]+\\\\\\\"\\u2026\\\\\\\")\\\\n\\\",\\n-    \\\"                if isinstance(art.get(\\\\\\\"content\\\\\\\"),str)\\\\n\\\",\\n-    \\\"                else \\\\\\\"\\\\\\\"\\\\n\\\",\\n-    \\\"            )\\\\n\\\",\\n-    \\\"        }\\\\n\\\",\\n-    \\\"        for art in summary.get(\\\\\\\"artifacts\\\\\\\",[])\\\\n\\\",\\n-    \\\"    ]\\\\n\\\",\\n-    \\\"    # dataset used\\\\n\\\",\\n-    \\\"    jsonld[\\\\\\\"used\\\\\\\"] = {\\\\n\\\",\\n-    \\\"        \\\\\\\"@type\\\\\\\":\\\\\\\"entity\\\\\\\",\\\\n\\\",\\n-    \\\"        \\\\\\\"label\\\\\\\": summary[\\\\\\\"tags\\\\\\\"].get(\\\\\\\"dataset_name\\\\\\\"),\\\\n\\\",\\n-    \\\"        \\\\\\\"version\\\\\\\": summary[\\\\\\\"tags\\\\\\\"].get(\\\\\\\"dataset_version\\\\\\\")\\\\n\\\",\\n-    \\\"    }\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    # write JSON-LD\\\\n\\\",\\n-    \\\"    out_jsonld = f\\\\\\\"MODEL_PROVENANCE/{basename}.jsonld\\\\\\\"\\\\n\\\",\\n-    \\\"    write_json(out_jsonld, jsonld)\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    # serialize TTL\\\\n\\\",\\n-    \\\"    g = Graph().parse(data=json.dumps(jsonld), format=\\\\\\\"json-ld\\\\\\\")\\\\n\\\",\\n-    \\\"    out_ttl = f\\\\\\\"MODEL_PROVENANCE/{basename}.ttl\\\\\\\"\\\\n\\\",\\n-    \\\"    g.serialize(destination=out_ttl, format=\\\\\\\"turtle\\\\\\\")\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    return out_jsonld, out_ttl\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"def normalize_jsonld(js):\\\\n\\\",\\n-    \\\"    \\\\\\\"\\\\\\\"\\\\\\\"Simple deep-sort so compare_json doesn\\u2019t trip over ordering.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\",\\n-    \\\"    if isinstance(js, dict):\\\\n\\\",\\n-    \\\"        return {k: normalize_jsonld(js[k]) for k in sorted(js)}\\\\n\\\",\\n-    \\\"    if isinstance(js, list):\\\\n\\\",\\n-    \\\"        return sorted((normalize_jsonld(el) for el in js),\\\\n\\\",\\n-    \\\"                      key=lambda x: json.dumps(x, sort_keys=True))\\\\n\\\",\\n-    \\\"    return js\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"def diff_roundtrip(orig_json, jsonld_path, ttl_path):\\\\n\\\",\\n-    \\\"    orig = load_json(orig_json)\\\\n\\\",\\n-    \\\"    ld   = load_json(jsonld_path)\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    # parse TTL back to JSON-LD\\\\n\\\",\\n-    \\\"    g = Graph().parse(ttl_path, format=\\\\\\\"turtle\\\\\\\")\\\\n\\\",\\n-    \\\"    ttl_as_ld = json.loads(g.serialize(format=\\\\\\\"json-ld\\\\\\\"))\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    # normalize\\\\n\\\",\\n-    \\\"    nl = normalize_jsonld(ld)\\\\n\\\",\\n-    \\\"    nt = normalize_jsonld(ttl_as_ld)\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    return {\\\\n\\\",\\n-    \\\"        \\\\\\\"orig_vs_jsonld\\\\\\\":   compare_json(orig, ld),\\\\n\\\",\\n-    \\\"        \\\\\\\"jsonld_vs_ttl_ld\\\\\\\": compare_json(nl, nt)\\\\n\\\",\\n-    \\\"    }\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# \\u2500\\u2500 Main flow \\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"def main():\\\\n\\\",\\n-    \\\"    ok = 0\\\\n\\\",\\n-    \\\"    total = len(JSON_SUMMARIES)\\\\n\\\",\\n-    \\\"    missing_reports = []\\\\n\\\",\\n-    \\\"    cases = {}  # store diff results per run\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    for js_path in JSON_SUMMARIES:\\\\n\\\",\\n-    \\\"        summary = load_json(js_path)\\\\n\\\",\\n-    \\\"        base    = os.path.basename(js_path).split(\\\\\\\"_run_summary.json\\\\\\\")[0]\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"        # 1) completeness check\\\\n\\\",\\n-    \\\"        if not REQUIRED_TOPLEVEL.issubset(summary):\\\\n\\\",\\n-    \\\"            missing = REQUIRED_TOPLEVEL - set(summary)\\\\n\\\",\\n-    \\\"            missing_reports.append((js_path, f\\\\\\\"missing fields {missing}\\\\\\\"))\\\\n\\\",\\n-    \\\"            continue\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"        if not (REQUIRED_PARAMS <= summary[\\\\\\\"params\\\\\\\"].keys()):\\\\n\\\",\\n-    \\\"            missing_reports.append((js_path, f\\\\\\\"params missing {REQUIRED_PARAMS - summary['params'].keys()}\\\\\\\"))\\\\n\\\",\\n-    \\\"            continue\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"        if not (REQUIRED_METRICS <= summary[\\\\\\\"metrics\\\\\\\"].keys()):\\\\n\\\",\\n-    \\\"            missing_reports.append((js_path, f\\\\\\\"metrics missing {REQUIRED_METRICS - summary['metrics'].keys()}\\\\\\\"))\\\\n\\\",\\n-    \\\"            continue\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"        ok += 1\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"        # 2) convert\\\\n\\\",\\n-    \\\"        jsonld_path, ttl_path = convert_to_jsonld_and_ttl(summary, base)\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"        # 3) diff\\\\n\\\",\\n-    \\\"        diffs = diff_roundtrip(js_path, jsonld_path, ttl_path)\\\\n\\\",\\n-    \\\"        cases[base] = diffs\\\\n\\\",\\n-    \\\"        print(f\\\\\\\"\\\\\\\\n\\u2500\\u2500 {base} diffs \\u2500\\u2500\\\\\\\")\\\\n\\\",\\n-    \\\"        print(\\\\\\\"  \\u2022 JSON \\u2192 JSON-LD:\\\\\\\", len(diffs[\\\\\\\"orig_vs_jsonld\\\\\\\"]), \\\\\\\"differences\\\\\\\")\\\\n\\\",\\n-    \\\"        print(\\\\\\\"  \\u2022 JSON-LD \\u2192 TTL \\u2192 JSON-LD:\\\\\\\", len(diffs[\\\\\\\"jsonld_vs_ttl_ld\\\\\\\"]), \\\\\\\"differences\\\\\\\")\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    # 4) completeness summary\\\\n\\\",\\n-    \\\"    completeness_pct = (100 * ok / total) if total else 0\\\\n\\\",\\n-    \\\"    print(f\\\\\\\"\\\\\\\\n{ok}/{total} runs passed completeness checks ({completeness_pct:.1f}%).\\\\\\\")\\\\n\\\",\\n-    \\\"    if missing_reports:\\\\n\\\",\\n-    \\\"        print(\\\\\\\"\\\\\\\\nFailures:\\\\\\\")\\\\n\\\",\\n-    \\\"        for path, reason in missing_reports:\\\\n\\\",\\n-    \\\"            print(f\\\\\\\" \\u2022 {path}: {reason}\\\\\\\")\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    # 5) integrity check\\\\n\\\",\\n-    \\\"    total_runs = len(cases)\\\\n\\\",\\n-    \\\"    zero_diff_runs = sum(\\\\n\\\",\\n-    \\\"        1\\\\n\\\",\\n-    \\\"        for diffs in cases.values()\\\\n\\\",\\n-    \\\"        if not diffs[\\\\\\\"orig_vs_jsonld\\\\\\\"] and not diffs[\\\\\\\"jsonld_vs_ttl_ld\\\\\\\"]\\\\n\\\",\\n-    \\\"    )\\\\n\\\",\\n-    \\\"    integrity_pct = (100 * zero_diff_runs / total_runs) if total_runs else 0\\\\n\\\",\\n-    \\\"    print(f\\\\\\\"\\\\\\\\nMapping integrity: {zero_diff_runs}/{total_runs} runs have zero diffs \\u2014 {integrity_pct:.1f}%\\\\\\\")\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    # 6) overall quality score\\\\n\\\",\\n-    \\\"    overall_score = (completeness_pct + integrity_pct) / 2\\\\n\\\",\\n-    \\\"    print(f\\\\\\\"Overall quality score: {overall_score:.1f}%\\\\\\\")\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    # 7) Benchmark your training fn\\\\n\\\",\\n-    \\\"    print(\\\\\\\"\\\\\\\\nBenchmarking train_and_log() overhead:\\\\\\\")\\\\n\\\",\\n-    \\\"    def train_and_log(use_mlflow=False):\\\\n\\\",\\n-    \\\"        # \\u2190 your real instrumentation + fit logic here\\\\n\\\",\\n-    \\\"        time.sleep(0.5 + (0.1 if use_mlflow else 0))  # stub\\\\n\\\",\\n-    \\\"        return\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    for flag in (False, True):\\\\n\\\",\\n-    \\\"        start = time.time()\\\\n\\\",\\n-    \\\"        train_and_log(use_mlflow=flag)\\\\n\\\",\\n-    \\\"        elapsed = time.time() - start\\\\n\\\",\\n-    \\\"        label = \\\\\\\"With MLflow\\\\\\\" if flag else \\\\\\\"No MLflow\\\\\\\"\\\\n\\\",\\n-    \\\"        print(f\\\\\\\"  \\u2022 {label:10s}: {elapsed:.3f}s\\\\\\\")\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"if __name__ == \\\\\\\"__main__\\\\\\\":\\\\n\\\",\\n-    \\\"    main()\\\"\\n-   ]\\n-  },\\n-  {\\n-   \\\"cell_type\\\": \\\"markdown\\\",\\n-   \\\"id\\\": \\\"5883f673-371e-415e-a73e-5c9c88b56fb1\\\",\\n-   \\\"metadata\\\": {},\\n-   \\\"source\\\": [\\n-    \\\"RQ2  implementation\\\"\\n-   ]\\n-  },\\n-  {\\n-   \\\"cell_type\\\": \\\"code\\\",\\n-   \\\"execution_count\\\": 96,\\n-   \\\"id\\\": \\\"57c1f653-ff09-494a-9c11-4433936f1824\\\",\\n-   \\\"metadata\\\": {},\\n-   \\\"outputs\\\": [\\n-    {\\n-     \\\"name\\\": \\\"stdout\\\",\\n-     \\\"output_type\\\": \\\"stream\\\",\\n-     \\\"text\\\": [\\n-      \\\"Requirement already satisfied: ace_tools in c:\\\\\\\\users\\\\\\\\reema\\\\\\\\anaconda3\\\\\\\\lib\\\\\\\\site-packages (0.0)\\\\n\\\"\\n-     ]\\n-    },\\n-    {\\n-     \\\"name\\\": \\\"stderr\\\",\\n-     \\\"output_type\\\": \\\"stream\\\",\\n-     \\\"text\\\": [\\n-      \\\"WARNING: There was an error checking the latest version of pip.\\\\n\\\"\\n-     ]\\n-    }\\n-   ],\\n-   \\\"source\\\": []\\n-  },\\n-  {\\n-   \\\"cell_type\\\": \\\"code\\\",\\n-   \\\"execution_count\\\": 148,\\n-   \\\"id\\\": \\\"6d07ac1c-ea80-4787-bcb9-da047d12167d\\\",\\n-   \\\"metadata\\\": {},\\n-   \\\"outputs\\\": [\\n-    {\\n-     \\\"data\\\": {\\n-      \\\"text/plain\\\": [\\n-       \\\"Index(['run_id', 'param_bootstrap', 'param_ccp_alpha', 'param_class_weight',\\\\n\\\",\\n-       \\\"       'param_columns_raw', 'param_criterion', 'param_database.description',\\\\n\\\",\\n-       \\\"       'param_database.id', 'param_database.name', 'param_database.owner',\\\\n\\\",\\n-       \\\"       'param_dataset.authors', 'param_dataset.doi', 'param_dataset.published',\\\\n\\\",\\n-       \\\"       'param_dataset.publisher', 'param_dataset.title',\\\\n\\\",\\n-       \\\"       'param_dropped_columns', 'param_feature_names',\\\\n\\\",\\n-       \\\"       'param_matplotlib_version', 'param_max_depth', 'param_max_features',\\\\n\\\",\\n-       \\\"       'param_max_leaf_nodes', 'param_max_samples',\\\\n\\\",\\n-       \\\"       'param_min_impurity_decrease', 'param_min_samples_leaf',\\\\n\\\",\\n-       \\\"       'param_min_samples_split', 'param_min_weight_fraction_leaf',\\\\n\\\",\\n-       \\\"       'param_numpy_version', 'param_n_estimators', 'param_n_features',\\\\n\\\",\\n-       \\\"       'param_n_features_final', 'param_n_jobs', 'param_n_records',\\\\n\\\",\\n-       \\\"       'param_n_test_samples', 'param_n_train_samples', 'param_oob_score',\\\\n\\\",\\n-       \\\"       'param_os_platform', 'param_pandas_version', 'param_python_version',\\\\n\\\",\\n-       \\\"       'param_random_state', 'param_retrieval_time', 'param_seaborn_version',\\\\n\\\",\\n-       \\\"       'param_shap_version', 'param_sklearn_version', 'param_test_size',\\\\n\\\",\\n-       \\\"       'param_verbose', 'param_warm_start', 'metric_accuracy',\\\\n\\\",\\n-       \\\"       'metric_accuracy_score_X_test', 'metric_dbrepo.num_deletes',\\\\n\\\",\\n-       \\\"       'metric_dbrepo.num_inserts', 'metric_dbrepo.row_count_end',\\\\n\\\",\\n-       \\\"       'metric_dbrepo.row_count_start', 'metric_f1_macro',\\\\n\\\",\\n-       \\\"       'metric_f1_score_X_test', 'metric_precision_macro',\\\\n\\\",\\n-       \\\"       'metric_precision_score_X_test', 'metric_recall_macro',\\\\n\\\",\\n-       \\\"       'metric_recall_score_X_test', 'metric_roc_auc',\\\\n\\\",\\n-       \\\"       'metric_roc_auc_score_X_test', 'metric_training_accuracy_score',\\\\n\\\",\\n-       \\\"       'metric_training_f1_score', 'metric_training_log_loss',\\\\n\\\",\\n-       \\\"       'metric_training_precision_score', 'metric_training_recall_score',\\\\n\\\",\\n-       \\\"       'metric_training_roc_auc', 'metric_training_score', 'tag_dataset_id',\\\\n\\\",\\n-       \\\"       'tag_dataset_name', 'tag_dataset_version', 'tag_data_source',\\\\n\\\",\\n-       \\\"       'tag_dbrepo.admin_email', 'tag_dbrepo.base_url',\\\\n\\\",\\n-       \\\"       'tag_dbrepo.granularity', 'tag_dbrepo.protocol_version',\\\\n\\\",\\n-       \\\"       'tag_dbrepo.repository_name', 'tag_dbrepo.table_last_modified',\\\\n\\\",\\n-       \\\"       'tag_estimator_class', 'tag_estimator_name',\\\\n\\\",\\n-       \\\"       'tag_git_current_commit_hash', 'tag_git_previous_commit_hash',\\\\n\\\",\\n-       \\\"       'tag_git__current_commit_url', 'tag_mlflow.log-model.history',\\\\n\\\",\\n-       \\\"       'tag_mlflow.runName', 'tag_mlflow.source.name',\\\\n\\\",\\n-       \\\"       'tag_mlflow.source.type', 'tag_mlflow.user', 'tag_model_name',\\\\n\\\",\\n-       \\\"       'tag_notebook_name', 'tag_target_name', 'tag_training_end_time',\\\\n\\\",\\n-       \\\"       'tag_training_start_time'],\\\\n\\\",\\n-       \\\"      dtype='object')\\\"\\n-      ]\\n-     },\\n-     \\\"execution_count\\\": 148,\\n-     \\\"metadata\\\": {},\\n-     \\\"output_type\\\": \\\"execute_result\\\"\\n-    }\\n-   ],\\n-   \\\"source\\\": [\\n-    \\\"import pandas as pd\\\\n\\\",\\n-    \\\"import glob\\\\n\\\",\\n-    \\\"import json\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# Load all run summary JSON files\\\\n\\\",\\n-    \\\"files = glob.glob(\\\\\\\"MODEL_PROVENANCE/*_run_summary.json\\\\\\\")\\\\n\\\",\\n-    \\\"rows = []\\\\n\\\",\\n-    \\\"for f in files:\\\\n\\\",\\n-    \\\"    with open(f) as fh:\\\\n\\\",\\n-    \\\"        summary = json.load(fh)\\\\n\\\",\\n-    \\\"    # Flatten parameters and metrics\\\\n\\\",\\n-    \\\"    row = {\\\\\\\"run_id\\\\\\\": summary[\\\\\\\"run_id\\\\\\\"]}\\\\n\\\",\\n-    \\\"    row.update({f\\\\\\\"param_{k}\\\\\\\": v for k, v in summary.get(\\\\\\\"params\\\\\\\", {}).items()})\\\\n\\\",\\n-    \\\"    row.update({f\\\\\\\"metric_{k}\\\\\\\": v for k, v in summary.get(\\\\\\\"metrics\\\\\\\", {}).items()})\\\\n\\\",\\n-    \\\"    row.update({f\\\\\\\"tag_{k}\\\\\\\": v for k, v in summary.get(\\\\\\\"tags\\\\\\\", {}).items()})\\\\n\\\",\\n-    \\\"    rows.append(row)\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# Create DataFrame\\\\n\\\",\\n-    \\\"df = pd.DataFrame(rows)\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# Display the DataFrame\\\\n\\\",\\n-    \\\"df.columns\\\\n\\\"\\n-   ]\\n-  },\\n-  {\\n-   \\\"cell_type\\\": \\\"markdown\\\",\\n-   \\\"id\\\": \\\"ba148da6-6ce5-45cf-a985-f164a53c969b\\\",\\n-   \\\"metadata\\\": {},\\n-   \\\"source\\\": [\\n-    \\\"1) Tracing preprocessing steps\\\\n\\\",\\n-    \\\":\\\\n\\\",\\n-    \\\"Here are the top 4 Iris\\u2010focused preprocessing\\u2010tracing use cases I\\u2019d tackle first:\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"Reconstruct a run\\u2019s exact preprocessing\\\\n\\\",\\n-    \\\"Fetch a run\\u2019s run_id, columns_raw, dropped_columns, feature_names and test_size so you can replay the exact data pull & split.\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"Feature\\u2010drop impact analysis\\\\n\\\",\\n-    \\\"Identify runs where one or more measurements (e.g. petalwidthcm) were dropped and compare their test accuracies.\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"Best feature subset discovery\\\\n\\\",\\n-    \\\"Group runs by which features they used (sepals only vs petals only vs both) and rank them by test F1 or accuracy.\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"Common steps in high-accuracy runs\\\\n\\\",\\n-    \\\"Filter for runs with accuracy_score_X_test \\u2265 0.95 and list the shared preprocessing settings (dropped columns, test_size, etc.).\\\"\\n-   ]\\n-  },\\n-  {\\n-   \\\"cell_type\\\": \\\"code\\\",\\n-   \\\"execution_count\\\": 145,\\n-   \\\"id\\\": \\\"6e147555-afbf-4bba-b6da-7e90ff391920\\\",\\n-   \\\"metadata\\\": {},\\n-   \\\"outputs\\\": [\\n-    {\\n-     \\\"name\\\": \\\"stderr\\\",\\n-     \\\"output_type\\\": \\\"stream\\\",\\n-     \\\"text\\\": [\\n-      \\\"2025/04/24 12:07:41 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'de1ce9f489f949cc8121489b43ce6ea0', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\\\\n\\\"\\n-     ]\\n-    },\\n-    {\\n-     \\\"data\\\": {\\n-      \\\"application/vnd.jupyter.widget-view+json\\\": {\\n-       \\\"model_id\\\": \\\"0dfb26a56b7a498982e572a07bb00f76\\\",\\n-       \\\"version_major\\\": 2,\\n-       \\\"version_minor\\\": 0\\n-      },\\n-      \\\"text/plain\\\": [\\n-       \\\"Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]\\\"\\n-      ]\\n-     },\\n-     \\\"metadata\\\": {},\\n-     \\\"output_type\\\": \\\"display_data\\\"\\n-    },\\n-    {\\n-     \\\"name\\\": \\\"stderr\\\",\\n-     \\\"output_type\\\": \\\"stream\\\",\\n-     \\\"text\\\": [\\n-      \\\"2025/04/24 12:07:47 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '138898a600114e3d9ab06790184b5356', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\\\\n\\\"\\n-     ]\\n-    },\\n-    {\\n-     \\\"data\\\": {\\n-      \\\"application/vnd.jupyter.widget-view+json\\\": {\\n-       \\\"model_id\\\": \\\"ed955ab5fb7246d0aa6f829e1f0062cf\\\",\\n-       \\\"version_major\\\": 2,\\n-       \\\"version_minor\\\": 0\\n-      },\\n-      \\\"text/plain\\\": [\\n-       \\\"Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]\\\"\\n-      ]\\n-     },\\n-     \\\"metadata\\\": {},\\n-     \\\"output_type\\\": \\\"display_data\\\"\\n-    },\\n-    {\\n-     \\\"name\\\": \\\"stderr\\\",\\n-     \\\"output_type\\\": \\\"stream\\\",\\n-     \\\"text\\\": [\\n-      \\\"2025/04/24 12:07:53 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '54d74e4b53e148fb94fa7338ab205c64', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\\\\n\\\"\\n-     ]\\n-    },\\n-    {\\n-     \\\"data\\\": {\\n-      \\\"application/vnd.jupyter.widget-view+json\\\": {\\n-       \\\"model_id\\\": \\\"0afb20462ac648bcb6b9d84e4953ae37\\\",\\n-       \\\"version_major\\\": 2,\\n-       \\\"version_minor\\\": 0\\n-      },\\n-      \\\"text/plain\\\": [\\n-       \\\"Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]\\\"\\n-      ]\\n-     },\\n-     \\\"metadata\\\": {},\\n-     \\\"output_type\\\": \\\"display_data\\\"\\n-    },\\n-    {\\n-     \\\"name\\\": \\\"stderr\\\",\\n-     \\\"output_type\\\": \\\"stream\\\",\\n-     \\\"text\\\": [\\n-      \\\"2025/04/24 12:07:59 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '3aaa56d6cd9f4f99917238af626c09e8', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\\\\n\\\"\\n-     ]\\n-    },\\n-    {\\n-     \\\"data\\\": {\\n-      \\\"application/vnd.jupyter.widget-view+json\\\": {\\n-       \\\"model_id\\\": \\\"76d774e068fd42a19c1c85f664375d00\\\",\\n-       \\\"version_major\\\": 2,\\n-       \\\"version_minor\\\": 0\\n-      },\\n-      \\\"text/plain\\\": [\\n-       \\\"Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]\\\"\\n-      ]\\n-     },\\n-     \\\"metadata\\\": {},\\n-     \\\"output_type\\\": \\\"display_data\\\"\\n-    },\\n-    {\\n-     \\\"name\\\": \\\"stderr\\\",\\n-     \\\"output_type\\\": \\\"stream\\\",\\n-     \\\"text\\\": [\\n-      \\\"2025/04/24 12:08:05 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '28c0256f7c314fb3a85beee8b915b84f', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\\\\n\\\"\\n-     ]\\n-    },\\n-    {\\n-     \\\"data\\\": {\\n-      \\\"application/vnd.jupyter.widget-view+json\\\": {\\n-       \\\"model_id\\\": \\\"da728bc463814a9b9ab9b03226e7d758\\\",\\n-       \\\"version_major\\\": 2,\\n-       \\\"version_minor\\\": 0\\n-      },\\n-      \\\"text/plain\\\": [\\n-       \\\"Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]\\\"\\n-      ]\\n-     },\\n-     \\\"metadata\\\": {},\\n-     \\\"output_type\\\": \\\"display_data\\\"\\n-    },\\n-    {\\n-     \\\"name\\\": \\\"stdout\\\",\\n-     \\\"output_type\\\": \\\"stream\\\",\\n-     \\\"text\\\": [\\n-      \\\"[{'dropped_feature': 'sepallengthcm', 'baseline_acc': 1.0, 'dropped_acc': 1.0, 'impact': 0.0}, {'dropped_feature': 'sepalwidthcm', 'baseline_acc': 1.0, 'dropped_acc': 1.0, 'impact': 0.0}, {'dropped_feature': 'petallengthcm', 'baseline_acc': 1.0, 'dropped_acc': 0.9666666666666667, 'impact': 0.0333}, {'dropped_feature': 'petalwidthcm', 'baseline_acc': 1.0, 'dropped_acc': 0.9666666666666667, 'impact': 0.0333}]\\\\n\\\"\\n-     ]\\n-    }\\n-   ],\\n-   \\\"source\\\": [\\n-    \\\"import pandas as pd\\\\n\\\",\\n-    \\\"import glob\\\\n\\\",\\n-    \\\"import json\\\\n\\\",\\n-    \\\"from typing import List, Dict, Any\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# --------------------------------------------\\\\n\\\",\\n-    \\\"# Query functions for Iris provenance exploration\\\\n\\\",\\n-    \\\"# --------------------------------------------\\\\n\\\",\\n-    \\\"import ast\\\\n\\\",\\n-    \\\"import pandas as pd\\\\n\\\",\\n-    \\\"from sklearn.datasets import load_iris\\\\n\\\",\\n-    \\\"from sklearn.ensemble import RandomForestClassifier\\\\n\\\",\\n-    \\\"from sklearn.model_selection import train_test_split\\\\n\\\",\\n-    \\\"from sklearn.metrics import accuracy_score\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# Helper to get the \\u201cofficial\\u201d feature_names from your summary DF\\\\n\\\",\\n-    \\\"def _get_all_features(df):\\\\n\\\",\\n-    \\\"    # assumes every row has the same param_feature_names\\\\n\\\",\\n-    \\\"    raw = df.loc[0, 'param_feature_names']\\\\n\\\",\\n-    \\\"    return ast.literal_eval(raw)\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# Train & eval RF on just these columns of Iris\\\\n\\\",\\n-    \\\"def evaluate_subset(features, test_size=0.2, random_state=42, n_estimators=200):\\\\n\\\",\\n-    \\\"    iris = load_iris()\\\\n\\\",\\n-    \\\"    X = pd.DataFrame(iris.data, columns=iris.feature_names)\\\\n\\\",\\n-    \\\"    # map sklearn\\u2019s names to your param names, e.g. \\\\\\\"sepal length (cm)\\\\\\\" \\u2192 \\\\\\\"sepallengthcm\\\\\\\"\\\\n\\\",\\n-    \\\"    canon = _get_all_features(df)\\\\n\\\",\\n-    \\\"    mapping = dict(zip(iris.feature_names, canon))\\\\n\\\",\\n-    \\\"    X = X.rename(columns=mapping)\\\\n\\\",\\n-    \\\"    X_sub = X[features]\\\\n\\\",\\n-    \\\"    y = iris.target\\\\n\\\",\\n-    \\\"    Xtr, Xte, ytr, yte = train_test_split(X_sub, y, test_size=test_size, random_state=random_state)\\\\n\\\",\\n-    \\\"    m = RandomForestClassifier(n_estimators=n_estimators, random_state=random_state)\\\\n\\\",\\n-    \\\"    m.fit(Xtr, ytr)\\\\n\\\",\\n-    \\\"    return accuracy_score(yte, m.predict(Xte))\\\\n\\\",\\n-    \\\"def trace_preprocessing(df, run_id=None):\\\\n\\\",\\n-    \\\"    cols = ['run_id',\\\\n\\\",\\n-    \\\"            'param_dataset.title',\\\\n\\\",\\n-    \\\"            'param_columns_raw',\\\\n\\\",\\n-    \\\"            'param_dropped_columns',\\\\n\\\",\\n-    \\\"            'param_feature_names',\\\\n\\\",\\n-    \\\"            'param_dataset.authors', 'param_dataset.doi', 'param_dataset.published',\\\\n\\\",\\n-    \\\"            'param_test_size',\\\\n\\\",\\n-    \\\"            'param_criterion',\\\\n\\\",\\n-    \\\"            'param_max_depth','param_max_leaf_nodes', 'param_max_samples',\\\\n\\\",\\n-    \\\"           'metric_accuracy','metric_f1_macro','metric_roc_auc']\\\\n\\\",\\n-    \\\"    if run_id is None:\\\\n\\\",\\n-    \\\"        subset = df.loc[:, cols]\\\\n\\\",\\n-    \\\"    else:\\\\n\\\",\\n-    \\\"        subset = df.loc[df['run_id'] == run_id, cols]\\\\n\\\",\\n-    \\\"    return subset.to_dict(orient='records')\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"def drop_impact(df, feature, **_):\\\\n\\\",\\n-    \\\"    all_feats = _get_all_features(df)\\\\n\\\",\\n-    \\\"    baseline = evaluate_subset(all_feats)\\\\n\\\",\\n-    \\\"    without = [f for f in all_feats if f!=feature]\\\\n\\\",\\n-    \\\"    dropped = evaluate_subset(without)\\\\n\\\",\\n-    \\\"    return {\\\\n\\\",\\n-    \\\"      'dropped_feature': feature,\\\\n\\\",\\n-    \\\"      'baseline_acc': baseline,\\\\n\\\",\\n-    \\\"      'dropped_acc': dropped,\\\\n\\\",\\n-    \\\"      'impact': baseline - dropped\\\\n\\\",\\n-    \\\"    }\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"def drop_impact_all(df: pd.DataFrame) -> List[Dict[str, Any]]:\\\\n\\\",\\n-    \\\"    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\",\\n-    \\\"    Compute drop-impact for every feature in the dataset.\\\\n\\\",\\n-    \\\"    Returns list of dicts with dropped_feature, baseline_acc, dropped_acc, impact.\\\\n\\\",\\n-    \\\"    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\",\\n-    \\\"    feats = _get_all_features(df)\\\\n\\\",\\n-    \\\"    baseline = evaluate_subset(feats)\\\\n\\\",\\n-    \\\"    summary = []\\\\n\\\",\\n-    \\\"    for feat in feats:\\\\n\\\",\\n-    \\\"        without = [f for f in feats if f != feat]\\\\n\\\",\\n-    \\\"        acc = evaluate_subset(without)\\\\n\\\",\\n-    \\\"        summary.append({\\\\n\\\",\\n-    \\\"            'dropped_feature': feat,\\\\n\\\",\\n-    \\\"            'baseline_acc': baseline,\\\\n\\\",\\n-    \\\"            'dropped_acc': acc,\\\\n\\\",\\n-    \\\"            'impact': round(baseline - acc, 4)\\\\n\\\",\\n-    \\\"        })\\\\n\\\",\\n-    \\\"    return summary\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"def best_feature_subset(df, features, **_):\\\\n\\\",\\n-    \\\"    acc = evaluate_subset(features)\\\\n\\\",\\n-    \\\"    return {'features': features, 'accuracy': acc}\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"def common_high_accuracy(df: pd.DataFrame, threshold: float = 0.95) -> List[Dict[str, Any]]:\\\\n\\\",\\n-    \\\"    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\",\\n-    \\\"    Filter runs with test accuracy >= threshold and list unique shared preprocessing settings.\\\\n\\\",\\n-    \\\"    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\",\\n-    \\\"    high = df[df['metric_accuracy_score_X_test'] >= threshold]\\\\n\\\",\\n-    \\\"    cols = ['param_dropped_columns', 'param_test_size', 'param_feature_names']\\\\n\\\",\\n-    \\\"    return high[cols].drop_duplicates().to_dict(orient='records')\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# --------------------------------------------\\\\n\\\",\\n-    \\\"# Use Case Registry with parameter order for minimal input\\\\n\\\",\\n-    \\\"# --------------------------------------------\\\\n\\\",\\n-    \\\"USE_CASES = {\\\\n\\\",\\n-    \\\"    'trace_preprocessing': {\\\\n\\\",\\n-    \\\"        'func': trace_preprocessing,\\\\n\\\",\\n-    \\\"        'required_params': [],            # none strictly required\\\\n\\\",\\n-    \\\"        'optional_params': ['run_id'],    # run_id can be supplied or not\\\\n\\\",\\n-    \\\"    },\\\\n\\\",\\n-    \\\"    'drop_impact': {\\\\n\\\",\\n-    \\\"        'func': drop_impact,\\\\n\\\",\\n-    \\\"        'required_params': ['feature'],\\\\n\\\",\\n-    \\\"        'optional_params': [],\\\\n\\\",\\n-    \\\"    },\\\\n\\\",\\n-    \\\"     'drop_impact_all': {\\\\n\\\",\\n-    \\\"        'func': drop_impact_all,\\\\n\\\",\\n-    \\\"        'required_params': [],\\\\n\\\",\\n-    \\\"        'optional_params': [],\\\\n\\\",\\n-    \\\"    },\\\\n\\\",\\n-    \\\"    'best_feature_subset': {\\\\n\\\",\\n-    \\\"        'func': best_feature_subset,\\\\n\\\",\\n-    \\\"        'required_params': ['features'],\\\\n\\\",\\n-    \\\"        'optional_params': [],\\\\n\\\",\\n-    \\\"    },\\\\n\\\",\\n-    \\\"    'common_high_accuracy': {\\\\n\\\",\\n-    \\\"        'func': common_high_accuracy,\\\\n\\\",\\n-    \\\"        'required_params': ['threshold'],\\\\n\\\",\\n-    \\\"        'optional_params': [],\\\\n\\\",\\n-    \\\"    },\\\\n\\\",\\n-    \\\"}\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"def call_use_case(df, use_case_name, **kwargs):\\\\n\\\",\\n-    \\\"    if use_case_name not in USE_CASES:\\\\n\\\",\\n-    \\\"        raise ValueError(f\\\\\\\"Unknown use case: {use_case_name}\\\\\\\")\\\\n\\\",\\n-    \\\"    case = USE_CASES[use_case_name]\\\\n\\\",\\n-    \\\"    func = case['func']\\\\n\\\",\\n-    \\\"    # check required\\\\n\\\",\\n-    \\\"    missing = [p for p in case['required_params'] if p not in kwargs]\\\\n\\\",\\n-    \\\"    if missing:\\\\n\\\",\\n-    \\\"        raise ValueError(f\\\\\\\"{use_case_name} missing required params: {missing}\\\\\\\")\\\\n\\\",\\n-    \\\"    # build args\\\\n\\\",\\n-    \\\"    args = {p: kwargs[p] for p in case['required_params']}\\\\n\\\",\\n-    \\\"    for p in case['optional_params']:\\\\n\\\",\\n-    \\\"        args[p] = kwargs.get(p)\\\\n\\\",\\n-    \\\"    return func(df, **args)\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# --------------------------------------------\\\\n\\\",\\n-    \\\"# Example Usage\\\\n\\\",\\n-    \\\"# --------------------------------------------\\\\n\\\",\\n-    \\\"if __name__ == '__main__':\\\\n\\\",\\n-    \\\"   # # 1) trace_preprocessing for all runs\\\\n\\\",\\n-    \\\"    # print(call_use_case(df, 'trace_preprocessing'))\\\\n\\\",\\n-    \\\"    \\\\n\\\",\\n-    \\\"    # 2) trace_preprocessing for a single run_id\\\\n\\\",\\n-    \\\"    # print(call_use_case(df, 'trace_preprocessing', run_id='361daa12f99f4129a06cd20b78dd6fa7'))\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    # 5) common_high_accuracy\\\\n\\\",\\n-    \\\"    # print(call_use_case(df, 'common_high_accuracy', threshold=0.99))\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    # 4) Best\\u2010subset on just sepals:\\\\n\\\",\\n-    \\\"    # print(call_use_case(df, 'best_feature_subset', features=['sepallengthcm','sepalwidthcm']))\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    # 3) Drop\\u2010impact for \\u201cpetallengthcm\\u201d:\\\\n\\\",\\n-    \\\"    # print(call_use_case(df, 'drop_impact', feature='petallengthcm'))\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    print(call_use_case(df, 'drop_impact_all'))  # summary for all features\\\\n\\\"\\n-   ]\\n-  },\\n-  {\\n-   \\\"cell_type\\\": \\\"markdown\\\",\\n-   \\\"id\\\": \\\"96f912d6-0e84-4155-858a-9668bef63f6e\\\",\\n-   \\\"metadata\\\": {},\\n-   \\\"source\\\": [\\n-    \\\" \\u2022 Detecting models trained with deprecated code versions\\\\n\\\",\\n-    \\\" \\u2022 Mapping models to specific datasets used during training\\\"\\n-   ]\\n-  },\\n-  {\\n-   \\\"cell_type\\\": \\\"code\\\",\\n-   \\\"execution_count\\\": 150,\\n-   \\\"id\\\": \\\"34a02c9a-5459-478f-a3c5-7f7a58ff22b0\\\",\\n-   \\\"metadata\\\": {},\\n-   \\\"outputs\\\": [\\n-    {\\n-     \\\"name\\\": \\\"stdout\\\",\\n-     \\\"output_type\\\": \\\"stream\\\",\\n-     \\\"text\\\": [\\n-      \\\"[{'param_dataset.doi': '10.5281/ZENODO.1404173',\\\\n\\\",\\n-      \\\"  'param_dataset.published': '2018-8-27',\\\\n\\\",\\n-      \\\"  'param_dataset.publisher': 'Zenodo',\\\\n\\\",\\n-      \\\"  'param_dataset.title': 'Scikit-Learn Iris',\\\\n\\\",\\n-      \\\"  'run_id': '361daa12f99f4129a06cd20b78dd6fa7',\\\\n\\\",\\n-      \\\"  'tag_model_name': 'RandomForest_Iris_v20250423_230422'},\\\\n\\\",\\n-      \\\" {'param_dataset.doi': '10.5281/ZENODO.1404173',\\\\n\\\",\\n-      \\\"  'param_dataset.published': '2018-8-27',\\\\n\\\",\\n-      \\\"  'param_dataset.publisher': 'Zenodo',\\\\n\\\",\\n-      \\\"  'param_dataset.title': 'Scikit-Learn Iris',\\\\n\\\",\\n-      \\\"  'run_id': 'dcb65d2337a047fdac192b7fe9c8e3d6',\\\\n\\\",\\n-      \\\"  'tag_model_name': 'RandomForest_Iris_v20250424_110923'},\\\\n\\\",\\n-      \\\" {'param_dataset.doi': '10.5281/ZENODO.1404173',\\\\n\\\",\\n-      \\\"  'param_dataset.published': '2018-8-27',\\\\n\\\",\\n-      \\\"  'param_dataset.publisher': 'Zenodo',\\\\n\\\",\\n-      \\\"  'param_dataset.title': 'Scikit-Learn Iris',\\\\n\\\",\\n-      \\\"  'run_id': 'e519450da74a4abbb11e6d00901bd435',\\\\n\\\",\\n-      \\\"  'tag_model_name': 'RandomForest_Iris_v20250424_111946'}]\\\\n\\\"\\n-     ]\\n-    }\\n-   ],\\n-   \\\"source\\\": [\\n-    \\\"# --------------------------------------------\\\\n\\\",\\n-    \\\"# New Query Functions\\\\n\\\",\\n-    \\\"# --------------------------------------------\\\\n\\\",\\n-    \\\"from typing import List, Dict, Any\\\\n\\\",\\n-    \\\"from pprint import pprint\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"def detect_deprecated_code(df: pd.DataFrame, deprecated_commits: List[str], **_) -> List[Dict[str, Any]]:\\\\n\\\",\\n-    \\\"    # we know the column is called tag_git_current_commit_hash\\\\n\\\",\\n-    \\\"    commit_col = 'tag_git_current_commit_hash'\\\\n\\\",\\n-    \\\"    if commit_col not in df.columns:\\\\n\\\",\\n-    \\\"        raise KeyError(f\\\\\\\"Missing {commit_col} in DataFrame\\\\\\\")\\\\n\\\",\\n-    \\\"    out = df[df[commit_col].isin(deprecated_commits)]\\\\n\\\",\\n-    \\\"    # include run_id and notebook/runName for context\\\\n\\\",\\n-    \\\"    cols = ['run_id', commit_col, 'tag_notebook_name', 'tag_mlflow.runName']\\\\n\\\",\\n-    \\\"    # drop any that don\\u2019t exist\\\\n\\\",\\n-    \\\"    cols = [c for c in cols if c in df.columns]\\\\n\\\",\\n-    \\\"    return out[cols].to_dict(orient='records')\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"def map_model_dataset(df: pd.DataFrame, **_) -> List[Dict[str, Any]]:\\\\n\\\",\\n-    \\\"    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\",\\n-    \\\"    For each run, return its model name (or run_id) alongside the dataset\\\\n\\\",\\n-    \\\"    title, DOI, published date and publisher.\\\\n\\\",\\n-    \\\"    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\",\\n-    \\\"    # pick whichever model-name column you have\\\\n\\\",\\n-    \\\"    model_col = 'tag_model_name' if 'tag_model_name' in df.columns else 'param_model_name'\\\\n\\\",\\n-    \\\"    cols = [\\\\n\\\",\\n-    \\\"        'run_id',\\\\n\\\",\\n-    \\\"        model_col,\\\\n\\\",\\n-    \\\"        'param_dataset.title',\\\\n\\\",\\n-    \\\"        'param_dataset.doi',\\\\n\\\",\\n-    \\\"        'param_dataset.published',\\\\n\\\",\\n-    \\\"        'param_dataset.publisher'\\\\n\\\",\\n-    \\\"    ]\\\\n\\\",\\n-    \\\"    # filter out any columns that don\\u2019t actually exist\\\\n\\\",\\n-    \\\"    cols = [c for c in cols if c in df.columns]\\\\n\\\",\\n-    \\\"    return df[cols].to_dict(orient='records')\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# --------------------------------------------\\\\n\\\",\\n-    \\\"# Extend Use-Case Registry\\\\n\\\",\\n-    \\\"# --------------------------------------------\\\\n\\\",\\n-    \\\"USE_CASES.update({\\\\n\\\",\\n-    \\\"    'detect_deprecated_code': {\\\\n\\\",\\n-    \\\"        'func': detect_deprecated_code,\\\\n\\\",\\n-    \\\"        'required_params': ['deprecated_commits'],\\\\n\\\",\\n-    \\\"        'optional_params': []\\\\n\\\",\\n-    \\\"    },\\\\n\\\",\\n-    \\\"    'map_model_dataset': {\\\\n\\\",\\n-    \\\"        'func': map_model_dataset,\\\\n\\\",\\n-    \\\"        'required_params': [],\\\\n\\\",\\n-    \\\"        'optional_params': []\\\\n\\\",\\n-    \\\"    },\\\\n\\\",\\n-    \\\"})\\\\n\\\",\\n-    \\\"# 1) Detect runs on deprecated commits:\\\\n\\\",\\n-    \\\"deprecated = [\\\\n\\\",\\n-    \\\"    \\\\\\\"a07434af4f547af2daab044d6873eb7081162293\\\\\\\",\\\\n\\\",\\n-    \\\"    \\\\\\\"d329c92495e196ec0f39fbb19dfdd367131a77d9\\\\\\\"\\\\n\\\",\\n-    \\\"]\\\\n\\\",\\n-    \\\"# print(call_use_case(df, \\\\\\\"detect_deprecated_code\\\\\\\", deprecated_commits=deprecated))\\\\n\\\",\\n-    \\\"pprint(call_use_case(df, 'map_model_dataset'))\\\\n\\\"\\n-   ]\\n-  },\\n-  {\\n-   \\\"cell_type\\\": \\\"code\\\",\\n-   \\\"execution_count\\\": null,\\n-   \\\"id\\\": \\\"da6f16e7-4086-4867-b326-5d6eecab2439\\\",\\n-   \\\"metadata\\\": {},\\n-   \\\"outputs\\\": [],\\n-   \\\"source\\\": []\\n-  },\\n-  {\\n-   \\\"cell_type\\\": \\\"markdown\\\",\\n-   \\\"id\\\": \\\"c52607ad-5849-4a2d-97ef-e8fc1ca16dc7\\\",\\n-   \\\"metadata\\\": {},\\n-   \\\"source\\\": [\\n-    \\\"Goal: Notify collaborators who have forked the GitHub repo if their fork is outdated (i.e., behind the current commit used to train a model).\\\"\\n-   ]\\n-  },\\n-  {\\n-   \\\"cell_type\\\": \\\"markdown\\\",\\n-   \\\"id\\\": \\\"f29c8ad9-00bb-4c1e-ac3b-ee6861991acd\\\",\\n-   \\\"metadata\\\": {},\\n-   \\\"source\\\": [\\n-    \\\"\\ud83e\\udde0 What We Need\\\\n\\\",\\n-    \\\"Current training run\\u2019s Git commit hash\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"GitHub API to fetch all forks of your repo\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"Compare each fork\\u2019s main or master branch head commit\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"Create an issue on their fork or on your repo tagging them if they\\u2019re behind\\\"\\n-   ]\\n-  },\\n-  {\\n-   \\\"cell_type\\\": \\\"markdown\\\",\\n-   \\\"id\\\": \\\"c72bed50-fb56-442d-a21e-bb7991892d07\\\",\\n-   \\\"metadata\\\": {},\\n-   \\\"source\\\": [\\n-    \\\"Option 1 (Practical): Notify via issues on your own repo\\\"\\n-   ]\\n-  },\\n-  {\\n-   \\\"cell_type\\\": \\\"code\\\",\\n-   \\\"execution_count\\\": 72,\\n-   \\\"id\\\": \\\"852f147c-9d0a-4d7f-a4ab-545d1e2375fb\\\",\\n-   \\\"metadata\\\": {\\n-    \\\"scrolled\\\": true\\n-   },\\n-   \\\"outputs\\\": [\\n-    {\\n-     \\\"name\\\": \\\"stdin\\\",\\n-     \\\"output_type\\\": \\\"stream\\\",\\n-     \\\"text\\\": [\\n-      \\\"Do you want to notify collaborators whose forks are behind? (y/N):  y\\\\n\\\"\\n-     ]\\n-    },\\n-    {\\n-     \\\"name\\\": \\\"stdout\\\",\\n-     \\\"output_type\\\": \\\"stream\\\",\\n-     \\\"text\\\": [\\n-      \\\"Latest upstream commit: d329c92495e196ec0f39fbb19dfdd367131a77d9\\\\n\\\",\\n-      \\\"\\u2192 POST https://api.github.com/repos/reema-dass26/REPO/issues\\\\n\\\",\\n-      \\\"\\u2192 Status code: 201\\\\n\\\",\\n-      \\\"\\u2192 Response headers: {'Date': 'Wed, 23 Apr 2025 21:06:22 GMT', 'Content-Type': 'application/json; charset=utf-8', 'Content-Length': '2383', 'Cache-Control': 'private, max-age=60, s-maxage=60', 'Vary': 'Accept, Authorization, Cookie, X-GitHub-OTP,Accept-Encoding, Accept, X-Requested-With', 'ETag': '\\\\\\\"7c97cb7c44baea87eb39ae010093b566d7f13db1ddd45bd81e7d8a302d330834\\\\\\\"', 'X-OAuth-Scopes': 'admin:enterprise, admin:gpg_key, admin:org, admin:org_hook, admin:public_key, admin:repo_hook, admin:ssh_signing_key, audit_log, codespace, copilot, delete:packages, delete_repo, gist, notifications, project, repo, user, workflow, write:discussion, write:network_configurations, write:packages', 'X-Accepted-OAuth-Scopes': '', 'Location': 'https://api.github.com/repos/reema-dass26/REPO/issues/3', 'X-GitHub-Media-Type': 'github.v3; format=json', 'x-github-api-version-selected': '2022-11-28', 'X-RateLimit-Limit': '5000', 'X-RateLimit-Remaining': '4996', 'X-RateLimit-Reset': '1745445980', 'X-RateLimit-Used': '4', 'X-RateLimit-Resource': 'core', 'Access-Control-Expose-Headers': 'ETag, Link, Location, Retry-After, X-GitHub-OTP, X-RateLimit-Limit, X-RateLimit-Remaining, X-RateLimit-Used, X-RateLimit-Resource, X-RateLimit-Reset, X-OAuth-Scopes, X-Accepted-OAuth-Scopes, X-Poll-Interval, X-GitHub-Media-Type, X-GitHub-SSO, X-GitHub-Request-Id, Deprecation, Sunset', 'Access-Control-Allow-Origin': '*', 'Strict-Transport-Security': 'max-age=31536000; includeSubdomains; preload', 'X-Frame-Options': 'deny', 'X-Content-Type-Options': 'nosniff', 'X-XSS-Protection': '0', 'Referrer-Policy': 'origin-when-cross-origin, strict-origin-when-cross-origin', 'Content-Security-Policy': \\\\\\\"default-src 'none'\\\\\\\", 'Server': 'github.com', 'X-GitHub-Request-Id': 'FF27:37CDC4:28E48A1:29EB238:6809564E'}\\\\n\\\",\\n-      \\\"\\u2192 Response JSON: {'url': 'https://api.github.com/repos/reema-dass26/REPO/issues/3', 'repository_url': 'https://api.github.com/repos/reema-dass26/REPO', 'labels_url': 'https://api.github.com/repos/reema-dass26/REPO/issues/3/labels{/name}', 'comments_url': 'https://api.github.com/repos/reema-dass26/REPO/issues/3/comments', 'events_url': 'https://api.github.com/repos/reema-dass26/REPO/issues/3/events', 'html_url': 'https://github.com/reema-dass26/REPO/issues/3', 'id': 3015254398, 'node_id': 'I_kwDOOdxdk86zuSF-', 'number': 3, 'title': '\\ud83d\\udd14 Notification: Your fork is behind the latest commit', 'user': {'login': 'reema-dass26', 'id': 106236154, 'node_id': 'U_kgDOBlUI-g', 'avatar_url': 'https://avatars.githubusercontent.com/u/106236154?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/reema-dass26', 'html_url': 'https://github.com/reema-dass26', 'followers_url': 'https://api.github.com/users/reema-dass26/followers', 'following_url': 'https://api.github.com/users/reema-dass26/following{/other_user}', 'gists_url': 'https://api.github.com/users/reema-dass26/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/reema-dass26/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/reema-dass26/subscriptions', 'organizations_url': 'https://api.github.com/users/reema-dass26/orgs', 'repos_url': 'https://api.github.com/users/reema-dass26/repos', 'events_url': 'https://api.github.com/users/reema-dass26/events{/privacy}', 'received_events_url': 'https://api.github.com/users/reema-dass26/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}, 'labels': [], 'state': 'open', 'locked': False, 'assignee': None, 'assignees': [], 'milestone': None, 'comments': 0, 'created_at': '2025-04-23T21:06:22Z', 'updated_at': '2025-04-23T21:06:22Z', 'closed_at': None, 'author_association': 'OWNER', 'sub_issues_summary': {'total': 0, 'completed': 0, 'percent_completed': 0}, 'active_lock_reason': None, 'body': 'Hi @reemagdass,\\\\\\\\n\\\\\\\\nThe main repository has been updated to commit `d329c92495e196ec0f39fbb19dfdd367131a77d9`.\\\\\\\\nPlease consider pulling the latest changes to stay in sync.\\\\\\\\n\\\\\\\\nThanks!', 'closed_by': None, 'reactions': {'url': 'https://api.github.com/repos/reema-dass26/REPO/issues/3/reactions', 'total_count': 0, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 0}, 'timeline_url': 'https://api.github.com/repos/reema-dass26/REPO/issues/3/timeline', 'performed_via_github_app': None, 'state_reason': None}\\\\n\\\",\\n-      \\\"\\u2192 html_url field: https://github.com/reema-dass26/REPO/issues/3\\\\n\\\"\\n-     ]\\n-    }\\n-   ],\\n-   \\\"source\\\": [\\n-    \\\"import requests\\\\n\\\",\\n-    \\\"import os\\\\n\\\",\\n-    \\\"from dotenv import load_dotenv\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"def notify_outdated_forks():\\\\n\\\",\\n-    \\\"    load_dotenv()\\\\n\\\",\\n-    \\\"    token     = os.getenv(\\\\\\\"THESIS_TOKEN\\\\\\\")\\\\n\\\",\\n-    \\\"    owner     = \\\\\\\"reema-dass26\\\\\\\"\\\\n\\\",\\n-    \\\"    repo      = \\\\\\\"REPO\\\\\\\"\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    if not token:\\\\n\\\",\\n-    \\\"        print(\\\\\\\"\\u26a0\\ufe0f GITHUB_TOKEN not set.\\\\\\\")\\\\n\\\",\\n-    \\\"        return\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    headers = {\\\\n\\\",\\n-    \\\"        \\\\\\\"Authorization\\\\\\\": f\\\\\\\"token {token}\\\\\\\",\\\\n\\\",\\n-    \\\"        \\\\\\\"Accept\\\\\\\":        \\\\\\\"application/vnd.github.v3+json\\\\\\\"\\\\n\\\",\\n-    \\\"    }\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    # 1) Get latest upstream commit\\\\n\\\",\\n-    \\\"    main_commits = requests.get(\\\\n\\\",\\n-    \\\"        f\\\\\\\"https://api.github.com/repos/{owner}/{repo}/commits\\\\\\\",\\\\n\\\",\\n-    \\\"        headers=headers,\\\\n\\\",\\n-    \\\"        params={\\\\\\\"per_page\\\\\\\": 1}\\\\n\\\",\\n-    \\\"    )\\\\n\\\",\\n-    \\\"    main_commits.raise_for_status()\\\\n\\\",\\n-    \\\"    new_commit_hash = main_commits.json()[0][\\\\\\\"sha\\\\\\\"]\\\\n\\\",\\n-    \\\"    print(f\\\\\\\"Latest upstream commit: {new_commit_hash}\\\\\\\")\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    # 2) List forks\\\\n\\\",\\n-    \\\"    forks_resp = requests.get(f\\\\\\\"https://api.github.com/repos/{owner}/{repo}/forks\\\\\\\", headers=headers)\\\\n\\\",\\n-    \\\"    forks_resp.raise_for_status()\\\\n\\\",\\n-    \\\"    forks = forks_resp.json()\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    # 3) Compare each fork\\\\n\\\",\\n-    \\\"    outdated = []\\\\n\\\",\\n-    \\\"    for fork in forks:\\\\n\\\",\\n-    \\\"        fork_owner = fork[\\\\\\\"owner\\\\\\\"][\\\\\\\"login\\\\\\\"]\\\\n\\\",\\n-    \\\"        fork_comm = requests.get(\\\\n\\\",\\n-    \\\"            fork[\\\\\\\"url\\\\\\\"] + \\\\\\\"/commits\\\\\\\",\\\\n\\\",\\n-    \\\"            headers=headers,\\\\n\\\",\\n-    \\\"            params={\\\\\\\"per_page\\\\\\\": 1}\\\\n\\\",\\n-    \\\"        )\\\\n\\\",\\n-    \\\"        if fork_comm.status_code != 200:\\\\n\\\",\\n-    \\\"            print(f\\\\\\\"\\u00a0\\u00a0\\u2013 could not fetch commits for {fork_owner}, skipping.\\\\\\\")\\\\n\\\",\\n-    \\\"            continue\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"        fork_sha = fork_comm.json()[0][\\\\\\\"sha\\\\\\\"]\\\\n\\\",\\n-    \\\"        if fork_sha != new_commit_hash:\\\\n\\\",\\n-    \\\"            outdated.append(f\\\\\\\"@{fork_owner}\\\\\\\")\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    # 4) Open an issue if any are behind\\\\n\\\",\\n-    \\\"    if outdated:\\\\n\\\",\\n-    \\\"        title = \\\\\\\"\\ud83d\\udd14 Notification: Your fork is behind the latest commit\\\\\\\"\\\\n\\\",\\n-    \\\"        body  = (\\\\n\\\",\\n-    \\\"            f\\\\\\\"Hi {' '.join(outdated)},\\\\\\\\n\\\\\\\\n\\\\\\\"\\\\n\\\",\\n-    \\\"            f\\\\\\\"The main repository has been updated to commit `{new_commit_hash}`.\\\\\\\\n\\\\\\\"\\\\n\\\",\\n-    \\\"            \\\\\\\"Please consider pulling the latest changes to stay in sync.\\\\\\\\n\\\\\\\\n\\\\\\\"\\\\n\\\",\\n-    \\\"            \\\\\\\"Thanks!\\\\\\\"\\\\n\\\",\\n-    \\\"        )\\\\n\\\",\\n-    \\\"        issues_url = f\\\\\\\"https://api.github.com/repos/{owner}/{repo}/issues\\\\\\\"\\\\n\\\",\\n-    \\\"        resp = requests.post(\\\\n\\\",\\n-    \\\"        issues_url,\\\\n\\\",\\n-    \\\"        headers=headers,\\\\n\\\",\\n-    \\\"        json={\\\\\\\"title\\\\\\\": title, \\\\\\\"body\\\\\\\": body}\\\\n\\\",\\n-    \\\"    )\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    # DEBUGGING OUTPUT\\\\n\\\",\\n-    \\\"    print(f\\\\\\\"\\u2192 POST {issues_url}\\\\\\\")\\\\n\\\",\\n-    \\\"    print(\\\\\\\"\\u2192 Status code:\\\\\\\", resp.status_code)\\\\n\\\",\\n-    \\\"    print(\\\\\\\"\\u2192 Response headers:\\\\\\\", resp.headers)\\\\n\\\",\\n-    \\\"    try:\\\\n\\\",\\n-    \\\"        data = resp.json()\\\\n\\\",\\n-    \\\"        print(\\\\\\\"\\u2192 Response JSON:\\\\\\\", data)\\\\n\\\",\\n-    \\\"        print(\\\\\\\"\\u2192 html_url field:\\\\\\\", data.get(\\\\\\\"html_url\\\\\\\"))\\\\n\\\",\\n-    \\\"    except ValueError:\\\\n\\\",\\n-    \\\"        print(\\\\\\\"\\u2192 No JSON response body; raw text:\\\\\\\", resp.text)\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"if __name__ == \\\\\\\"__main__\\\\\\\":\\\\n\\\",\\n-    \\\"    answer = input(\\\\\\\"Do you want to notify collaborators whose forks are behind? (y/N): \\\\\\\").strip().lower()\\\\n\\\",\\n-    \\\"    if answer in (\\\\\\\"y\\\\\\\", \\\\\\\"yes\\\\\\\"):\\\\n\\\",\\n-    \\\"        notify_outdated_forks()\\\\n\\\",\\n-    \\\"    else:\\\\n\\\",\\n-    \\\"        print(\\\\\\\"No action taken.\\\\\\\")\\\\n\\\"\\n-   ]\\n-  },\\n-  {\\n-   \\\"cell_type\\\": \\\"markdown\\\",\\n-   \\\"id\\\": \\\"cda31f16-fbe9-40ce-ac1b-9ebc898c8820\\\",\\n-   \\\"metadata\\\": {},\\n-   \\\"source\\\": [\\n-    \\\"INVENIO INTEGRETION\\\"\\n-   ]\\n-  },\\n-  {\\n-   \\\"cell_type\\\": \\\"code\\\",\\n-   \\\"execution_count\\\": 168,\\n-   \\\"id\\\": \\\"7dd71550-7221-41db-b64d-f87ffead2f56\\\",\\n-   \\\"metadata\\\": {},\\n-   \\\"outputs\\\": [\\n-    {\\n-     \\\"name\\\": \\\"stdout\\\",\\n-     \\\"output_type\\\": \\\"stream\\\",\\n-     \\\"text\\\": [\\n-      \\\"\\u2705 Draft created: 7vtzn-76461\\\\n\\\",\\n-      \\\"  \\u2022 Uploaded plots/RandomForest_Iris_v20250423_230422/confusion_matrix.png\\\\n\\\",\\n-      \\\"\\u274c PUT failed (400): {\\\\\\\"status\\\\\\\": 400, \\\\\\\"message\\\\\\\": \\\\\\\"The file upload transfer failed, please try again.\\\\\\\"}\\\\n\\\"\\n-     ]\\n-    },\\n-    {\\n-     \\\"ename\\\": \\\"HTTPError\\\",\\n-     \\\"evalue\\\": \\\"400 Client Error: BAD REQUEST for url: https://127.0.0.1:5000/api/records/7vtzn-76461/draft/files/plots/RandomForest_Iris_v20250423_230422/confusion_matrix.png/content\\\",\\n-     \\\"output_type\\\": \\\"error\\\",\\n-     \\\"traceback\\\": [\\n-      \\\"\\\\u001b[1;31m---------------------------------------------------------------------------\\\\u001b[0m\\\",\\n-      \\\"\\\\u001b[1;31mHTTPError\\\\u001b[0m                                 Traceback (most recent call last)\\\",\\n-      \\\"Cell \\\\u001b[1;32mIn[168], line 84\\\\u001b[0m\\\\n\\\\u001b[0;32m     82\\\\u001b[0m \\\\u001b[38;5;28;01mif\\\\u001b[39;00m \\\\u001b[38;5;129;01mnot\\\\u001b[39;00m r2\\\\u001b[38;5;241m.\\\\u001b[39mok:\\\\n\\\\u001b[0;32m     83\\\\u001b[0m     \\\\u001b[38;5;28mprint\\\\u001b[39m(\\\\u001b[38;5;124mf\\\\u001b[39m\\\\u001b[38;5;124m\\\\\\\"\\\\u001b[39m\\\\u001b[38;5;124m\\u274c PUT failed (\\\\u001b[39m\\\\u001b[38;5;132;01m{\\\\u001b[39;00mr2\\\\u001b[38;5;241m.\\\\u001b[39mstatus_code\\\\u001b[38;5;132;01m}\\\\u001b[39;00m\\\\u001b[38;5;124m): \\\\u001b[39m\\\\u001b[38;5;132;01m{\\\\u001b[39;00mr2\\\\u001b[38;5;241m.\\\\u001b[39mtext\\\\u001b[38;5;132;01m}\\\\u001b[39;00m\\\\u001b[38;5;124m\\\\\\\"\\\\u001b[39m)\\\\n\\\\u001b[1;32m---> 84\\\\u001b[0m     \\\\u001b[43mr2\\\\u001b[49m\\\\u001b[38;5;241;43m.\\\\u001b[39;49m\\\\u001b[43mraise_for_status\\\\u001b[49m\\\\u001b[43m(\\\\u001b[49m\\\\u001b[43m)\\\\u001b[49m\\\\n\\\\u001b[0;32m     86\\\\u001b[0m \\\\u001b[38;5;66;03m# 2c) commit the upload\\\\u001b[39;00m\\\\n\\\\u001b[0;32m     87\\\\u001b[0m r3 \\\\u001b[38;5;241m=\\\\u001b[39m requests\\\\u001b[38;5;241m.\\\\u001b[39mpost(\\\\n\\\\u001b[0;32m     88\\\\u001b[0m     commit_url,\\\\n\\\\u001b[0;32m     89\\\\u001b[0m     headers\\\\u001b[38;5;241m=\\\\u001b[39mH_JSON,\\\\n\\\\u001b[0;32m     90\\\\u001b[0m     verify\\\\u001b[38;5;241m=\\\\u001b[39mVERIFY_SSL\\\\n\\\\u001b[0;32m     91\\\\u001b[0m )\\\\n\\\",\\n-      \\\"File \\\\u001b[1;32m~\\\\\\\\anaconda3\\\\\\\\Lib\\\\\\\\site-packages\\\\\\\\requests\\\\\\\\models.py:1021\\\\u001b[0m, in \\\\u001b[0;36mResponse.raise_for_status\\\\u001b[1;34m(self)\\\\u001b[0m\\\\n\\\\u001b[0;32m   1016\\\\u001b[0m     http_error_msg \\\\u001b[38;5;241m=\\\\u001b[39m (\\\\n\\\\u001b[0;32m   1017\\\\u001b[0m         \\\\u001b[38;5;124mf\\\\u001b[39m\\\\u001b[38;5;124m\\\\\\\"\\\\u001b[39m\\\\u001b[38;5;132;01m{\\\\u001b[39;00m\\\\u001b[38;5;28mself\\\\u001b[39m\\\\u001b[38;5;241m.\\\\u001b[39mstatus_code\\\\u001b[38;5;132;01m}\\\\u001b[39;00m\\\\u001b[38;5;124m Server Error: \\\\u001b[39m\\\\u001b[38;5;132;01m{\\\\u001b[39;00mreason\\\\u001b[38;5;132;01m}\\\\u001b[39;00m\\\\u001b[38;5;124m for url: \\\\u001b[39m\\\\u001b[38;5;132;01m{\\\\u001b[39;00m\\\\u001b[38;5;28mself\\\\u001b[39m\\\\u001b[38;5;241m.\\\\u001b[39murl\\\\u001b[38;5;132;01m}\\\\u001b[39;00m\\\\u001b[38;5;124m\\\\\\\"\\\\u001b[39m\\\\n\\\\u001b[0;32m   1018\\\\u001b[0m     )\\\\n\\\\u001b[0;32m   1020\\\\u001b[0m \\\\u001b[38;5;28;01mif\\\\u001b[39;00m http_error_msg:\\\\n\\\\u001b[1;32m-> 1021\\\\u001b[0m     \\\\u001b[38;5;28;01mraise\\\\u001b[39;00m HTTPError(http_error_msg, response\\\\u001b[38;5;241m=\\\\u001b[39m\\\\u001b[38;5;28mself\\\\u001b[39m)\\\\n\\\",\\n-      \\\"\\\\u001b[1;31mHTTPError\\\\u001b[0m: 400 Client Error: BAD REQUEST for url: https://127.0.0.1:5000/api/records/7vtzn-76461/draft/files/plots/RandomForest_Iris_v20250423_230422/confusion_matrix.png/content\\\"\\n-     ]\\n-    }\\n-   ],\\n-   \\\"source\\\": [\\n-    \\\"import os\\\\n\\\",\\n-    \\\"import json\\\\n\\\",\\n-    \\\"import requests\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n-    \\\"# Configuration\\\\n\\\",\\n-    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n-    \\\"API_BASE   = \\\\\\\"https://127.0.0.1:5000\\\\\\\"\\\\n\\\",\\n-    \\\"TOKEN      = \\\\\\\"ZctHtk65umtROkzOFq2Ot7WbJTqz46q5wS8uAYc2WOMry2c2rT9CqaRbySNp\\\\\\\"\\\\n\\\",\\n-    \\\"VERIFY_SSL = False  # only for local dev with self-signed cert\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"H_JSON = {\\\\n\\\",\\n-    \\\"    \\\\\\\"Accept\\\\\\\":        \\\\\\\"application/json\\\\\\\",\\\\n\\\",\\n-    \\\"    \\\\\\\"Content-Type\\\\\\\":  \\\\\\\"application/json\\\\\\\",\\\\n\\\",\\n-    \\\"    \\\\\\\"Authorization\\\\\\\": f\\\\\\\"Bearer {TOKEN}\\\\\\\",\\\\n\\\",\\n-    \\\"}\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"H_OCTET = {\\\\n\\\",\\n-    \\\"    \\\\\\\"Content-Type\\\\\\\":  \\\\\\\"application/octet-stream\\\\\\\",\\\\n\\\",\\n-    \\\"    \\\\\\\"Authorization\\\\\\\": f\\\\\\\"Bearer {TOKEN}\\\\\\\",\\\\n\\\",\\n-    \\\"}\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"TO_UPLOAD = [\\\\\\\"plots\\\\\\\", \\\\\\\"MODEL_PROVENANCE\\\\\\\"]\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n-    \\\"# 1) Create a new draft record\\\\n\\\",\\n-    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n-    \\\"payload = {\\\\n\\\",\\n-    \\\"    \\\\\\\"title\\\\\\\":       \\\\\\\"My trained ML model\\\\\\\",\\\\n\\\",\\n-    \\\"    \\\\\\\"description\\\\\\\": \\\\\\\"Unstructured metadata + artifacts for RandomForest on Iris\\\\\\\",\\\\n\\\",\\n-    \\\"    \\\\\\\"creator\\\\\\\":     \\\\\\\"Reema Dass\\\\\\\"\\\\n\\\",\\n-    \\\"}\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"r = requests.post(\\\\n\\\",\\n-    \\\"    f\\\\\\\"{API_BASE}/api/records\\\\\\\",\\\\n\\\",\\n-    \\\"    headers=H_JSON,\\\\n\\\",\\n-    \\\"    data=json.dumps(payload),\\\\n\\\",\\n-    \\\"    verify=VERIFY_SSL\\\\n\\\",\\n-    \\\")\\\\n\\\",\\n-    \\\"r.raise_for_status()\\\\n\\\",\\n-    \\\"draft = r.json()\\\\n\\\",\\n-    \\\"recid = draft[\\\\\\\"id\\\\\\\"]\\\\n\\\",\\n-    \\\"links = draft[\\\\\\\"links\\\\\\\"]\\\\n\\\",\\n-    \\\"print(f\\\\\\\"\\u2705 Draft created: {recid}\\\\\\\")\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n-    \\\"# 2) Walk & upload every file\\\\n\\\",\\n-    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n-    \\\"for topdir in TO_UPLOAD:\\\\n\\\",\\n-    \\\"    if not os.path.isdir(topdir):\\\\n\\\",\\n-    \\\"        print(f\\\\\\\"\\u26a0\\ufe0f  Skipping missing folder {topdir}\\\\\\\")\\\\n\\\",\\n-    \\\"        continue\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    for root, _, files in os.walk(topdir):\\\\n\\\",\\n-    \\\"        for fn in files:\\\\n\\\",\\n-    \\\"            local_path = os.path.join(root, fn)\\\\n\\\",\\n-    \\\"            # build a key that preserves the folder structure under topdir\\\\n\\\",\\n-    \\\"            key = os.path.relpath(local_path, start=os.path.dirname(topdir)).replace(\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\"/\\\\\\\")\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"            # 2a) register the file key\\\\n\\\",\\n-    \\\"            register_body = [{\\\\\\\"key\\\\\\\": key}]\\\\n\\\",\\n-    \\\"            r1 = requests.post(\\\\n\\\",\\n-    \\\"                links[\\\\\\\"files\\\\\\\"],\\\\n\\\",\\n-    \\\"                headers=H_JSON,\\\\n\\\",\\n-    \\\"                data=json.dumps(register_body),\\\\n\\\",\\n-    \\\"                verify=VERIFY_SSL\\\\n\\\",\\n-    \\\"            )\\\\n\\\",\\n-    \\\"            r1.raise_for_status()\\\\n\\\",\\n-    \\\"            entry = r1.json()[\\\\\\\"entries\\\\\\\"][0]\\\\n\\\",\\n-    \\\"            upload_url = entry[\\\\\\\"links\\\\\\\"][\\\\\\\"content\\\\\\\"]\\\\n\\\",\\n-    \\\"            commit_url = entry[\\\\\\\"links\\\\\\\"][\\\\\\\"commit\\\\\\\"]\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"            # 2b) read & PUT the file in one shot so Content-Length is set\\\\n\\\",\\n-    \\\"            with open(local_path, \\\\\\\"rb\\\\\\\") as fp:\\\\n\\\",\\n-    \\\"                data = fp.read()\\\\n\\\",\\n-    \\\"            r2 = requests.put(\\\\n\\\",\\n-    \\\"                upload_url,\\\\n\\\",\\n-    \\\"                headers=H_OCTET,\\\\n\\\",\\n-    \\\"                data=data,\\\\n\\\",\\n-    \\\"                verify=VERIFY_SSL\\\\n\\\",\\n-    \\\"            )\\\\n\\\",\\n-    \\\"            if not r2.ok:\\\\n\\\",\\n-    \\\"                print(f\\\\\\\"\\u274c PUT failed ({r2.status_code}): {r2.text}\\\\\\\")\\\\n\\\",\\n-    \\\"                r2.raise_for_status()\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"            # 2c) commit the upload\\\\n\\\",\\n-    \\\"            r3 = requests.post(\\\\n\\\",\\n-    \\\"                commit_url,\\\\n\\\",\\n-    \\\"                headers=H_JSON,\\\\n\\\",\\n-    \\\"                verify=VERIFY_SSL\\\\n\\\",\\n-    \\\"            )\\\\n\\\",\\n-    \\\"            r3.raise_for_status()\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"            print(f\\\\\\\"  \\u2022 Uploaded {key}\\\\\\\")\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n-    \\\"# 3) Publish the draft\\\\n\\\",\\n-    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n-    \\\"rpub = requests.post(\\\\n\\\",\\n-    \\\"    links[\\\\\\\"publish\\\\\\\"],\\\\n\\\",\\n-    \\\"    headers=H_JSON,\\\\n\\\",\\n-    \\\"    verify=VERIFY_SSL\\\\n\\\",\\n-    \\\")\\\\n\\\",\\n-    \\\"rpub.raise_for_status()\\\\n\\\",\\n-    \\\"print(f\\\\\\\"\\u2705 Published: {rpub.json()['id']}\\\\\\\")\\\\n\\\"\\n-   ]\\n-  },\\n-  {\\n-   \\\"cell_type\\\": \\\"code\\\",\\n-   \\\"execution_count\\\": 209,\\n-   \\\"id\\\": \\\"d1809a51-46a4-4595-bea9-da64e86f9b87\\\",\\n-   \\\"metadata\\\": {},\\n-   \\\"outputs\\\": [\\n-    {\\n-     \\\"name\\\": \\\"stdout\\\",\\n-     \\\"output_type\\\": \\\"stream\\\",\\n-     \\\"text\\\": [\\n-      \\\"Collecting streamlit-agraph\\\\n\\\",\\n-      \\\"  Obtaining dependency information for streamlit-agraph from https://files.pythonhosted.org/packages/b9/80/8a666e700332a9fe19e458678c95fab4d78340251d2f12da7d2ad915458a/streamlit_agraph-0.0.45-py3-none-any.whl.metadata\\\\n\\\",\\n-      \\\"  Downloading streamlit_agraph-0.0.45-py3-none-any.whl.metadata (3.2 kB)\\\\n\\\",\\n-      \\\"Requirement already satisfied: streamlit>=0.63 in c:\\\\\\\\users\\\\\\\\reema\\\\\\\\anaconda3\\\\\\\\lib\\\\\\\\site-packages (from streamlit-agraph) (1.44.1)\\\\n\\\",\\n-      \\\"Requirement already satisfied: networkx>=2.5 in c:\\\\\\\\users\\\\\\\\reema\\\\\\\\anaconda3\\\\\\\\lib\\\\\\\\site-packages (from streamlit-agraph) (3.1)\\\\n\\\",\\n-      \\\"Requirement already satisfied: rdflib>=6.0.2 in c:\\\\\\\\users\\\\\\\\reema\\\\\\\\anaconda3\\\\\\\\lib\\\\\\\\site-packages (from streamlit-agraph) (6.3.2)\\\\n\\\",\\n-      \\\"Requirement already satisfied: isodate<0.7.0,>=0.6.0 in c:\\\\\\\\users\\\\\\\\reema\\\\\\\\anaconda3\\\\\\\\lib\\\\\\\\site-packages (from rdflib>=6.0.2->streamlit-agraph) (0.6.1)\\\\n\\\",\\n-      \\\"Requirement already satisfied: pyparsing<4,>=2.1.0 in c:\\\\\\\\users\\\\\\\\reema\\\\\\\\anaconda3\\\\\\\\lib\\\\\\\\site-packages (from rdflib>=6.0.2->streamlit-agraph) (3.0.9)\\\\n\\\",\\n-      \\\"Requirement already satisfied: altair<6,>=4.0 in c:\\\\\\\\users\\\\\\\\reema\\\\\\\\anaconda3\\\\\\\\lib\\\\\\\\site-packages (from streamlit>=0.63->streamlit-agraph) (5.5.0)\\\\n\\\",\\n-      \\\"Requirement already satisfied: blinker<2,>=1.0.0 in c:\\\\\\\\users\\\\\\\\reema\\\\\\\\anaconda3\\\\\\\\lib\\\\\\\\site-packages (from streamlit>=0.63->streamlit-agraph) (1.9.0)\\\\n\\\",\\n-      \\\"Requirement already satisfied: cachetools<6,>=4.0 in c:\\\\\\\\users\\\\\\\\reema\\\\\\\\anaconda3\\\\\\\\lib\\\\\\\\site-packages (from streamlit>=0.63->streamlit-agraph) (5.5.2)\\\\n\\\",\\n-      \\\"Requirement already satisfied: click<9,>=7.0 in c:\\\\\\\\users\\\\\\\\reema\\\\\\\\anaconda3\\\\\\\\lib\\\\\\\\site-packages (from streamlit>=0.63->streamlit-agraph) (8.1.8)\\\\n\\\",\\n-      \\\"Requirement already satisfied: numpy<3,>=1.23 in c:\\\\\\\\users\\\\\\\\reema\\\\\\\\anaconda3\\\\\\\\lib\\\\\\\\site-packages (from streamlit>=0.63->streamlit-agraph) (1.24.4)\\\\n\\\",\\n-      \\\"Requirement already satisfied: packaging<25,>=20 in c:\\\\\\\\users\\\\\\\\reema\\\\\\\\anaconda3\\\\\\\\lib\\\\\\\\site-packages (from streamlit>=0.63->streamlit-agraph) (23.1)\\\\n\\\",\\n-      \\\"Requirement already satisfied: pandas<3,>=1.4.0 in c:\\\\\\\\users\\\\\\\\reema\\\\\\\\anaconda3\\\\\\\\lib\\\\\\\\site-packages (from streamlit>=0.63->streamlit-agraph) (2.2.3)\\\\n\\\",\\n-      \\\"Requirement already satisfied: pillow<12,>=7.1.0 in c:\\\\\\\\users\\\\\\\\reema\\\\\\\\anaconda3\\\\\\\\lib\\\\\\\\site-packages (from streamlit>=0.63->streamlit-agraph) (9.4.0)\\\\n\\\",\\n-      \\\"Requirement already satisfied: protobuf<6,>=3.20 in c:\\\\\\\\users\\\\\\\\reema\\\\\\\\anaconda3\\\\\\\\lib\\\\\\\\site-packages (from streamlit>=0.63->streamlit-agraph) (5.29.3)\\\\n\\\",\\n-      \\\"Requirement already satisfied: pyarrow>=7.0 in c:\\\\\\\\users\\\\\\\\reema\\\\\\\\anaconda3\\\\\\\\lib\\\\\\\\site-packages (from streamlit>=0.63->streamlit-agraph) (11.0.0)\\\\n\\\",\\n-      \\\"Requirement already satisfied: requests<3,>=2.27 in c:\\\\\\\\users\\\\\\\\reema\\\\\\\\anaconda3\\\\\\\\lib\\\\\\\\site-packages (from streamlit>=0.63->streamlit-agraph) (2.31.0)\\\\n\\\",\\n-      \\\"Requirement already satisfied: tenacity<10,>=8.1.0 in c:\\\\\\\\users\\\\\\\\reema\\\\\\\\anaconda3\\\\\\\\lib\\\\\\\\site-packages (from streamlit>=0.63->streamlit-agraph) (8.2.2)\\\\n\\\",\\n-      \\\"Requirement already satisfied: toml<2,>=0.10.1 in c:\\\\\\\\users\\\\\\\\reema\\\\\\\\anaconda3\\\\\\\\lib\\\\\\\\site-packages (from streamlit>=0.63->streamlit-agraph) (0.10.2)\\\\n\\\",\\n-      \\\"Requirement already satisfied: typing-extensions<5,>=4.4.0 in c:\\\\\\\\users\\\\\\\\reema\\\\\\\\anaconda3\\\\\\\\lib\\\\\\\\site-packages (from streamlit>=0.63->streamlit-agraph) (4.12.2)\\\\n\\\",\\n-      \\\"Requirement already satisfied: watchdog<7,>=2.1.5 in c:\\\\\\\\users\\\\\\\\reema\\\\\\\\anaconda3\\\\\\\\lib\\\\\\\\site-packages (from streamlit>=0.63->streamlit-agraph) (2.1.6)\\\\n\\\",\\n-      \\\"Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in c:\\\\\\\\users\\\\\\\\reema\\\\\\\\anaconda3\\\\\\\\lib\\\\\\\\site-packages (from streamlit>=0.63->streamlit-agraph) (3.1.43)\\\\n\\\",\\n-      \\\"Requirement already satisfied: pydeck<1,>=0.8.0b4 in c:\\\\\\\\users\\\\\\\\reema\\\\\\\\anaconda3\\\\\\\\lib\\\\\\\\site-packages (from streamlit>=0.63->streamlit-agraph) (0.9.1)\\\\n\\\",\\n-      \\\"Requirement already satisfied: tornado<7,>=6.0.3 in c:\\\\\\\\users\\\\\\\\reema\\\\\\\\appdata\\\\\\\\roaming\\\\\\\\python\\\\\\\\python311\\\\\\\\site-packages (from streamlit>=0.63->streamlit-agraph) (6.3.2)\\\\n\\\",\\n-      \\\"Requirement already satisfied: jinja2 in c:\\\\\\\\users\\\\\\\\reema\\\\\\\\anaconda3\\\\\\\\lib\\\\\\\\site-packages (from altair<6,>=4.0->streamlit>=0.63->streamlit-agraph) (3.1.2)\\\\n\\\",\\n-      \\\"Requirement already satisfied: jsonschema>=3.0 in c:\\\\\\\\users\\\\\\\\reema\\\\\\\\anaconda3\\\\\\\\lib\\\\\\\\site-packages (from altair<6,>=4.0->streamlit>=0.63->streamlit-agraph) (4.23.0)\\\\n\\\",\\n-      \\\"Requirement already satisfied: narwhals>=1.14.2 in c:\\\\\\\\users\\\\\\\\reema\\\\\\\\anaconda3\\\\\\\\lib\\\\\\\\site-packages (from altair<6,>=4.0->streamlit>=0.63->streamlit-agraph) (1.30.0)\\\\n\\\",\\n-      \\\"Requirement already satisfied: colorama in c:\\\\\\\\users\\\\\\\\reema\\\\\\\\appdata\\\\\\\\roaming\\\\\\\\python\\\\\\\\python311\\\\\\\\site-packages (from click<9,>=7.0->streamlit>=0.63->streamlit-agraph) (0.4.6)\\\\n\\\",\\n-      \\\"Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\\\\\\\users\\\\\\\\reema\\\\\\\\anaconda3\\\\\\\\lib\\\\\\\\site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit>=0.63->streamlit-agraph) (4.0.11)\\\\n\\\",\\n-      \\\"Requirement already satisfied: six in c:\\\\\\\\users\\\\\\\\reema\\\\\\\\anaconda3\\\\\\\\lib\\\\\\\\site-packages (from isodate<0.7.0,>=0.6.0->rdflib>=6.0.2->streamlit-agraph) (1.17.0)\\\\n\\\",\\n-      \\\"Requirement already satisfied: python-dateutil>=2.8.2 in c:\\\\\\\\users\\\\\\\\reema\\\\\\\\anaconda3\\\\\\\\lib\\\\\\\\site-packages (from pandas<3,>=1.4.0->streamlit>=0.63->streamlit-agraph) (2.9.0.post0)\\\\n\\\",\\n-      \\\"Requirement already satisfied: pytz>=2020.1 in c:\\\\\\\\users\\\\\\\\reema\\\\\\\\anaconda3\\\\\\\\lib\\\\\\\\site-packages (from pandas<3,>=1.4.0->streamlit>=0.63->streamlit-agraph) (2025.2)\\\\n\\\",\\n-      \\\"Requirement already satisfied: tzdata>=2022.7 in c:\\\\\\\\users\\\\\\\\reema\\\\\\\\anaconda3\\\\\\\\lib\\\\\\\\site-packages (from pandas<3,>=1.4.0->streamlit>=0.63->streamlit-agraph) (2025.2)\\\\n\\\",\\n-      \\\"Requirement already satisfied: charset-normalizer<4,>=2 in c:\\\\\\\\users\\\\\\\\reema\\\\\\\\anaconda3\\\\\\\\lib\\\\\\\\site-packages (from requests<3,>=2.27->streamlit>=0.63->streamlit-agraph) (2.0.4)\\\\n\\\",\\n-      \\\"Requirement already satisfied: idna<4,>=2.5 in c:\\\\\\\\users\\\\\\\\reema\\\\\\\\anaconda3\\\\\\\\lib\\\\\\\\site-packages (from requests<3,>=2.27->streamlit>=0.63->streamlit-agraph) (3.4)\\\\n\\\",\\n-      \\\"Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\\\\\\\users\\\\\\\\reema\\\\\\\\anaconda3\\\\\\\\lib\\\\\\\\site-packages (from requests<3,>=2.27->streamlit>=0.63->streamlit-agraph) (1.26.16)\\\\n\\\",\\n-      \\\"Requirement already satisfied: certifi>=2017.4.17 in c:\\\\\\\\users\\\\\\\\reema\\\\\\\\anaconda3\\\\\\\\lib\\\\\\\\site-packages (from requests<3,>=2.27->streamlit>=0.63->streamlit-agraph) (2023.7.22)\\\\n\\\",\\n-      \\\"Requirement already satisfied: smmap<6,>=3.0.1 in c:\\\\\\\\users\\\\\\\\reema\\\\\\\\anaconda3\\\\\\\\lib\\\\\\\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit>=0.63->streamlit-agraph) (5.0.1)\\\\n\\\",\\n-      \\\"Requirement already satisfied: MarkupSafe>=2.0 in c:\\\\\\\\users\\\\\\\\reema\\\\\\\\anaconda3\\\\\\\\lib\\\\\\\\site-packages (from jinja2->altair<6,>=4.0->streamlit>=0.63->streamlit-agraph) (2.1.1)\\\\n\\\",\\n-      \\\"Requirement already satisfied: attrs>=22.2.0 in c:\\\\\\\\users\\\\\\\\reema\\\\\\\\anaconda3\\\\\\\\lib\\\\\\\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.63->streamlit-agraph) (23.2.0)\\\\n\\\",\\n-      \\\"Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\\\\\\\users\\\\\\\\reema\\\\\\\\anaconda3\\\\\\\\lib\\\\\\\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.63->streamlit-agraph) (2024.10.1)\\\\n\\\",\\n-      \\\"Requirement already satisfied: referencing>=0.28.4 in c:\\\\\\\\users\\\\\\\\reema\\\\\\\\anaconda3\\\\\\\\lib\\\\\\\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.63->streamlit-agraph) (0.35.1)\\\\n\\\",\\n-      \\\"Requirement already satisfied: rpds-py>=0.7.1 in c:\\\\\\\\users\\\\\\\\reema\\\\\\\\anaconda3\\\\\\\\lib\\\\\\\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.63->streamlit-agraph) (0.22.3)\\\\n\\\",\\n-      \\\"Downloading streamlit_agraph-0.0.45-py3-none-any.whl (1.3 MB)\\\\n\\\",\\n-      \\\"   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\\\\n\\\",\\n-      \\\"    --------------------------------------- 0.0/1.3 MB 1.3 MB/s eta 0:00:02\\\\n\\\",\\n-      \\\"   ------------------- -------------------- 0.7/1.3 MB 10.2 MB/s eta 0:00:01\\\\n\\\",\\n-      \\\"   ------------------------------- -------- 1.0/1.3 MB 13.1 MB/s eta 0:00:01\\\\n\\\",\\n-      \\\"   ------------------------------- -------- 1.0/1.3 MB 13.1 MB/s eta 0:00:01\\\\n\\\",\\n-      \\\"   ------------------------------- -------- 1.0/1.3 MB 13.1 MB/s eta 0:00:01\\\\n\\\",\\n-      \\\"   ---------------------------------------- 1.3/1.3 MB 5.5 MB/s eta 0:00:00\\\\n\\\",\\n-      \\\"Installing collected packages: streamlit-agraph\\\\n\\\",\\n-      \\\"Successfully installed streamlit-agraph-0.0.45\\\\n\\\"\\n-     ]\\n-    },\\n-    {\\n-     \\\"name\\\": \\\"stderr\\\",\\n-     \\\"output_type\\\": \\\"stream\\\",\\n-     \\\"text\\\": [\\n-      \\\"WARNING: There was an error checking the latest version of pip.\\\\n\\\"\\n-     ]\\n-    }\\n-   ],\\n-   \\\"source\\\": [\\n-    \\\"!pip install streamlit-agraph\\\\n\\\"\\n-   ]\\n-  },\\n-  {\\n-   \\\"cell_type\\\": \\\"code\\\",\\n-   \\\"execution_count\\\": 169,\\n-   \\\"id\\\": \\\"962a7e5d-f305-40f1-b853-0a236b444d86\\\",\\n-   \\\"metadata\\\": {},\\n-   \\\"outputs\\\": [\\n-    {\\n-     \\\"ename\\\": \\\"FileNotFoundError\\\",\\n-     \\\"evalue\\\": \\\"[Errno 2] No such file or directory: 'MODEL_PROVENANCE/run1234.json'\\\",\\n-     \\\"output_type\\\": \\\"error\\\",\\n-     \\\"traceback\\\": [\\n-      \\\"\\\\u001b[1;31m---------------------------------------------------------------------------\\\\u001b[0m\\\",\\n-      \\\"\\\\u001b[1;31mFileNotFoundError\\\\u001b[0m                         Traceback (most recent call last)\\\",\\n-      \\\"Cell \\\\u001b[1;32mIn[169], line 37\\\\u001b[0m\\\\n\\\\u001b[0;32m     32\\\\u001b[0m     \\\\u001b[38;5;28;01mreturn\\\\u001b[39;00m json\\\\u001b[38;5;241m.\\\\u001b[39mloads(g\\\\u001b[38;5;241m.\\\\u001b[39mserialize(\\\\u001b[38;5;28mformat\\\\u001b[39m\\\\u001b[38;5;241m=\\\\u001b[39m\\\\u001b[38;5;124m\\\\\\\"\\\\u001b[39m\\\\u001b[38;5;124mjson-ld\\\\u001b[39m\\\\u001b[38;5;124m\\\\\\\"\\\\u001b[39m))\\\\n\\\\u001b[0;32m     34\\\\u001b[0m \\\\u001b[38;5;66;03m# -----------------------------------------------------------------------------\\\\u001b[39;00m\\\\n\\\\u001b[0;32m     35\\\\u001b[0m \\\\u001b[38;5;66;03m#  1) Read your raw provenance JSON\\\\u001b[39;00m\\\\n\\\\u001b[0;32m     36\\\\u001b[0m \\\\u001b[38;5;66;03m# -----------------------------------------------------------------------------\\\\u001b[39;00m\\\\n\\\\u001b[1;32m---> 37\\\\u001b[0m \\\\u001b[38;5;28;01mwith\\\\u001b[39;00m \\\\u001b[38;5;28;43mopen\\\\u001b[39;49m\\\\u001b[43m(\\\\u001b[49m\\\\u001b[38;5;124;43m\\\\\\\"\\\\u001b[39;49m\\\\u001b[38;5;124;43mMODEL_PROVENANCE/run1234.json\\\\u001b[39;49m\\\\u001b[38;5;124;43m\\\\\\\"\\\\u001b[39;49m\\\\u001b[43m)\\\\u001b[49m \\\\u001b[38;5;28;01mas\\\\u001b[39;00m fp:\\\\n\\\\u001b[0;32m     38\\\\u001b[0m     run_meta \\\\u001b[38;5;241m=\\\\u001b[39m json\\\\u001b[38;5;241m.\\\\u001b[39mload(fp)\\\\n\\\\u001b[0;32m     40\\\\u001b[0m ttl \\\\u001b[38;5;241m=\\\\u001b[39m json_to_prov_ttl(run_meta)\\\\n\\\",\\n-      \\\"File \\\\u001b[1;32m~\\\\\\\\AppData\\\\\\\\Roaming\\\\\\\\Python\\\\\\\\Python311\\\\\\\\site-packages\\\\\\\\IPython\\\\\\\\core\\\\\\\\interactiveshell.py:284\\\\u001b[0m, in \\\\u001b[0;36m_modified_open\\\\u001b[1;34m(file, *args, **kwargs)\\\\u001b[0m\\\\n\\\\u001b[0;32m    277\\\\u001b[0m \\\\u001b[38;5;28;01mif\\\\u001b[39;00m file \\\\u001b[38;5;129;01min\\\\u001b[39;00m {\\\\u001b[38;5;241m0\\\\u001b[39m, \\\\u001b[38;5;241m1\\\\u001b[39m, \\\\u001b[38;5;241m2\\\\u001b[39m}:\\\\n\\\\u001b[0;32m    278\\\\u001b[0m     \\\\u001b[38;5;28;01mraise\\\\u001b[39;00m \\\\u001b[38;5;167;01mValueError\\\\u001b[39;00m(\\\\n\\\\u001b[0;32m    279\\\\u001b[0m         \\\\u001b[38;5;124mf\\\\u001b[39m\\\\u001b[38;5;124m\\\\\\\"\\\\u001b[39m\\\\u001b[38;5;124mIPython won\\\\u001b[39m\\\\u001b[38;5;124m'\\\\u001b[39m\\\\u001b[38;5;124mt let you open fd=\\\\u001b[39m\\\\u001b[38;5;132;01m{\\\\u001b[39;00mfile\\\\u001b[38;5;132;01m}\\\\u001b[39;00m\\\\u001b[38;5;124m by default \\\\u001b[39m\\\\u001b[38;5;124m\\\\\\\"\\\\u001b[39m\\\\n\\\\u001b[0;32m    280\\\\u001b[0m         \\\\u001b[38;5;124m\\\\\\\"\\\\u001b[39m\\\\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \\\\u001b[39m\\\\u001b[38;5;124m\\\\\\\"\\\\u001b[39m\\\\n\\\\u001b[0;32m    281\\\\u001b[0m         \\\\u001b[38;5;124m\\\\\\\"\\\\u001b[39m\\\\u001b[38;5;124myou can use builtins\\\\u001b[39m\\\\u001b[38;5;124m'\\\\u001b[39m\\\\u001b[38;5;124m open.\\\\u001b[39m\\\\u001b[38;5;124m\\\\\\\"\\\\u001b[39m\\\\n\\\\u001b[0;32m    282\\\\u001b[0m     )\\\\n\\\\u001b[1;32m--> 284\\\\u001b[0m \\\\u001b[38;5;28;01mreturn\\\\u001b[39;00m \\\\u001b[43mio_open\\\\u001b[49m\\\\u001b[43m(\\\\u001b[49m\\\\u001b[43mfile\\\\u001b[49m\\\\u001b[43m,\\\\u001b[49m\\\\u001b[43m \\\\u001b[49m\\\\u001b[38;5;241;43m*\\\\u001b[39;49m\\\\u001b[43margs\\\\u001b[49m\\\\u001b[43m,\\\\u001b[49m\\\\u001b[43m \\\\u001b[49m\\\\u001b[38;5;241;43m*\\\\u001b[39;49m\\\\u001b[38;5;241;43m*\\\\u001b[39;49m\\\\u001b[43mkwargs\\\\u001b[49m\\\\u001b[43m)\\\\u001b[49m\\\\n\\\",\\n-      \\\"\\\\u001b[1;31mFileNotFoundError\\\\u001b[0m: [Errno 2] No such file or directory: 'MODEL_PROVENANCE/run1234.json'\\\"\\n-     ]\\n-    }\\n-   ],\\n-   \\\"source\\\": []\\n-  },\\n-  {\\n-   \\\"cell_type\\\": \\\"code\\\",\\n-   \\\"execution_count\\\": 207,\\n-   \\\"id\\\": \\\"31d1fd16-0257-4fbb-b20d-4b05424d67ca\\\",\\n-   \\\"metadata\\\": {},\\n-   \\\"outputs\\\": [\\n-    {\\n-     \\\"name\\\": \\\"stdout\\\",\\n-     \\\"output_type\\\": \\\"stream\\\",\\n-     \\\"text\\\": [\\n-      \\\"Collecting streamlit-option-menu\\\\n\\\",\\n-      \\\"  Obtaining dependency information for streamlit-option-menu from https://files.pythonhosted.org/packages/fd/52/2f525ad4262dc83d67297f69ec5afcee1438b9e9ae22aa318396725ddbed/streamlit_option_menu-0.4.0-py3-none-any.whl.metadata\\\\n\\\",\\n-      \\\"  Downloading streamlit_option_menu-0.4.0-py3-none-any.whl.metadata (2.5 kB)\\\\n\\\",\\n-      \\\"Requirement already satisfied: streamlit>=1.36 in c:\\\\\\\\users\\\\\\\\reema\\\\\\\\anaconda3\\\\\\\\lib\\\\\\\\site-packages (from streamlit-option-menu) (1.44.1)\\\\n\\\",\\n-      \\\"Requirement already satisfied: altair<6,>=4.0 in c:\\\\\\\\users\\\\\\\\reema\\\\\\\\anaconda3\\\\\\\\lib\\\\\\\\site-packages (from streamlit>=1.36->streamlit-option-menu) (5.5.0)\\\\n\\\",\\n-      \\\"Requirement already satisfied: blinker<2,>=1.0.0 in c:\\\\\\\\users\\\\\\\\reema\\\\\\\\anaconda3\\\\\\\\lib\\\\\\\\site-packages (from streamlit>=1.36->streamlit-option-menu) (1.9.0)\\\\n\\\",\\n-      \\\"Requirement already satisfied: cachetools<6,>=4.0 in c:\\\\\\\\users\\\\\\\\reema\\\\\\\\anaconda3\\\\\\\\lib\\\\\\\\site-packages (from streamlit>=1.36->streamlit-option-menu) (5.5.2)\\\\n\\\",\\n-      \\\"Requirement already satisfied: click<9,>=7.0 in c:\\\\\\\\users\\\\\\\\reema\\\\\\\\anaconda3\\\\\\\\lib\\\\\\\\site-packages (from streamlit>=1.36->streamlit-option-menu) (8.1.8)\\\\n\\\",\\n-      \\\"Requirement already satisfied: numpy<3,>=1.23 in c:\\\\\\\\users\\\\\\\\reema\\\\\\\\anaconda3\\\\\\\\lib\\\\\\\\site-packages (from streamlit>=1.36->streamlit-option-menu) (1.24.4)\\\\n\\\",\\n-      \\\"Requirement already satisfied: packaging<25,>=20 in c:\\\\\\\\users\\\\\\\\reema\\\\\\\\anaconda3\\\\\\\\lib\\\\\\\\site-packages (from streamlit>=1.36->streamlit-option-menu) (23.1)\\\\n\\\",\\n-      \\\"Requirement already satisfied: pandas<3,>=1.4.0 in c:\\\\\\\\users\\\\\\\\reema\\\\\\\\anaconda3\\\\\\\\lib\\\\\\\\site-packages (from streamlit>=1.36->streamlit-option-menu) (2.2.3)\\\\n\\\",\\n-      \\\"Requirement already satisfied: pillow<12,>=7.1.0 in c:\\\\\\\\users\\\\\\\\reema\\\\\\\\anaconda3\\\\\\\\lib\\\\\\\\site-packages (from streamlit>=1.36->streamlit-option-menu) (9.4.0)\\\\n\\\",\\n-      \\\"Requirement already satisfied: protobuf<6,>=3.20 in c:\\\\\\\\users\\\\\\\\reema\\\\\\\\anaconda3\\\\\\\\lib\\\\\\\\site-packages (from streamlit>=1.36->streamlit-option-menu) (5.29.3)\\\\n\\\",\\n-      \\\"Requirement already satisfied: pyarrow>=7.0 in c:\\\\\\\\users\\\\\\\\reema\\\\\\\\anaconda3\\\\\\\\lib\\\\\\\\site-packages (from streamlit>=1.36->streamlit-option-menu) (11.0.0)\\\\n\\\",\\n-      \\\"Requirement already satisfied: requests<3,>=2.27 in c:\\\\\\\\users\\\\\\\\reema\\\\\\\\anaconda3\\\\\\\\lib\\\\\\\\site-packages (from streamlit>=1.36->streamlit-option-menu) (2.31.0)\\\\n\\\",\\n-      \\\"Requirement already satisfied: tenacity<10,>=8.1.0 in c:\\\\\\\\users\\\\\\\\reema\\\\\\\\anaconda3\\\\\\\\lib\\\\\\\\site-packages (from streamlit>=1.36->streamlit-option-menu) (8.2.2)\\\\n\\\",\\n-      \\\"Requirement already satisfied: toml<2,>=0.10.1 in c:\\\\\\\\users\\\\\\\\reema\\\\\\\\anaconda3\\\\\\\\lib\\\\\\\\site-packages (from streamlit>=1.36->streamlit-option-menu) (0.10.2)\\\\n\\\",\\n-      \\\"Requirement already satisfied: typing-extensions<5,>=4.4.0 in c:\\\\\\\\users\\\\\\\\reema\\\\\\\\anaconda3\\\\\\\\lib\\\\\\\\site-packages (from streamlit>=1.36->streamlit-option-menu) (4.12.2)\\\\n\\\",\\n-      \\\"Requirement already satisfied: watchdog<7,>=2.1.5 in c:\\\\\\\\users\\\\\\\\reema\\\\\\\\anaconda3\\\\\\\\lib\\\\\\\\site-packages (from streamlit>=1.36->streamlit-option-menu) (2.1.6)\\\\n\\\",\\n-      \\\"Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in c:\\\\\\\\users\\\\\\\\reema\\\\\\\\anaconda3\\\\\\\\lib\\\\\\\\site-packages (from streamlit>=1.36->streamlit-option-menu) (3.1.43)\\\\n\\\",\\n-      \\\"Requirement already satisfied: pydeck<1,>=0.8.0b4 in c:\\\\\\\\users\\\\\\\\reema\\\\\\\\anaconda3\\\\\\\\lib\\\\\\\\site-packages (from streamlit>=1.36->streamlit-option-menu) (0.9.1)\\\\n\\\",\\n-      \\\"Requirement already satisfied: tornado<7,>=6.0.3 in c:\\\\\\\\users\\\\\\\\reema\\\\\\\\appdata\\\\\\\\roaming\\\\\\\\python\\\\\\\\python311\\\\\\\\site-packages (from streamlit>=1.36->streamlit-option-menu) (6.3.2)\\\\n\\\",\\n-      \\\"Requirement already satisfied: jinja2 in c:\\\\\\\\users\\\\\\\\reema\\\\\\\\anaconda3\\\\\\\\lib\\\\\\\\site-packages (from altair<6,>=4.0->streamlit>=1.36->streamlit-option-menu) (3.1.2)\\\\n\\\",\\n-      \\\"Requirement already satisfied: jsonschema>=3.0 in c:\\\\\\\\users\\\\\\\\reema\\\\\\\\anaconda3\\\\\\\\lib\\\\\\\\site-packages (from altair<6,>=4.0->streamlit>=1.36->streamlit-option-menu) (4.23.0)\\\\n\\\",\\n-      \\\"Requirement already satisfied: narwhals>=1.14.2 in c:\\\\\\\\users\\\\\\\\reema\\\\\\\\anaconda3\\\\\\\\lib\\\\\\\\site-packages (from altair<6,>=4.0->streamlit>=1.36->streamlit-option-menu) (1.30.0)\\\\n\\\",\\n-      \\\"Requirement already satisfied: colorama in c:\\\\\\\\users\\\\\\\\reema\\\\\\\\appdata\\\\\\\\roaming\\\\\\\\python\\\\\\\\python311\\\\\\\\site-packages (from click<9,>=7.0->streamlit>=1.36->streamlit-option-menu) (0.4.6)\\\\n\\\",\\n-      \\\"Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\\\\\\\users\\\\\\\\reema\\\\\\\\anaconda3\\\\\\\\lib\\\\\\\\site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit>=1.36->streamlit-option-menu) (4.0.11)\\\\n\\\",\\n-      \\\"Requirement already satisfied: python-dateutil>=2.8.2 in c:\\\\\\\\users\\\\\\\\reema\\\\\\\\anaconda3\\\\\\\\lib\\\\\\\\site-packages (from pandas<3,>=1.4.0->streamlit>=1.36->streamlit-option-menu) (2.9.0.post0)\\\\n\\\",\\n-      \\\"Requirement already satisfied: pytz>=2020.1 in c:\\\\\\\\users\\\\\\\\reema\\\\\\\\anaconda3\\\\\\\\lib\\\\\\\\site-packages (from pandas<3,>=1.4.0->streamlit>=1.36->streamlit-option-menu) (2025.2)\\\\n\\\",\\n-      \\\"Requirement already satisfied: tzdata>=2022.7 in c:\\\\\\\\users\\\\\\\\reema\\\\\\\\anaconda3\\\\\\\\lib\\\\\\\\site-packages (from pandas<3,>=1.4.0->streamlit>=1.36->streamlit-option-menu) (2025.2)\\\\n\\\",\\n-      \\\"Requirement already satisfied: charset-normalizer<4,>=2 in c:\\\\\\\\users\\\\\\\\reema\\\\\\\\anaconda3\\\\\\\\lib\\\\\\\\site-packages (from requests<3,>=2.27->streamlit>=1.36->streamlit-option-menu) (2.0.4)\\\\n\\\",\\n-      \\\"Requirement already satisfied: idna<4,>=2.5 in c:\\\\\\\\users\\\\\\\\reema\\\\\\\\anaconda3\\\\\\\\lib\\\\\\\\site-packages (from requests<3,>=2.27->streamlit>=1.36->streamlit-option-menu) (3.4)\\\\n\\\",\\n-      \\\"Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\\\\\\\users\\\\\\\\reema\\\\\\\\anaconda3\\\\\\\\lib\\\\\\\\site-packages (from requests<3,>=2.27->streamlit>=1.36->streamlit-option-menu) (1.26.16)\\\\n\\\",\\n-      \\\"Requirement already satisfied: certifi>=2017.4.17 in c:\\\\\\\\users\\\\\\\\reema\\\\\\\\anaconda3\\\\\\\\lib\\\\\\\\site-packages (from requests<3,>=2.27->streamlit>=1.36->streamlit-option-menu) (2023.7.22)\\\\n\\\",\\n-      \\\"Requirement already satisfied: smmap<6,>=3.0.1 in c:\\\\\\\\users\\\\\\\\reema\\\\\\\\anaconda3\\\\\\\\lib\\\\\\\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit>=1.36->streamlit-option-menu) (5.0.1)\\\\n\\\",\\n-      \\\"Requirement already satisfied: MarkupSafe>=2.0 in c:\\\\\\\\users\\\\\\\\reema\\\\\\\\anaconda3\\\\\\\\lib\\\\\\\\site-packages (from jinja2->altair<6,>=4.0->streamlit>=1.36->streamlit-option-menu) (2.1.1)\\\\n\\\",\\n-      \\\"Requirement already satisfied: attrs>=22.2.0 in c:\\\\\\\\users\\\\\\\\reema\\\\\\\\anaconda3\\\\\\\\lib\\\\\\\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=1.36->streamlit-option-menu) (23.2.0)\\\\n\\\",\\n-      \\\"Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\\\\\\\users\\\\\\\\reema\\\\\\\\anaconda3\\\\\\\\lib\\\\\\\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=1.36->streamlit-option-menu) (2024.10.1)\\\\n\\\",\\n-      \\\"Requirement already satisfied: referencing>=0.28.4 in c:\\\\\\\\users\\\\\\\\reema\\\\\\\\anaconda3\\\\\\\\lib\\\\\\\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=1.36->streamlit-option-menu) (0.35.1)\\\\n\\\",\\n-      \\\"Requirement already satisfied: rpds-py>=0.7.1 in c:\\\\\\\\users\\\\\\\\reema\\\\\\\\anaconda3\\\\\\\\lib\\\\\\\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=1.36->streamlit-option-menu) (0.22.3)\\\\n\\\",\\n-      \\\"Requirement already satisfied: six>=1.5 in c:\\\\\\\\users\\\\\\\\reema\\\\\\\\anaconda3\\\\\\\\lib\\\\\\\\site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit>=1.36->streamlit-option-menu) (1.17.0)\\\\n\\\",\\n-      \\\"Downloading streamlit_option_menu-0.4.0-py3-none-any.whl (829 kB)\\\\n\\\",\\n-      \\\"   ---------------------------------------- 0.0/829.3 kB ? eta -:--:--\\\\n\\\",\\n-      \\\"   ---------------------------------------- 0.0/829.3 kB ? eta -:--:--\\\\n\\\",\\n-      \\\"    -------------------------------------- 20.5/829.3 kB 682.7 kB/s eta 0:00:02\\\\n\\\",\\n-      \\\"   -------- ------------------------------- 184.3/829.3 kB 2.8 MB/s eta 0:00:01\\\\n\\\",\\n-      \\\"   ---------------------------------------- 829.3/829.3 kB 7.5 MB/s eta 0:00:00\\\\n\\\",\\n-      \\\"Installing collected packages: streamlit-option-menu\\\\n\\\",\\n-      \\\"Successfully installed streamlit-option-menu-0.4.0\\\\n\\\"\\n-     ]\\n-    },\\n-    {\\n-     \\\"name\\\": \\\"stderr\\\",\\n-     \\\"output_type\\\": \\\"stream\\\",\\n-     \\\"text\\\": [\\n-      \\\"WARNING: There was an error checking the latest version of pip.\\\\n\\\"\\n-     ]\\n-    }\\n-   ],\\n-   \\\"source\\\": [\\n-    \\\"!pip install streamlit-option-menu\\\\n\\\"\\n-   ]\\n-  },\\n-  {\\n-   \\\"cell_type\\\": \\\"code\\\",\\n-   \\\"execution_count\\\": 170,\\n-   \\\"id\\\": \\\"fb02692d-ffdb-4431-997d-5198e3e8f755\\\",\\n-   \\\"metadata\\\": {},\\n-   \\\"outputs\\\": [\\n-    {\\n-     \\\"ename\\\": \\\"HTTPError\\\",\\n-     \\\"evalue\\\": \\\"403 Client Error: FORBIDDEN for url: https://127.0.0.1:5000/api/records\\\",\\n-     \\\"output_type\\\": \\\"error\\\",\\n-     \\\"traceback\\\": [\\n-      \\\"\\\\u001b[1;31m---------------------------------------------------------------------------\\\\u001b[0m\\\",\\n-      \\\"\\\\u001b[1;31mHTTPError\\\\u001b[0m                                 Traceback (most recent call last)\\\",\\n-      \\\"Cell \\\\u001b[1;32mIn[170], line 84\\\\u001b[0m\\\\n\\\\u001b[0;32m     77\\\\u001b[0m \\\\u001b[38;5;66;03m# -----------------------------------------------------------------------------\\\\u001b[39;00m\\\\n\\\\u001b[0;32m     78\\\\u001b[0m \\\\u001b[38;5;66;03m#  2) Create a new draft\\\\u001b[39;00m\\\\n\\\\u001b[0;32m     79\\\\u001b[0m \\\\u001b[38;5;66;03m# -----------------------------------------------------------------------------\\\\u001b[39;00m\\\\n\\\\u001b[0;32m     80\\\\u001b[0m r \\\\u001b[38;5;241m=\\\\u001b[39m requests\\\\u001b[38;5;241m.\\\\u001b[39mpost(\\\\u001b[38;5;124mf\\\\u001b[39m\\\\u001b[38;5;124m\\\\\\\"\\\\u001b[39m\\\\u001b[38;5;132;01m{\\\\u001b[39;00mAPI_BASE\\\\u001b[38;5;132;01m}\\\\u001b[39;00m\\\\u001b[38;5;124m/api/records\\\\u001b[39m\\\\u001b[38;5;124m\\\\\\\"\\\\u001b[39m,\\\\n\\\\u001b[0;32m     81\\\\u001b[0m                   headers\\\\u001b[38;5;241m=\\\\u001b[39mH_JSON,\\\\n\\\\u001b[0;32m     82\\\\u001b[0m                   json\\\\u001b[38;5;241m=\\\\u001b[39mmeta,\\\\n\\\\u001b[0;32m     83\\\\u001b[0m                   verify\\\\u001b[38;5;241m=\\\\u001b[39mVERIFY_SSL)\\\\n\\\\u001b[1;32m---> 84\\\\u001b[0m \\\\u001b[43mr\\\\u001b[49m\\\\u001b[38;5;241;43m.\\\\u001b[39;49m\\\\u001b[43mraise_for_status\\\\u001b[49m\\\\u001b[43m(\\\\u001b[49m\\\\u001b[43m)\\\\u001b[49m\\\\n\\\\u001b[0;32m     85\\\\u001b[0m draft \\\\u001b[38;5;241m=\\\\u001b[39m r\\\\u001b[38;5;241m.\\\\u001b[39mjson()\\\\n\\\\u001b[0;32m     86\\\\u001b[0m recid \\\\u001b[38;5;241m=\\\\u001b[39m draft[\\\\u001b[38;5;124m\\\\\\\"\\\\u001b[39m\\\\u001b[38;5;124mid\\\\u001b[39m\\\\u001b[38;5;124m\\\\\\\"\\\\u001b[39m]\\\\n\\\",\\n-      \\\"File \\\\u001b[1;32m~\\\\\\\\anaconda3\\\\\\\\Lib\\\\\\\\site-packages\\\\\\\\requests\\\\\\\\models.py:1021\\\\u001b[0m, in \\\\u001b[0;36mResponse.raise_for_status\\\\u001b[1;34m(self)\\\\u001b[0m\\\\n\\\\u001b[0;32m   1016\\\\u001b[0m     http_error_msg \\\\u001b[38;5;241m=\\\\u001b[39m (\\\\n\\\\u001b[0;32m   1017\\\\u001b[0m         \\\\u001b[38;5;124mf\\\\u001b[39m\\\\u001b[38;5;124m\\\\\\\"\\\\u001b[39m\\\\u001b[38;5;132;01m{\\\\u001b[39;00m\\\\u001b[38;5;28mself\\\\u001b[39m\\\\u001b[38;5;241m.\\\\u001b[39mstatus_code\\\\u001b[38;5;132;01m}\\\\u001b[39;00m\\\\u001b[38;5;124m Server Error: \\\\u001b[39m\\\\u001b[38;5;132;01m{\\\\u001b[39;00mreason\\\\u001b[38;5;132;01m}\\\\u001b[39;00m\\\\u001b[38;5;124m for url: \\\\u001b[39m\\\\u001b[38;5;132;01m{\\\\u001b[39;00m\\\\u001b[38;5;28mself\\\\u001b[39m\\\\u001b[38;5;241m.\\\\u001b[39murl\\\\u001b[38;5;132;01m}\\\\u001b[39;00m\\\\u001b[38;5;124m\\\\\\\"\\\\u001b[39m\\\\n\\\\u001b[0;32m   1018\\\\u001b[0m     )\\\\n\\\\u001b[0;32m   1020\\\\u001b[0m \\\\u001b[38;5;28;01mif\\\\u001b[39;00m http_error_msg:\\\\n\\\\u001b[1;32m-> 1021\\\\u001b[0m     \\\\u001b[38;5;28;01mraise\\\\u001b[39;00m HTTPError(http_error_msg, response\\\\u001b[38;5;241m=\\\\u001b[39m\\\\u001b[38;5;28mself\\\\u001b[39m)\\\\n\\\",\\n-      \\\"\\\\u001b[1;31mHTTPError\\\\u001b[0m: 403 Client Error: FORBIDDEN for url: https://127.0.0.1:5000/api/records\\\"\\n-     ]\\n-    }\\n-   ],\\n-   \\\"source\\\": [\\n-    \\\"import os\\\\n\\\",\\n-    \\\"import json\\\\n\\\",\\n-    \\\"import requests\\\\n\\\",\\n-    \\\"from rdflib import Graph, URIRef, Literal\\\\n\\\",\\n-    \\\"from rdflib.namespace import PROV, XSD\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n-    \\\"#  CONFIGURATION\\\\n\\\",\\n-    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n-    \\\"API_BASE   = \\\\\\\"https://127.0.0.1:5000\\\\\\\"\\\\n\\\",\\n-    \\\"TOKEN      = \\\\\\\"ZctHtk65umtROkzOFq2Ot7WbJTqz46q5w8SOMry2c2rT9CqaRbySNp\\\\\\\"\\\\n\\\",\\n-    \\\"VERIFY_SSL = False   # for local self-signed\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"H_JSON = {\\\\n\\\",\\n-    \\\"    \\\\\\\"Accept\\\\\\\":        \\\\\\\"application/json\\\\\\\",\\\\n\\\",\\n-    \\\"    \\\\\\\"Content-Type\\\\\\\":  \\\\\\\"application/json\\\\\\\",\\\\n\\\",\\n-    \\\"    \\\\\\\"Authorization\\\\\\\": f\\\\\\\"Bearer {TOKEN}\\\\\\\",\\\\n\\\",\\n-    \\\"}\\\\n\\\",\\n-    \\\"H_OCTET = {\\\\n\\\",\\n-    \\\"    \\\\\\\"Authorization\\\\\\\": f\\\\\\\"Bearer {TOKEN}\\\\\\\",\\\\n\\\",\\n-    \\\"    \\\\\\\"Content-Type\\\\\\\":  \\\\\\\"application/octet-stream\\\\\\\",\\\\n\\\",\\n-    \\\"}\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# top-level folders you want to push\\\\n\\\",\\n-    \\\"TO_UPLOAD = [\\\\\\\"Trained_models\\\\\\\", \\\\\\\"plots\\\\\\\", \\\\\\\"MODEL_PROVENANCE\\\\\\\"]\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n-    \\\"#  OPTIONAL: turn your JSON provenance \\u2192 PROV-O \\u2192 JSON-LD (if you want structured metadata)\\\\n\\\",\\n-    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n-    \\\"def json_to_prov_ttl(raw: dict) -> str:\\\\n\\\",\\n-    \\\"    g   = Graph()\\\\n\\\",\\n-    \\\"    run = URIRef(f\\\\\\\"urn:run:{raw['run_id']}\\\\\\\")\\\\n\\\",\\n-    \\\"    g.bind(\\\\\\\"prov\\\\\\\", PROV)\\\\n\\\",\\n-    \\\"    # example: timestamps\\\\n\\\",\\n-    \\\"    g.add((run, PROV.startedAtTime,\\\\n\\\",\\n-    \\\"           Literal(raw[\\\\\\\"start_time\\\\\\\"], datatype=XSD.dateTime)))\\\\n\\\",\\n-    \\\"    # params \\u2192 prov:hadParameter\\\\n\\\",\\n-    \\\"    for k, v in raw.get(\\\\\\\"params\\\\\\\", {}).items():\\\\n\\\",\\n-    \\\"        g.add((run, PROV.hadParameter, Literal(v, datatype=XSD.string)))\\\\n\\\",\\n-    \\\"    # metrics \\u2192 prov:hadQuality\\\\n\\\",\\n-    \\\"    for k, v in raw.get(\\\\\\\"metrics\\\\\\\", {}).items():\\\\n\\\",\\n-    \\\"        g.add((run, PROV.hadQuality, Literal(v, datatype=XSD.decimal)))\\\\n\\\",\\n-    \\\"    return g.serialize(format=\\\\\\\"turtle\\\\\\\").decode()\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"def ttl_to_jsonld(ttl: str) -> dict:\\\\n\\\",\\n-    \\\"    g = Graph().parse(data=ttl, format=\\\\\\\"turtle\\\\\\\")\\\\n\\\",\\n-    \\\"    return json.loads(g.serialize(format=\\\\\\\"json-ld\\\\\\\"))\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n-    \\\"#  1) (optional) read your raw provenance JSON and embed as JSON-LD under \\\\\\\"metadata\\\\\\\"\\\\n\\\",\\n-    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n-    \\\"# with open(\\\\\\\"MODEL_PROVENANCE/run1234.json\\\\\\\") as fp:\\\\n\\\",\\n-    \\\"#     raw_meta = json.load(fp)\\\\n\\\",\\n-    \\\"# ttl    = json_to_prov_ttl(raw_meta)\\\\n\\\",\\n-    \\\"# jsonld = ttl_to_jsonld(ttl)\\\\n\\\",\\n-    \\\"# meta   = {\\\\n\\\",\\n-    \\\"#     \\\\\\\"title\\\\\\\":       f\\\\\\\"Iris RF run {raw_meta['run_id']}\\\\\\\",\\\\n\\\",\\n-    \\\"#     \\\\\\\"description\\\\\\\": \\\\\\\"Structured PROV-O in JSON-LD\\\\\\\",\\\\n\\\",\\n-    \\\"#     \\\\\\\"metadata\\\\\\\": {\\\\n\\\",\\n-    \\\"#         \\\\\\\"@context\\\\\\\": jsonld.get(\\\\\\\"@context\\\\\\\", {}),\\\\n\\\",\\n-    \\\"#         \\\\\\\"@graph\\\\\\\":   jsonld.get(\\\\\\\"@graph\\\\\\\", [])\\\\n\\\",\\n-    \\\"#     }\\\\n\\\",\\n-    \\\"# }\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n-    \\\"#  1') Or, if you don\\u2019t need JSON-LD, just supply minimal metadata:\\\\n\\\",\\n-    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n-    \\\"meta = {\\\\n\\\",\\n-    \\\"    \\\\\\\"title\\\\\\\":       \\\\\\\"My trained ML model\\\\\\\",\\\\n\\\",\\n-    \\\"    \\\\\\\"description\\\\\\\": \\\\\\\"All artifacts for RandomForest on Iris\\\\\\\",\\\\n\\\",\\n-    \\\"    \\\\\\\"creator\\\\\\\":     \\\\\\\"Reema Dass\\\\\\\"\\\\n\\\",\\n-    \\\"}\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n-    \\\"#  2) Create a new draft\\\\n\\\",\\n-    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n-    \\\"r = requests.post(f\\\\\\\"{API_BASE}/api/records\\\\\\\",\\\\n\\\",\\n-    \\\"                  headers=H_JSON,\\\\n\\\",\\n-    \\\"                  json=meta,\\\\n\\\",\\n-    \\\"                  verify=VERIFY_SSL)\\\\n\\\",\\n-    \\\"r.raise_for_status()\\\\n\\\",\\n-    \\\"draft = r.json()\\\\n\\\",\\n-    \\\"recid = draft[\\\\\\\"id\\\\\\\"]\\\\n\\\",\\n-    \\\"files_link = draft[\\\\\\\"links\\\\\\\"][\\\\\\\"files\\\\\\\"]\\\\n\\\",\\n-    \\\"print(f\\\\\\\"\\u2705 Draft created: {recid}\\\\\\\")\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n-    \\\"#  3) Walk & upload every file in each folder\\\\n\\\",\\n-    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n-    \\\"for folder in TO_UPLOAD:\\\\n\\\",\\n-    \\\"    if not os.path.isdir(folder):\\\\n\\\",\\n-    \\\"        print(f\\\\\\\"\\u26a0\\ufe0f  Skipping missing folder {folder}\\\\\\\")\\\\n\\\",\\n-    \\\"        continue\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    for root, _, filenames in os.walk(folder):\\\\n\\\",\\n-    \\\"        for fn in filenames:\\\\n\\\",\\n-    \\\"            local_path = os.path.join(root, fn)\\\\n\\\",\\n-    \\\"            # build the \\u201ckey\\u201d so that in Invenio it shows up under folder/\\u2026\\\\n\\\",\\n-    \\\"            rel = os.path.relpath(local_path, start=folder).replace(\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\"/\\\\\\\")\\\\n\\\",\\n-    \\\"            key = f\\\\\\\"{folder}/{rel}\\\\\\\"\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"            # 3a) register the file in the draft\\\\n\\\",\\n-    \\\"            entry = [{\\\\\\\"key\\\\\\\": key}]\\\\n\\\",\\n-    \\\"            r1 = requests.post(files_link,\\\\n\\\",\\n-    \\\"                               headers=H_JSON,\\\\n\\\",\\n-    \\\"                               json=entry,\\\\n\\\",\\n-    \\\"                               verify=VERIFY_SSL)\\\\n\\\",\\n-    \\\"            r1.raise_for_status()\\\\n\\\",\\n-    \\\"            file_links = r1.json()[\\\\\\\"entries\\\\\\\"][0][\\\\\\\"links\\\\\\\"]\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"            # 3b) upload the content\\\\n\\\",\\n-    \\\"            with open(local_path, \\\\\\\"rb\\\\\\\") as fp:\\\\n\\\",\\n-    \\\"                r2 = requests.put(file_links[\\\\\\\"content\\\\\\\"],\\\\n\\\",\\n-    \\\"                                  headers=H_OCTET,\\\\n\\\",\\n-    \\\"                                  data=fp,\\\\n\\\",\\n-    \\\"                                  verify=VERIFY_SSL)\\\\n\\\",\\n-    \\\"            r2.raise_for_status()\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"            # 3c) commit it\\\\n\\\",\\n-    \\\"            r3 = requests.post(file_links[\\\\\\\"commit\\\\\\\"],\\\\n\\\",\\n-    \\\"                               headers=H_JSON,\\\\n\\\",\\n-    \\\"                               verify=VERIFY_SSL)\\\\n\\\",\\n-    \\\"            r3.raise_for_status()\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"            print(f\\\\\\\"  \\u2022 Uploaded {key}\\\\\\\")\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n-    \\\"#  4) Publish the draft\\\\n\\\",\\n-    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n-    \\\"rp = requests.post(draft[\\\\\\\"links\\\\\\\"][\\\\\\\"publish\\\\\\\"],\\\\n\\\",\\n-    \\\"                   headers=H_JSON,\\\\n\\\",\\n-    \\\"                   verify=VERIFY_SSL)\\\\n\\\",\\n-    \\\"rp.raise_for_status()\\\\n\\\",\\n-    \\\"print(\\\\\\\"\\u2705 Published:\\\\\\\", rp.json()[\\\\\\\"id\\\\\\\"])\\\\n\\\"\\n-   ]\\n-  },\\n-  {\\n-   \\\"cell_type\\\": \\\"code\\\",\\n-   \\\"execution_count\\\": 176,\\n-   \\\"id\\\": \\\"82bda3d9-62af-44e8-96a5-58008973bd70\\\",\\n-   \\\"metadata\\\": {},\\n-   \\\"outputs\\\": [\\n-    {\\n-     \\\"ename\\\": \\\"HTTPError\\\",\\n-     \\\"evalue\\\": \\\"403 Client Error: FORBIDDEN for url: https://127.0.0.1:5000/api/records\\\",\\n-     \\\"output_type\\\": \\\"error\\\",\\n-     \\\"traceback\\\": [\\n-      \\\"\\\\u001b[1;31m---------------------------------------------------------------------------\\\\u001b[0m\\\",\\n-      \\\"\\\\u001b[1;31mHTTPError\\\\u001b[0m                                 Traceback (most recent call last)\\\",\\n-      \\\"Cell \\\\u001b[1;32mIn[176], line 43\\\\u001b[0m\\\\n\\\\u001b[0;32m     38\\\\u001b[0m \\\\u001b[38;5;66;03m# 3) Create the draft record\\\\u001b[39;00m\\\\n\\\\u001b[0;32m     39\\\\u001b[0m r \\\\u001b[38;5;241m=\\\\u001b[39m requests\\\\u001b[38;5;241m.\\\\u001b[39mpost(\\\\u001b[38;5;124mf\\\\u001b[39m\\\\u001b[38;5;124m\\\\\\\"\\\\u001b[39m\\\\u001b[38;5;132;01m{\\\\u001b[39;00mAPI_BASE\\\\u001b[38;5;132;01m}\\\\u001b[39;00m\\\\u001b[38;5;124m/api/records\\\\u001b[39m\\\\u001b[38;5;124m\\\\\\\"\\\\u001b[39m,\\\\n\\\\u001b[0;32m     40\\\\u001b[0m                   headers\\\\u001b[38;5;241m=\\\\u001b[39mH_JSON,\\\\n\\\\u001b[0;32m     41\\\\u001b[0m                   json\\\\u001b[38;5;241m=\\\\u001b[39mpayload,\\\\n\\\\u001b[0;32m     42\\\\u001b[0m                   verify\\\\u001b[38;5;241m=\\\\u001b[39mVERIFY_SSL)\\\\n\\\\u001b[1;32m---> 43\\\\u001b[0m \\\\u001b[43mr\\\\u001b[49m\\\\u001b[38;5;241;43m.\\\\u001b[39;49m\\\\u001b[43mraise_for_status\\\\u001b[49m\\\\u001b[43m(\\\\u001b[49m\\\\u001b[43m)\\\\u001b[49m\\\\n\\\\u001b[0;32m     44\\\\u001b[0m draft \\\\u001b[38;5;241m=\\\\u001b[39m r\\\\u001b[38;5;241m.\\\\u001b[39mjson()\\\\n\\\\u001b[0;32m     45\\\\u001b[0m recid \\\\u001b[38;5;241m=\\\\u001b[39m draft[\\\\u001b[38;5;124m\\\\\\\"\\\\u001b[39m\\\\u001b[38;5;124mid\\\\u001b[39m\\\\u001b[38;5;124m\\\\\\\"\\\\u001b[39m]\\\\n\\\",\\n-      \\\"File \\\\u001b[1;32m~\\\\\\\\anaconda3\\\\\\\\Lib\\\\\\\\site-packages\\\\\\\\requests\\\\\\\\models.py:1021\\\\u001b[0m, in \\\\u001b[0;36mResponse.raise_for_status\\\\u001b[1;34m(self)\\\\u001b[0m\\\\n\\\\u001b[0;32m   1016\\\\u001b[0m     http_error_msg \\\\u001b[38;5;241m=\\\\u001b[39m (\\\\n\\\\u001b[0;32m   1017\\\\u001b[0m         \\\\u001b[38;5;124mf\\\\u001b[39m\\\\u001b[38;5;124m\\\\\\\"\\\\u001b[39m\\\\u001b[38;5;132;01m{\\\\u001b[39;00m\\\\u001b[38;5;28mself\\\\u001b[39m\\\\u001b[38;5;241m.\\\\u001b[39mstatus_code\\\\u001b[38;5;132;01m}\\\\u001b[39;00m\\\\u001b[38;5;124m Server Error: \\\\u001b[39m\\\\u001b[38;5;132;01m{\\\\u001b[39;00mreason\\\\u001b[38;5;132;01m}\\\\u001b[39;00m\\\\u001b[38;5;124m for url: \\\\u001b[39m\\\\u001b[38;5;132;01m{\\\\u001b[39;00m\\\\u001b[38;5;28mself\\\\u001b[39m\\\\u001b[38;5;241m.\\\\u001b[39murl\\\\u001b[38;5;132;01m}\\\\u001b[39;00m\\\\u001b[38;5;124m\\\\\\\"\\\\u001b[39m\\\\n\\\\u001b[0;32m   1018\\\\u001b[0m     )\\\\n\\\\u001b[0;32m   1020\\\\u001b[0m \\\\u001b[38;5;28;01mif\\\\u001b[39;00m http_error_msg:\\\\n\\\\u001b[1;32m-> 1021\\\\u001b[0m     \\\\u001b[38;5;28;01mraise\\\\u001b[39;00m HTTPError(http_error_msg, response\\\\u001b[38;5;241m=\\\\u001b[39m\\\\u001b[38;5;28mself\\\\u001b[39m)\\\\n\\\",\\n-      \\\"\\\\u001b[1;31mHTTPError\\\\u001b[0m: 403 Client Error: FORBIDDEN for url: https://127.0.0.1:5000/api/records\\\"\\n-     ]\\n-    }\\n-   ],\\n-   \\\"source\\\": [\\n-    \\\"import os\\\\n\\\",\\n-    \\\"import json\\\\n\\\",\\n-    \\\"import requests\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n-    \\\"# CONFIGURATION\\\\n\\\",\\n-    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n-    \\\"API_BASE   = \\\\\\\"https://127.0.0.1:5000\\\\\\\"\\\\n\\\",\\n-    \\\"TOKEN      = \\\\\\\"ZctHtk65umtROkzOFq2Ot7WbJTqz46q5w8SOMry2c2rT9CqaRbySNp\\\\\\\"\\\\n\\\",\\n-    \\\"VERIFY_SSL = False  # only for local dev\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"H_JSON = {\\\\n\\\",\\n-    \\\"    \\\\\\\"Accept\\\\\\\":        \\\\\\\"application/json\\\\\\\",\\\\n\\\",\\n-    \\\"    \\\\\\\"Content-Type\\\\\\\":  \\\\\\\"application/json\\\\\\\",\\\\n\\\",\\n-    \\\"    \\\\\\\"Authorization\\\\\\\": f\\\\\\\"Bearer {TOKEN}\\\\\\\",\\\\n\\\",\\n-    \\\"}\\\\n\\\",\\n-    \\\"H_OCTET = {\\\\n\\\",\\n-    \\\"    \\\\\\\"Accept\\\\\\\":        \\\\\\\"application/json\\\\\\\",\\\\n\\\",\\n-    \\\"    \\\\\\\"Content-Type\\\\\\\":  \\\\\\\"application/octet-stream\\\\\\\",\\\\n\\\",\\n-    \\\"    \\\\\\\"Authorization\\\\\\\": f\\\\\\\"Bearer {TOKEN}\\\\\\\",\\\\n\\\",\\n-    \\\"}\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n-    \\\"# 1) Point this at your folder that contains only .pkl (and maybe other) files\\\\n\\\",\\n-    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n-    \\\"RECORD_FOLDER = \\\\\\\"Trained_models\\\\\\\"     # \\u2190 adjust as needed\\\\n\\\",\\n-    \\\"CREATOR       = \\\\\\\"Reema Dass\\\\\\\"         # your name or email\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n-    \\\"# 2) Build a minimal metadata payload in\\u2010memory\\\\n\\\",\\n-    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n-    \\\"payload = {\\\\n\\\",\\n-    \\\"    \\\\\\\"title\\\\\\\":       os.path.basename(RECORD_FOLDER),\\\\n\\\",\\n-    \\\"    \\\\\\\"description\\\\\\\": f\\\\\\\"All artifacts in folder `{RECORD_FOLDER}`\\\\\\\",\\\\n\\\",\\n-    \\\"    \\\\\\\"creator\\\\\\\":     CREATOR\\\\n\\\",\\n-    \\\"}\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# 3) Create the draft record\\\\n\\\",\\n-    \\\"r = requests.post(f\\\\\\\"{API_BASE}/api/records\\\\\\\",\\\\n\\\",\\n-    \\\"                  headers=H_JSON,\\\\n\\\",\\n-    \\\"                  json=payload,\\\\n\\\",\\n-    \\\"                  verify=VERIFY_SSL)\\\\n\\\",\\n-    \\\"r.raise_for_status()\\\\n\\\",\\n-    \\\"draft = r.json()\\\\n\\\",\\n-    \\\"recid = draft[\\\\\\\"id\\\\\\\"]\\\\n\\\",\\n-    \\\"links = draft[\\\\\\\"links\\\\\\\"]\\\\n\\\",\\n-    \\\"print(f\\\\\\\"\\u2705 Draft created: {recid}\\\\\\\")\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n-    \\\"# 4) Walk your folder and upload every file you find\\\\n\\\",\\n-    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n-    \\\"for root, _, filenames in os.walk(RECORD_FOLDER):\\\\n\\\",\\n-    \\\"    for fn in filenames:\\\\n\\\",\\n-    \\\"        local_path = os.path.join(root, fn)\\\\n\\\",\\n-    \\\"        # compute the \\u201ckey\\u201d under which it\\u2019ll live in your record\\\\n\\\",\\n-    \\\"        key = os.path.relpath(local_path, start=RECORD_FOLDER).replace(\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\"/\\\\\\\")\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"        # a) register that key\\\\n\\\",\\n-    \\\"        entry = [{\\\\\\\"key\\\\\\\": key}]\\\\n\\\",\\n-    \\\"        r1 = requests.post(links[\\\\\\\"files\\\\\\\"],\\\\n\\\",\\n-    \\\"                           headers=H_JSON,\\\\n\\\",\\n-    \\\"                           json=entry,\\\\n\\\",\\n-    \\\"                           verify=VERIFY_SSL)\\\\n\\\",\\n-    \\\"        r1.raise_for_status()\\\\n\\\",\\n-    \\\"        file_links = r1.json()[\\\\\\\"entries\\\\\\\"][0][\\\\\\\"links\\\\\\\"]\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"        # b) upload bytes\\\\n\\\",\\n-    \\\"        with open(local_path, \\\\\\\"rb\\\\\\\") as fp:\\\\n\\\",\\n-    \\\"            r2 = requests.put(file_links[\\\\\\\"content\\\\\\\"],\\\\n\\\",\\n-    \\\"                              headers=H_OCTET,\\\\n\\\",\\n-    \\\"                              data=fp,\\\\n\\\",\\n-    \\\"                              verify=VERIFY_SSL)\\\\n\\\",\\n-    \\\"        r2.raise_for_status()\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"        # c) commit\\\\n\\\",\\n-    \\\"        r3 = requests.post(file_links[\\\\\\\"commit\\\\\\\"],\\\\n\\\",\\n-    \\\"                           headers=H_JSON,\\\\n\\\",\\n-    \\\"                           verify=VERIFY_SSL)\\\\n\\\",\\n-    \\\"        r3.raise_for_status()\\\\n\\\",\\n-    \\\"        print(f\\\\\\\"  \\u2022 Uploaded {key}\\\\\\\")\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n-    \\\"# 5) Publish\\\\n\\\",\\n-    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n-    \\\"rpub = requests.post(links[\\\\\\\"publish\\\\\\\"],\\\\n\\\",\\n-    \\\"                     headers=H_JSON,\\\\n\\\",\\n-    \\\"                     verify=VERIFY_SSL)\\\\n\\\",\\n-    \\\"rpub.raise_for_status()\\\\n\\\",\\n-    \\\"print(f\\\\\\\"\\u2705 Published: {rpub.json()['id']}\\\\\\\")\\\\n\\\"\\n-   ]\\n-  },\\n-  {\\n-   \\\"cell_type\\\": \\\"code\\\",\\n-   \\\"execution_count\\\": 178,\\n-   \\\"id\\\": \\\"94115adc-62d2-413a-9f51-5b13d3f46392\\\",\\n-   \\\"metadata\\\": {\\n-    \\\"scrolled\\\": true\\n-   },\\n-   \\\"outputs\\\": [\\n-    {\\n-     \\\"name\\\": \\\"stdout\\\",\\n-     \\\"output_type\\\": \\\"stream\\\",\\n-     \\\"text\\\": [\\n-      \\\"200\\\\n\\\",\\n-      \\\"200 {'hits': {'hits': [{'id': 'a5eb3-j9f36', 'created': '2025-04-24T11:52:42.696314+00:00', 'updated': '2025-04-24T11:52:42.961276+00:00', 'links': {'self': 'https://127.0.0.1:5000/api/records/a5eb3-j9f36', 'self_html': 'https://127.0.0.1:5000/records/a5eb3-j9f36', 'parent': 'https://127.0.0.1:5000/api/records/39q9z-4cp60', 'parent_html': 'https://127.0.0.1:5000/records/39q9z-4cp60', 'self_iiif_manifest': 'https://127.0.0.1:5000/api/iiif/record:a5eb3-j9f36/manifest', 'self_iiif_sequence': 'https://127.0.0.1:5000/api/iiif/record:a5eb3-j9f36/sequence/default', 'files': 'https://127.0.0.1:5000/api/records/a5eb3-j9f36/files', 'media_files': 'https://127.0.0.1:5000/api/records/a5eb3-j9f36/media-files', 'archive': 'https://127.0.0.1:5000/api/records/a5eb3-j9f36/files-archive', 'archive_media': 'https://127.0.0.1:5000/api/records/a5eb3-j9f36/media-files-archive', 'latest': 'https://127.0.0.1:5000/api/records/a5eb3-j9f36/versions/latest', 'latest_html': 'https://127.0.0.1:5000/records/a5eb3-j9f36/latest', 'draft': 'https://127.0.0.1:5000/api/records/a5eb3-j9f36/draft', 'versions': 'https://127.0.0.1:5000/api/records/a5eb3-j9f36/versions', 'access_links': 'https://127.0.0.1:5000/api/records/a5eb3-j9f36/access/links', 'access_grants': 'https://127.0.0.1:5000/api/records/a5eb3-j9f36/access/grants', 'access_users': 'https://127.0.0.1:5000/api/records/a5eb3-j9f36/access/users', 'access_groups': 'https://127.0.0.1:5000/api/records/a5eb3-j9f36/access/groups', 'access_request': 'https://127.0.0.1:5000/api/records/a5eb3-j9f36/access/request', 'access': 'https://127.0.0.1:5000/api/records/a5eb3-j9f36/access', 'reserve_doi': 'https://127.0.0.1:5000/api/records/a5eb3-j9f36/draft/pids/doi', 'communities': 'https://127.0.0.1:5000/api/records/a5eb3-j9f36/communities', 'communities-suggestions': 'https://127.0.0.1:5000/api/records/a5eb3-j9f36/communities-suggestions', 'requests': 'https://127.0.0.1:5000/api/records/a5eb3-j9f36/requests'}, 'revision_id': 4, 'parent': {'id': '39q9z-4cp60', 'access': {'grants': [], 'owned_by': {'user': '3'}, 'links': [], 'settings': {'allow_user_requests': False, 'allow_guest_requests': False, 'accept_conditions_text': None, 'secret_link_expiration': 0}}, 'communities': {}, 'pids': {}}, 'versions': {'is_latest': True, 'is_latest_draft': True, 'index': 1}, 'is_published': True, 'is_draft': False, 'pids': {'oai': {'identifier': 'oai:my-site.com:a5eb3-j9f36', 'provider': 'oai'}}, 'metadata': {'resource_type': {'id': 'other', 'title': {'de': 'Sonstige', 'en': 'Other', 'sv': '\\u00d6vrig'}}, 'creators': [{'person_or_org': {'type': 'personal', 'name': 'Dass, Reema', 'given_name': 'Reema', 'family_name': 'Dass'}}], 'title': 'ML model', 'publisher': 'My Site', 'publication_date': '2025-04-24', 'rights': [{'id': 'cc-by-4.0', 'title': {'en': 'Creative Commons Attribution 4.0 International'}, 'description': {'en': 'The Creative Commons Attribution license allows re-distribution and re-use of a licensed work on the condition that the creator is appropriately credited.'}, 'icon': 'cc-by-icon', 'props': {'url': 'https://creativecommons.org/licenses/by/4.0/', 'scheme': 'spdx'}}]}, 'custom_fields': {}, 'access': {'record': 'public', 'files': 'public', 'embargo': {'active': False, 'reason': None}, 'status': 'open'}, 'files': {'enabled': True, 'order': [], 'count': 9, 'total_bytes': 171368, 'entries': {'roc_curve_cls_1.png': {'id': '4f4c8b29-02b3-40c4-af33-412f589a05f4', 'checksum': 'md5:917e9847fda527b030c0bcad8f2a2ea3', 'ext': 'png', 'size': 20143, 'mimetype': 'image/png', 'key': 'roc_curve_cls_1.png', 'metadata': {'width': 640, 'height': 480}, 'access': {'hidden': False}}, 'shap_summary.png': {'id': 'aebc0a0b-0b09-44ea-85ef-83ad0ac64fb3', 'checksum': 'md5:ac7959b6085a30cab3d8778a32d54d1a', 'ext': 'png', 'size': 16885, 'mimetype': 'image/png', 'key': 'shap_summary.png', 'metadata': {'width': 1150, 'height': 660}, 'access': {'hidden': False}}, 'roc_curve_cls_2.png': {'id': '2dfc6ced-6321-42dc-80bf-294dfaffe88c', 'checksum': 'md5:c076643c49b9ae7ba3cf0794b18f74db', 'ext': 'png', 'size': 20227, 'mimetype': 'image/png', 'key': 'roc_curve_cls_2.png', 'metadata': {'width': 640, 'height': 480}, 'access': {'hidden': False}}, 'confusion_matrix.png': {'id': 'dde4083c-8029-44de-b64e-bdef98e75601', 'checksum': 'md5:41c356960df1b924d7db4d4a5cc9b254', 'ext': 'png', 'size': 14453, 'mimetype': 'image/png', 'key': 'confusion_matrix.png', 'metadata': {'width': 600, 'height': 600}, 'access': {'hidden': False}}, 'feature_importances.png': {'id': 'cdfb75da-1e15-4fdb-a5fe-3bc5e181bf84', 'checksum': 'md5:1702afd2578c67988efdcf1f28fe1b04', 'ext': 'png', 'size': 19167, 'mimetype': 'image/png', 'key': 'feature_importances.png', 'metadata': {'width': 800, 'height': 600}, 'access': {'hidden': False}}, 'pr_curve_cls_0.png': {'id': '363871b4-6f5a-4c89-b197-e5cc5cbccf2f', 'checksum': 'md5:30a6a3742bcbd69750bc5fd30aea58d2', 'ext': 'png', 'size': 20358, 'mimetype': 'image/png', 'key': 'pr_curve_cls_0.png', 'metadata': {'width': 640, 'height': 480}, 'access': {'hidden': False}}, 'pr_curve_cls_1.png': {'id': '77ca9443-8953-4b20-8b6f-293961b4eabd', 'checksum': 'md5:7f396723afbfa90eb3d5f3e850f52c80', 'ext': 'png', 'size': 20226, 'mimetype': 'image/png', 'key': 'pr_curve_cls_1.png', 'metadata': {'width': 640, 'height': 480}, 'access': {'hidden': False}}, 'pr_curve_cls_2.png': {'id': '74ce57eb-f11d-434c-b030-7f045c467f48', 'checksum': 'md5:22a124dad652fd24fb3a5691abcae494', 'ext': 'png', 'size': 19809, 'mimetype': 'image/png', 'key': 'pr_curve_cls_2.png', 'metadata': {'width': 640, 'height': 480}, 'access': {'hidden': False}}, 'roc_curve_cls_0.png': {'id': 'f0e6047e-2af3-477d-936d-6041ed4d5d85', 'checksum': 'md5:f6d5e559a27d81fb010b416bddc2fb02', 'ext': 'png', 'size': 20100, 'mimetype': 'image/png', 'key': 'roc_curve_cls_0.png', 'metadata': {'width': 640, 'height': 480}, 'access': {'hidden': False}}}}, 'media_files': {'enabled': False, 'order': [], 'count': 0, 'total_bytes': 0, 'entries': {}}, 'status': 'published', 'deletion_status': {'is_deleted': False, 'status': 'P'}, 'stats': {'this_version': {'views': 0, 'unique_views': 0, 'downloads': 0, 'unique_downloads': 0, 'data_volume': 0.0}, 'all_versions': {'views': 0, 'unique_views': 0, 'downloads': 0, 'unique_downloads': 0, 'data_volume': 0.0}}}], 'total': 101}, 'aggregations': {'access_status': {'buckets': [{'key': 'metadata-only', 'doc_count': 100, 'label': 'Metadata-only', 'is_selected': False}, {'key': 'open', 'doc_count': 1, 'label': 'Open', 'is_selected': False}], 'label': 'Access status'}, 'file_type': {'buckets': [{'key': 'png', 'doc_count': 1, 'label': 'PNG', 'is_selected': False}], 'label': 'File type'}, 'resource_type': {'buckets': [{'key': 'publication', 'doc_count': 50, 'label': 'Publication', 'is_selected': False, 'inner': {'buckets': [{'key': 'publication-annotationcollection', 'doc_count': 4, 'label': 'Annotation collection', 'is_selected': False}, {'key': 'publication-datapaper', 'doc_count': 4, 'label': 'Data paper', 'is_selected': False}, {'key': 'publication-peerreview', 'doc_count': 4, 'label': 'Peer review', 'is_selected': False}, {'key': 'publication-deliverable', 'doc_count': 3, 'label': 'Project deliverable', 'is_selected': False}, {'key': 'publication-preprint', 'doc_count': 3, 'label': 'Preprint', 'is_selected': False}, {'key': 'publication-section', 'doc_count': 3, 'label': 'Book chapter', 'is_selected': False}, {'key': 'publication-taxonomictreatment', 'doc_count': 3, 'label': 'Taxonomic treatment', 'is_selected': False}, {'key': 'publication-thesis', 'doc_count': 3, 'label': 'Thesis', 'is_selected': False}, {'key': 'publication-book', 'doc_count': 2, 'label': 'Book', 'is_selected': False}, {'key': 'publication-datamanagementplan', 'doc_count': 2, 'label': 'Output management plan', 'is_selected': False}]}}, {'key': 'image', 'doc_count': 19, 'label': 'Image', 'is_selected': False, 'inner': {'buckets': [{'key': 'image-diagram', 'doc_count': 5, 'label': 'Diagram', 'is_selected': False}, {'key': 'image-other', 'doc_count': 5, 'label': 'Other', 'is_selected': False}, {'key': 'image-photo', 'doc_count': 4, 'label': 'Photo', 'is_selected': False}, {'key': 'image-plot', 'doc_count': 2, 'label': 'Plot', 'is_selected': False}, {'key': 'image-drawing', 'doc_count': 1, 'label': 'Drawing', 'is_selected': False}, {'key': 'image-figure', 'doc_count': 1, 'label': 'Figure', 'is_selected': False}]}}, {'key': 'software', 'doc_count': 6, 'label': 'Software', 'is_selected': False, 'inner': {'buckets': [{'key': 'software-computationalnotebook', 'doc_count': 2, 'label': 'Computational notebook', 'is_selected': False}]}}, {'key': 'model', 'doc_count': 5, 'label': 'Model', 'is_selected': False, 'inner': {'buckets': []}}, {'key': 'dataset', 'doc_count': 4, 'label': 'Dataset', 'is_selected': False, 'inner': {'buckets': []}}, {'key': 'other', 'doc_count': 4, 'label': 'Other', 'is_selected': False, 'inner': {'buckets': []}}, {'key': 'workflow', 'doc_count': 3, 'label': 'Workflow', 'is_selected': False, 'inner': {'buckets': []}}, {'key': 'audio', 'doc_count': 2, 'label': 'Audio', 'is_selected': False, 'inner': {'buckets': []}}, {'key': 'physicalobject', 'doc_count': 2, 'label': 'Physical object', 'is_selected': False, 'inner': {'buckets': []}}, {'key': 'presentation', 'doc_count': 2, 'label': 'Presentation', 'is_selected': False, 'inner': {'buckets': []}}], 'label': 'Resource types'}}, 'sortBy': 'newest', 'links': {'self': 'https://127.0.0.1:5000/api/records?page=1&size=1&sort=newest', 'next': 'https://127.0.0.1:5000/api/records?page=2&size=1&sort=newest'}}\\\\n\\\"\\n-     ]\\n-    }\\n-   ],\\n-   \\\"source\\\": [\\n-    \\\"import requests\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"API_BASE = \\\\\\\"https://127.0.0.1:5000\\\\\\\"\\\\n\\\",\\n-    \\\"TOKEN    = \\\\\\\"8LnqJuz3TsBHffnDJ3isPLHYHtRbWrC0M667Nb5haEbnXpWqGbFRyfDApymr\\\\\\\"\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# 1) Test read\\u2010scope by listing records (no size param or size=1)\\\\n\\\",\\n-    \\\"resp = requests.get(\\\\n\\\",\\n-    \\\"    f\\\\\\\"{API_BASE}/api/records\\\\\\\",\\\\n\\\",\\n-    \\\"    headers={\\\\\\\"Authorization\\\\\\\": f\\\\\\\"Bearer {TOKEN}\\\\\\\"},\\\\n\\\",\\n-    \\\"    verify=False\\\\n\\\",\\n-    \\\")\\\\n\\\",\\n-    \\\"print(resp.status_code)\\\\n\\\",\\n-    \\\"# should be 200 and a JSON page of records\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# or explicitly:\\\\n\\\",\\n-    \\\"resp = requests.get(\\\\n\\\",\\n-    \\\"    f\\\\\\\"{API_BASE}/api/records?size=1\\\\\\\",\\\\n\\\",\\n-    \\\"    headers={\\\\\\\"Authorization\\\\\\\": f\\\\\\\"Bearer {TOKEN}\\\\\\\"},\\\\n\\\",\\n-    \\\"    verify=False\\\\n\\\",\\n-    \\\")\\\\n\\\",\\n-    \\\"print(resp.status_code, resp.json())\\\\n\\\"\\n-   ]\\n-  },\\n-  {\\n-   \\\"cell_type\\\": \\\"code\\\",\\n-   \\\"execution_count\\\": 179,\\n-   \\\"id\\\": \\\"8965535e-fa56-49c6-a489-e75b63900fd6\\\",\\n-   \\\"metadata\\\": {},\\n-   \\\"outputs\\\": [\\n-    {\\n-     \\\"name\\\": \\\"stdout\\\",\\n-     \\\"output_type\\\": \\\"stream\\\",\\n-     \\\"text\\\": [\\n-      \\\"Allowed methods: HEAD, POST, OPTIONS, GET\\\\n\\\"\\n-     ]\\n-    }\\n-   ],\\n-   \\\"source\\\": [\\n-    \\\"import requests\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"API_BASE = \\\\\\\"https://127.0.0.1:5000\\\\\\\"\\\\n\\\",\\n-    \\\"TOKEN    = \\\\\\\"8LnqJuz3TsBHffnDJ3isPLHYHtRbWrC0M667Nb5haEbnXpWqGbFRyfDApymr\\\\\\\"\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"resp = requests.options(\\\\n\\\",\\n-    \\\"    f\\\\\\\"{API_BASE}/api/records\\\\\\\",\\\\n\\\",\\n-    \\\"    headers={\\\\\\\"Authorization\\\\\\\": f\\\\\\\"Bearer {TOKEN}\\\\\\\"},\\\\n\\\",\\n-    \\\"    verify=False\\\\n\\\",\\n-    \\\")\\\\n\\\",\\n-    \\\"print(\\\\\\\"Allowed methods:\\\\\\\", resp.headers.get(\\\\\\\"Allow\\\\\\\"))\\\\n\\\"\\n-   ]\\n-  },\\n-  {\\n-   \\\"cell_type\\\": \\\"code\\\",\\n-   \\\"execution_count\\\": 188,\\n-   \\\"id\\\": \\\"7e5b2cc5-ecf3-4e13-8cac-47f57f12cbdd\\\",\\n-   \\\"metadata\\\": {},\\n-   \\\"outputs\\\": [\\n-    {\\n-     \\\"name\\\": \\\"stdout\\\",\\n-     \\\"output_type\\\": \\\"stream\\\",\\n-     \\\"text\\\": [\\n-      \\\"\\u2705 Draft created: p8a8y-1bn93\\\\n\\\",\\n-      \\\"  \\u2022 Uploaded RandomForest_Iris_v20250423_230422.pkl\\\\n\\\",\\n-      \\\"  \\u2022 Uploaded RandomForest_Iris_v20250424_111946.pkl\\\\n\\\",\\n-      \\\"  \\u2022 Uploaded RandomForest_Iris_v20250423_230422/confusion_matrix.png\\\\n\\\",\\n-      \\\"  \\u2022 Uploaded RandomForest_Iris_v20250423_230422/feature_importances.png\\\\n\\\",\\n-      \\\"  \\u2022 Uploaded RandomForest_Iris_v20250423_230422/pr_curve_cls_0.png\\\\n\\\",\\n-      \\\"  \\u2022 Uploaded RandomForest_Iris_v20250423_230422/pr_curve_cls_1.png\\\\n\\\",\\n-      \\\"  \\u2022 Uploaded RandomForest_Iris_v20250423_230422/pr_curve_cls_2.png\\\\n\\\",\\n-      \\\"  \\u2022 Uploaded RandomForest_Iris_v20250423_230422/roc_curve_cls_0.png\\\\n\\\",\\n-      \\\"  \\u2022 Uploaded RandomForest_Iris_v20250423_230422/roc_curve_cls_1.png\\\\n\\\",\\n-      \\\"  \\u2022 Uploaded RandomForest_Iris_v20250423_230422/roc_curve_cls_2.png\\\\n\\\",\\n-      \\\"  \\u2022 Uploaded RandomForest_Iris_v20250423_230422/shap_summary.png\\\\n\\\",\\n-      \\\"  \\u2022 Uploaded RandomForest_Iris_v20250424_110923/confusion_matrix.png\\\\n\\\",\\n-      \\\"  \\u2022 Uploaded RandomForest_Iris_v20250424_110923/feature_importances.png\\\\n\\\",\\n-      \\\"  \\u2022 Uploaded RandomForest_Iris_v20250424_110923/pr_curve_cls_0.png\\\\n\\\",\\n-      \\\"  \\u2022 Uploaded RandomForest_Iris_v20250424_110923/pr_curve_cls_1.png\\\\n\\\",\\n-      \\\"  \\u2022 Uploaded RandomForest_Iris_v20250424_110923/pr_curve_cls_2.png\\\\n\\\",\\n-      \\\"  \\u2022 Uploaded RandomForest_Iris_v20250424_110923/roc_curve_cls_0.png\\\\n\\\",\\n-      \\\"  \\u2022 Uploaded RandomForest_Iris_v20250424_110923/roc_curve_cls_1.png\\\\n\\\",\\n-      \\\"  \\u2022 Uploaded RandomForest_Iris_v20250424_110923/roc_curve_cls_2.png\\\\n\\\",\\n-      \\\"  \\u2022 Uploaded RandomForest_Iris_v20250424_110923/shap_summary.png\\\\n\\\",\\n-      \\\"  \\u2022 Uploaded RandomForest_Iris_v20250424_111946/confusion_matrix.png\\\\n\\\",\\n-      \\\"  \\u2022 Uploaded RandomForest_Iris_v20250424_111946/feature_importances.png\\\\n\\\",\\n-      \\\"  \\u2022 Uploaded RandomForest_Iris_v20250424_111946/pr_curve_cls_0.png\\\\n\\\",\\n-      \\\"  \\u2022 Uploaded RandomForest_Iris_v20250424_111946/pr_curve_cls_1.png\\\\n\\\",\\n-      \\\"  \\u2022 Uploaded RandomForest_Iris_v20250424_111946/pr_curve_cls_2.png\\\\n\\\",\\n-      \\\"  \\u2022 Uploaded RandomForest_Iris_v20250424_111946/roc_curve_cls_0.png\\\\n\\\",\\n-      \\\"  \\u2022 Uploaded RandomForest_Iris_v20250424_111946/roc_curve_cls_1.png\\\\n\\\",\\n-      \\\"  \\u2022 Uploaded RandomForest_Iris_v20250424_111946/roc_curve_cls_2.png\\\\n\\\",\\n-      \\\"  \\u2022 Uploaded RandomForest_Iris_v20250424_111946/shap_summary.png\\\\n\\\",\\n-      \\\"  \\u2022 Uploaded RandomForest_Iris_v20250423_230422.jsonld\\\\n\\\",\\n-      \\\"  \\u2022 Uploaded RandomForest_Iris_v20250423_230422.ttl\\\\n\\\",\\n-      \\\"  \\u2022 Uploaded RandomForest_Iris_v20250423_230422_run_summary.json\\\\n\\\",\\n-      \\\"  \\u2022 Uploaded RandomForest_Iris_v20250424_110923_run_summary.json\\\\n\\\",\\n-      \\\"  \\u2022 Uploaded RandomForest_Iris_v20250424_111946_run_summary.json\\\\n\\\",\\n-      \\\"  \\u2022 Uploaded .ipynb_checkpoints/RandomForest_Iris_v20250423_230422_run_summary-checkpoint.json\\\\n\\\",\\n-      \\\"  \\u2022 Uploaded .ipynb_checkpoints/RandomForest_Iris_v20250424_110923_run_summary-checkpoint.json\\\\n\\\",\\n-      \\\"  \\u2022 Uploaded .ipynb_checkpoints/RandomForest_Iris_v20250424_111946_run_summary-checkpoint.json\\\\n\\\",\\n-      \\\"\\u2705 Published: p8a8y-1bn93\\\\n\\\",\\n-      \\\"\\u2705 Metadata fetched successfully\\\\n\\\",\\n-      \\\"\\u2705 Metadata saved as metadata_p8a8y-1bn93.json\\\\n\\\",\\n-      \\\"None\\\\n\\\"\\n-     ]\\n-    }\\n-   ],\\n-   \\\"source\\\": [\\n-    \\\"import os, json, requests\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n-    \\\"# Configuration\\\\n\\\",\\n-    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n-    \\\"API_BASE   = \\\\\\\"https://127.0.0.1:5000\\\\\\\"\\\\n\\\",\\n-    \\\"TOKEN      = \\\\\\\"8LnqJuz3TsBHffnDJ3isPLHYHtRbWrC0M667Nb5haEbnXpWqGbFRyfDApymr\\\\\\\"\\\\n\\\",\\n-    \\\"VERIFY_SSL = False  # only for self\\u2010signed dev\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"HEADERS_JSON = {\\\\n\\\",\\n-    \\\"    \\\\\\\"Accept\\\\\\\":        \\\\\\\"application/json\\\\\\\",\\\\n\\\",\\n-    \\\"    \\\\\\\"Content-Type\\\\\\\":  \\\\\\\"application/json\\\\\\\",\\\\n\\\",\\n-    \\\"    \\\\\\\"Authorization\\\\\\\": f\\\\\\\"Bearer {TOKEN}\\\\\\\",\\\\n\\\",\\n-    \\\"}\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"HEADERS_OCTET = {\\\\n\\\",\\n-    \\\"    \\\\\\\"Content-Type\\\\\\\":  \\\\\\\"application/octet-stream\\\\\\\",\\\\n\\\",\\n-    \\\"    \\\\\\\"Authorization\\\\\\\": f\\\\\\\"Bearer {TOKEN}\\\\\\\",\\\\n\\\",\\n-    \\\"}\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# The folders you want to walk & upload:\\\\n\\\",\\n-    \\\"TO_UPLOAD = [\\\\\\\"Trained_models\\\\\\\", \\\\\\\"plots\\\\\\\", \\\\\\\"MODEL_PROVENANCE\\\\\\\"]\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n-    \\\"# 1) Create draft with ALL required metadata\\\\n\\\",\\n-    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n-    \\\"def create_draft():\\\\n\\\",\\n-    \\\"    payload = {\\\\n\\\",\\n-    \\\"  \\\\\\\"metadata\\\\\\\": {\\\\n\\\",\\n-    \\\"    \\\\\\\"title\\\\\\\":            \\\\\\\"RandomForest Iris Model Artifacts\\\\\\\",\\\\n\\\",\\n-    \\\"    \\\\\\\"creators\\\\\\\": [ {\\\\n\\\",\\n-    \\\"      \\\\\\\"person_or_org\\\\\\\": {\\\\n\\\",\\n-    \\\"        \\\\\\\"type\\\\\\\":        \\\\\\\"personal\\\\\\\",\\\\n\\\",\\n-    \\\"        \\\\\\\"given_name\\\\\\\":  \\\\\\\"Reema\\\\\\\",\\\\n\\\",\\n-    \\\"        \\\\\\\"family_name\\\\\\\": \\\\\\\"Dass\\\\\\\"\\\\n\\\",\\n-    \\\"      }\\\\n\\\",\\n-    \\\"    } ],\\\\n\\\",\\n-    \\\"    \\\\\\\"publication_date\\\\\\\": \\\\\\\"2025-04-24\\\\\\\",\\\\n\\\",\\n-    \\\"    \\\\\\\"resource_type\\\\\\\":    { \\\\\\\"id\\\\\\\": \\\\\\\"software\\\\\\\" },\\\\n\\\",\\n-    \\\"    \\\\\\\"access\\\\\\\": {\\\\n\\\",\\n-    \\\"      \\\\\\\"record\\\\\\\": \\\\\\\"public\\\\\\\",\\\\n\\\",\\n-    \\\"      \\\\\\\"files\\\\\\\":  \\\\\\\"public\\\\\\\"\\\\n\\\",\\n-    \\\"    }\\\\n\\\",\\n-    \\\"  }\\\\n\\\",\\n-    \\\"}\\\\n\\\",\\n-    \\\"    r = requests.post(f\\\\\\\"{API_BASE}/api/records\\\\\\\",\\\\n\\\",\\n-    \\\"                      headers=HEADERS_JSON,\\\\n\\\",\\n-    \\\"                      json=payload,\\\\n\\\",\\n-    \\\"                      verify=VERIFY_SSL)\\\\n\\\",\\n-    \\\"    r.raise_for_status()\\\\n\\\",\\n-    \\\"    draft = r.json()\\\\n\\\",\\n-    \\\"    print(\\\\\\\"\\u2705 Draft created:\\\\\\\", draft[\\\\\\\"id\\\\\\\"])\\\\n\\\",\\n-    \\\"    return draft[\\\\\\\"id\\\\\\\"], draft[\\\\\\\"links\\\\\\\"]\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n-    \\\"# 2) Register, upload and commit a single file\\\\n\\\",\\n-    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n-    \\\"def upload_and_commit(links, key, path):\\\\n\\\",\\n-    \\\"    # 2a) register the filename in the draft\\\\n\\\",\\n-    \\\"    r1 = requests.post(links[\\\\\\\"files\\\\\\\"],\\\\n\\\",\\n-    \\\"                       headers=HEADERS_JSON,\\\\n\\\",\\n-    \\\"                       json=[{\\\\\\\"key\\\\\\\": key}],\\\\n\\\",\\n-    \\\"                       verify=VERIFY_SSL)\\\\n\\\",\\n-    \\\"    r1.raise_for_status()\\\\n\\\",\\n-    \\\"    entry = next(e for e in r1.json()[\\\\\\\"entries\\\\\\\"] if e[\\\\\\\"key\\\\\\\"] == key)\\\\n\\\",\\n-    \\\"    file_links = entry[\\\\\\\"links\\\\\\\"]\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    # 2b) upload the bytes\\\\n\\\",\\n-    \\\"    with open(path, \\\\\\\"rb\\\\\\\") as fp:\\\\n\\\",\\n-    \\\"        r2 = requests.put(file_links[\\\\\\\"content\\\\\\\"],\\\\n\\\",\\n-    \\\"                          headers=HEADERS_OCTET,\\\\n\\\",\\n-    \\\"                          data=fp,\\\\n\\\",\\n-    \\\"                          verify=VERIFY_SSL)\\\\n\\\",\\n-    \\\"    r2.raise_for_status()\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    # 2c) commit the upload\\\\n\\\",\\n-    \\\"    r3 = requests.post(file_links[\\\\\\\"commit\\\\\\\"],\\\\n\\\",\\n-    \\\"                       headers=HEADERS_JSON,\\\\n\\\",\\n-    \\\"                       verify=VERIFY_SSL)\\\\n\\\",\\n-    \\\"    r3.raise_for_status()\\\\n\\\",\\n-    \\\"    print(f\\\\\\\"  \\u2022 Uploaded {key}\\\\\\\")\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n-    \\\"# 3) Walk each folder and upload every file\\\\n\\\",\\n-    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n-    \\\"def upload_folder(links):\\\\n\\\",\\n-    \\\"    for folder in TO_UPLOAD:\\\\n\\\",\\n-    \\\"        if not os.path.isdir(folder):\\\\n\\\",\\n-    \\\"            print(f\\\\\\\"\\u26a0\\ufe0f Skipping missing folder {folder}\\\\\\\")\\\\n\\\",\\n-    \\\"            continue\\\\n\\\",\\n-    \\\"        base = os.path.dirname(folder) or folder\\\\n\\\",\\n-    \\\"        for root, _, files in os.walk(folder):\\\\n\\\",\\n-    \\\"            for fn in files:\\\\n\\\",\\n-    \\\"                local = os.path.join(root, fn)\\\\n\\\",\\n-    \\\"                # create a POSIX\\u2010style key preserving subfolders\\\\n\\\",\\n-    \\\"                key = os.path.relpath(local, start=base).replace(os.sep, \\\\\\\"/\\\\\\\")\\\\n\\\",\\n-    \\\"                upload_and_commit(links, key, local)\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n-    \\\"# 4) Publish the draft\\\\n\\\",\\n-    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n-    \\\"def publish(links):\\\\n\\\",\\n-    \\\"    r = requests.post(links[\\\\\\\"publish\\\\\\\"],\\\\n\\\",\\n-    \\\"                      headers=HEADERS_JSON,\\\\n\\\",\\n-    \\\"                      verify=VERIFY_SSL)\\\\n\\\",\\n-    \\\"    if not r.ok:\\\\n\\\",\\n-    \\\"        print(\\\\\\\"\\u274c Publish failed:\\\\\\\", r.status_code, r.text)\\\\n\\\",\\n-    \\\"        try: print(r.json())\\\\n\\\",\\n-    \\\"        except: pass\\\\n\\\",\\n-    \\\"        r.raise_for_status()\\\\n\\\",\\n-    \\\"    print(\\\\\\\"\\u2705 Published:\\\\\\\", r.json()[\\\\\\\"id\\\\\\\"])\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n-    \\\"# 5) Fetch metadata and save to a file\\\\n\\\",\\n-    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n-    \\\"def fetch_metadata(record_id):\\\\n\\\",\\n-    \\\"    r = requests.get(f\\\\\\\"{API_BASE}/api/records/{record_id}\\\\\\\",\\\\n\\\",\\n-    \\\"                     headers=HEADERS_JSON,\\\\n\\\",\\n-    \\\"                     verify=VERIFY_SSL)\\\\n\\\",\\n-    \\\"    r.raise_for_status()\\\\n\\\",\\n-    \\\"    metadata = r.json()\\\\n\\\",\\n-    \\\"    print(\\\\\\\"\\u2705 Metadata fetched successfully\\\\\\\")\\\\n\\\",\\n-    \\\"    \\\\n\\\",\\n-    \\\"    # Save the metadata to a file\\\\n\\\",\\n-    \\\"    with open(f\\\\\\\"metadata_{record_id}.json\\\\\\\", \\\\\\\"w\\\\\\\") as f:\\\\n\\\",\\n-    \\\"        json.dump(metadata, f, indent=4)\\\\n\\\",\\n-    \\\"    print(f\\\\\\\"\\u2705 Metadata saved as metadata_{record_id}.json\\\\\\\")\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n-    \\\"# Main\\\\n\\\",\\n-    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n-    \\\"if __name__ == \\\\\\\"__main__\\\\\\\":\\\\n\\\",\\n-    \\\"    recid, links = create_draft()\\\\n\\\",\\n-    \\\"    upload_folder(links)\\\\n\\\",\\n-    \\\"    publish(links)\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    # Fetch and save metadata after publishing\\\\n\\\",\\n-    \\\"    print(fetch_metadata(recid))\\\\n\\\"\\n-   ]\\n-  },\\n-  {\\n-   \\\"cell_type\\\": \\\"code\\\",\\n-   \\\"execution_count\\\": 201,\\n-   \\\"id\\\": \\\"0013878b-37da-4a22-9586-3773531bfd01\\\",\\n-   \\\"metadata\\\": {\\n-    \\\"scrolled\\\": true\\n-   },\\n-   \\\"outputs\\\": [\\n-    {\\n-     \\\"name\\\": \\\"stdout\\\",\\n-     \\\"output_type\\\": \\\"stream\\\",\\n-     \\\"text\\\": [\\n-      \\\"Debug: Original Metadata (start): {\\\\n\\\",\\n-      \\\"    \\\\\\\"id\\\\\\\": \\\\\\\"p8a8y-1bn93\\\\\\\",\\\\n\\\",\\n-      \\\"    \\\\\\\"created\\\\\\\": \\\\\\\"2025-04-24T13:48:33.108906+00:00\\\\\\\",\\\\n\\\",\\n-      \\\"    \\\\\\\"updated\\\\\\\": \\\\\\\"2025-04-24T13:48:34.519283+00:00\\\\\\\",\\\\n\\\",\\n-      \\\"    \\\\\\\"links\\\\\\\": {\\\\n\\\",\\n-      \\\"        \\\\\\\"self\\\\\\\": \\\\\\\"https://127.0.0.1:5000/api/records/p8a8y-1bn93\\\\\\\",\\\\n\\\",\\n-      \\\"        \\\\\\\"self_html\\\\\\\": \\\\\\\"https://127.0.0.1:5000/records/p8a8y-1bn93\\\\\\\",\\\\n\\\",\\n-      \\\"        \\\\\\\"parent\\\\\\\": \\\\\\\"https://127.0.0.1:5000/api/records/0r0p8-gzf02\\\\\\\",\\\\n\\\",\\n-      \\\"        \\\\\\\"parent_html\\\\\\\": \\\\\\\"https://127.0.0.1:5000/records/0r0p8-gzf02\\\\\\\",\\\\n\\\",\\n-      \\\"        \\\\\\\"self_iiif_manifest\\\\\\\": \\\\\\\"https://127.0.0.1:5000/api/iiif/record:p8a8y-1bn93/manifest\\\\\\\",\\\\n\\\",\\n-      \\\"        \\\\\\\"self_iiif_sequence\\\\\\\": \\\\\\\"https://127.0.0.1:5000/api/iiif/record:p8a8y-1bn93/sequence/default\\\\\\\",\\\\n\\\",\\n-      \\\"        \\\\\\\"files\\\\\\\": \\\\\\\"https://127.0.0.1:5000/api/records/p8a8y-1bn93/files\\\\\\\",\\\\n\\\",\\n-      \\\"        \\\\\\\"media_files\\\\\\\": \\\\\\\"https://127.0.0.1:5000/api/records/p8a8y-1bn93/media-files\\\\\\\",\\\\n\\\",\\n-      \\\"        \\\\\\\"archive\\\\\\\": \\\\\\\"https://127.0.0.1:5000/api/records/p8a8y-1bn93/files-archive\\\\\\\",\\\\n\\\",\\n-      \\\"        \\\\\\\"archive_media\\\\\\\": \\\\\\\"https://127.0.0.1:5000/api/records/p8a8y-1bn93/media-files-archive\\\\\\\",\\\\n\\\",\\n-      \\\"        \\\\\\\"latest\\\\\\\": \\\\\\\"https://127.0.0.1:5000/api/records/p8\\\\n\\\",\\n-      \\\"Debug: Metadata loaded successfully\\\\n\\\",\\n-      \\\"p8a8y-1bn93\\\\n\\\",\\n-      \\\"Debug: Extracting fields from metadata...\\\\n\\\",\\n-      \\\"Debug: Extracted Metadata: {\\\\n\\\",\\n-      \\\"    \\\\\\\"invenio_metadata\\\\\\\": {\\\\n\\\",\\n-      \\\"        \\\\\\\"id\\\\\\\": \\\\\\\"p8a8y-1bn93\\\\\\\",\\\\n\\\",\\n-      \\\"        \\\\\\\"title\\\\\\\": \\\\\\\"RandomForest Iris Model Artifacts\\\\\\\",\\\\n\\\",\\n-      \\\"        \\\\\\\"creator\\\\\\\": \\\\\\\"Dass, Reema\\\\\\\",\\\\n\\\",\\n-      \\\"        \\\\\\\"publication_date\\\\\\\": \\\\\\\"2025-04-24\\\\\\\",\\\\n\\\",\\n-      \\\"        \\\\\\\"files\\\\\\\": [\\\\n\\\",\\n-      \\\"            {\\\\n\\\",\\n-      \\\"                \\\\\\\"key\\\\\\\": \\\\\\\"RandomForest_Iris_v20250423_230422.pkl\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"url\\\\\\\": \\\\\\\"https://127.0.0.1:5000/api/records/p8a8y-1bn93/files/RandomForest_Iris_v20250423_230422.pkl/content\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"size\\\\\\\": 282910,\\\\n\\\",\\n-      \\\"                \\\\\\\"mimetype\\\\\\\": \\\\\\\"application/octet-stream\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"checksum\\\\\\\": \\\\\\\"md5:a9f9e15b9c808d94c8e5737089beaa7d\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"metadata\\\\\\\": {}\\\\n\\\",\\n-      \\\"            },\\\\n\\\",\\n-      \\\"            {\\\\n\\\",\\n-      \\\"                \\\\\\\"key\\\\\\\": \\\\\\\"RandomForest_Iris_v20250424_110923/pr_curve_cls_1.png\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"url\\\\\\\": \\\\\\\"https://127.0.0.1:5000/api/records/p8a8y-1bn93/files/RandomForest_Iris_v20250424_110923/pr_curve_cls_1.png/content\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"size\\\\\\\": 20226,\\\\n\\\",\\n-      \\\"                \\\\\\\"mimetype\\\\\\\": \\\\\\\"image/png\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"checksum\\\\\\\": \\\\\\\"md5:7f396723afbfa90eb3d5f3e850f52c80\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"metadata\\\\\\\": {\\\\n\\\",\\n-      \\\"                    \\\\\\\"width\\\\\\\": 640,\\\\n\\\",\\n-      \\\"                    \\\\\\\"height\\\\\\\": 480\\\\n\\\",\\n-      \\\"                }\\\\n\\\",\\n-      \\\"            },\\\\n\\\",\\n-      \\\"            {\\\\n\\\",\\n-      \\\"                \\\\\\\"key\\\\\\\": \\\\\\\"RandomForest_Iris_v20250423_230422/confusion_matrix.png\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"url\\\\\\\": \\\\\\\"https://127.0.0.1:5000/api/records/p8a8y-1bn93/files/RandomForest_Iris_v20250423_230422/confusion_matrix.png/content\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"size\\\\\\\": 14453,\\\\n\\\",\\n-      \\\"                \\\\\\\"mimetype\\\\\\\": \\\\\\\"image/png\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"checksum\\\\\\\": \\\\\\\"md5:41c356960df1b924d7db4d4a5cc9b254\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"metadata\\\\\\\": {\\\\n\\\",\\n-      \\\"                    \\\\\\\"width\\\\\\\": 600,\\\\n\\\",\\n-      \\\"                    \\\\\\\"height\\\\\\\": 600\\\\n\\\",\\n-      \\\"                }\\\\n\\\",\\n-      \\\"            },\\\\n\\\",\\n-      \\\"            {\\\\n\\\",\\n-      \\\"                \\\\\\\"key\\\\\\\": \\\\\\\"RandomForest_Iris_v20250424_110923/feature_importances.png\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"url\\\\\\\": \\\\\\\"https://127.0.0.1:5000/api/records/p8a8y-1bn93/files/RandomForest_Iris_v20250424_110923/feature_importances.png/content\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"size\\\\\\\": 19167,\\\\n\\\",\\n-      \\\"                \\\\\\\"mimetype\\\\\\\": \\\\\\\"image/png\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"checksum\\\\\\\": \\\\\\\"md5:1702afd2578c67988efdcf1f28fe1b04\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"metadata\\\\\\\": {\\\\n\\\",\\n-      \\\"                    \\\\\\\"width\\\\\\\": 800,\\\\n\\\",\\n-      \\\"                    \\\\\\\"height\\\\\\\": 600\\\\n\\\",\\n-      \\\"                }\\\\n\\\",\\n-      \\\"            },\\\\n\\\",\\n-      \\\"            {\\\\n\\\",\\n-      \\\"                \\\\\\\"key\\\\\\\": \\\\\\\"RandomForest_Iris_v20250423_230422/roc_curve_cls_1.png\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"url\\\\\\\": \\\\\\\"https://127.0.0.1:5000/api/records/p8a8y-1bn93/files/RandomForest_Iris_v20250423_230422/roc_curve_cls_1.png/content\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"size\\\\\\\": 20143,\\\\n\\\",\\n-      \\\"                \\\\\\\"mimetype\\\\\\\": \\\\\\\"image/png\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"checksum\\\\\\\": \\\\\\\"md5:917e9847fda527b030c0bcad8f2a2ea3\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"metadata\\\\\\\": {\\\\n\\\",\\n-      \\\"                    \\\\\\\"width\\\\\\\": 640,\\\\n\\\",\\n-      \\\"                    \\\\\\\"height\\\\\\\": 480\\\\n\\\",\\n-      \\\"                }\\\\n\\\",\\n-      \\\"            },\\\\n\\\",\\n-      \\\"            {\\\\n\\\",\\n-      \\\"                \\\\\\\"key\\\\\\\": \\\\\\\"RandomForest_Iris_v20250423_230422/pr_curve_cls_0.png\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"url\\\\\\\": \\\\\\\"https://127.0.0.1:5000/api/records/p8a8y-1bn93/files/RandomForest_Iris_v20250423_230422/pr_curve_cls_0.png/content\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"size\\\\\\\": 20358,\\\\n\\\",\\n-      \\\"                \\\\\\\"mimetype\\\\\\\": \\\\\\\"image/png\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"checksum\\\\\\\": \\\\\\\"md5:30a6a3742bcbd69750bc5fd30aea58d2\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"metadata\\\\\\\": {\\\\n\\\",\\n-      \\\"                    \\\\\\\"width\\\\\\\": 640,\\\\n\\\",\\n-      \\\"                    \\\\\\\"height\\\\\\\": 480\\\\n\\\",\\n-      \\\"                }\\\\n\\\",\\n-      \\\"            },\\\\n\\\",\\n-      \\\"            {\\\\n\\\",\\n-      \\\"                \\\\\\\"key\\\\\\\": \\\\\\\"RandomForest_Iris_v20250423_230422/pr_curve_cls_2.png\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"url\\\\\\\": \\\\\\\"https://127.0.0.1:5000/api/records/p8a8y-1bn93/files/RandomForest_Iris_v20250423_230422/pr_curve_cls_2.png/content\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"size\\\\\\\": 19809,\\\\n\\\",\\n-      \\\"                \\\\\\\"mimetype\\\\\\\": \\\\\\\"image/png\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"checksum\\\\\\\": \\\\\\\"md5:22a124dad652fd24fb3a5691abcae494\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"metadata\\\\\\\": {\\\\n\\\",\\n-      \\\"                    \\\\\\\"width\\\\\\\": 640,\\\\n\\\",\\n-      \\\"                    \\\\\\\"height\\\\\\\": 480\\\\n\\\",\\n-      \\\"                }\\\\n\\\",\\n-      \\\"            },\\\\n\\\",\\n-      \\\"            {\\\\n\\\",\\n-      \\\"                \\\\\\\"key\\\\\\\": \\\\\\\"RandomForest_Iris_v20250424_110923/pr_curve_cls_0.png\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"url\\\\\\\": \\\\\\\"https://127.0.0.1:5000/api/records/p8a8y-1bn93/files/RandomForest_Iris_v20250424_110923/pr_curve_cls_0.png/content\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"size\\\\\\\": 20358,\\\\n\\\",\\n-      \\\"                \\\\\\\"mimetype\\\\\\\": \\\\\\\"image/png\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"checksum\\\\\\\": \\\\\\\"md5:30a6a3742bcbd69750bc5fd30aea58d2\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"metadata\\\\\\\": {\\\\n\\\",\\n-      \\\"                    \\\\\\\"width\\\\\\\": 640,\\\\n\\\",\\n-      \\\"                    \\\\\\\"height\\\\\\\": 480\\\\n\\\",\\n-      \\\"                }\\\\n\\\",\\n-      \\\"            },\\\\n\\\",\\n-      \\\"            {\\\\n\\\",\\n-      \\\"                \\\\\\\"key\\\\\\\": \\\\\\\"RandomForest_Iris_v20250423_230422/shap_summary.png\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"url\\\\\\\": \\\\\\\"https://127.0.0.1:5000/api/records/p8a8y-1bn93/files/RandomForest_Iris_v20250423_230422/shap_summary.png/content\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"size\\\\\\\": 16939,\\\\n\\\",\\n-      \\\"                \\\\\\\"mimetype\\\\\\\": \\\\\\\"image/png\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"checksum\\\\\\\": \\\\\\\"md5:ac330a1d4feeb8463ca1e9551303c4c8\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"metadata\\\\\\\": {\\\\n\\\",\\n-      \\\"                    \\\\\\\"width\\\\\\\": 1150,\\\\n\\\",\\n-      \\\"                    \\\\\\\"height\\\\\\\": 660\\\\n\\\",\\n-      \\\"                }\\\\n\\\",\\n-      \\\"            },\\\\n\\\",\\n-      \\\"            {\\\\n\\\",\\n-      \\\"                \\\\\\\"key\\\\\\\": \\\\\\\"RandomForest_Iris_v20250424_110923/roc_curve_cls_0.png\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"url\\\\\\\": \\\\\\\"https://127.0.0.1:5000/api/records/p8a8y-1bn93/files/RandomForest_Iris_v20250424_110923/roc_curve_cls_0.png/content\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"size\\\\\\\": 20100,\\\\n\\\",\\n-      \\\"                \\\\\\\"mimetype\\\\\\\": \\\\\\\"image/png\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"checksum\\\\\\\": \\\\\\\"md5:f6d5e559a27d81fb010b416bddc2fb02\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"metadata\\\\\\\": {\\\\n\\\",\\n-      \\\"                    \\\\\\\"width\\\\\\\": 640,\\\\n\\\",\\n-      \\\"                    \\\\\\\"height\\\\\\\": 480\\\\n\\\",\\n-      \\\"                }\\\\n\\\",\\n-      \\\"            },\\\\n\\\",\\n-      \\\"            {\\\\n\\\",\\n-      \\\"                \\\\\\\"key\\\\\\\": \\\\\\\"RandomForest_Iris_v20250424_110923/pr_curve_cls_2.png\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"url\\\\\\\": \\\\\\\"https://127.0.0.1:5000/api/records/p8a8y-1bn93/files/RandomForest_Iris_v20250424_110923/pr_curve_cls_2.png/content\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"size\\\\\\\": 19809,\\\\n\\\",\\n-      \\\"                \\\\\\\"mimetype\\\\\\\": \\\\\\\"image/png\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"checksum\\\\\\\": \\\\\\\"md5:22a124dad652fd24fb3a5691abcae494\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"metadata\\\\\\\": {\\\\n\\\",\\n-      \\\"                    \\\\\\\"width\\\\\\\": 640,\\\\n\\\",\\n-      \\\"                    \\\\\\\"height\\\\\\\": 480\\\\n\\\",\\n-      \\\"                }\\\\n\\\",\\n-      \\\"            },\\\\n\\\",\\n-      \\\"            {\\\\n\\\",\\n-      \\\"                \\\\\\\"key\\\\\\\": \\\\\\\"RandomForest_Iris_v20250424_110923/roc_curve_cls_1.png\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"url\\\\\\\": \\\\\\\"https://127.0.0.1:5000/api/records/p8a8y-1bn93/files/RandomForest_Iris_v20250424_110923/roc_curve_cls_1.png/content\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"size\\\\\\\": 20143,\\\\n\\\",\\n-      \\\"                \\\\\\\"mimetype\\\\\\\": \\\\\\\"image/png\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"checksum\\\\\\\": \\\\\\\"md5:917e9847fda527b030c0bcad8f2a2ea3\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"metadata\\\\\\\": {\\\\n\\\",\\n-      \\\"                    \\\\\\\"width\\\\\\\": 640,\\\\n\\\",\\n-      \\\"                    \\\\\\\"height\\\\\\\": 480\\\\n\\\",\\n-      \\\"                }\\\\n\\\",\\n-      \\\"            },\\\\n\\\",\\n-      \\\"            {\\\\n\\\",\\n-      \\\"                \\\\\\\"key\\\\\\\": \\\\\\\"RandomForest_Iris_v20250424_110923/roc_curve_cls_2.png\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"url\\\\\\\": \\\\\\\"https://127.0.0.1:5000/api/records/p8a8y-1bn93/files/RandomForest_Iris_v20250424_110923/roc_curve_cls_2.png/content\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"size\\\\\\\": 20227,\\\\n\\\",\\n-      \\\"                \\\\\\\"mimetype\\\\\\\": \\\\\\\"image/png\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"checksum\\\\\\\": \\\\\\\"md5:c076643c49b9ae7ba3cf0794b18f74db\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"metadata\\\\\\\": {\\\\n\\\",\\n-      \\\"                    \\\\\\\"width\\\\\\\": 640,\\\\n\\\",\\n-      \\\"                    \\\\\\\"height\\\\\\\": 480\\\\n\\\",\\n-      \\\"                }\\\\n\\\",\\n-      \\\"            },\\\\n\\\",\\n-      \\\"            {\\\\n\\\",\\n-      \\\"                \\\\\\\"key\\\\\\\": \\\\\\\"RandomForest_Iris_v20250424_110923/shap_summary.png\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"url\\\\\\\": \\\\\\\"https://127.0.0.1:5000/api/records/p8a8y-1bn93/files/RandomForest_Iris_v20250424_110923/shap_summary.png/content\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"size\\\\\\\": 16821,\\\\n\\\",\\n-      \\\"                \\\\\\\"mimetype\\\\\\\": \\\\\\\"image/png\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"checksum\\\\\\\": \\\\\\\"md5:28ee8be9c0dbf6dc16c4acd70b42273d\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"metadata\\\\\\\": {\\\\n\\\",\\n-      \\\"                    \\\\\\\"width\\\\\\\": 1150,\\\\n\\\",\\n-      \\\"                    \\\\\\\"height\\\\\\\": 660\\\\n\\\",\\n-      \\\"                }\\\\n\\\",\\n-      \\\"            },\\\\n\\\",\\n-      \\\"            {\\\\n\\\",\\n-      \\\"                \\\\\\\"key\\\\\\\": \\\\\\\"RandomForest_Iris_v20250424_111946/confusion_matrix.png\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"url\\\\\\\": \\\\\\\"https://127.0.0.1:5000/api/records/p8a8y-1bn93/files/RandomForest_Iris_v20250424_111946/confusion_matrix.png/content\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"size\\\\\\\": 14453,\\\\n\\\",\\n-      \\\"                \\\\\\\"mimetype\\\\\\\": \\\\\\\"image/png\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"checksum\\\\\\\": \\\\\\\"md5:41c356960df1b924d7db4d4a5cc9b254\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"metadata\\\\\\\": {\\\\n\\\",\\n-      \\\"                    \\\\\\\"width\\\\\\\": 600,\\\\n\\\",\\n-      \\\"                    \\\\\\\"height\\\\\\\": 600\\\\n\\\",\\n-      \\\"                }\\\\n\\\",\\n-      \\\"            },\\\\n\\\",\\n-      \\\"            {\\\\n\\\",\\n-      \\\"                \\\\\\\"key\\\\\\\": \\\\\\\"RandomForest_Iris_v20250423_230422/pr_curve_cls_1.png\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"url\\\\\\\": \\\\\\\"https://127.0.0.1:5000/api/records/p8a8y-1bn93/files/RandomForest_Iris_v20250423_230422/pr_curve_cls_1.png/content\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"size\\\\\\\": 20226,\\\\n\\\",\\n-      \\\"                \\\\\\\"mimetype\\\\\\\": \\\\\\\"image/png\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"checksum\\\\\\\": \\\\\\\"md5:7f396723afbfa90eb3d5f3e850f52c80\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"metadata\\\\\\\": {\\\\n\\\",\\n-      \\\"                    \\\\\\\"width\\\\\\\": 640,\\\\n\\\",\\n-      \\\"                    \\\\\\\"height\\\\\\\": 480\\\\n\\\",\\n-      \\\"                }\\\\n\\\",\\n-      \\\"            },\\\\n\\\",\\n-      \\\"            {\\\\n\\\",\\n-      \\\"                \\\\\\\"key\\\\\\\": \\\\\\\"RandomForest_Iris_v20250424_111946.pkl\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"url\\\\\\\": \\\\\\\"https://127.0.0.1:5000/api/records/p8a8y-1bn93/files/RandomForest_Iris_v20250424_111946.pkl/content\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"size\\\\\\\": 282910,\\\\n\\\",\\n-      \\\"                \\\\\\\"mimetype\\\\\\\": \\\\\\\"application/octet-stream\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"checksum\\\\\\\": \\\\\\\"md5:5055123396a01237596e771a2621a82f\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"metadata\\\\\\\": {}\\\\n\\\",\\n-      \\\"            },\\\\n\\\",\\n-      \\\"            {\\\\n\\\",\\n-      \\\"                \\\\\\\"key\\\\\\\": \\\\\\\"RandomForest_Iris_v20250423_230422/feature_importances.png\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"url\\\\\\\": \\\\\\\"https://127.0.0.1:5000/api/records/p8a8y-1bn93/files/RandomForest_Iris_v20250423_230422/feature_importances.png/content\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"size\\\\\\\": 19167,\\\\n\\\",\\n-      \\\"                \\\\\\\"mimetype\\\\\\\": \\\\\\\"image/png\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"checksum\\\\\\\": \\\\\\\"md5:1702afd2578c67988efdcf1f28fe1b04\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"metadata\\\\\\\": {\\\\n\\\",\\n-      \\\"                    \\\\\\\"width\\\\\\\": 800,\\\\n\\\",\\n-      \\\"                    \\\\\\\"height\\\\\\\": 600\\\\n\\\",\\n-      \\\"                }\\\\n\\\",\\n-      \\\"            },\\\\n\\\",\\n-      \\\"            {\\\\n\\\",\\n-      \\\"                \\\\\\\"key\\\\\\\": \\\\\\\"RandomForest_Iris_v20250423_230422/roc_curve_cls_0.png\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"url\\\\\\\": \\\\\\\"https://127.0.0.1:5000/api/records/p8a8y-1bn93/files/RandomForest_Iris_v20250423_230422/roc_curve_cls_0.png/content\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"size\\\\\\\": 20100,\\\\n\\\",\\n-      \\\"                \\\\\\\"mimetype\\\\\\\": \\\\\\\"image/png\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"checksum\\\\\\\": \\\\\\\"md5:f6d5e559a27d81fb010b416bddc2fb02\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"metadata\\\\\\\": {\\\\n\\\",\\n-      \\\"                    \\\\\\\"width\\\\\\\": 640,\\\\n\\\",\\n-      \\\"                    \\\\\\\"height\\\\\\\": 480\\\\n\\\",\\n-      \\\"                }\\\\n\\\",\\n-      \\\"            },\\\\n\\\",\\n-      \\\"            {\\\\n\\\",\\n-      \\\"                \\\\\\\"key\\\\\\\": \\\\\\\"RandomForest_Iris_v20250423_230422/roc_curve_cls_2.png\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"url\\\\\\\": \\\\\\\"https://127.0.0.1:5000/api/records/p8a8y-1bn93/files/RandomForest_Iris_v20250423_230422/roc_curve_cls_2.png/content\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"size\\\\\\\": 20227,\\\\n\\\",\\n-      \\\"                \\\\\\\"mimetype\\\\\\\": \\\\\\\"image/png\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"checksum\\\\\\\": \\\\\\\"md5:c076643c49b9ae7ba3cf0794b18f74db\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"metadata\\\\\\\": {\\\\n\\\",\\n-      \\\"                    \\\\\\\"width\\\\\\\": 640,\\\\n\\\",\\n-      \\\"                    \\\\\\\"height\\\\\\\": 480\\\\n\\\",\\n-      \\\"                }\\\\n\\\",\\n-      \\\"            },\\\\n\\\",\\n-      \\\"            {\\\\n\\\",\\n-      \\\"                \\\\\\\"key\\\\\\\": \\\\\\\"RandomForest_Iris_v20250424_110923/confusion_matrix.png\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"url\\\\\\\": \\\\\\\"https://127.0.0.1:5000/api/records/p8a8y-1bn93/files/RandomForest_Iris_v20250424_110923/confusion_matrix.png/content\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"size\\\\\\\": 14453,\\\\n\\\",\\n-      \\\"                \\\\\\\"mimetype\\\\\\\": \\\\\\\"image/png\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"checksum\\\\\\\": \\\\\\\"md5:41c356960df1b924d7db4d4a5cc9b254\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"metadata\\\\\\\": {\\\\n\\\",\\n-      \\\"                    \\\\\\\"width\\\\\\\": 600,\\\\n\\\",\\n-      \\\"                    \\\\\\\"height\\\\\\\": 600\\\\n\\\",\\n-      \\\"                }\\\\n\\\",\\n-      \\\"            },\\\\n\\\",\\n-      \\\"            {\\\\n\\\",\\n-      \\\"                \\\\\\\"key\\\\\\\": \\\\\\\"RandomForest_Iris_v20250424_111946/feature_importances.png\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"url\\\\\\\": \\\\\\\"https://127.0.0.1:5000/api/records/p8a8y-1bn93/files/RandomForest_Iris_v20250424_111946/feature_importances.png/content\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"size\\\\\\\": 19167,\\\\n\\\",\\n-      \\\"                \\\\\\\"mimetype\\\\\\\": \\\\\\\"image/png\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"checksum\\\\\\\": \\\\\\\"md5:1702afd2578c67988efdcf1f28fe1b04\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"metadata\\\\\\\": {\\\\n\\\",\\n-      \\\"                    \\\\\\\"width\\\\\\\": 800,\\\\n\\\",\\n-      \\\"                    \\\\\\\"height\\\\\\\": 600\\\\n\\\",\\n-      \\\"                }\\\\n\\\",\\n-      \\\"            },\\\\n\\\",\\n-      \\\"            {\\\\n\\\",\\n-      \\\"                \\\\\\\"key\\\\\\\": \\\\\\\"RandomForest_Iris_v20250424_111946/pr_curve_cls_1.png\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"url\\\\\\\": \\\\\\\"https://127.0.0.1:5000/api/records/p8a8y-1bn93/files/RandomForest_Iris_v20250424_111946/pr_curve_cls_1.png/content\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"size\\\\\\\": 20226,\\\\n\\\",\\n-      \\\"                \\\\\\\"mimetype\\\\\\\": \\\\\\\"image/png\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"checksum\\\\\\\": \\\\\\\"md5:7f396723afbfa90eb3d5f3e850f52c80\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"metadata\\\\\\\": {\\\\n\\\",\\n-      \\\"                    \\\\\\\"width\\\\\\\": 640,\\\\n\\\",\\n-      \\\"                    \\\\\\\"height\\\\\\\": 480\\\\n\\\",\\n-      \\\"                }\\\\n\\\",\\n-      \\\"            },\\\\n\\\",\\n-      \\\"            {\\\\n\\\",\\n-      \\\"                \\\\\\\"key\\\\\\\": \\\\\\\"RandomForest_Iris_v20250424_111946/roc_curve_cls_0.png\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"url\\\\\\\": \\\\\\\"https://127.0.0.1:5000/api/records/p8a8y-1bn93/files/RandomForest_Iris_v20250424_111946/roc_curve_cls_0.png/content\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"size\\\\\\\": 20100,\\\\n\\\",\\n-      \\\"                \\\\\\\"mimetype\\\\\\\": \\\\\\\"image/png\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"checksum\\\\\\\": \\\\\\\"md5:f6d5e559a27d81fb010b416bddc2fb02\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"metadata\\\\\\\": {\\\\n\\\",\\n-      \\\"                    \\\\\\\"width\\\\\\\": 640,\\\\n\\\",\\n-      \\\"                    \\\\\\\"height\\\\\\\": 480\\\\n\\\",\\n-      \\\"                }\\\\n\\\",\\n-      \\\"            },\\\\n\\\",\\n-      \\\"            {\\\\n\\\",\\n-      \\\"                \\\\\\\"key\\\\\\\": \\\\\\\"RandomForest_Iris_v20250424_111946/roc_curve_cls_2.png\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"url\\\\\\\": \\\\\\\"https://127.0.0.1:5000/api/records/p8a8y-1bn93/files/RandomForest_Iris_v20250424_111946/roc_curve_cls_2.png/content\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"size\\\\\\\": 20227,\\\\n\\\",\\n-      \\\"                \\\\\\\"mimetype\\\\\\\": \\\\\\\"image/png\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"checksum\\\\\\\": \\\\\\\"md5:c076643c49b9ae7ba3cf0794b18f74db\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"metadata\\\\\\\": {\\\\n\\\",\\n-      \\\"                    \\\\\\\"width\\\\\\\": 640,\\\\n\\\",\\n-      \\\"                    \\\\\\\"height\\\\\\\": 480\\\\n\\\",\\n-      \\\"                }\\\\n\\\",\\n-      \\\"            },\\\\n\\\",\\n-      \\\"            {\\\\n\\\",\\n-      \\\"                \\\\\\\"key\\\\\\\": \\\\\\\"RandomForest_Iris_v20250424_111946/pr_curve_cls_0.png\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"url\\\\\\\": \\\\\\\"https://127.0.0.1:5000/api/records/p8a8y-1bn93/files/RandomForest_Iris_v20250424_111946/pr_curve_cls_0.png/content\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"size\\\\\\\": 20358,\\\\n\\\",\\n-      \\\"                \\\\\\\"mimetype\\\\\\\": \\\\\\\"image/png\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"checksum\\\\\\\": \\\\\\\"md5:30a6a3742bcbd69750bc5fd30aea58d2\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"metadata\\\\\\\": {\\\\n\\\",\\n-      \\\"                    \\\\\\\"width\\\\\\\": 640,\\\\n\\\",\\n-      \\\"                    \\\\\\\"height\\\\\\\": 480\\\\n\\\",\\n-      \\\"                }\\\\n\\\",\\n-      \\\"            },\\\\n\\\",\\n-      \\\"            {\\\\n\\\",\\n-      \\\"                \\\\\\\"key\\\\\\\": \\\\\\\"RandomForest_Iris_v20250424_111946/pr_curve_cls_2.png\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"url\\\\\\\": \\\\\\\"https://127.0.0.1:5000/api/records/p8a8y-1bn93/files/RandomForest_Iris_v20250424_111946/pr_curve_cls_2.png/content\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"size\\\\\\\": 19809,\\\\n\\\",\\n-      \\\"                \\\\\\\"mimetype\\\\\\\": \\\\\\\"image/png\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"checksum\\\\\\\": \\\\\\\"md5:22a124dad652fd24fb3a5691abcae494\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"metadata\\\\\\\": {\\\\n\\\",\\n-      \\\"                    \\\\\\\"width\\\\\\\": 640,\\\\n\\\",\\n-      \\\"                    \\\\\\\"height\\\\\\\": 480\\\\n\\\",\\n-      \\\"                }\\\\n\\\",\\n-      \\\"            },\\\\n\\\",\\n-      \\\"            {\\\\n\\\",\\n-      \\\"                \\\\\\\"key\\\\\\\": \\\\\\\"RandomForest_Iris_v20250424_111946/roc_curve_cls_1.png\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"url\\\\\\\": \\\\\\\"https://127.0.0.1:5000/api/records/p8a8y-1bn93/files/RandomForest_Iris_v20250424_111946/roc_curve_cls_1.png/content\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"size\\\\\\\": 20143,\\\\n\\\",\\n-      \\\"                \\\\\\\"mimetype\\\\\\\": \\\\\\\"image/png\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"checksum\\\\\\\": \\\\\\\"md5:917e9847fda527b030c0bcad8f2a2ea3\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"metadata\\\\\\\": {\\\\n\\\",\\n-      \\\"                    \\\\\\\"width\\\\\\\": 640,\\\\n\\\",\\n-      \\\"                    \\\\\\\"height\\\\\\\": 480\\\\n\\\",\\n-      \\\"                }\\\\n\\\",\\n-      \\\"            },\\\\n\\\",\\n-      \\\"            {\\\\n\\\",\\n-      \\\"                \\\\\\\"key\\\\\\\": \\\\\\\"RandomForest_Iris_v20250424_111946/shap_summary.png\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"url\\\\\\\": \\\\\\\"https://127.0.0.1:5000/api/records/p8a8y-1bn93/files/RandomForest_Iris_v20250424_111946/shap_summary.png/content\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"size\\\\\\\": 16885,\\\\n\\\",\\n-      \\\"                \\\\\\\"mimetype\\\\\\\": \\\\\\\"image/png\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"checksum\\\\\\\": \\\\\\\"md5:ac7959b6085a30cab3d8778a32d54d1a\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"metadata\\\\\\\": {\\\\n\\\",\\n-      \\\"                    \\\\\\\"width\\\\\\\": 1150,\\\\n\\\",\\n-      \\\"                    \\\\\\\"height\\\\\\\": 660\\\\n\\\",\\n-      \\\"                }\\\\n\\\",\\n-      \\\"            },\\\\n\\\",\\n-      \\\"            {\\\\n\\\",\\n-      \\\"                \\\\\\\"key\\\\\\\": \\\\\\\"RandomForest_Iris_v20250423_230422.jsonld\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"url\\\\\\\": \\\\\\\"https://127.0.0.1:5000/api/records/p8a8y-1bn93/files/RandomForest_Iris_v20250423_230422.jsonld/content\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"size\\\\\\\": 11745,\\\\n\\\",\\n-      \\\"                \\\\\\\"mimetype\\\\\\\": \\\\\\\"application/ld+json\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"checksum\\\\\\\": \\\\\\\"md5:e037b37c0a582b6f32c1c638c003480b\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"metadata\\\\\\\": {}\\\\n\\\",\\n-      \\\"            },\\\\n\\\",\\n-      \\\"            {\\\\n\\\",\\n-      \\\"                \\\\\\\"key\\\\\\\": \\\\\\\"RandomForest_Iris_v20250423_230422.ttl\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"url\\\\\\\": \\\\\\\"https://127.0.0.1:5000/api/records/p8a8y-1bn93/files/RandomForest_Iris_v20250423_230422.ttl/content\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"size\\\\\\\": 10107,\\\\n\\\",\\n-      \\\"                \\\\\\\"mimetype\\\\\\\": \\\\\\\"text/turtle\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"checksum\\\\\\\": \\\\\\\"md5:50f91e3780c4abfb55bf58d6ac5388d7\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"metadata\\\\\\\": {}\\\\n\\\",\\n-      \\\"            },\\\\n\\\",\\n-      \\\"            {\\\\n\\\",\\n-      \\\"                \\\\\\\"key\\\\\\\": \\\\\\\"RandomForest_Iris_v20250423_230422_run_summary.json\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"url\\\\\\\": \\\\\\\"https://127.0.0.1:5000/api/records/p8a8y-1bn93/files/RandomForest_Iris_v20250423_230422_run_summary.json/content\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"size\\\\\\\": 135528,\\\\n\\\",\\n-      \\\"                \\\\\\\"mimetype\\\\\\\": \\\\\\\"application/json\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"checksum\\\\\\\": \\\\\\\"md5:b017a4306d62eb2ef12f95d992b2946d\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"metadata\\\\\\\": {}\\\\n\\\",\\n-      \\\"            },\\\\n\\\",\\n-      \\\"            {\\\\n\\\",\\n-      \\\"                \\\\\\\"key\\\\\\\": \\\\\\\"RandomForest_Iris_v20250424_110923_run_summary.json\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"url\\\\\\\": \\\\\\\"https://127.0.0.1:5000/api/records/p8a8y-1bn93/files/RandomForest_Iris_v20250424_110923_run_summary.json/content\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"size\\\\\\\": 152427,\\\\n\\\",\\n-      \\\"                \\\\\\\"mimetype\\\\\\\": \\\\\\\"application/json\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"checksum\\\\\\\": \\\\\\\"md5:dbec09724b35b554410d3df63d89e334\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"metadata\\\\\\\": {}\\\\n\\\",\\n-      \\\"            },\\\\n\\\",\\n-      \\\"            {\\\\n\\\",\\n-      \\\"                \\\\\\\"key\\\\\\\": \\\\\\\"RandomForest_Iris_v20250424_111946_run_summary.json\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"url\\\\\\\": \\\\\\\"https://127.0.0.1:5000/api/records/p8a8y-1bn93/files/RandomForest_Iris_v20250424_111946_run_summary.json/content\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"size\\\\\\\": 155273,\\\\n\\\",\\n-      \\\"                \\\\\\\"mimetype\\\\\\\": \\\\\\\"application/json\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"checksum\\\\\\\": \\\\\\\"md5:1b0f020894735a7e335f8dd9715b8157\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"metadata\\\\\\\": {}\\\\n\\\",\\n-      \\\"            },\\\\n\\\",\\n-      \\\"            {\\\\n\\\",\\n-      \\\"                \\\\\\\"key\\\\\\\": \\\\\\\".ipynb_checkpoints/RandomForest_Iris_v20250423_230422_run_summary-checkpoint.json\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"url\\\\\\\": \\\\\\\"https://127.0.0.1:5000/api/records/p8a8y-1bn93/files/.ipynb_checkpoints/RandomForest_Iris_v20250423_230422_run_summary-checkpoint.json/content\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"size\\\\\\\": 135528,\\\\n\\\",\\n-      \\\"                \\\\\\\"mimetype\\\\\\\": \\\\\\\"application/json\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"checksum\\\\\\\": \\\\\\\"md5:b017a4306d62eb2ef12f95d992b2946d\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"metadata\\\\\\\": {}\\\\n\\\",\\n-      \\\"            },\\\\n\\\",\\n-      \\\"            {\\\\n\\\",\\n-      \\\"                \\\\\\\"key\\\\\\\": \\\\\\\".ipynb_checkpoints/RandomForest_Iris_v20250424_110923_run_summary-checkpoint.json\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"url\\\\\\\": \\\\\\\"https://127.0.0.1:5000/api/records/p8a8y-1bn93/files/.ipynb_checkpoints/RandomForest_Iris_v20250424_110923_run_summary-checkpoint.json/content\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"size\\\\\\\": 152427,\\\\n\\\",\\n-      \\\"                \\\\\\\"mimetype\\\\\\\": \\\\\\\"application/json\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"checksum\\\\\\\": \\\\\\\"md5:dbec09724b35b554410d3df63d89e334\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"metadata\\\\\\\": {}\\\\n\\\",\\n-      \\\"            },\\\\n\\\",\\n-      \\\"            {\\\\n\\\",\\n-      \\\"                \\\\\\\"key\\\\\\\": \\\\\\\".ipynb_checkpoints/RandomForest_Iris_v20250424_111946_run_summary-checkpoint.json\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"url\\\\\\\": \\\\\\\"https://127.0.0.1:5000/api/records/p8a8y-1bn93/files/.ipynb_checkpoints/RandomForest_Iris_v20250424_111946_run_summary-checkpoint.json/content\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"size\\\\\\\": 155273,\\\\n\\\",\\n-      \\\"                \\\\\\\"mimetype\\\\\\\": \\\\\\\"application/json\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"checksum\\\\\\\": \\\\\\\"md5:1b0f020894735a7e335f8dd9715b8157\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"metadata\\\\\\\": {}\\\\n\\\",\\n-      \\\"            }\\\\n\\\",\\n-      \\\"        ],\\\\n\\\",\\n-      \\\"        \\\\\\\"pids\\\\\\\": {\\\\n\\\",\\n-      \\\"            \\\\\\\"oai\\\\\\\": {\\\\n\\\",\\n-      \\\"                \\\\\\\"identifier\\\\\\\": \\\\\\\"oai:my-site.com:p8a8y-1bn93\\\\\\\",\\\\n\\\",\\n-      \\\"                \\\\\\\"provider\\\\\\\": \\\\\\\"oai\\\\\\\"\\\\n\\\",\\n-      \\\"            }\\\\n\\\",\\n-      \\\"        },\\\\n\\\",\\n-      \\\"        \\\\\\\"version_info\\\\\\\": {\\\\n\\\",\\n-      \\\"            \\\\\\\"is_latest\\\\\\\": true,\\\\n\\\",\\n-      \\\"            \\\\\\\"is_latest_draft\\\\\\\": true,\\\\n\\\",\\n-      \\\"            \\\\\\\"index\\\\\\\": 1\\\\n\\\",\\n-      \\\"        },\\\\n\\\",\\n-      \\\"        \\\\\\\"status\\\\\\\": \\\\\\\"published\\\\\\\",\\\\n\\\",\\n-      \\\"        \\\\\\\"views\\\\\\\": 0,\\\\n\\\",\\n-      \\\"        \\\\\\\"downloads\\\\\\\": 0\\\\n\\\",\\n-      \\\"    }\\\\n\\\",\\n-      \\\"}\\\\n\\\",\\n-      \\\"\\u2705 New dynamic metadata added successfully!\\\\n\\\"\\n-     ]\\n-    }\\n-   ],\\n-   \\\"source\\\": [\\n-    \\\"import json\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# Function to dynamically extract and structure metadata from the original JSON\\\\n\\\",\\n-    \\\"def extract_metadata(metadata):\\\\n\\\",\\n-    \\\"    # Debug: Check if metadata is loaded correctly\\\\n\\\",\\n-    \\\"    print(\\\\\\\"Debug: Metadata loaded successfully\\\\\\\")\\\\n\\\",\\n-    \\\"    print(metadata.get(\\\\\\\"id\\\\\\\", \\\\\\\"\\\\\\\"))  # Check if 'id' is being fetched\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    # Check if the required fields are in the metadata\\\\n\\\",\\n-    \\\"    print(\\\\\\\"Debug: Extracting fields from metadata...\\\\\\\")\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    extracted_data = {\\\\n\\\",\\n-    \\\"        \\\\\\\"invenio_metadata\\\\\\\": {\\\\n\\\",\\n-    \\\"            \\\\\\\"id\\\\\\\": metadata.get(\\\\\\\"id\\\\\\\", \\\\\\\"\\\\\\\"),\\\\n\\\",\\n-    \\\"            \\\\\\\"title\\\\\\\": metadata.get(\\\\\\\"metadata\\\\\\\", {}).get(\\\\\\\"title\\\\\\\", \\\\\\\"\\\\\\\"),\\\\n\\\",\\n-    \\\"            \\\\\\\"creator\\\\\\\": \\\\\\\", \\\\\\\".join([creator[\\\\\\\"person_or_org\\\\\\\"].get(\\\\\\\"name\\\\\\\", \\\\\\\"\\\\\\\") for creator in metadata.get(\\\\\\\"metadata\\\\\\\", {}).get(\\\\\\\"creators\\\\\\\", [])]),\\\\n\\\",\\n-    \\\"            \\\\\\\"publication_date\\\\\\\": metadata.get(\\\\\\\"metadata\\\\\\\", {}).get(\\\\\\\"publication_date\\\\\\\", \\\\\\\"\\\\\\\"),\\\\n\\\",\\n-    \\\"            \\\\\\\"files\\\\\\\": [],  # Initialize 'files' as a list\\\\n\\\",\\n-    \\\"            \\\\\\\"pids\\\\\\\": metadata.get(\\\\\\\"pids\\\\\\\", {}),\\\\n\\\",\\n-    \\\"            \\\\\\\"version_info\\\\\\\": metadata.get(\\\\\\\"versions\\\\\\\", {}),\\\\n\\\",\\n-    \\\"            \\\\\\\"status\\\\\\\": metadata.get(\\\\\\\"status\\\\\\\", \\\\\\\"\\\\\\\"),\\\\n\\\",\\n-    \\\"            \\\\\\\"views\\\\\\\": metadata.get(\\\\\\\"stats\\\\\\\", {}).get(\\\\\\\"this_version\\\\\\\", {}).get(\\\\\\\"views\\\\\\\", 0),\\\\n\\\",\\n-    \\\"            \\\\\\\"downloads\\\\\\\": metadata.get(\\\\\\\"stats\\\\\\\", {}).get(\\\\\\\"this_version\\\\\\\", {}).get(\\\\\\\"downloads\\\\\\\", 0),\\\\n\\\",\\n-    \\\"        }\\\\n\\\",\\n-    \\\"    }\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    # Extract file details from the metadata\\\\n\\\",\\n-    \\\"    for key, file_info in metadata.get(\\\\\\\"files\\\\\\\", {}).get(\\\\\\\"entries\\\\\\\", {}).items():\\\\n\\\",\\n-    \\\"        file_detail = {\\\\n\\\",\\n-    \\\"            \\\\\\\"key\\\\\\\": key,\\\\n\\\",\\n-    \\\"            \\\\\\\"url\\\\\\\": file_info[\\\\\\\"links\\\\\\\"].get(\\\\\\\"content\\\\\\\", \\\\\\\"\\\\\\\"),\\\\n\\\",\\n-    \\\"            \\\\\\\"size\\\\\\\": file_info.get(\\\\\\\"size\\\\\\\", 0),\\\\n\\\",\\n-    \\\"            \\\\\\\"mimetype\\\\\\\": file_info.get(\\\\\\\"mimetype\\\\\\\", \\\\\\\"\\\\\\\"),\\\\n\\\",\\n-    \\\"            \\\\\\\"checksum\\\\\\\": file_info.get(\\\\\\\"checksum\\\\\\\", \\\\\\\"\\\\\\\"),\\\\n\\\",\\n-    \\\"            \\\\\\\"metadata\\\\\\\": file_info.get(\\\\\\\"metadata\\\\\\\", {}),\\\\n\\\",\\n-    \\\"        }\\\\n\\\",\\n-    \\\"        extracted_data[\\\\\\\"invenio_metadata\\\\\\\"][\\\\\\\"files\\\\\\\"].append(file_detail)  # Append to the 'files' list\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    return extracted_data\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# Load the original metadata from the JSON file (replace with your actual file path)\\\\n\\\",\\n-    \\\"with open('metadata_p8a8y-1bn93.json', 'r') as f: \\\\n\\\",\\n-    \\\"    original_metadata = json.load(f)\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# Debugging: print out the first part of the original metadata to verify its structure\\\\n\\\",\\n-    \\\"print(\\\\\\\"Debug: Original Metadata (start):\\\\\\\", json.dumps(original_metadata, indent=4)[:1000])  # Print only the start for review\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# Extract relevant details dynamically\\\\n\\\",\\n-    \\\"extracted_metadata = extract_metadata(original_metadata)\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# Debugging: print the extracted metadata to verify it's correct\\\\n\\\",\\n-    \\\"print(\\\\\\\"Debug: Extracted Metadata:\\\\\\\", json.dumps(extracted_metadata, indent=4))\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# Load the existing JSON file (replace with your actual file path)\\\\n\\\",\\n-    \\\"with open('MODEL_PROVENANCE/RandomForest_Iris_v20250424_111946_run_summary.json', 'r') as f:\\\\n\\\",\\n-    \\\"    existing_metadata = json.load(f)\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# Add the extracted metadata as a new node\\\\n\\\",\\n-    \\\"existing_metadata.update(extracted_metadata)\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# Save the updated metadata back to the file\\\\n\\\",\\n-    \\\"with open('updated_metadata.json', 'w') as f:\\\\n\\\",\\n-    \\\"    json.dump(existing_metadata, f, indent=4)\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"print(\\\\\\\"\\u2705 New dynamic metadata added successfully!\\\\\\\")\\\\n\\\"\\n-   ]\\n-  },\\n-  {\\n-   \\\"cell_type\\\": \\\"code\\\",\\n-   \\\"execution_count\\\": null,\\n-   \\\"id\\\": \\\"f55d4a99-2bf2-4bd2-aeb0-4cbcb3698f90\\\",\\n-   \\\"metadata\\\": {},\\n-   \\\"outputs\\\": [],\\n-   \\\"source\\\": []\\n-  },\\n-  {\\n-   \\\"cell_type\\\": \\\"code\\\",\\n-   \\\"execution_count\\\": 204,\\n-   \\\"id\\\": \\\"38a807a7-6ecd-4ea7-93ac-78c0f853825c\\\",\\n-   \\\"metadata\\\": {},\\n-   \\\"outputs\\\": [\\n-    {\\n-     \\\"name\\\": \\\"stderr\\\",\\n-     \\\"output_type\\\": \\\"stream\\\",\\n-     \\\"text\\\": [\\n-      \\\"[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\\\\n\\\",\\n-      \\\"[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.0s\\\\n\\\",\\n-      \\\"[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    0.3s\\\\n\\\",\\n-      \\\"[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    0.4s finished\\\\n\\\",\\n-      \\\"[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\\\\n\\\",\\n-      \\\"[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\\\\n\\\",\\n-      \\\"[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\\\\n\\\",\\n-      \\\"[Parallel(n_jobs=12)]: Done 200 out of 200 | elapsed:    0.0s finished\\\\n\\\",\\n-      \\\"[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\\\\n\\\",\\n-      \\\"[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\\\\n\\\",\\n-      \\\"[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\\\\n\\\",\\n-      \\\"[Parallel(n_jobs=12)]: Done 200 out of 200 | elapsed:    0.0s finished\\\\n\\\",\\n-      \\\"[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\\\\n\\\",\\n-      \\\"[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\\\\n\\\",\\n-      \\\"[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\\\\n\\\",\\n-      \\\"[Parallel(n_jobs=12)]: Done 200 out of 200 | elapsed:    0.0s finished\\\\n\\\",\\n-      \\\"[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\\\\n\\\",\\n-      \\\"[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\\\\n\\\",\\n-      \\\"[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\\\\n\\\",\\n-      \\\"[Parallel(n_jobs=12)]: Done 200 out of 200 | elapsed:    0.0s finished\\\\n\\\",\\n-      \\\"[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\\\\n\\\",\\n-      \\\"[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\\\\n\\\",\\n-      \\\"[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\\\\n\\\",\\n-      \\\"[Parallel(n_jobs=12)]: Done 200 out of 200 | elapsed:    0.0s finished\\\\n\\\"\\n-     ]\\n-    }\\n-   ],\\n-   \\\"source\\\": [\\n-    \\\"import mlflow\\\\n\\\",\\n-    \\\"import mlflow.sklearn\\\\n\\\",\\n-    \\\"from sklearn.datasets import load_iris\\\\n\\\",\\n-    \\\"from sklearn.ensemble import RandomForestClassifier\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"X, y = load_iris(return_X_y=True)\\\\n\\\",\\n-    \\\"mlflow.sklearn.autolog()\\\\n\\\",\\n-    \\\"with mlflow.start_run() as run:\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    model = RandomForestClassifier(**hyperparams)\\\\n\\\",\\n-    \\\"    model.fit(X_train, y_train)\\\"\\n-   ]\\n-  },\\n-  {\\n-   \\\"cell_type\\\": \\\"code\\\",\\n-   \\\"execution_count\\\": null,\\n-   \\\"id\\\": \\\"570fa169-a5e2-47b3-b7f5-44f9577f22ad\\\",\\n-   \\\"metadata\\\": {},\\n-   \\\"outputs\\\": [],\\n-   \\\"source\\\": []\\n-  },\\n-  {\\n-   \\\"cell_type\\\": \\\"code\\\",\\n-   \\\"execution_count\\\": null,\\n-   \\\"id\\\": \\\"f67b7a46-a70d-44ea-976c-322a1a795311\\\",\\n-   \\\"metadata\\\": {\\n-    \\\"scrolled\\\": true\\n-   },\\n-   \\\"outputs\\\": [],\\n-   \\\"source\\\": [\\n-    \\\"# # ============================\\\\n\\\",\\n-    \\\"# # \\ud83d\\ude80 Start MLflow Run CURRENT BACKUP\\\\n\\\",\\n-    \\\"# # ============================\\\\n\\\",\\n-    \\\"# with mlflow.start_run() as run:\\\\n\\\",\\n-    \\\"#     model_name = f\\\\\\\"RandomForest_Iris_v1.0.0\\\\\\\"\\\\n\\\",\\n-    \\\"#     training_time_start = time.time()\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"#     # \\ud83d\\udcc8 Model Training\\\\n\\\",\\n-    \\\"#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\\\\n\\\",\\n-    \\\"#     model = RandomForestClassifier(n_estimators=100, random_state=42)\\\\n\\\",\\n-    \\\"#     model.fit(X_train, y_train)\\\\n\\\",\\n-    \\\"#     y_pred = model.predict(X_test)\\\\n\\\",\\n-    \\\"#     y_proba = model.predict_proba(X_test)\\\\n\\\",\\n-    \\\"#     acc = accuracy_score(y_test, y_pred)\\\\n\\\",\\n-    \\\"#     auc = roc_auc_score(y_test, y_proba, multi_class=\\\\\\\"ovr\\\\\\\")\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"#     # \\u2705 Log Environment Automatically\\\\n\\\",\\n-    \\\"#     mlflow.log_params({\\\\n\\\",\\n-    \\\"#         \\\\\\\"python_version\\\\\\\": platform.python_version(),\\\\n\\\",\\n-    \\\"#         \\\\\\\"os_platform\\\\\\\": f\\\\\\\"{platform.system()} {platform.release()}\\\\\\\",\\\\n\\\",\\n-    \\\"#         \\\\\\\"sklearn_version\\\\\\\": sklearn.__version__,\\\\n\\\",\\n-    \\\"#         \\\\\\\"pandas_version\\\\\\\": pd.__version__,\\\\n\\\",\\n-    \\\"#         \\\\\\\"numpy_version\\\\\\\": np.__version__,\\\\n\\\",\\n-    \\\"#         \\\\\\\"matplotlib_version\\\\\\\": matplotlib.__version__,\\\\n\\\",\\n-    \\\"#         \\\\\\\"seaborn_version\\\\\\\": sns.__version__,\\\\n\\\",\\n-    \\\"#         \\\\\\\"shap_version\\\\\\\": shap.__version__,\\\\n\\\",\\n-    \\\"#     })\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"#     # \\u2705 Git and Notebook Metadata\\\\n\\\",\\n-    \\\"#     mlflow.set_tag(\\\\\\\"notebook_name\\\\\\\", \\\\\\\"RQ1.ipynb\\\\\\\")\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"#     # \\u2705 Dataset Metadata Tags\\\\n\\\",\\n-    \\\"#     mlflow.set_tag(\\\\\\\"dataset_name\\\\\\\", \\\\\\\"Iris\\\\\\\") #TODO\\\\n\\\",\\n-    \\\"#     mlflow.set_tag(\\\\\\\"dataset_version\\\\\\\", \\\\\\\"1.0.0\\\\\\\") #TODO\\\\n\\\",\\n-    \\\"#     mlflow.set_tag(\\\\\\\"dataset_id\\\\\\\", \\\\\\\"iris_local\\\\\\\") #TODO\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"#     # \\u2705 Confusion Matrix Plot\\\\n\\\",\\n-    \\\"#     cm = confusion_matrix(y_test, y_pred)\\\\n\\\",\\n-    \\\"#     plt.figure(figsize=(6, 6))\\\\n\\\",\\n-    \\\"#     sns.heatmap(cm, annot=True, fmt=\\\\\\\"d\\\\\\\", cmap=\\\\\\\"Blues\\\\\\\")\\\\n\\\",\\n-    \\\"#     plt.title(\\\\\\\"Confusion Matrix\\\\\\\")\\\\n\\\",\\n-    \\\"#     plt.xlabel(\\\\\\\"Predicted\\\\\\\")\\\\n\\\",\\n-    \\\"#     plt.ylabel(\\\\\\\"Actual\\\\\\\")\\\\n\\\",\\n-    \\\"#     cm_path = \\\\\\\"confusion_matrix.png\\\\\\\"\\\\n\\\",\\n-    \\\"#     plt.savefig(cm_path)\\\\n\\\",\\n-    \\\"#     mlflow.log_artifact(cm_path)\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"#     # \\u2705 SHAP Summary\\\\n\\\",\\n-    \\\"#     explainer = shap.TreeExplainer(model)\\\\n\\\",\\n-    \\\"#     shap_values = explainer.shap_values(X_test)\\\\n\\\",\\n-    \\\"#     shap.summary_plot(shap_values, X_test, show=False)\\\\n\\\",\\n-    \\\"#     shap_path = \\\\\\\"shap_summary.png\\\\\\\"\\\\n\\\",\\n-    \\\"#     plt.savefig(shap_path)\\\\n\\\",\\n-    \\\"#     mlflow.log_artifact(shap_path)\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"#     def get_latest_commit_hash(repo_path=\\\\\\\".\\\\\\\"):\\\\n\\\",\\n-    \\\"#         # returns the full SHA of HEAD\\\\n\\\",\\n-    \\\"#         res = subprocess.run(\\\\n\\\",\\n-    \\\"#             [\\\\\\\"git\\\\\\\", \\\\\\\"-C\\\\\\\", repo_path, \\\\\\\"rev-parse\\\\\\\", \\\\\\\"HEAD\\\\\\\"],\\\\n\\\",\\n-    \\\"#             capture_output=True, text=True, check=True\\\\n\\\",\\n-    \\\"        \\\\n\\\",\\n-    \\\"#         return res.stdout.strip()\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"#     def get_remote_url(repo_path=\\\\\\\".\\\\\\\", remote=\\\\\\\"origin\\\\\\\"):\\\\n\\\",\\n-    \\\"#         # returns something like git@github.com:user/repo.git or https://...\\\\n\\\",\\n-    \\\"#         res = subprocess.run(\\\\n\\\",\\n-    \\\"#             [\\\\\\\"git\\\\\\\", \\\\\\\"-C\\\\\\\", repo_path, \\\\\\\"config\\\\\\\", \\\\\\\"--get\\\\\\\", f\\\\\\\"remote.{remote}.url\\\\\\\"],\\\\n\\\",\\n-    \\\"#             capture_output=True, text=True, check=True\\\\n\\\",\\n-    \\\"#         )\\\\n\\\",\\n-    \\\"#         return res.stdout.strip()\\\\n\\\",\\n-    \\\"    \\\\n\\\",\\n-    \\\"#     def make_commit_link(remote_url, commit_hash):\\\\n\\\",\\n-    \\\"#         # handle GitHub/GitLab convention; strip \\u201c.git\\u201d if present\\\\n\\\",\\n-    \\\"#         base = remote_url.rstrip(\\\\\\\".git\\\\\\\")\\\\n\\\",\\n-    \\\"#         # if SSH form (git@github.com:owner/repo), convert to https\\\\n\\\",\\n-    \\\"#         if base.startswith(\\\\\\\"git@\\\\\\\"):\\\\n\\\",\\n-    \\\"#             base = base.replace(\\\\\\\":\\\\\\\", \\\\\\\"/\\\\\\\").replace(\\\\\\\"git@\\\\\\\", \\\\\\\"https://\\\\\\\")\\\\n\\\",\\n-    \\\"#         return f\\\\\\\"{base}/commit/{commit_hash}\\\\\\\"\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"    \\\\n\\\",\\n-    \\\"#     def simple_commit_and_push_and_log(repo_path=\\\\\\\".\\\\\\\", message=\\\\\\\"Auto commit\\\\\\\", remote=\\\\\\\"origin\\\\\\\", branch=\\\\\\\"main\\\\\\\"):\\\\n\\\",\\n-    \\\"#     # 1) Check for changes\\\\n\\\",\\n-    \\\"#         status = subprocess.run(\\\\n\\\",\\n-    \\\"#             [\\\\\\\"git\\\\\\\", \\\\\\\"-C\\\\\\\", repo_path, \\\\\\\"status\\\\\\\", \\\\\\\"--porcelain\\\\\\\"],\\\\n\\\",\\n-    \\\"#             capture_output=True, text=True\\\\n\\\",\\n-    \\\"#         )\\\\n\\\",\\n-    \\\"#         if not status.stdout.strip():\\\\n\\\",\\n-    \\\"#             print(\\\\\\\"\\ud83d\\udfe1 No changes to commit.\\\\\\\")\\\\n\\\",\\n-    \\\"#             return None, None\\\\n\\\",\\n-    \\\"    \\\\n\\\",\\n-    \\\"#         # 2) Stage everything\\\\n\\\",\\n-    \\\"#         add = subprocess.run(\\\\n\\\",\\n-    \\\"#             [\\\\\\\"git\\\\\\\", \\\\\\\"-C\\\\\\\", repo_path, \\\\\\\"add\\\\\\\", \\\\\\\"--all\\\\\\\"],\\\\n\\\",\\n-    \\\"#             capture_output=True, text=True\\\\n\\\",\\n-    \\\"#         )\\\\n\\\",\\n-    \\\"#         if add.returncode:\\\\n\\\",\\n-    \\\"#             print(\\\\\\\"\\u274c git add failed:\\\\\\\\n\\\\\\\", add.stderr)\\\\n\\\",\\n-    \\\"#             return None, None\\\\n\\\",\\n-    \\\"    \\\\n\\\",\\n-    \\\"#         # 3) Commit\\\\n\\\",\\n-    \\\"#         commit = subprocess.run(\\\\n\\\",\\n-    \\\"#             [\\\\\\\"git\\\\\\\", \\\\\\\"-C\\\\\\\", repo_path, \\\\\\\"commit\\\\\\\", \\\\\\\"-m\\\\\\\", message],\\\\n\\\",\\n-    \\\"#             capture_output=True, text=True\\\\n\\\",\\n-    \\\"#         )\\\\n\\\",\\n-    \\\"#         if commit.returncode:\\\\n\\\",\\n-    \\\"#             print(\\\\\\\"\\u274c git commit failed:\\\\\\\\n\\\\\\\", commit.stderr)\\\\n\\\",\\n-    \\\"#             return None, None\\\\n\\\",\\n-    \\\"#         print(\\\\\\\"\\u2705 Commit successful.\\\\\\\")\\\\n\\\",\\n-    \\\"    \\\\n\\\",\\n-    \\\"#         # 4) Push\\\\n\\\",\\n-    \\\"#         push = subprocess.run(\\\\n\\\",\\n-    \\\"#             [\\\\\\\"git\\\\\\\", \\\\\\\"-C\\\\\\\", repo_path, \\\\\\\"push\\\\\\\", \\\\\\\"-u\\\\\\\", remote, branch],\\\\n\\\",\\n-    \\\"#             capture_output=True, text=True\\\\n\\\",\\n-    \\\"#         )\\\\n\\\",\\n-    \\\"#         if push.returncode:\\\\n\\\",\\n-    \\\"#             print(\\\\\\\"\\u274c git push failed:\\\\\\\\n\\\\\\\", push.stderr)\\\\n\\\",\\n-    \\\"#         else:\\\\n\\\",\\n-    \\\"#             print(\\\\\\\"\\ud83d\\ude80 Push successful.\\\\\\\")\\\\n\\\",\\n-    \\\"    \\\\n\\\",\\n-    \\\"#         # 5) Retrieve hash & remote URL\\\\n\\\",\\n-    \\\"#         sha = get_latest_commit_hash(repo_path)\\\\n\\\",\\n-    \\\"#         url = get_remote_url(repo_path, remote)\\\\n\\\",\\n-    \\\"#         link = make_commit_link(url, sha)\\\\n\\\",\\n-    \\\"    \\\\n\\\",\\n-    \\\"#         return sha, link\\\\n\\\",\\n-    \\\"    \\\\n\\\",\\n-    \\\"      \\\\n\\\",\\n-    \\\"#     sha, link = simple_commit_and_push_and_log(\\\\n\\\",\\n-    \\\"#         repo_path=\\\\\\\".\\\\\\\",\\\\n\\\",\\n-    \\\"#         message=\\\\\\\"Auto commit after successful training\\\\\\\"\\\\n\\\",\\n-    \\\"#     )\\\\n\\\",\\n-    \\\"#     if sha and link:\\\\n\\\",\\n-    \\\"#         diff_text = subprocess.check_output(\\\\n\\\",\\n-    \\\"#             [\\\\\\\"git\\\\\\\", \\\\\\\"-C\\\\\\\", \\\\\\\".\\\\\\\", \\\\\\\"diff\\\\\\\", previous_commit_hash, sha], text=True\\\\n\\\",\\n-    \\\"#         )\\\\n\\\",\\n-    \\\"                \\\\n\\\",\\n-    \\\"#         # 1) Get your repo\\u2019s remote URL and normalize to HTTPS\\\\n\\\",\\n-    \\\"#         remote_url = subprocess.check_output(\\\\n\\\",\\n-    \\\"#             [\\\\\\\"git\\\\\\\", \\\\\\\"config\\\\\\\", \\\\\\\"--get\\\\\\\", \\\\\\\"remote.origin.url\\\\\\\"],\\\\n\\\",\\n-    \\\"#             text=True\\\\n\\\",\\n-    \\\"#         ).strip().rstrip(\\\\\\\".git\\\\\\\")\\\\n\\\",\\n-    \\\"#         if remote_url.startswith(\\\\\\\"git@\\\\\\\"):\\\\n\\\",\\n-    \\\"#             # git@github.com:owner/repo.git \\u2192 https://github.com/owner/repo\\\\n\\\",\\n-    \\\"#             remote_url = remote_url.replace(\\\\\\\":\\\\\\\", \\\\\\\"/\\\\\\\").replace(\\\\\\\"git@\\\\\\\", \\\\\\\"https://\\\\\\\")\\\\n\\\",\\n-    \\\"        \\\\n\\\",\\n-    \\\"#         # 2) Build commit URLs\\\\n\\\",\\n-    \\\"#         previous_commit_url  = f\\\\\\\"{remote_url}/commit/{previous_commit_hash}\\\\\\\"\\\\n\\\",\\n-    \\\"#         current_commit_url = f\\\\\\\"{remote_url}/commit/{sha}\\\\\\\"\\\\n\\\",\\n-    \\\"#         diff_data = {\\\\n\\\",\\n-    \\\"#             \\\\\\\"previous_commit\\\\\\\":  previous_commit_hash,\\\\n\\\",\\n-    \\\"#             \\\\\\\"previous_commit_url\\\\\\\":previous_commit_url,\\\\n\\\",\\n-    \\\"#             \\\\\\\"current_commit_url\\\\\\\":current_commit_url,\\\\n\\\",\\n-    \\\"#             \\\\\\\"current_commit\\\\\\\": sha,\\\\n\\\",\\n-    \\\"#             \\\\\\\"diff\\\\\\\": diff_text\\\\n\\\",\\n-    \\\"#         }\\\\n\\\",\\n-    \\\"#         mlflow.log_dict(\\\\n\\\",\\n-    \\\"#             diff_data,\\\\n\\\",\\n-    \\\"#             artifact_file=\\\\\\\"commit_diff.json\\\\\\\"\\\\n\\\",\\n-    \\\"#         )\\\\n\\\",\\n-    \\\"#         mlflow.set_tag(\\\\\\\"git_previous_commit_hash\\\\\\\", previous_commit_hash)\\\\n\\\",\\n-    \\\"#         mlflow.set_tag(\\\\\\\"git_current_commit_hash\\\\\\\", sha)\\\\n\\\",\\n-    \\\"#         mlflow.set_tag(\\\\\\\"git__current_commit_url\\\\\\\", link) \\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"#     client   = MlflowClient()\\\\n\\\",\\n-    \\\"#     run_id    = run.info.run_id\\\\n\\\",\\n-    \\\"#     run_info  = client.get_run(run_id).info\\\\n\\\",\\n-    \\\"#     run_data  = client.get_run(run_id).data\\\\n\\\",\\n-    \\\"    \\\\n\\\",\\n-    \\\"#     # 1) params, metrics, tags\\\\n\\\",\\n-    \\\"#     params  = dict(run_data.params)\\\\n\\\",\\n-    \\\"#     metrics = dict(run_data.metrics)\\\\n\\\",\\n-    \\\"#     tags    = dict(run_data.tags)\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"#     # (4) List artifacts under a specific subfolder\\\\n\\\",\\n-    \\\"#     artifact_paths = [af.path for af in client.list_artifacts(run_id)]\\\\n\\\",\\n-    \\\"    \\\\n\\\",\\n-    \\\"#     # # 2) recursively gather all artifact paths\\\\n\\\",\\n-    \\\"#     # artifact_paths = []\\\\n\\\",\\n-    \\\"#     # def _gather(path=\\\\\\\"\\\\\\\"):\\\\n\\\",\\n-    \\\"#     #     for af in client.list_artifacts(run_id, path):\\\\n\\\",\\n-    \\\"#     #         if af.is_dir:\\\\n\\\",\\n-    \\\"#     #             _gather(af.path)\\\\n\\\",\\n-    \\\"#     #         else:\\\\n\\\",\\n-    \\\"#     #             artifact_paths.append(af.path)\\\\n\\\",\\n-    \\\"#     # _gather()\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"#     # 3) assemble summary\\\\n\\\",\\n-    \\\"#     summary = {\\\\n\\\",\\n-    \\\"#         \\\\\\\"run_id\\\\\\\":         run_id,\\\\n\\\",\\n-    \\\"#         \\\\\\\"run_name\\\\\\\": run_info.run_name,\\\\n\\\",\\n-    \\\"#         \\\\\\\"experiment_id\\\\\\\":  run_info.experiment_id,\\\\n\\\",\\n-    \\\"#         \\\\\\\"start_time\\\\\\\":     run_info.start_time,\\\\n\\\",\\n-    \\\"#         \\\\\\\"end_time\\\\\\\":       run_info.end_time,\\\\n\\\",\\n-    \\\"#         \\\\\\\"params\\\\\\\":         params,\\\\n\\\",\\n-    \\\"#         \\\\\\\"metrics\\\\\\\":        metrics,\\\\n\\\",\\n-    \\\"#         \\\\\\\"tags\\\\\\\":           tags,\\\\n\\\",\\n-    \\\"#         \\\\\\\"artifacts\\\\\\\":      artifact_paths\\\\n\\\",\\n-    \\\"#     }\\\\n\\\",\\n-    \\\"#     # 1) Create (or reuse) a base folder for run summaries\\\\n\\\",\\n-    \\\"#     base_dir = \\\\\\\"run_summaries\\\\\\\"\\\\n\\\",\\n-    \\\"#     os.makedirs(base_dir, exist_ok=True)\\\\n\\\",\\n-    \\\"    \\\\n\\\",\\n-    \\\"#    # 2) Pick next numeric folder\\\\n\\\",\\n-    \\\"#     existing = [\\\\n\\\",\\n-    \\\"#         d for d in os.listdir(base_dir)\\\\n\\\",\\n-    \\\"#         if os.path.isdir(os.path.join(base_dir, d)) and d.isdigit()\\\\n\\\",\\n-    \\\"#     ]\\\\n\\\",\\n-    \\\"#     next_num = max(map(int, existing), default=0) + 1\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"#     mlflow.log_dict(\\\\n\\\",\\n-    \\\"#         summary,\\\\n\\\",\\n-    \\\"#         artifact_file=f\\\\\\\"run_summaries/{next_num}/run_summary.json\\\\\\\"\\\\n\\\",\\n-    \\\"#     )\\\\n\\\",\\n-    \\\"#     # 3) Save the summary JSON into that folder\\\\n\\\",\\n-    \\\"#     # local_path = os.path.join(run_folder, \\\\\\\"run_summary.json\\\\\\\")\\\\n\\\",\\n-    \\\"#     # with open(local_path, \\\\\\\"w\\\\\\\") as f:\\\\n\\\",\\n-    \\\"#     #     json.dump(summary, f, indent=2)\\\\n\\\",\\n-    \\\"#     # # 4) (Optional) Mirror it into MLflow artifacts under the same counter path\\\\n\\\",\\n-    \\\"#     # mlflow.log_artifact(local_path, artifact_path=f\\\\\\\"run_summaries/{next_num}\\\\\\\")\\\\n\\\",\\n-    \\\"    \\\\n\\\",\\n-    \\\"#     # 5) Also tag the run with the folder name for easy reference\\\\n\\\",\\n-    \\\"#     mlflow.set_tag(\\\\\\\"summary_folder\\\\\\\", str(next_num))\\\\n\\\",\\n-    \\\"#         # with open(\\\\\\\"model_metadata_fair4ml.json\\\\\\\", \\\\\\\"w\\\\\\\") as f:\\\\n\\\",\\n-    \\\"#     #     json.dump(fair4ml_metadata, f, indent=2)\\\\n\\\",\\n-    \\\"#     # mlflow.log_artifact(\\\\\\\"model_metadata_fair4ml.json\\\\\\\")\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"#     mlflow.end_run()\\\"\\n-   ]\\n-  },\\n-  {\\n-   \\\"cell_type\\\": \\\"code\\\",\\n-   \\\"execution_count\\\": null,\\n-   \\\"id\\\": \\\"4211bdef-5785-472d-8ea5-0bc24a3faf3c\\\",\\n-   \\\"metadata\\\": {},\\n-   \\\"outputs\\\": [],\\n-   \\\"source\\\": [\\n-    \\\"# # ============================\\\\n\\\",\\n-    \\\"# # \\ud83d\\ude80 Start MLflow Run\\\\n\\\",\\n-    \\\"# # ============================\\\\n\\\",\\n-    \\\"# with mlflow.start_run() as run:\\\\n\\\",\\n-    \\\"#     model_name = f\\\\\\\"RandomForest_Iris_v1.0.0\\\\\\\"\\\\n\\\",\\n-    \\\"#     training_time_start = time.time()\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"#     # \\ud83d\\udcc8 Model Training\\\\n\\\",\\n-    \\\"#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\\\\n\\\",\\n-    \\\"#     model = RandomForestClassifier(n_estimators=100, random_state=42)\\\\n\\\",\\n-    \\\"#     model.fit(X_train, y_train)\\\\n\\\",\\n-    \\\"#     y_pred = model.predict(X_test)\\\\n\\\",\\n-    \\\"#     y_proba = model.predict_proba(X_test)\\\\n\\\",\\n-    \\\"#     acc = accuracy_score(y_test, y_pred)\\\\n\\\",\\n-    \\\"#     auc = roc_auc_score(y_test, y_proba, multi_class=\\\\\\\"ovr\\\\\\\")\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"#     # \\u2705 Log Environment Automatically\\\\n\\\",\\n-    \\\"#     mlflow.log_params({\\\\n\\\",\\n-    \\\"#         \\\\\\\"python_version\\\\\\\": platform.python_version(),\\\\n\\\",\\n-    \\\"#         \\\\\\\"os_platform\\\\\\\": f\\\\\\\"{platform.system()} {platform.release()}\\\\\\\",\\\\n\\\",\\n-    \\\"#         \\\\\\\"sklearn_version\\\\\\\": sklearn.__version__,\\\\n\\\",\\n-    \\\"#         \\\\\\\"pandas_version\\\\\\\": pd.__version__,\\\\n\\\",\\n-    \\\"#         \\\\\\\"numpy_version\\\\\\\": np.__version__,\\\\n\\\",\\n-    \\\"#         \\\\\\\"matplotlib_version\\\\\\\": matplotlib.__version__,\\\\n\\\",\\n-    \\\"#         \\\\\\\"seaborn_version\\\\\\\": sns.__version__,\\\\n\\\",\\n-    \\\"#         \\\\\\\"shap_version\\\\\\\": shap.__version__,\\\\n\\\",\\n-    \\\"#     })\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"#     # \\u2705 Git and Notebook Metadata\\\\n\\\",\\n-    \\\"#     mlflow.set_tag(\\\\\\\"git_commit_hash\\\\\\\", commit_hash)\\\\n\\\",\\n-    \\\"#     mlflow.set_tag(\\\\\\\"notebook_name\\\\\\\", \\\\\\\"RQ1.ipynb\\\\\\\")\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"#     # \\u2705 Dataset Metadata Tags\\\\n\\\",\\n-    \\\"#     mlflow.set_tag(\\\\\\\"dataset_name\\\\\\\", \\\\\\\"Iris\\\\\\\")\\\\n\\\",\\n-    \\\"#     mlflow.set_tag(\\\\\\\"dataset_version\\\\\\\", \\\\\\\"1.0.0\\\\\\\")\\\\n\\\",\\n-    \\\"#     mlflow.set_tag(\\\\\\\"dataset_id\\\\\\\", \\\\\\\"iris_local\\\\\\\")\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"#     # \\u2705 Confusion Matrix Plot\\\\n\\\",\\n-    \\\"#     cm = confusion_matrix(y_test, y_pred)\\\\n\\\",\\n-    \\\"#     plt.figure(figsize=(6, 6))\\\\n\\\",\\n-    \\\"#     sns.heatmap(cm, annot=True, fmt=\\\\\\\"d\\\\\\\", cmap=\\\\\\\"Blues\\\\\\\")\\\\n\\\",\\n-    \\\"#     plt.title(\\\\\\\"Confusion Matrix\\\\\\\")\\\\n\\\",\\n-    \\\"#     plt.xlabel(\\\\\\\"Predicted\\\\\\\")\\\\n\\\",\\n-    \\\"#     plt.ylabel(\\\\\\\"Actual\\\\\\\")\\\\n\\\",\\n-    \\\"#     cm_path = \\\\\\\"confusion_matrix.png\\\\\\\"\\\\n\\\",\\n-    \\\"#     plt.savefig(cm_path)\\\\n\\\",\\n-    \\\"#     mlflow.log_artifact(cm_path)\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"#     # \\u2705 SHAP Summary\\\\n\\\",\\n-    \\\"#     explainer = shap.TreeExplainer(model)\\\\n\\\",\\n-    \\\"#     shap_values = explainer.shap_values(X_test)\\\\n\\\",\\n-    \\\"#     shap.summary_plot(shap_values, X_test, show=False)\\\\n\\\",\\n-    \\\"#     shap_path = \\\\\\\"shap_summary.png\\\\\\\"\\\\n\\\",\\n-    \\\"#     plt.savefig(shap_path)\\\\n\\\",\\n-    \\\"#     mlflow.log_artifact(shap_path)\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"#     # \\u2705 FAIR4ML-style Metadata JSON\\\\n\\\",\\n-    \\\"#     fair4ml_metadata = {\\\\n\\\",\\n-    \\\"#         \\\\\\\"@type\\\\\\\": \\\\\\\"MLModel\\\\\\\",\\\\n\\\",\\n-    \\\"#         \\\\\\\"name\\\\\\\": model_name,\\\\n\\\",\\n-    \\\"#         \\\\\\\"algorithm\\\\\\\": \\\\\\\"RandomForestClassifier\\\\\\\",\\\\n\\\",\\n-    \\\"#         \\\\\\\"hyperParameters\\\\\\\": model.get_params(),\\\\n\\\",\\n-    \\\"#         \\\\\\\"trainingDataset\\\\\\\": {\\\\n\\\",\\n-    \\\"#             \\\\\\\"name\\\\\\\": \\\\\\\"Iris\\\\\\\",\\\\n\\\",\\n-    \\\"#             \\\\\\\"version\\\\\\\": \\\\\\\"1.0.0\\\\\\\",\\\\n\\\",\\n-    \\\"#             \\\\\\\"identifier\\\\\\\": \\\\\\\"iris_local\\\\\\\"\\\\n\\\",\\n-    \\\"#         },\\\\n\\\",\\n-    \\\"#         \\\\\\\"trainingMetrics\\\\\\\": {\\\\n\\\",\\n-    \\\"#             \\\\\\\"accuracy\\\\\\\": acc,\\\\n\\\",\\n-    \\\"#             \\\\\\\"roc_auc\\\\\\\": auc,\\\\n\\\",\\n-    \\\"#             \\\\\\\"precision\\\\\\\": precision_score(y_test, y_pred, average='macro'),\\\\n\\\",\\n-    \\\"#             \\\\\\\"recall\\\\\\\": recall_score(y_test, y_pred, average='macro'),\\\\n\\\",\\n-    \\\"#             \\\\\\\"f1_score\\\\\\\": f1_score(y_test, y_pred, average='macro')\\\\n\\\",\\n-    \\\"#         },\\\\n\\\",\\n-    \\\"#         \\\\\\\"environment\\\\\\\": {\\\\n\\\",\\n-    \\\"#             \\\\\\\"python\\\\\\\": platform.python_version(),\\\\n\\\",\\n-    \\\"#             \\\\\\\"os\\\\\\\": f\\\\\\\"{platform.system()} {platform.release()}\\\\\\\",\\\\n\\\",\\n-    \\\"#             \\\\\\\"libraries\\\\\\\": {\\\\n\\\",\\n-    \\\"#                 \\\\\\\"sklearn\\\\\\\": sklearn.__version__,\\\\n\\\",\\n-    \\\"#                 \\\\\\\"pandas\\\\\\\": pd.__version__,\\\\n\\\",\\n-    \\\"#                 \\\\\\\"numpy\\\\\\\": np.__version__\\\\n\\\",\\n-    \\\"#             }\\\\n\\\",\\n-    \\\"#         },\\\\n\\\",\\n-    \\\"#         \\\\\\\"source\\\\\\\": {\\\\n\\\",\\n-    \\\"#             \\\\\\\"git_commit\\\\\\\": commit_hash,\\\\n\\\",\\n-    \\\"#             \\\\\\\"notebook\\\\\\\": \\\\\\\"RQ1.ipynb\\\\\\\"\\\\n\\\",\\n-    \\\"#         }\\\\n\\\",\\n-    \\\"#     }\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"#     # \\u2500\\u2500\\u2500 UPDATE: Save FAIR4ML metadata as artifact (already in place)\\\\n\\\",\\n-    \\\"#     with open(\\\\\\\"model_metadata_fair4ml.json\\\\\\\", \\\\\\\"w\\\\\\\") as f:\\\\n\\\",\\n-    \\\"#         json.dump(fair4ml_metadata, f, indent=2)\\\\n\\\",\\n-    \\\"#     mlflow.log_artifact(\\\\\\\"model_metadata_fair4ml.json\\\\\\\")\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"#     # \\u2190 NEW: Import PROV\\u2011O library for RQ1.2\\\\n\\\",\\n-    \\\"#     from prov.model import ProvDocument, Namespace, PROV\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"#     # \\u2190 NEW: Build PROV\\u2011O document for the training run (RQ1.2)\\\\n\\\",\\n-    \\\"#     prov = ProvDocument()\\\\n\\\",\\n-    \\\"#     ex = Namespace(\\\\\\\"ex\\\\\\\", \\\\\\\"http://example.org/\\\\\\\")\\\\n\\\",\\n-    \\\"#     prov.add_namespace(ex)\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"#     # \\u2190 NEW: Define entities and activity\\\\n\\\",\\n-    \\\"#     data_ent = prov.entity(ex[\\\\\\\"dataset/iris\\\\\\\"], {\\\\n\\\",\\n-    \\\"#         \\\\\\\"prov:label\\\\\\\": \\\\\\\"Iris Dataset\\\\\\\",\\\\n\\\",\\n-    \\\"#         \\\\\\\"ex:split\\\\\\\": \\\\\\\"80/20\\\\\\\"\\\\n\\\",\\n-    \\\"#     })\\\\n\\\",\\n-    \\\"#     model_ent = prov.entity(ex[f\\\\\\\"model/{run.info.run_id}\\\\\\\"], {\\\\n\\\",\\n-    \\\"#         \\\\\\\"prov:label\\\\\\\": \\\\\\\"RandomForestClassifier\\\\\\\",\\\\n\\\",\\n-    \\\"#         \\\\\\\"ex:params\\\\\\\": json.dumps(model.get_params())\\\\n\\\",\\n-    \\\"#     })\\\\n\\\",\\n-    \\\"#     act_train = prov.activity(\\\\n\\\",\\n-    \\\"#         ex[f\\\\\\\"activity/train/{run.info.run_id}\\\\\\\"],\\\\n\\\",\\n-    \\\"#         None, None,\\\\n\\\",\\n-    \\\"#         {\\\\\\\"prov:label\\\\\\\": \\\\\\\"Model training\\\\\\\",\\\\n\\\",\\n-    \\\"#          \\\\\\\"ex:startTime\\\\\\\": run.info.start_time,\\\\n\\\",\\n-    \\\"#          \\\\\\\"ex:endTime\\\\\\\": run.info.end_time}\\\\n\\\",\\n-    \\\"#     )\\\\n\\\",\\n-    \\\"#     prov.wasGeneratedBy(model_ent, act_train)\\\\n\\\",\\n-    \\\"#     prov.used(act_train, data_ent)\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"#     # \\u2190 NEW: Serialize & log PROV\\u2011O JSON\\u2011LD artifact\\\\n\\\",\\n-    \\\"#     prov_path = \\\\\\\"model_provenance.jsonld\\\\\\\"\\\\n\\\",\\n-    \\\"#     with open(prov_path, \\\\\\\"w\\\\\\\") as f:\\\\n\\\",\\n-    \\\"#         f.write(prov.serialize(indent=2))\\\\n\\\",\\n-    \\\"#     mlflow.log_artifact(prov_path)\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"#     # (your existing git\\u2010commit & push helpers unchanged\\u2026)\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"#     sha, link = simple_commit_and_push_and_log(\\\\n\\\",\\n-    \\\"#         repo_path=\\\\\\\".\\\\\\\",\\\\n\\\",\\n-    \\\"#         message=\\\\\\\"Auto commit after successful training\\\\\\\"\\\\n\\\",\\n-    \\\"#     )\\\\n\\\",\\n-    \\\"#     if sha and link:\\\\n\\\",\\n-    \\\"#         mlflow.set_tag(\\\\\\\"git_commit_hash\\\\\\\", sha)\\\\n\\\",\\n-    \\\"#         mlflow.set_tag(\\\\\\\"git_commit_url\\\\\\\", link)\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"#     mlflow.end_run()\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# # \\u2190 NEW: RQ2 helper functions for auditing and reproducibility checks\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# def trace_run_provenance(run_id):\\\\n\\\",\\n-    \\\"#     \\\\\\\"\\\\\\\"\\\\\\\"Print key metadata and artifacts for a given MLflow run.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\",\\n-    \\\"#     from mlflow.tracking import MlflowClient\\\\n\\\",\\n-    \\\"#     client = MlflowClient()\\\\n\\\",\\n-    \\\"#     run = client.get_run(run_id)\\\\n\\\",\\n-    \\\"#     print(f\\\\\\\"\\ud83d\\udcdd Run {run_id} provenance:\\\\\\\")\\\\n\\\",\\n-    \\\"#     print(\\\\\\\"  \\u2022 Git SHA:\\\\\\\", run.data.tags.get(\\\\\\\"git_commit_hash\\\\\\\"))\\\\n\\\",\\n-    \\\"#     print(\\\\\\\"  \\u2022 Commit URL:\\\\\\\", run.data.tags.get(\\\\\\\"git_commit_url\\\\\\\"))\\\\n\\\",\\n-    \\\"#     print(\\\\\\\"  \\u2022 Dataset split:\\\\\\\", run.data.tags.get(\\\\\\\"dataset_split\\\\\\\"))\\\\n\\\",\\n-    \\\"#     print(\\\\\\\"  \\u2022 Metrics:\\\\\\\", run.data.metrics)\\\\n\\\",\\n-    \\\"#     print(\\\\\\\"  \\u2022 Artifacts:\\\\\\\", [a.path for a in client.list_artifacts(run_id)])\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# def detect_deprecated_code(run_id, grace_days=7):\\\\n\\\",\\n-    \\\"#     \\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\",\\n-    \\\"#     Check if the run's commit is older than origin/main by > grace_days.\\\\n\\\",\\n-    \\\"#     \\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\",\\n-    \\\"#     import subprocess\\\\n\\\",\\n-    \\\"#     from mlflow.tracking import MlflowClient\\\\n\\\",\\n-    \\\"#     client = MlflowClient()\\\\n\\\",\\n-    \\\"#     run = client.get_run(run_id)\\\\n\\\",\\n-    \\\"#     sha = run.data.tags.get(\\\\\\\"git_commit_hash\\\\\\\")\\\\n\\\",\\n-    \\\"#     main_ts = int(subprocess.check_output(\\\\n\\\",\\n-    \\\"#         [\\\\\\\"git\\\\\\\", \\\\\\\"log\\\\\\\", \\\\\\\"-1\\\\\\\", \\\\\\\"--format=%ct\\\\\\\", \\\\\\\"origin/main\\\\\\\"]\\\\n\\\",\\n-    \\\"#     ).strip())\\\\n\\\",\\n-    \\\"#     run_ts = int(subprocess.check_output(\\\\n\\\",\\n-    \\\"#         [\\\\\\\"git\\\\\\\", \\\\\\\"log\\\\\\\", \\\\\\\"-1\\\\\\\", \\\\\\\"--format=%ct\\\\\\\", sha]\\\\n\\\",\\n-    \\\"#     ).strip())\\\\n\\\",\\n-    \\\"#     age = (main_ts - run_ts) / 86400\\\\n\\\",\\n-    \\\"#     status = \\\\\\\"\\u26a0\\ufe0f\\\\\\\" if age > grace_days else \\\\\\\"\\u2705\\\\\\\"\\\\n\\\",\\n-    \\\"#     print(f\\\\\\\"{status} Run {run_id} is {age:.1f} days behind main.\\\\\\\")\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# # \\u2500\\u2500\\u2500 USAGE:\\\\n\\\",\\n-    \\\"# # After you execute your training cell, you can call:\\\\n\\\",\\n-    \\\"# # trace_run_provenance(<run_id>)\\\\n\\\",\\n-    \\\"# # detect_deprecated_code(<run_id>, grace_days=5)\\\\n\\\"\\n-   ]\\n-  },\\n-  {\\n-   \\\"cell_type\\\": \\\"code\\\",\\n-   \\\"execution_count\\\": null,\\n-   \\\"id\\\": \\\"9d4d71f2-ef66-4e04-9d9b-c4b381d45590\\\",\\n-   \\\"metadata\\\": {},\\n-   \\\"outputs\\\": [],\\n-   \\\"source\\\": []\\n-  }\\n- ],\\n- \\\"metadata\\\": {\\n-  \\\"kernelspec\\\": {\\n-   \\\"display_name\\\": \\\"Python 3 (ipykernel)\\\",\\n-   \\\"language\\\": \\\"python\\\",\\n-   \\\"name\\\": \\\"python3\\\"\\n-  },\\n-  \\\"language_info\\\": {\\n-   \\\"codemirror_mode\\\": {\\n-    \\\"name\\\": \\\"ipython\\\",\\n-    \\\"version\\\": 3\\n-   },\\n-   \\\"file_extension\\\": \\\".py\\\",\\n-   \\\"mimetype\\\": \\\"text/x-python\\\",\\n-   \\\"name\\\": \\\"python\\\",\\n-   \\\"nbconvert_exporter\\\": \\\"python\\\",\\n-   \\\"pygments_lexer\\\": \\\"ipython3\\\",\\n-   \\\"version\\\": \\\"3.11.5\\\"\\n-  }\\n- },\\n- \\\"nbformat\\\": 4,\\n- \\\"nbformat_minor\\\": 5\\n-}\\ndiff --git a/notebooks/RQ_notebooks/RQ1_updated_integretingsklearn_autolog.ipynb b/notebooks/RQ_notebooks/RQ1_updated_integretingsklearn_autolog.ipynb\\nnew file mode 100644\\nindex 0000000..49292cd\\n--- /dev/null\\n+++ b/notebooks/RQ_notebooks/RQ1_updated_integretingsklearn_autolog.ipynb\\n@@ -0,0 +1,3314 @@\\n+{\\n+ \\\"cells\\\": [\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 2,\\n+   \\\"id\\\": \\\"12fa6f59-927c-4003-964f-83e53793fd36\\\",\\n+   \\\"metadata\\\": {\\n+    \\\"scrolled\\\": true\\n+   },\\n+   \\\"outputs\\\": [],\\n+   \\\"source\\\": [\\n+    \\\"# TODO: atm the mlflow autolog isnt capturing metrics n params\\\\n\\\",\\n+    \\\"# and sklearn.autolog throws error( posted the issue on github)\\\\n\\\",\\n+    \\\"# Ideally, I should be able to fetch most of the imp detail via MLFLOW AUTOLOG. will check that later in time\\\\n\\\",\\n+    \\\"#============================\\\\n\\\",\\n+    \\\"# \\ud83e\\udde0 MLflow Autologging\\\\n\\\",\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# mlflow.autolog(log_input_examples=True, log_model_signatures=True)\\\\n\\\",\\n+    \\\"# mlflow.sklearn.autolog() \\\\n\\\",\\n+    \\\"# mlflow.sklearn.autolog(\\\\n\\\",\\n+    \\\"#     log_input_examples=True,\\\\n\\\",\\n+    \\\"#     log_model_signatures=True,\\\\n\\\",\\n+    \\\"#     log_post_training_metrics=True,        # calls model.score() \\u2192 accuracy\\\\n\\\",\\n+    \\\"#     disable_for_unsupported_versions=True,  # skips if versions still wonky\\\\n\\\",\\n+    \\\"#     exclusive=True                          # only patch the sklearn integration\\\\n\\\",\\n+    \\\"# )\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 3,\\n+   \\\"id\\\": \\\"1ce1a579-f08b-40bd-b4db-21b388aaea74\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [],\\n+   \\\"source\\\": [\\n+    \\\"\\\\n\\\",\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"# \\u2699\\ufe0f Install Dependencies (if needed )\\\\n\\\",\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"# !pip install mlflow scikit-learn pandas numpy matplotlib seaborn shap requests GitPython\\\\n\\\",\\n+    \\\"# !pip install --upgrade threadpoolctl\\\\n\\\",\\n+    \\\"# !pip install setuptools\\\\n\\\",\\n+    \\\"# !pip install ace_tools \\\\n\\\",\\n+    \\\"# !pip install rdflib\\\\n\\\",\\n+    \\\"# !pip install streamlit-option-menu\\\\n\\\",\\n+    \\\"# !pip install streamlit-agraph\\\\n\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"1ca4f0ae-39ee-4b22-b013-dfb1fa1b5694\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"LIBRARY IMPORTS:\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 4,\\n+   \\\"id\\\": \\\"8ca332e5-6501-4310-920b-2b769477b46e\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [],\\n+   \\\"source\\\": [\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"# \\ud83d\\udce6 Standard Library Imports\\\\n\\\",\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"import os\\\\n\\\",\\n+    \\\"import glob\\\\n\\\",\\n+    \\\"import io\\\\n\\\",\\n+    \\\"import json\\\\n\\\",\\n+    \\\"import time\\\\n\\\",\\n+    \\\"import ast\\\\n\\\",\\n+    \\\"import pickle\\\\n\\\",\\n+    \\\"import platform\\\\n\\\",\\n+    \\\"import subprocess\\\\n\\\",\\n+    \\\"from datetime import datetime, timezone\\\\n\\\",\\n+    \\\"from pprint import pprint\\\\n\\\",\\n+    \\\"from typing import List, Dict, Any\\\\n\\\",\\n+    \\\"import xml.etree.ElementTree as ET\\\\n\\\",\\n+    \\\"import urllib.parse\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"# \\ud83d\\udcca Data and Visualization\\\\n\\\",\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"import pandas as pd\\\\n\\\",\\n+    \\\"import numpy as np\\\\n\\\",\\n+    \\\"import seaborn as sns\\\\n\\\",\\n+    \\\"import matplotlib\\\\n\\\",\\n+    \\\"import matplotlib.pyplot as plt\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"# \\ud83e\\udd16 Machine Learning\\\\n\\\",\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"import sklearn\\\\n\\\",\\n+    \\\"from sklearn.datasets import load_iris\\\\n\\\",\\n+    \\\"from sklearn.ensemble import RandomForestClassifier\\\\n\\\",\\n+    \\\"from sklearn.model_selection import train_test_split\\\\n\\\",\\n+    \\\"from sklearn.preprocessing import LabelEncoder, label_binarize\\\\n\\\",\\n+    \\\"from sklearn.metrics import (\\\\n\\\",\\n+    \\\"    accuracy_score,\\\\n\\\",\\n+    \\\"    roc_auc_score,\\\\n\\\",\\n+    \\\"    confusion_matrix,\\\\n\\\",\\n+    \\\"    precision_score,\\\\n\\\",\\n+    \\\"    recall_score,\\\\n\\\",\\n+    \\\"    f1_score,\\\\n\\\",\\n+    \\\"    RocCurveDisplay,\\\\n\\\",\\n+    \\\"    PrecisionRecallDisplay\\\\n\\\",\\n+    \\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"# \\ud83d\\udd2c Experiment Tracking\\\\n\\\",\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"import mlflow\\\\n\\\",\\n+    \\\"import mlflow.sklearn\\\\n\\\",\\n+    \\\"from mlflow import MlflowClient\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"# \\ud83c\\udf10 Web / API / Networking\\\\n\\\",\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"import requests\\\\n\\\",\\n+    \\\"from dotenv import load_dotenv\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"# \\ud83e\\uddea Git & Version Control\\\\n\\\",\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"import git\\\\n\\\",\\n+    \\\"from git import Repo, GitCommandError\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"# \\ud83e\\udde0 SHAP for Explainability\\\\n\\\",\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"import shap\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"# \\ud83e\\uddec RDF & Provenance (rdflib)\\\\n\\\",\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"from rdflib import Graph, URIRef, Literal\\\\n\\\",\\n+    \\\"from rdflib.namespace import PROV, XSD\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"# \\u2699\\ufe0f System Monitoring\\\\n\\\",\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"import psutil\\\\n\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"61d4d6b8-34a9-47b5-974d-5927c0ee2256\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"DBREPO INTEGRETION\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 5,\\n+   \\\"id\\\": \\\"8e3570e2-9a60-45b4-8653-28060071e728\\\",\\n+   \\\"metadata\\\": {\\n+    \\\"scrolled\\\": true\\n+   },\\n+   \\\"outputs\\\": [\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"API Response: [{'id': '1', 'sepallengthcm': '5.100000000000000000', 'sepalwidthcm': '3.500000000000000000', 'petallengthcm': '1.400000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '2', 'sepallengthcm': '4.900000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '1.400000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '3', 'sepallengthcm': '4.700000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '1.300000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '4', 'sepallengthcm': '4.600000000000000000', 'sepalwidthcm': '3.100000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '5', 'sepallengthcm': '5.000000000000000000', 'sepalwidthcm': '3.600000000000000000', 'petallengthcm': '1.400000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '6', 'sepallengthcm': '5.400000000000000000', 'sepalwidthcm': '3.900000000000000000', 'petallengthcm': '1.700000000000000000', 'petalwidthcm': '0.400000000000000000', 'species': 'Iris-setosa'}, {'id': '7', 'sepallengthcm': '4.600000000000000000', 'sepalwidthcm': '3.400000000000000000', 'petallengthcm': '1.400000000000000000', 'petalwidthcm': '0.300000000000000000', 'species': 'Iris-setosa'}, {'id': '8', 'sepallengthcm': '5.000000000000000000', 'sepalwidthcm': '3.400000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '9', 'sepallengthcm': '4.400000000000000000', 'sepalwidthcm': '2.900000000000000000', 'petallengthcm': '1.400000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '10', 'sepallengthcm': '4.900000000000000000', 'sepalwidthcm': '3.100000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.100000000000000000', 'species': 'Iris-setosa'}, {'id': '11', 'sepallengthcm': '5.400000000000000000', 'sepalwidthcm': '3.700000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '12', 'sepallengthcm': '4.800000000000000000', 'sepalwidthcm': '3.400000000000000000', 'petallengthcm': '1.600000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '13', 'sepallengthcm': '4.800000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '1.400000000000000000', 'petalwidthcm': '0.100000000000000000', 'species': 'Iris-setosa'}, {'id': '14', 'sepallengthcm': '4.300000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '1.100000000000000000', 'petalwidthcm': '0.100000000000000000', 'species': 'Iris-setosa'}, {'id': '15', 'sepallengthcm': '5.800000000000000000', 'sepalwidthcm': '4.000000000000000000', 'petallengthcm': '1.200000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '16', 'sepallengthcm': '5.700000000000000000', 'sepalwidthcm': '4.400000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.400000000000000000', 'species': 'Iris-setosa'}, {'id': '17', 'sepallengthcm': '5.400000000000000000', 'sepalwidthcm': '3.900000000000000000', 'petallengthcm': '1.300000000000000000', 'petalwidthcm': '0.400000000000000000', 'species': 'Iris-setosa'}, {'id': '18', 'sepallengthcm': '5.100000000000000000', 'sepalwidthcm': '3.500000000000000000', 'petallengthcm': '1.400000000000000000', 'petalwidthcm': '0.300000000000000000', 'species': 'Iris-setosa'}, {'id': '19', 'sepallengthcm': '5.700000000000000000', 'sepalwidthcm': '3.800000000000000000', 'petallengthcm': '1.700000000000000000', 'petalwidthcm': '0.300000000000000000', 'species': 'Iris-setosa'}, {'id': '20', 'sepallengthcm': '5.100000000000000000', 'sepalwidthcm': '3.800000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.300000000000000000', 'species': 'Iris-setosa'}, {'id': '21', 'sepallengthcm': '5.400000000000000000', 'sepalwidthcm': '3.400000000000000000', 'petallengthcm': '1.700000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '22', 'sepallengthcm': '5.100000000000000000', 'sepalwidthcm': '3.700000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.400000000000000000', 'species': 'Iris-setosa'}, {'id': '23', 'sepallengthcm': '4.600000000000000000', 'sepalwidthcm': '3.600000000000000000', 'petallengthcm': '1.000000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '24', 'sepallengthcm': '5.100000000000000000', 'sepalwidthcm': '3.300000000000000000', 'petallengthcm': '1.700000000000000000', 'petalwidthcm': '0.500000000000000000', 'species': 'Iris-setosa'}, {'id': '25', 'sepallengthcm': '4.800000000000000000', 'sepalwidthcm': '3.400000000000000000', 'petallengthcm': '1.900000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '26', 'sepallengthcm': '5.000000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '1.600000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '27', 'sepallengthcm': '5.000000000000000000', 'sepalwidthcm': '3.400000000000000000', 'petallengthcm': '1.600000000000000000', 'petalwidthcm': '0.400000000000000000', 'species': 'Iris-setosa'}, {'id': '28', 'sepallengthcm': '5.200000000000000000', 'sepalwidthcm': '3.500000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '29', 'sepallengthcm': '5.200000000000000000', 'sepalwidthcm': '3.400000000000000000', 'petallengthcm': '1.400000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '30', 'sepallengthcm': '4.700000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '1.600000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '31', 'sepallengthcm': '4.800000000000000000', 'sepalwidthcm': '3.100000000000000000', 'petallengthcm': '1.600000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '32', 'sepallengthcm': '5.400000000000000000', 'sepalwidthcm': '3.400000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.400000000000000000', 'species': 'Iris-setosa'}, {'id': '33', 'sepallengthcm': '5.200000000000000000', 'sepalwidthcm': '4.100000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.100000000000000000', 'species': 'Iris-setosa'}, {'id': '34', 'sepallengthcm': '5.500000000000000000', 'sepalwidthcm': '4.200000000000000000', 'petallengthcm': '1.400000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '35', 'sepallengthcm': '4.900000000000000000', 'sepalwidthcm': '3.100000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.100000000000000000', 'species': 'Iris-setosa'}, {'id': '36', 'sepallengthcm': '5.000000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '1.200000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '37', 'sepallengthcm': '5.500000000000000000', 'sepalwidthcm': '3.500000000000000000', 'petallengthcm': '1.300000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '38', 'sepallengthcm': '4.900000000000000000', 'sepalwidthcm': '3.100000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.100000000000000000', 'species': 'Iris-setosa'}, {'id': '39', 'sepallengthcm': '4.400000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '1.300000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '40', 'sepallengthcm': '5.100000000000000000', 'sepalwidthcm': '3.400000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '41', 'sepallengthcm': '5.000000000000000000', 'sepalwidthcm': '3.500000000000000000', 'petallengthcm': '1.300000000000000000', 'petalwidthcm': '0.300000000000000000', 'species': 'Iris-setosa'}, {'id': '42', 'sepallengthcm': '4.500000000000000000', 'sepalwidthcm': '2.300000000000000000', 'petallengthcm': '1.300000000000000000', 'petalwidthcm': '0.300000000000000000', 'species': 'Iris-setosa'}, {'id': '43', 'sepallengthcm': '4.400000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '1.300000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '44', 'sepallengthcm': '5.000000000000000000', 'sepalwidthcm': '3.500000000000000000', 'petallengthcm': '1.600000000000000000', 'petalwidthcm': '0.600000000000000000', 'species': 'Iris-setosa'}, {'id': '45', 'sepallengthcm': '5.100000000000000000', 'sepalwidthcm': '3.800000000000000000', 'petallengthcm': '1.900000000000000000', 'petalwidthcm': '0.400000000000000000', 'species': 'Iris-setosa'}, {'id': '46', 'sepallengthcm': '4.800000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '1.400000000000000000', 'petalwidthcm': '0.300000000000000000', 'species': 'Iris-setosa'}, {'id': '47', 'sepallengthcm': '5.100000000000000000', 'sepalwidthcm': '3.800000000000000000', 'petallengthcm': '1.600000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '48', 'sepallengthcm': '4.600000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '1.400000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '49', 'sepallengthcm': '5.300000000000000000', 'sepalwidthcm': '3.700000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '50', 'sepallengthcm': '5.000000000000000000', 'sepalwidthcm': '3.300000000000000000', 'petallengthcm': '1.400000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '51', 'sepallengthcm': '7.000000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '4.700000000000000000', 'petalwidthcm': '1.400000000000000000', 'species': 'Iris-versicolor'}, {'id': '52', 'sepallengthcm': '6.400000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '4.500000000000000000', 'petalwidthcm': '1.500000000000000000', 'species': 'Iris-versicolor'}, {'id': '53', 'sepallengthcm': '6.900000000000000000', 'sepalwidthcm': '3.100000000000000000', 'petallengthcm': '4.900000000000000000', 'petalwidthcm': '1.500000000000000000', 'species': 'Iris-versicolor'}, {'id': '54', 'sepallengthcm': '5.500000000000000000', 'sepalwidthcm': '2.300000000000000000', 'petallengthcm': '4.000000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '55', 'sepallengthcm': '6.500000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '4.600000000000000000', 'petalwidthcm': '1.500000000000000000', 'species': 'Iris-versicolor'}, {'id': '56', 'sepallengthcm': '5.700000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '4.500000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '57', 'sepallengthcm': '6.300000000000000000', 'sepalwidthcm': '3.300000000000000000', 'petallengthcm': '4.700000000000000000', 'petalwidthcm': '1.600000000000000000', 'species': 'Iris-versicolor'}, {'id': '58', 'sepallengthcm': '4.900000000000000000', 'sepalwidthcm': '2.400000000000000000', 'petallengthcm': '3.300000000000000000', 'petalwidthcm': '1.000000000000000000', 'species': 'Iris-versicolor'}, {'id': '59', 'sepallengthcm': '6.600000000000000000', 'sepalwidthcm': '2.900000000000000000', 'petallengthcm': '4.600000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '60', 'sepallengthcm': '5.200000000000000000', 'sepalwidthcm': '2.700000000000000000', 'petallengthcm': '3.900000000000000000', 'petalwidthcm': '1.400000000000000000', 'species': 'Iris-versicolor'}, {'id': '61', 'sepallengthcm': '5.000000000000000000', 'sepalwidthcm': '2.000000000000000000', 'petallengthcm': '3.500000000000000000', 'petalwidthcm': '1.000000000000000000', 'species': 'Iris-versicolor'}, {'id': '62', 'sepallengthcm': '5.900000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '4.200000000000000000', 'petalwidthcm': '1.500000000000000000', 'species': 'Iris-versicolor'}, {'id': '63', 'sepallengthcm': '6.000000000000000000', 'sepalwidthcm': '2.200000000000000000', 'petallengthcm': '4.000000000000000000', 'petalwidthcm': '1.000000000000000000', 'species': 'Iris-versicolor'}, {'id': '64', 'sepallengthcm': '6.100000000000000000', 'sepalwidthcm': '2.900000000000000000', 'petallengthcm': '4.700000000000000000', 'petalwidthcm': '1.400000000000000000', 'species': 'Iris-versicolor'}, {'id': '65', 'sepallengthcm': '5.600000000000000000', 'sepalwidthcm': '2.900000000000000000', 'petallengthcm': '3.600000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '66', 'sepallengthcm': '6.700000000000000000', 'sepalwidthcm': '3.100000000000000000', 'petallengthcm': '4.400000000000000000', 'petalwidthcm': '1.400000000000000000', 'species': 'Iris-versicolor'}, {'id': '67', 'sepallengthcm': '5.600000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '4.500000000000000000', 'petalwidthcm': '1.500000000000000000', 'species': 'Iris-versicolor'}, {'id': '68', 'sepallengthcm': '5.800000000000000000', 'sepalwidthcm': '2.700000000000000000', 'petallengthcm': '4.100000000000000000', 'petalwidthcm': '1.000000000000000000', 'species': 'Iris-versicolor'}, {'id': '69', 'sepallengthcm': '6.200000000000000000', 'sepalwidthcm': '2.200000000000000000', 'petallengthcm': '4.500000000000000000', 'petalwidthcm': '1.500000000000000000', 'species': 'Iris-versicolor'}, {'id': '70', 'sepallengthcm': '5.600000000000000000', 'sepalwidthcm': '2.500000000000000000', 'petallengthcm': '3.900000000000000000', 'petalwidthcm': '1.100000000000000000', 'species': 'Iris-versicolor'}, {'id': '71', 'sepallengthcm': '5.900000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '4.800000000000000000', 'petalwidthcm': '1.800000000000000000', 'species': 'Iris-versicolor'}, {'id': '72', 'sepallengthcm': '6.100000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '4.000000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '73', 'sepallengthcm': '6.300000000000000000', 'sepalwidthcm': '2.500000000000000000', 'petallengthcm': '4.900000000000000000', 'petalwidthcm': '1.500000000000000000', 'species': 'Iris-versicolor'}, {'id': '74', 'sepallengthcm': '6.100000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '4.700000000000000000', 'petalwidthcm': '1.200000000000000000', 'species': 'Iris-versicolor'}, {'id': '75', 'sepallengthcm': '6.400000000000000000', 'sepalwidthcm': '2.900000000000000000', 'petallengthcm': '4.300000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '76', 'sepallengthcm': '6.600000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '4.400000000000000000', 'petalwidthcm': '1.400000000000000000', 'species': 'Iris-versicolor'}, {'id': '77', 'sepallengthcm': '6.800000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '4.800000000000000000', 'petalwidthcm': '1.400000000000000000', 'species': 'Iris-versicolor'}, {'id': '78', 'sepallengthcm': '6.700000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '5.000000000000000000', 'petalwidthcm': '1.700000000000000000', 'species': 'Iris-versicolor'}, {'id': '79', 'sepallengthcm': '6.000000000000000000', 'sepalwidthcm': '2.900000000000000000', 'petallengthcm': '4.500000000000000000', 'petalwidthcm': '1.500000000000000000', 'species': 'Iris-versicolor'}, {'id': '80', 'sepallengthcm': '5.700000000000000000', 'sepalwidthcm': '2.600000000000000000', 'petallengthcm': '3.500000000000000000', 'petalwidthcm': '1.000000000000000000', 'species': 'Iris-versicolor'}, {'id': '81', 'sepallengthcm': '5.500000000000000000', 'sepalwidthcm': '2.400000000000000000', 'petallengthcm': '3.800000000000000000', 'petalwidthcm': '1.100000000000000000', 'species': 'Iris-versicolor'}, {'id': '82', 'sepallengthcm': '5.500000000000000000', 'sepalwidthcm': '2.400000000000000000', 'petallengthcm': '3.700000000000000000', 'petalwidthcm': '1.000000000000000000', 'species': 'Iris-versicolor'}, {'id': '83', 'sepallengthcm': '5.800000000000000000', 'sepalwidthcm': '2.700000000000000000', 'petallengthcm': '3.900000000000000000', 'petalwidthcm': '1.200000000000000000', 'species': 'Iris-versicolor'}, {'id': '84', 'sepallengthcm': '6.000000000000000000', 'sepalwidthcm': '2.700000000000000000', 'petallengthcm': '5.100000000000000000', 'petalwidthcm': '1.600000000000000000', 'species': 'Iris-versicolor'}, {'id': '85', 'sepallengthcm': '5.400000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '4.500000000000000000', 'petalwidthcm': '1.500000000000000000', 'species': 'Iris-versicolor'}, {'id': '86', 'sepallengthcm': '6.000000000000000000', 'sepalwidthcm': '3.400000000000000000', 'petallengthcm': '4.500000000000000000', 'petalwidthcm': '1.600000000000000000', 'species': 'Iris-versicolor'}, {'id': '87', 'sepallengthcm': '6.700000000000000000', 'sepalwidthcm': '3.100000000000000000', 'petallengthcm': '4.700000000000000000', 'petalwidthcm': '1.500000000000000000', 'species': 'Iris-versicolor'}, {'id': '88', 'sepallengthcm': '6.300000000000000000', 'sepalwidthcm': '2.300000000000000000', 'petallengthcm': '4.400000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '89', 'sepallengthcm': '5.600000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '4.100000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '90', 'sepallengthcm': '5.500000000000000000', 'sepalwidthcm': '2.500000000000000000', 'petallengthcm': '4.000000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '91', 'sepallengthcm': '5.500000000000000000', 'sepalwidthcm': '2.600000000000000000', 'petallengthcm': '4.400000000000000000', 'petalwidthcm': '1.200000000000000000', 'species': 'Iris-versicolor'}, {'id': '92', 'sepallengthcm': '6.100000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '4.600000000000000000', 'petalwidthcm': '1.400000000000000000', 'species': 'Iris-versicolor'}, {'id': '93', 'sepallengthcm': '5.800000000000000000', 'sepalwidthcm': '2.600000000000000000', 'petallengthcm': '4.000000000000000000', 'petalwidthcm': '1.200000000000000000', 'species': 'Iris-versicolor'}, {'id': '94', 'sepallengthcm': '5.000000000000000000', 'sepalwidthcm': '2.300000000000000000', 'petallengthcm': '3.300000000000000000', 'petalwidthcm': '1.000000000000000000', 'species': 'Iris-versicolor'}, {'id': '95', 'sepallengthcm': '5.600000000000000000', 'sepalwidthcm': '2.700000000000000000', 'petallengthcm': '4.200000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '96', 'sepallengthcm': '5.700000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '4.200000000000000000', 'petalwidthcm': '1.200000000000000000', 'species': 'Iris-versicolor'}, {'id': '97', 'sepallengthcm': '5.700000000000000000', 'sepalwidthcm': '2.900000000000000000', 'petallengthcm': '4.200000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '98', 'sepallengthcm': '6.200000000000000000', 'sepalwidthcm': '2.900000000000000000', 'petallengthcm': '4.300000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '99', 'sepallengthcm': '5.100000000000000000', 'sepalwidthcm': '2.500000000000000000', 'petallengthcm': '3.000000000000000000', 'petalwidthcm': '1.100000000000000000', 'species': 'Iris-versicolor'}, {'id': '100', 'sepallengthcm': '5.700000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '4.100000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '101', 'sepallengthcm': '6.300000000000000000', 'sepalwidthcm': '3.300000000000000000', 'petallengthcm': '6.000000000000000000', 'petalwidthcm': '2.500000000000000000', 'species': 'Iris-virginica'}, {'id': '102', 'sepallengthcm': '5.800000000000000000', 'sepalwidthcm': '2.700000000000000000', 'petallengthcm': '5.100000000000000000', 'petalwidthcm': '1.900000000000000000', 'species': 'Iris-virginica'}, {'id': '103', 'sepallengthcm': '7.100000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '5.900000000000000000', 'petalwidthcm': '2.100000000000000000', 'species': 'Iris-virginica'}, {'id': '104', 'sepallengthcm': '6.300000000000000000', 'sepalwidthcm': '2.900000000000000000', 'petallengthcm': '5.600000000000000000', 'petalwidthcm': '1.800000000000000000', 'species': 'Iris-virginica'}, {'id': '105', 'sepallengthcm': '6.500000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '5.800000000000000000', 'petalwidthcm': '2.200000000000000000', 'species': 'Iris-virginica'}, {'id': '106', 'sepallengthcm': '7.600000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '6.600000000000000000', 'petalwidthcm': '2.100000000000000000', 'species': 'Iris-virginica'}, {'id': '107', 'sepallengthcm': '4.900000000000000000', 'sepalwidthcm': '2.500000000000000000', 'petallengthcm': '4.500000000000000000', 'petalwidthcm': '1.700000000000000000', 'species': 'Iris-virginica'}, {'id': '108', 'sepallengthcm': '7.300000000000000000', 'sepalwidthcm': '2.900000000000000000', 'petallengthcm': '6.300000000000000000', 'petalwidthcm': '1.800000000000000000', 'species': 'Iris-virginica'}, {'id': '109', 'sepallengthcm': '6.700000000000000000', 'sepalwidthcm': '2.500000000000000000', 'petallengthcm': '5.800000000000000000', 'petalwidthcm': '1.800000000000000000', 'species': 'Iris-virginica'}, {'id': '110', 'sepallengthcm': '7.200000000000000000', 'sepalwidthcm': '3.600000000000000000', 'petallengthcm': '6.100000000000000000', 'petalwidthcm': '2.500000000000000000', 'species': 'Iris-virginica'}, {'id': '111', 'sepallengthcm': '6.500000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '5.100000000000000000', 'petalwidthcm': '2.000000000000000000', 'species': 'Iris-virginica'}, {'id': '112', 'sepallengthcm': '6.400000000000000000', 'sepalwidthcm': '2.700000000000000000', 'petallengthcm': '5.300000000000000000', 'petalwidthcm': '1.900000000000000000', 'species': 'Iris-virginica'}, {'id': '113', 'sepallengthcm': '6.800000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '5.500000000000000000', 'petalwidthcm': '2.100000000000000000', 'species': 'Iris-virginica'}, {'id': '114', 'sepallengthcm': '5.700000000000000000', 'sepalwidthcm': '2.500000000000000000', 'petallengthcm': '5.000000000000000000', 'petalwidthcm': '2.000000000000000000', 'species': 'Iris-virginica'}, {'id': '115', 'sepallengthcm': '5.800000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '5.100000000000000000', 'petalwidthcm': '2.400000000000000000', 'species': 'Iris-virginica'}, {'id': '116', 'sepallengthcm': '6.400000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '5.300000000000000000', 'petalwidthcm': '2.300000000000000000', 'species': 'Iris-virginica'}, {'id': '117', 'sepallengthcm': '6.500000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '5.500000000000000000', 'petalwidthcm': '1.800000000000000000', 'species': 'Iris-virginica'}, {'id': '118', 'sepallengthcm': '7.700000000000000000', 'sepalwidthcm': '3.800000000000000000', 'petallengthcm': '6.700000000000000000', 'petalwidthcm': '2.200000000000000000', 'species': 'Iris-virginica'}, {'id': '119', 'sepallengthcm': '7.700000000000000000', 'sepalwidthcm': '2.600000000000000000', 'petallengthcm': '6.900000000000000000', 'petalwidthcm': '2.300000000000000000', 'species': 'Iris-virginica'}, {'id': '120', 'sepallengthcm': '6.000000000000000000', 'sepalwidthcm': '2.200000000000000000', 'petallengthcm': '5.000000000000000000', 'petalwidthcm': '1.500000000000000000', 'species': 'Iris-virginica'}, {'id': '121', 'sepallengthcm': '6.900000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '5.700000000000000000', 'petalwidthcm': '2.300000000000000000', 'species': 'Iris-virginica'}, {'id': '122', 'sepallengthcm': '5.600000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '4.900000000000000000', 'petalwidthcm': '2.000000000000000000', 'species': 'Iris-virginica'}, {'id': '123', 'sepallengthcm': '7.700000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '6.700000000000000000', 'petalwidthcm': '2.000000000000000000', 'species': 'Iris-virginica'}, {'id': '124', 'sepallengthcm': '6.300000000000000000', 'sepalwidthcm': '2.700000000000000000', 'petallengthcm': '4.900000000000000000', 'petalwidthcm': '1.800000000000000000', 'species': 'Iris-virginica'}, {'id': '125', 'sepallengthcm': '6.700000000000000000', 'sepalwidthcm': '3.300000000000000000', 'petallengthcm': '5.700000000000000000', 'petalwidthcm': '2.100000000000000000', 'species': 'Iris-virginica'}, {'id': '126', 'sepallengthcm': '7.200000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '6.000000000000000000', 'petalwidthcm': '1.800000000000000000', 'species': 'Iris-virginica'}, {'id': '127', 'sepallengthcm': '6.200000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '4.800000000000000000', 'petalwidthcm': '1.800000000000000000', 'species': 'Iris-virginica'}, {'id': '128', 'sepallengthcm': '6.100000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '4.900000000000000000', 'petalwidthcm': '1.800000000000000000', 'species': 'Iris-virginica'}, {'id': '129', 'sepallengthcm': '6.400000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '5.600000000000000000', 'petalwidthcm': '2.100000000000000000', 'species': 'Iris-virginica'}, {'id': '130', 'sepallengthcm': '7.200000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '5.800000000000000000', 'petalwidthcm': '1.600000000000000000', 'species': 'Iris-virginica'}, {'id': '131', 'sepallengthcm': '7.400000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '6.100000000000000000', 'petalwidthcm': '1.900000000000000000', 'species': 'Iris-virginica'}, {'id': '132', 'sepallengthcm': '7.900000000000000000', 'sepalwidthcm': '3.800000000000000000', 'petallengthcm': '6.400000000000000000', 'petalwidthcm': '2.000000000000000000', 'species': 'Iris-virginica'}, {'id': '133', 'sepallengthcm': '6.400000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '5.600000000000000000', 'petalwidthcm': '2.200000000000000000', 'species': 'Iris-virginica'}, {'id': '134', 'sepallengthcm': '6.300000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '5.100000000000000000', 'petalwidthcm': '1.500000000000000000', 'species': 'Iris-virginica'}, {'id': '135', 'sepallengthcm': '6.100000000000000000', 'sepalwidthcm': '2.600000000000000000', 'petallengthcm': '5.600000000000000000', 'petalwidthcm': '1.400000000000000000', 'species': 'Iris-virginica'}, {'id': '136', 'sepallengthcm': '7.700000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '6.100000000000000000', 'petalwidthcm': '2.300000000000000000', 'species': 'Iris-virginica'}, {'id': '137', 'sepallengthcm': '6.300000000000000000', 'sepalwidthcm': '3.400000000000000000', 'petallengthcm': '5.600000000000000000', 'petalwidthcm': '2.400000000000000000', 'species': 'Iris-virginica'}, {'id': '138', 'sepallengthcm': '6.400000000000000000', 'sepalwidthcm': '3.100000000000000000', 'petallengthcm': '5.500000000000000000', 'petalwidthcm': '1.800000000000000000', 'species': 'Iris-virginica'}, {'id': '139', 'sepallengthcm': '6.000000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '4.800000000000000000', 'petalwidthcm': '1.800000000000000000', 'species': 'Iris-virginica'}, {'id': '140', 'sepallengthcm': '6.900000000000000000', 'sepalwidthcm': '3.100000000000000000', 'petallengthcm': '5.400000000000000000', 'petalwidthcm': '2.100000000000000000', 'species': 'Iris-virginica'}, {'id': '141', 'sepallengthcm': '6.700000000000000000', 'sepalwidthcm': '3.100000000000000000', 'petallengthcm': '5.600000000000000000', 'petalwidthcm': '2.400000000000000000', 'species': 'Iris-virginica'}, {'id': '142', 'sepallengthcm': '6.900000000000000000', 'sepalwidthcm': '3.100000000000000000', 'petallengthcm': '5.100000000000000000', 'petalwidthcm': '2.300000000000000000', 'species': 'Iris-virginica'}, {'id': '143', 'sepallengthcm': '5.800000000000000000', 'sepalwidthcm': '2.700000000000000000', 'petallengthcm': '5.100000000000000000', 'petalwidthcm': '1.900000000000000000', 'species': 'Iris-virginica'}, {'id': '144', 'sepallengthcm': '6.800000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '5.900000000000000000', 'petalwidthcm': '2.300000000000000000', 'species': 'Iris-virginica'}, {'id': '145', 'sepallengthcm': '6.700000000000000000', 'sepalwidthcm': '3.300000000000000000', 'petallengthcm': '5.700000000000000000', 'petalwidthcm': '2.500000000000000000', 'species': 'Iris-virginica'}, {'id': '146', 'sepallengthcm': '6.700000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '5.200000000000000000', 'petalwidthcm': '2.300000000000000000', 'species': 'Iris-virginica'}, {'id': '147', 'sepallengthcm': '6.300000000000000000', 'sepalwidthcm': '2.500000000000000000', 'petallengthcm': '5.000000000000000000', 'petalwidthcm': '1.900000000000000000', 'species': 'Iris-virginica'}, {'id': '148', 'sepallengthcm': '6.500000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '5.200000000000000000', 'petalwidthcm': '2.000000000000000000', 'species': 'Iris-virginica'}, {'id': '149', 'sepallengthcm': '6.200000000000000000', 'sepalwidthcm': '3.400000000000000000', 'petallengthcm': '5.400000000000000000', 'petalwidthcm': '2.300000000000000000', 'species': 'Iris-virginica'}, {'id': '150', 'sepallengthcm': '5.900000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '5.100000000000000000', 'petalwidthcm': '1.800000000000000000', 'species': 'Iris-virginica'}]\\\\n\\\",\\n+      \\\"<built-in method count of list object at 0x0000022ADD5443C0>\\\\n\\\"\\n+     ]\\n+    }\\n+   ],\\n+   \\\"source\\\": [\\n+    \\\"# API endpoint URL\\\\n\\\",\\n+    \\\"API_URL = \\\\\\\"http://localhost/api/database/c3a42d17-42b7-43c9-a504-2363fb4c9c8d/table/5315e7da-64fb-4fdb-b493-95b4138c765f/data?size=100000&page=0\\\\\\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# Define the headers\\\\n\\\",\\n+    \\\"headers = {\\\\n\\\",\\n+    \\\"    \\\\\\\"Accept\\\\\\\": \\\\\\\"application/json\\\\\\\"  # Specify the expected response format\\\\n\\\",\\n+    \\\"}\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"try:\\\\n\\\",\\n+    \\\"    # Send a GET request to the API with the Accept header\\\\n\\\",\\n+    \\\"    response = requests.get(API_URL, headers=headers)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # Check if the request was successful\\\\n\\\",\\n+    \\\"    if response.status_code == 200:\\\\n\\\",\\n+    \\\"        # Parse the JSON response\\\\n\\\",\\n+    \\\"        dataset = response.json()\\\\n\\\",\\n+    \\\"        print(\\\\\\\"API Response:\\\\\\\", dataset)\\\\n\\\",\\n+    \\\"        print( dataset.count)\\\\n\\\",\\n+    \\\"    else:\\\\n\\\",\\n+    \\\"        print(f\\\\\\\"Error: Received status code {response.status_code}\\\\\\\")\\\\n\\\",\\n+    \\\"        print(\\\\\\\"Response content:\\\\\\\", response.text)\\\\n\\\",\\n+    \\\"       \\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"except requests.exceptions.RequestException as e:\\\\n\\\",\\n+    \\\"    print(f\\\\\\\"Request failed: {e}\\\\\\\")\\\\n\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"09557f94-325c-4bd6-882a-069a9e3c5ecd\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"replacing dynamic fetching of data When and if DBREPO isnt running \\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 6,\\n+   \\\"id\\\": \\\"ce6e020d-cb80-49ec-8bcc-687b1e08885c\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [],\\n+   \\\"source\\\": [\\n+    \\\"# 1. Read the JSON file id the API isnt available this data is saved locally but the data is from the API endpoint\\\\n\\\",\\n+    \\\"with open(\\\\\\\"iris_data.json\\\\\\\", \\\\\\\"r\\\\\\\") as f:\\\\n\\\",\\n+    \\\"    dataset = json.load(f)\\\\n\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"a6c6007a-2126-4b1a-90ee-3326eb39a362\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"Metadata fetching from db repo API CALLS\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"9165f478-a44e-4125-8929-a8d77fdcb4c5\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"METADATA ON DATABASE LEVEL\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 7,\\n+   \\\"id\\\": \\\"abe912e7-bf9b-4bbd-8e43-6046745ade3f\\\",\\n+   \\\"metadata\\\": {\\n+    \\\"scrolled\\\": true\\n+   },\\n+   \\\"outputs\\\": [],\\n+   \\\"source\\\": [\\n+    \\\"\\\\n\\\",\\n+    \\\"DB_API = \\\\\\\"http://localhost/api/database/{db_id}\\\\\\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"def fetch_db_metadata(db_id: str) -> dict:\\\\n\\\",\\n+    \\\"    url = DB_API.format(db_id=db_id)\\\\n\\\",\\n+    \\\"    try:\\\\n\\\",\\n+    \\\"        resp = requests.get(url)\\\\n\\\",\\n+    \\\"        resp.raise_for_status()\\\\n\\\",\\n+    \\\"        return resp.json()\\\\n\\\",\\n+    \\\"    except requests.exceptions.RequestException as e:\\\\n\\\",\\n+    \\\"        print(f\\\\\\\"[\\u26a0\\ufe0f Error] Failed to fetch DB metadata for {db_id}: {e}\\\\\\\")\\\\n\\\",\\n+    \\\"        return {}  # or return None, depending on what your app prefers\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"def log_db_metadata(db_meta: dict):\\\\n\\\",\\n+    \\\"    # 1) Core DB fields as params, defaulting to empty string if key is missing\\\\n\\\",\\n+    \\\"    mlflow.log_param(\\\\\\\"database.id\\\\\\\",          db_meta.get(\\\\\\\"id\\\\\\\", \\\\\\\"\\\\\\\"))\\\\n\\\",\\n+    \\\"    mlflow.log_param(\\\\\\\"database.name\\\\\\\",        db_meta.get(\\\\\\\"name\\\\\\\", \\\\\\\"\\\\\\\"))\\\\n\\\",\\n+    \\\"    mlflow.log_param(\\\\\\\"database.description\\\\\\\", db_meta.get(\\\\\\\"description\\\\\\\", \\\\\\\"\\\\\\\"))\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # 2) Handle nested keys safely for owner\\\\n\\\",\\n+    \\\"    try:\\\\n\\\",\\n+    \\\"        owner = db_meta.get(\\\\\\\"tables\\\\\\\", [{}])[0].get(\\\\\\\"owner\\\\\\\", {}).get(\\\\\\\"username\\\\\\\", \\\\\\\"\\\\\\\")\\\\n\\\",\\n+    \\\"    except Exception:\\\\n\\\",\\n+    \\\"        owner = \\\\\\\"\\\\\\\"\\\\n\\\",\\n+    \\\"    mlflow.log_param(\\\\\\\"database.owner\\\\\\\", owner)\\\\n\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"53cbd7eb-0d97-4326-9bfc-f6fcee14ef9c\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"MATADATA FROM: <ns0:OAI-PMH xmlns:ns0=\\\\\\\"http://www.openarchives.org/OAI/2.0/\\\\\\\" xmlns:xsi=\\\\\\\"http://www.w3.org/2001/XMLSchema-instance\\\\\\\" xsi:schemaLocation=\\\\\\\"http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd\\\\\\\">\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 8,\\n+   \\\"id\\\": \\\"296f307e-e01b-477a-9406-92cab9f2d7bf\\\",\\n+   \\\"metadata\\\": {\\n+    \\\"scrolled\\\": true\\n+   },\\n+   \\\"outputs\\\": [\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"<ns0:OAI-PMH xmlns:ns0=\\\\\\\"http://www.openarchives.org/OAI/2.0/\\\\\\\" xmlns:xsi=\\\\\\\"http://www.w3.org/2001/XMLSchema-instance\\\\\\\" xsi:schemaLocation=\\\\\\\"http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd\\\\\\\">\\\\n\\\",\\n+      \\\"    <ns0:responseDate>2025-04-25T11:13:30Z</ns0:responseDate>\\\\n\\\",\\n+      \\\"    <ns0:request verb=\\\\\\\"Identify\\\\\\\">https://localhost/api/oai</ns0:request>\\\\n\\\",\\n+      \\\"    <ns0:Identify>\\\\n\\\",\\n+      \\\"    <ns0:repositoryName>Database Repository</ns0:repositoryName>\\\\n\\\",\\n+      \\\"    <ns0:baseURL>http://localhost</ns0:baseURL>\\\\n\\\",\\n+      \\\"    <ns0:protocolVersion>2.0</ns0:protocolVersion>\\\\n\\\",\\n+      \\\"    <ns0:adminEmail>noreply@localhost</ns0:adminEmail>\\\\n\\\",\\n+      \\\"    <ns0:earliestDatestamp />\\\\n\\\",\\n+      \\\"    <ns0:deletedRecord>persistent</ns0:deletedRecord>\\\\n\\\",\\n+      \\\"    <ns0:granularity>YYYY-MM-DDThh:mm:ssZ</ns0:granularity>\\\\n\\\",\\n+      \\\"</ns0:Identify>\\\\n\\\",\\n+      \\\"</ns0:OAI-PMH>\\\\n\\\"\\n+     ]\\n+    }\\n+   ],\\n+   \\\"source\\\": [\\n+    \\\"# 1) Fetch your database metadata\\\\n\\\",\\n+    \\\"db_url = \\\\\\\"http://localhost/api/database/c3a42d17-42b7-43c9-a504-2363fb4c9c8d\\\\\\\"\\\\n\\\",\\n+    \\\"db_resp = requests.get(db_url)\\\\n\\\",\\n+    \\\"db_resp.raise_for_status()\\\\n\\\",\\n+    \\\"db_data = db_resp.json()\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"db_id  = db_data[\\\\\\\"id\\\\\\\"]\\\\n\\\",\\n+    \\\"tbl_id = db_data[\\\\\\\"tables\\\\\\\"][0][\\\\\\\"id\\\\\\\"]\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# 2) Build the OAI-PMH URL, URL-encoding the `set` param\\\\n\\\",\\n+    \\\"set_param   = f\\\\\\\"Databases/{db_id}/Tables/{tbl_id}\\\\\\\"\\\\n\\\",\\n+    \\\"encoded_set = urllib.parse.quote(set_param, safe=\\\\\\\"\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"oai_url = (\\\\n\\\",\\n+    \\\"    \\\\\\\"http://localhost/api/oai\\\\\\\"\\\\n\\\",\\n+    \\\"    f\\\\\\\"?metadataPrefix=oai_dc\\\\\\\"\\\\n\\\",\\n+    \\\"    f\\\\\\\"&from=2025-03-01\\\\\\\"\\\\n\\\",\\n+    \\\"    f\\\\\\\"&until=2025-03-07\\\\\\\"\\\\n\\\",\\n+    \\\"    f\\\\\\\"&set={encoded_set}\\\\\\\"\\\\n\\\",\\n+    \\\"    f\\\\\\\"&resumptionToken=string\\\\\\\"\\\\n\\\",\\n+    \\\"    f\\\\\\\"&fromDate=2025-03-07T19%3A35%3A51.476Z\\\\\\\"\\\\n\\\",\\n+    \\\"    f\\\\\\\"&untilDate=2025-03-07T19%3A35%3A51.476Z\\\\\\\"\\\\n\\\",\\n+    \\\"    f\\\\\\\"&parametersString=string\\\\\\\"\\\\n\\\",\\n+    \\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# 3) Call and parse\\\\n\\\",\\n+    \\\"try:\\\\n\\\",\\n+    \\\"    resp = requests.get(oai_url)\\\\n\\\",\\n+    \\\"    resp.raise_for_status()\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    if \\\\\\\"xml\\\\\\\" in resp.headers.get(\\\\\\\"Content-Type\\\\\\\", \\\\\\\"\\\\\\\"):\\\\n\\\",\\n+    \\\"        root = ET.fromstring(resp.text)\\\\n\\\",\\n+    \\\"        print(ET.tostring(root, encoding=\\\\\\\"utf-8\\\\\\\").decode())\\\\n\\\",\\n+    \\\"    else:\\\\n\\\",\\n+    \\\"        print(\\\\\\\"Non-XML response:\\\\\\\", resp.headers.get(\\\\\\\"Content-Type\\\\\\\"), resp.text)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"except requests.exceptions.RequestException as e:\\\\n\\\",\\n+    \\\"    print(\\\\\\\"Request failed:\\\\\\\", e)\\\\n\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 9,\\n+   \\\"id\\\": \\\"61cc99ab-4a5c-4142-8725-e7c940673ffd\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [],\\n+   \\\"source\\\": [\\n+    \\\"# \\u2026after you fetch & parse your XML into `root`\\u2026\\\\n\\\",\\n+    \\\"ns = {\\\\\\\"oai\\\\\\\": \\\\\\\"http://www.openarchives.org/OAI/2.0/\\\\\\\"}\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"repo_name   = root.findtext(\\\\\\\"oai:Identify/oai:repositoryName\\\\\\\", namespaces=ns) or \\\\\\\"N/A\\\\\\\"\\\\n\\\",\\n+    \\\"base_url    = root.findtext(\\\\\\\"oai:Identify/oai:baseURL\\\\\\\", namespaces=ns) or \\\\\\\"N/A\\\\\\\"\\\\n\\\",\\n+    \\\"protocol    = root.findtext(\\\\\\\"oai:Identify/oai:protocolVersion\\\\\\\", namespaces=ns) or \\\\\\\"N/A\\\\\\\"\\\\n\\\",\\n+    \\\"admin_email = root.findtext(\\\\\\\"oai:Identify/oai:adminEmail\\\\\\\", namespaces=ns) or \\\\\\\"N/A\\\\\\\"\\\\n\\\",\\n+    \\\"gran        = root.findtext(\\\\\\\"oai:Identify/oai:granularity\\\\\\\", namespaces=ns) or \\\\\\\"N/A\\\\\\\"\\\\n\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"74214aa7-c12f-414e-9feb-094a366b855b\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"METADATA ON History Logging\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 10,\\n+   \\\"id\\\": \\\"e9c74e9b-c9b0-4b4a-82eb-2a6e56456508\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"API Response: [{'timestamp': '2025-04-23T20:42:29.501Z', 'event': 'insert', 'total': 150}]\\\\n\\\"\\n+     ]\\n+    }\\n+   ],\\n+   \\\"source\\\": [\\n+    \\\"url = \\\\\\\"http://localhost/api/database/c3a42d17-42b7-43c9-a504-2363fb4c9c8d/table/5315e7da-64fb-4fdb-b493-95b4138c765f/history\\\\\\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"try:\\\\n\\\",\\n+    \\\"    # Send a GET request to the API\\\\n\\\",\\n+    \\\"    response = requests.get(url)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # Check if the request was successful\\\\n\\\",\\n+    \\\"    if response.status_code == 200:\\\\n\\\",\\n+    \\\"        # Parse the JSON response\\\\n\\\",\\n+    \\\"        data = response.json()\\\\n\\\",\\n+    \\\"        print(\\\\\\\"API Response:\\\\\\\", data)\\\\n\\\",\\n+    \\\"    else:\\\\n\\\",\\n+    \\\"        print(f\\\\\\\"Error: Received status code {response.status_code}\\\\\\\")\\\\n\\\",\\n+    \\\"        print(\\\\\\\"Response content:\\\\\\\", response.text)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"except requests.exceptions.RequestException as e:\\\\n\\\",\\n+    \\\"    print(f\\\\\\\"Request failed: {e}\\\\\\\")\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 11,\\n+   \\\"id\\\": \\\"3630c954-5ad2-4759-b9a0-fa6e20e184ef\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [],\\n+   \\\"source\\\": [\\n+    \\\"first   = data[0]\\\\n\\\",\\n+    \\\"last    = data[-1]\\\\n\\\",\\n+    \\\"count_0 = first[\\\\\\\"total\\\\\\\"]    # e.g. 149\\\\n\\\",\\n+    \\\"count_N = last[\\\\\\\"total\\\\\\\"]     # e.g. 149 again, or changed\\\\n\\\",\\n+    \\\"ts_last = last[\\\\\\\"timestamp\\\\\\\"]  # e.g. \\\\\\\"2025-03-28T17:42:38.058Z\\\\\\\"\\\\n\\\",\\n+    \\\"n_insert = sum(1 for ev in data if ev[\\\\\\\"event\\\\\\\"]==\\\\\\\"insert\\\\\\\")\\\\n\\\",\\n+    \\\"n_delete = sum(1 for ev in data if ev[\\\\\\\"event\\\\\\\"]==\\\\\\\"delete\\\\\\\")\\\\n\\\",\\n+    \\\"history = response.json()\\\\n\\\",\\n+    \\\"first, last = history[0], history[-1]\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# summary stats\\\\n\\\",\\n+    \\\"count_start = first[\\\\\\\"total\\\\\\\"]\\\\n\\\",\\n+    \\\"count_end   = last[\\\\\\\"total\\\\\\\"]\\\\n\\\",\\n+    \\\"ts_last     = last[\\\\\\\"timestamp\\\\\\\"]\\\\n\\\",\\n+    \\\"n_insert    = sum(1 for ev in history if ev[\\\\\\\"event\\\\\\\"]==\\\\\\\"insert\\\\\\\")\\\\n\\\",\\n+    \\\"n_delete    = sum(1 for ev in history if ev[\\\\\\\"event\\\\\\\"]==\\\\\\\"delete\\\\\\\")\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"1afd5dad-72d5-42e1-a0fa-b7bd3455937b\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"Dataset metadata fetching from ZONEDO or any public dataset repositories to gain more details\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 12,\\n+   \\\"id\\\": \\\"a7fa122a-c6e5-4b38-842a-dc81590a1f46\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [],\\n+   \\\"source\\\": [\\n+    \\\"\\\\n\\\",\\n+    \\\"def fetch_and_log_dataset_metadata_nested(doi_url: str):\\\\n\\\",\\n+    \\\"    # 1) fetch the CSL+JSON\\\\n\\\",\\n+    \\\"    headers = {\\\\\\\"Accept\\\\\\\": \\\\\\\"application/vnd.citationstyles.csl+json\\\\\\\"}\\\\n\\\",\\n+    \\\"    r = requests.get(doi_url, headers=headers); r.raise_for_status()\\\\n\\\",\\n+    \\\"    meta = r.json()\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # 2) pull out what you care about\\\\n\\\",\\n+    \\\"    authors = [f\\\\\\\"{a.get('family','')} {a.get('given','')}\\\\\\\".strip()\\\\n\\\",\\n+    \\\"               for a in meta.get(\\\\\\\"author\\\\\\\", [])]\\\\n\\\",\\n+    \\\"    pubdate = \\\\\\\"-\\\\\\\".join(str(x) for x in meta.get(\\\\\\\"issued\\\\\\\",{}).get(\\\\\\\"date-parts\\\\\\\",[[]])[0])\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # 3) assemble one nested dict\\\\n\\\",\\n+    \\\"    public_datasetRepository_metadata = {\\\\n\\\",\\n+    \\\"      \\\\\\\"zenodo\\\\\\\": {\\\\n\\\",\\n+    \\\"        \\\\\\\"title\\\\\\\":     meta.get(\\\\\\\"title\\\\\\\"),\\\\n\\\",\\n+    \\\"        \\\\\\\"doi\\\\\\\":       meta.get(\\\\\\\"DOI\\\\\\\"),\\\\n\\\",\\n+    \\\"        \\\\\\\"authors\\\\\\\":   authors,\\\\n\\\",\\n+    \\\"        \\\\\\\"published\\\\\\\": pubdate,\\\\n\\\",\\n+    \\\"        \\\\\\\"publisher\\\\\\\": meta.get(\\\\\\\"publisher\\\\\\\"),\\\\n\\\",\\n+    \\\"      },\\\\n\\\",\\n+    \\\"   \\\\n\\\",\\n+    \\\"    }\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"      # 4) log it as a single JSON artifact\\\\n\\\",\\n+    \\\"    mlflow.log_dict(public_datasetRepository_metadata,\\\\n\\\",\\n+    \\\"                \\\\\\\"public_datasetRepository_metadata.json\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # 2) Flatten and log the important bits as params:\\\\n\\\",\\n+    \\\"    z = public_datasetRepository_metadata[\\\\\\\"zenodo\\\\\\\"]\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    mlflow.log_param(\\\\\\\"dataset.title\\\\\\\",     z[\\\\\\\"title\\\\\\\"])\\\\n\\\",\\n+    \\\"    mlflow.log_param(\\\\\\\"dataset.doi\\\\\\\",       z[\\\\\\\"doi\\\\\\\"])\\\\n\\\",\\n+    \\\"    mlflow.log_param(\\\\\\\"dataset.authors\\\\\\\",   json.dumps(z[\\\\\\\"authors\\\\\\\"]))\\\\n\\\",\\n+    \\\"    mlflow.log_param(\\\\\\\"dataset.published\\\\\\\", z[\\\\\\\"published\\\\\\\"])\\\\n\\\",\\n+    \\\"    mlflow.log_param(\\\\\\\"dataset.publisher\\\\\\\", z[\\\\\\\"publisher\\\\\\\"])\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"   \\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"58c92e13-eb57-418d-b354-83777f88aa98\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"##################################################################\\\\n\\\",\\n+    \\\"# DATA PREPROCESSING STEPS\\\\n\\\",\\n+    \\\"###################################################################\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"9832d0df-af0a-4eee-90d0-fab926e03e85\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"STEP 1: LOAD DATASET\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 13,\\n+   \\\"id\\\": \\\"77402d80-22d1-4bed-9489-768958c3e9fa\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [],\\n+   \\\"source\\\": [\\n+    \\\"# \\u2500\\u2500 2) Load into a DataFrame \\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\\\n\\\",\\n+    \\\"df = pd.DataFrame(dataset)\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"6862e341-3ea1-43f6-a1ac-9a51188fe614\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"STEP2: seperate Dependent and Independent variables and drop unnecessary columns like ID\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 14,\\n+   \\\"id\\\": \\\"01309a7b-53d2-4df4-b334-0f0db8b03333\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"Shapes: (150, 4) (150,)\\\\n\\\"\\n+     ]\\n+    }\\n+   ],\\n+   \\\"source\\\": [\\n+    \\\"target_col = df.columns[-1]      # e.g. \\\\\\\"species\\\\\\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# 2) extract y as the Series of labels\\\\n\\\",\\n+    \\\"y = df[target_col]               # length == n_samples\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# 3) build X by dropping just that one column\\\\n\\\",\\n+    \\\"X = df.drop(columns=[target_col])\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# 4) drop any ID column (case-insensitive)\\\\n\\\",\\n+    \\\"id_cols = [c for c in X.columns if c.lower() == \\\\\\\"id\\\\\\\"]\\\\n\\\",\\n+    \\\"if id_cols:\\\\n\\\",\\n+    \\\"    X = X.drop(columns=id_cols)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# 5) coerce numeric where possible\\\\n\\\",\\n+    \\\"for c in X.columns:\\\\n\\\",\\n+    \\\"    try:\\\\n\\\",\\n+    \\\"        X[c] = pd.to_numeric(X[c])\\\\n\\\",\\n+    \\\"    except Exception:\\\\n\\\",\\n+    \\\"        pass\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"print(\\\\\\\"Shapes:\\\\\\\", X.shape, y.shape)\\\\n\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"367d6256-a30a-4f91-bc64-f20966d828ab\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"STEP3: Label Encoding as the target values are class names\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 15,\\n+   \\\"id\\\": \\\"11f5126d-6a03-48c6-9ecf-39ed0d43688c\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"Classes: ['Iris-setosa' 'Iris-versicolor' 'Iris-virginica']\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"data\\\": {\\n+      \\\"text/plain\\\": [\\n+       \\\"array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\\\\n\\\",\\n+       \\\"       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\\\\n\\\",\\n+       \\\"       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\\\\n\\\",\\n+       \\\"       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\\\\n\\\",\\n+       \\\"       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\\\\n\\\",\\n+       \\\"       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\\\\n\\\",\\n+       \\\"       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\\\"\\n+      ]\\n+     },\\n+     \\\"execution_count\\\": 15,\\n+     \\\"metadata\\\": {},\\n+     \\\"output_type\\\": \\\"execute_result\\\"\\n+    }\\n+   ],\\n+   \\\"source\\\": [\\n+    \\\"\\\\n\\\",\\n+    \\\"le = LabelEncoder()\\\\n\\\",\\n+    \\\"y = le.fit_transform(y)  \\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# now y_enc is a 1d numpy array of ints 0,1,2\\\\n\\\",\\n+    \\\"print(\\\\\\\"Classes:\\\\\\\", le.classes_)  \\\\n\\\",\\n+    \\\"y\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 16,\\n+   \\\"id\\\": \\\"68d0a924-c65f-4a44-a5cc-bbb32d17e96f\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [],\\n+   \\\"source\\\": [\\n+    \\\"# \\u2500\\u2500 4) Cast feature columns to numeric where possible \\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\\\n\\\",\\n+    \\\"for col in X.columns:\\\\n\\\",\\n+    \\\"    try:\\\\n\\\",\\n+    \\\"        X[col] = pd.to_numeric(X[col])   # no errors=\\\\\\\"ignore\\\\\\\"\\\\n\\\",\\n+    \\\"    except ValueError:\\\\n\\\",\\n+    \\\"        # if it can\\u2019t be cast, just leave it as-is\\\\n\\\",\\n+    \\\"        pass\\\\n\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 17,\\n+   \\\"id\\\": \\\"e17f39ce-3322-4626-83a6-079d304bbc04\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [],\\n+   \\\"source\\\": [\\n+    \\\"# \\u2500\\u2500 5) Drop any \\u201cid\\u201d column (case-insensitive) \\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\\\n\\\",\\n+    \\\"dropped = [c for c in X.columns if c.lower() == \\\\\\\"id\\\\\\\"]\\\\n\\\",\\n+    \\\"X = X.drop(columns=dropped, errors=\\\\\\\"ignore\\\\\\\")\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"6fcf2244-14dd-4e3d-b8cf-f7f3ba34f80f\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"# \\ud83d\\udcc2 Setup MLflow\\\\n\\\",\\n+    \\\"# ============================\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 30,\\n+   \\\"id\\\": \\\"cbe91ec0-6447-4586-b7cc-2c1f74d4218f\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [],\\n+   \\\"source\\\": [\\n+    \\\"\\\\n\\\",\\n+    \\\"project_dir = os.getcwd()\\\\n\\\",\\n+    \\\"mlflow.set_tracking_uri(\\\\\\\"mlrunlogs/mlflow.db\\\\\\\")\\\\n\\\",\\n+    \\\"mlflow.set_experiment(\\\\\\\"RandomForest-Iris-CSV\\\\\\\")\\\\n\\\",\\n+    \\\"mlflow.sklearn.autolog(log_input_examples=False, log_model_signatures=True)\\\\n\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"af2c2c5f-cc36-41a3-9643-83ef95b9f55e\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"# \\ud83d\\udd04 Git Commit Hash for previous commit for metadata\\\\n\\\",\\n+    \\\"# ============================\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 19,\\n+   \\\"id\\\": \\\"838dd233-25dc-4725-974d-4da89c257782\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [],\\n+   \\\"source\\\": [\\n+    \\\"\\\\n\\\",\\n+    \\\"repo_dir = \\\\\\\"C:/Users/reema/REPO\\\\\\\"\\\\n\\\",\\n+    \\\"previous_commit_repo = git.Repo(repo_dir)\\\\n\\\",\\n+    \\\"previous_commit_hash = previous_commit_repo.head.object.hexsha\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"430d15ef-3432-4e45-88fb-b7048a5b10a9\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"# Make threadpoolctl safe so MLflow\\u2019s autologger won\\u2019t crash \\u2500\\u2500\\u2500\\\\n\\\",\\n+    \\\"# ============================\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 20,\\n+   \\\"id\\\": \\\"9668451f-4352-4bdc-8b6b-bbe49074212a\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [\\n+    {\\n+     \\\"name\\\": \\\"stderr\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"2025/04/25 13:13:44 INFO mlflow.tracking.fluent: Autologging successfully enabled for statsmodels.\\\\n\\\"\\n+     ]\\n+    }\\n+   ],\\n+   \\\"source\\\": [\\n+    \\\"try:\\\\n\\\",\\n+    \\\"    import threadpoolctl\\\\n\\\",\\n+    \\\"    _orig = threadpoolctl.threadpool_info\\\\n\\\",\\n+    \\\"    def _safe_threadpool_info(*args, **kwargs):\\\\n\\\",\\n+    \\\"        try:\\\\n\\\",\\n+    \\\"            return _orig(*args, **kwargs)\\\\n\\\",\\n+    \\\"        except Exception:\\\\n\\\",\\n+    \\\"            return []\\\\n\\\",\\n+    \\\"    threadpoolctl.threadpool_info = _safe_threadpool_info\\\\n\\\",\\n+    \\\"except ImportError:\\\\n\\\",\\n+    \\\"    pass  # if threadpoolctl isn\\u2019t installed, autolog will skip unsupported versions\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# \\u2500\\u2500\\u2500 1) Enable generic autolog (will auto-patch sklearn under the hood) \\u2500\\u2500\\u2500\\\\n\\\",\\n+    \\\"import mlflow\\\\n\\\",\\n+    \\\"mlflow.autolog(\\\\n\\\",\\n+    \\\"    log_input_examples=True,\\\\n\\\",\\n+    \\\"    log_model_signatures=True\\\\n\\\",\\n+    \\\")\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"9058319a-adba-4a6b-93e9-d17080c0594d\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"# \\ud83d\\ude80 Start MLflow Run \\\\n\\\",\\n+    \\\"# ============================\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 31,\\n+   \\\"id\\\": \\\"14c62f08-a116-4060-9689-f69968e9f240\\\",\\n+   \\\"metadata\\\": {\\n+    \\\"scrolled\\\": true\\n+   },\\n+   \\\"outputs\\\": [\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\\\n\\\",\\n+      \\\"\\ud83d\\udcdd Justification for `n_estimators` (Hyperparameter configuration)\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdin\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\u2192 Why did you choose this value?  test\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\\\n\\\",\\n+      \\\"\\ud83d\\udcdd Justification for `criterion` (Hyperparameter configuration)\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdin\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\u2192 Why did you choose this value?  test\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\\\n\\\",\\n+      \\\"\\ud83d\\udcdd Justification for `max_depth` (Hyperparameter configuration)\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdin\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\u2192 Why did you choose this value?  test\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\\\n\\\",\\n+      \\\"\\ud83d\\udcdd Justification for `min_samples_split` (Hyperparameter configuration)\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdin\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\u2192 Why did you choose this value?  test\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\\\n\\\",\\n+      \\\"\\ud83d\\udcdd Justification for `min_samples_leaf` (Hyperparameter configuration)\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdin\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\u2192 Why did you choose this value?  test\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\\\n\\\",\\n+      \\\"\\ud83d\\udcdd Justification for `max_features` (Hyperparameter configuration)\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdin\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\u2192 Why did you choose this value?  test\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\\\n\\\",\\n+      \\\"\\ud83d\\udcdd Justification for `bootstrap` (Hyperparameter configuration)\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdin\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\u2192 Why did you choose this value?  test\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\\\n\\\",\\n+      \\\"\\ud83d\\udcdd Justification for `oob_score` (Hyperparameter configuration)\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdin\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\u2192 Why did you choose this value?  test\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\\\n\\\",\\n+      \\\"\\ud83d\\udcdd Justification for `class_weight` (Hyperparameter configuration)\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdin\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\u2192 Why did you choose this value?  test\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\\\n\\\",\\n+      \\\"\\ud83d\\udcdd Justification for `random_state` (Hyperparameter configuration)\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdin\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\u2192 Why did you choose this value?  test\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\\\n\\\",\\n+      \\\"\\ud83d\\udcdd Justification for `verbose` (Hyperparameter configuration)\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdin\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\u2192 Why did you choose this value?  test\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\\\n\\\",\\n+      \\\"\\ud83d\\udcdd Justification for `n_jobs` (Hyperparameter configuration)\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdin\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\u2192 Why did you choose this value?  test\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\\\n\\\",\\n+      \\\"\\ud83d\\udcdd Justification for `model_choice`\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdin\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\u2192 Why did you choose RandomForestClassifier for this task?  test\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\\\n\\\",\\n+      \\\"\\ud83d\\udcdd Justification for `target_variable`\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdin\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\u2192 Why did you choose this column as the prediction target?  test\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\\\n\\\",\\n+      \\\"\\ud83d\\udcdd Justification for `test_split`\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdin\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\u2192 Why this train/test ratio (e.g., 80/20)?  test\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\\\n\\\",\\n+      \\\"\\ud83d\\udcdd Justification for `metric_choice`\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdin\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\u2192 Why accuracy/f1/ROC-AUC as your evaluation metric?  test\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\\\n\\\",\\n+      \\\"\\ud83d\\udcdd Justification for `threshold_accuracy`\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdin\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\u2192 Why 0.95 as performance threshold?  test\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\\\n\\\",\\n+      \\\"\\ud83d\\udcdd Justification for `dataset_version`\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdin\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\u2192 Why use this specific dataset version?  test\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\\\n\\\",\\n+      \\\"\\ud83d\\udcdd Justification for `drop_column_X`\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdin\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\u2192 Why drop any specific columns from the dataset?  test\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\\\n\\\",\\n+      \\\"\\ud83d\\udcdd Justification for `experiment_name`\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdin\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\u2192 Any context behind this experiment name or setup?  test\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stderr\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.0s\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    0.2s\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    0.2s finished\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Done 200 out of 200 | elapsed:    0.0s finished\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Done 200 out of 200 | elapsed:    0.0s finished\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Done 200 out of 200 | elapsed:    0.0s finished\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Done 200 out of 200 | elapsed:    0.0s finished\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Done 200 out of 200 | elapsed:    0.0s finished\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Done 200 out of 200 | elapsed:    0.0s finished\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Done 200 out of 200 | elapsed:    0.0s finished\\\\n\\\",\\n+      \\\"C:\\\\\\\\Users\\\\\\\\reema\\\\\\\\anaconda3\\\\\\\\Lib\\\\\\\\site-packages\\\\\\\\shap\\\\\\\\plots\\\\\\\\_beeswarm.py:1153: UserWarning: The figure layout has changed to tight\\\\n\\\",\\n+      \\\"  pl.tight_layout()\\\\n\\\",\\n+      \\\"C:\\\\\\\\Users\\\\\\\\reema\\\\\\\\anaconda3\\\\\\\\Lib\\\\\\\\site-packages\\\\\\\\shap\\\\\\\\plots\\\\\\\\_beeswarm.py:761: UserWarning: The figure layout has changed to tight\\\\n\\\",\\n+      \\\"  pl.tight_layout(pad=0, w_pad=0, h_pad=0.0)\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\u2705 Commit successful.\\\\n\\\",\\n+      \\\"\\ud83d\\ude80 Push successful.\\\\n\\\"\\n+     ]\\n+    }\\n+   ],\\n+   \\\"source\\\": [\\n+    \\\"\\\\n\\\",\\n+    \\\"with mlflow.start_run() as run:\\\\n\\\",\\n+    \\\"    #################################################\\\\n\\\",\\n+    \\\"# Justification LOGGER\\\\n\\\",\\n+    \\\"################################################\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    def log_with_justification(log_func, key, value, context=\\\\\\\"\\\\\\\"):\\\\n\\\",\\n+    \\\"        \\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\",\\n+    \\\"        Log a parameter/metric/tag using `log_func` and ask for justification via console.\\\\n\\\",\\n+    \\\"        \\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\",\\n+    \\\"        log_func(key, value)\\\\n\\\",\\n+    \\\"        print(f\\\\\\\"\\\\\\\\n\\ud83d\\udcdd Justification for `{key}` ({context})\\\\\\\")\\\\n\\\",\\n+    \\\"        user_reason = input(\\\\\\\"\\u2192 Why did you choose this value? \\\\\\\")\\\\n\\\",\\n+    \\\"        mlflow.set_tag(f\\\\\\\"justification_{key}\\\\\\\", user_reason or \\\\\\\"No justification provided\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    def log_justification(key: str, question: str):\\\\n\\\",\\n+    \\\"        print(f\\\\\\\"\\\\\\\\n\\ud83d\\udcdd Justification for `{key}`\\\\\\\")\\\\n\\\",\\n+    \\\"        user_reason = input(f\\\\\\\"\\u2192 {question} \\\\\\\")\\\\n\\\",\\n+    \\\"        mlflow.set_tag(f\\\\\\\"justification_{key}\\\\\\\", user_reason or \\\\\\\"No justification provided\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    meta = fetch_and_log_dataset_metadata_nested(\\\\n\\\",\\n+    \\\"            \\\\\\\"https://doi.org/10.5281/zenodo.1404173\\\\\\\",\\\\n\\\",\\n+    \\\"           \\\\n\\\",\\n+    \\\"        )\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    #Datasbase info logging\\\\n\\\",\\n+    \\\"    db_id = \\\\\\\"c3a42d17-42b7-43c9-a504-2363fb4c9c8d\\\\\\\"\\\\n\\\",\\n+    \\\"    db_meta = fetch_db_metadata(db_id)\\\\n\\\",\\n+    \\\"    log_db_metadata(db_meta)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    #OAI metadata logging from api endpoint\\\\n\\\",\\n+    \\\"    # log as tags\\\\n\\\",\\n+    \\\"    mlflow.set_tag(\\\\\\\"dbrepo.repository_name\\\\\\\", repo_name)\\\\n\\\",\\n+    \\\"    mlflow.set_tag(\\\\\\\"dbrepo.base_url\\\\\\\",       base_url)\\\\n\\\",\\n+    \\\"    mlflow.set_tag(\\\\\\\"dbrepo.protocol_version\\\\\\\", protocol)\\\\n\\\",\\n+    \\\"    mlflow.set_tag(\\\\\\\"dbrepo.admin_email\\\\\\\",     admin_email)\\\\n\\\",\\n+    \\\"    mlflow.set_tag(\\\\\\\"dbrepo.granularity\\\\\\\",     gran)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    #From history API logging\\\\n\\\",\\n+    \\\"    # provenance tags\\\\n\\\",\\n+    \\\"    mlflow.set_tag(\\\\\\\"dbrepo.table_last_modified\\\\\\\", ts_last)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # row-count metrics\\\\n\\\",\\n+    \\\"    mlflow.log_metric(\\\\\\\"dbrepo.row_count_start\\\\\\\", count_start)\\\\n\\\",\\n+    \\\"    mlflow.log_metric(\\\\\\\"dbrepo.row_count_end\\\\\\\",   count_end)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # change-event metrics\\\\n\\\",\\n+    \\\"    mlflow.log_metric(\\\\\\\"dbrepo.num_inserts\\\\\\\", n_insert)\\\\n\\\",\\n+    \\\"    mlflow.log_metric(\\\\\\\"dbrepo.num_deletes\\\\\\\", n_delete)\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    # 2) Capture raw metadata\\\\n\\\",\\n+    \\\"    mlflow.set_tag(\\\\\\\"data_source\\\\\\\", API_URL)\\\\n\\\",\\n+    \\\"    mlflow.log_param(\\\\\\\"retrieval_time\\\\\\\", datetime.utcnow().isoformat())\\\\n\\\",\\n+    \\\"    mlflow.log_param(\\\\\\\"n_records\\\\\\\", len(df))\\\\n\\\",\\n+    \\\"    mlflow.log_param(\\\\\\\"columns_raw\\\\\\\", df.columns.tolist())\\\\n\\\",\\n+    \\\"    mlflow.log_param(\\\\\\\"dropped_columns\\\\\\\", id_cols)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # 4) Post\\u2010processing metadata\\\\n\\\",\\n+    \\\"    mlflow.log_param(\\\\\\\"n_features_final\\\\\\\", X.shape[1])\\\\n\\\",\\n+    \\\"    mlflow.log_param(\\\\\\\"feature_names\\\\\\\", X.columns.tolist())\\\\n\\\",\\n+    \\\"    mlflow.set_tag(\\\\\\\"target_name\\\\\\\", y)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"       # Label encoding\\\\n\\\",\\n+    \\\"    label_map = {int(idx): cls for idx, cls in enumerate(le.classes_)}\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    # Save to an in-memory file\\\\n\\\",\\n+    \\\"    buffer = io.StringIO()\\\\n\\\",\\n+    \\\"    json.dump(label_map, buffer, indent=2)\\\\n\\\",\\n+    \\\"    buffer.seek(0)\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    # Log it to MLflow\\\\n\\\",\\n+    \\\"    mlflow.log_text(buffer.getvalue(), artifact_file=\\\\\\\"label_mapping.json\\\\\\\")\\\\n\\\",\\n+    \\\"   \\\\n\\\",\\n+    \\\"    ts = datetime.now().strftime(\\\\\\\"%Y%m%d_%H%M%S\\\\\\\")\\\\n\\\",\\n+    \\\"    model_name = f\\\\\\\"RandomForest_Iris_v{ts}\\\\\\\"\\\\n\\\",\\n+    \\\"    mlflow.set_tag(\\\\\\\"model_name\\\\\\\",model_name)\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    train_start_ts = datetime.now().isoformat()\\\\n\\\",\\n+    \\\"    mlflow.set_tag(\\\\\\\"training_start_time\\\\\\\", train_start_ts)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    test_size    = 0.2\\\\n\\\",\\n+    \\\"    random_state = 42\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    # \\ud83d\\udcc8 Model Training\\\\n\\\",\\n+    \\\"    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    # \\u2500\\u2500 2) Log dataset split params \\u2500\\u2500\\\\n\\\",\\n+    \\\"    mlflow.log_param(\\\\\\\"test_size\\\\\\\", test_size)\\\\n\\\",\\n+    \\\"    mlflow.log_param(\\\\\\\"random_state\\\\\\\", random_state)\\\\n\\\",\\n+    \\\"    mlflow.log_param(\\\\\\\"n_train_samples\\\\\\\", X_train.shape[0])\\\\n\\\",\\n+    \\\"    mlflow.log_param(\\\\\\\"n_test_samples\\\\\\\",  X_test.shape[0])\\\\n\\\",\\n+    \\\"    mlflow.log_param(\\\\\\\"n_features\\\\\\\",      X_train.shape[1])\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"     # 1) Define a more complex hyperparameter dict\\\\n\\\",\\n+    \\\"    hyperparams = {\\\\n\\\",\\n+    \\\"        \\\\\\\"n_estimators\\\\\\\":       200,\\\\n\\\",\\n+    \\\"        \\\\\\\"criterion\\\\\\\":          \\\\\\\"entropy\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"max_depth\\\\\\\":          12,\\\\n\\\",\\n+    \\\"        \\\\\\\"min_samples_split\\\\\\\":  5,\\\\n\\\",\\n+    \\\"        \\\\\\\"min_samples_leaf\\\\\\\":   2,\\\\n\\\",\\n+    \\\"        \\\\\\\"max_features\\\\\\\":       \\\\\\\"sqrt\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"bootstrap\\\\\\\":          True,\\\\n\\\",\\n+    \\\"        \\\\\\\"oob_score\\\\\\\":          False,\\\\n\\\",\\n+    \\\"        \\\\\\\"class_weight\\\\\\\":       None,\\\\n\\\",\\n+    \\\"        \\\\\\\"random_state\\\\\\\":       42,\\\\n\\\",\\n+    \\\"        \\\\\\\"verbose\\\\\\\":            1,\\\\n\\\",\\n+    \\\"        \\\\\\\"n_jobs\\\\\\\":             -1\\\\n\\\",\\n+    \\\"    }\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    # 2) Log them ALL at once\\\\n\\\",\\n+    \\\"    # mlflow.log_params(hyperparams) #TEST\\\\n\\\",\\n+    \\\"    model = RandomForestClassifier(**hyperparams)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    for key, val in hyperparams.items():\\\\n\\\",\\n+    \\\"        log_with_justification(mlflow.log_param, key, val, context=\\\\\\\"Hyperparameter configuration\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # Prompt for and log justifications for high-level modeling decisions\\\\n\\\",\\n+    \\\"    log_justification(\\\\\\\"model_choice\\\\\\\", \\\\\\\"Why did you choose RandomForestClassifier for this task?\\\\\\\")\\\\n\\\",\\n+    \\\"    log_justification(\\\\\\\"target_variable\\\\\\\", \\\\\\\"Why did you choose this column as the prediction target?\\\\\\\")\\\\n\\\",\\n+    \\\"    log_justification(\\\\\\\"test_split\\\\\\\", \\\\\\\"Why this train/test ratio (e.g., 80/20)?\\\\\\\")\\\\n\\\",\\n+    \\\"    log_justification(\\\\\\\"metric_choice\\\\\\\", \\\\\\\"Why accuracy/f1/ROC-AUC as your evaluation metric?\\\\\\\")\\\\n\\\",\\n+    \\\"    log_justification(\\\\\\\"threshold_accuracy\\\\\\\", \\\\\\\"Why 0.95 as performance threshold?\\\\\\\")\\\\n\\\",\\n+    \\\"    log_justification(\\\\\\\"dataset_version\\\\\\\", \\\\\\\"Why use this specific dataset version?\\\\\\\")\\\\n\\\",\\n+    \\\"    log_justification(\\\\\\\"drop_column_X\\\\\\\", \\\\\\\"Why drop any specific columns from the dataset?\\\\\\\")\\\\n\\\",\\n+    \\\"    log_justification(\\\\\\\"experiment_name\\\\\\\", \\\\\\\"Any context behind this experiment name or setup?\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    model.fit(X_train, y_train)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    train_end_ts = datetime.now().isoformat()\\\\n\\\",\\n+    \\\"    mlflow.set_tag(\\\\\\\"training_end_time\\\\\\\", train_end_ts)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"     # \\u2500\\u2500 6) Predict & log metrics \\u2500\\u2500\\\\n\\\",\\n+    \\\"    y_pred = model.predict(X_test)\\\\n\\\",\\n+    \\\"    y_proba = model.predict_proba(X_test)\\\\n\\\",\\n+    \\\"    acc = accuracy_score(y_test, y_pred)\\\\n\\\",\\n+    \\\"    auc = roc_auc_score(y_test, y_proba, multi_class=\\\\\\\"ovr\\\\\\\")\\\\n\\\",\\n+    \\\"    prec = precision_score(y_test, y_pred, average=\\\\\\\"macro\\\\\\\")\\\\n\\\",\\n+    \\\"    rec  = recall_score(y_test,    y_pred, average=\\\\\\\"macro\\\\\\\")\\\\n\\\",\\n+    \\\"    f1   = f1_score(y_test,      y_pred, average=\\\\\\\"macro\\\\\\\")\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    # mlflow.log_metric(\\\\\\\"precision_macro\\\\\\\", prec) #TEST\\\\n\\\",\\n+    \\\"    # mlflow.log_metric(\\\\\\\"recall_macro\\\\\\\",    rec)#TEST\\\\n\\\",\\n+    \\\"    # mlflow.log_metric(\\\\\\\"f1_macro\\\\\\\",        f1)#TEST\\\\n\\\",\\n+    \\\"    # mlflow.log_metric(\\\\\\\"accuracy\\\\\\\", acc)#TEST\\\\n\\\",\\n+    \\\"    # mlflow.log_metric(\\\\\\\"roc_auc\\\\\\\",   auc)#TEST\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # \\u2705 Log Environment Automatically\\\\n\\\",\\n+    \\\"    # mlflow.log_params({\\\\n\\\",\\n+    \\\"    #     \\\\\\\"python_version\\\\\\\": platform.python_version(),\\\\n\\\",\\n+    \\\"    #     \\\\\\\"os_platform\\\\\\\": f\\\\\\\"{platform.system()} {platform.release()}\\\\\\\",\\\\n\\\",\\n+    \\\"    #     \\\\\\\"sklearn_version\\\\\\\": sklearn.__version__,\\\\n\\\",\\n+    \\\"    #     \\\\\\\"pandas_version\\\\\\\": pd.__version__,\\\\n\\\",\\n+    \\\"    #     \\\\\\\"numpy_version\\\\\\\": np.__version__,\\\\n\\\",\\n+    \\\"    #     \\\\\\\"matplotlib_version\\\\\\\": matplotlib.__version__,\\\\n\\\",\\n+    \\\"    #     \\\\\\\"seaborn_version\\\\\\\": sns.__version__,\\\\n\\\",\\n+    \\\"    #     \\\\\\\"shap_version\\\\\\\": shap.__version__,\\\\n\\\",\\n+    \\\"    # })#TEST\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # \\u2705 Git and Notebook Metadata\\\\n\\\",\\n+    \\\"    mlflow.set_tag(\\\\\\\"notebook_name\\\\\\\", \\\\\\\"RQ1.ipynb\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # \\u2705 Dataset Metadata Tags\\\\n\\\",\\n+    \\\"    mlflow.set_tag(\\\\\\\"dataset_name\\\\\\\", \\\\\\\"Iris\\\\\\\") #TODO\\\\n\\\",\\n+    \\\"    mlflow.set_tag(\\\\\\\"dataset_version\\\\\\\", \\\\\\\"1.0.0\\\\\\\") #TODO\\\\n\\\",\\n+    \\\"    mlflow.set_tag(\\\\\\\"dataset_id\\\\\\\", \\\\\\\"iris_local\\\\\\\") #TODO\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # \\u2500\\u2500\\u2500 2) Create a folder for this run\\u2019s plots \\u2500\\u2500\\u2500\\\\n\\\",\\n+    \\\"    plot_dir = os.path.join(\\\\\\\"plots\\\\\\\", model_name)\\\\n\\\",\\n+    \\\"    os.makedirs(plot_dir, exist_ok=True)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # 1) Feature Importance Bar Chart\\\\n\\\",\\n+    \\\"    importances = model.feature_importances_\\\\n\\\",\\n+    \\\"    try:\\\\n\\\",\\n+    \\\"        feature_names = X_train.columns\\\\n\\\",\\n+    \\\"    except AttributeError:\\\\n\\\",\\n+    \\\"        feature_names = [f\\\\\\\"f{i}\\\\\\\" for i in range(X_train.shape[1])]\\\\n\\\",\\n+    \\\"    fi_path = os.path.join(plot_dir, \\\\\\\"feature_importances.png\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    plt.figure(figsize=(8, 6))\\\\n\\\",\\n+    \\\"    sns.barplot(x=importances, y=feature_names)\\\\n\\\",\\n+    \\\"    plt.title(\\\\\\\"Feature Importances\\\\\\\")\\\\n\\\",\\n+    \\\"    plt.xlabel(\\\\\\\"Importance\\\\\\\")\\\\n\\\",\\n+    \\\"    plt.ylabel(\\\\\\\"Feature\\\\\\\")\\\\n\\\",\\n+    \\\"    plt.tight_layout()\\\\n\\\",\\n+    \\\"    plt.savefig(fi_path)\\\\n\\\",\\n+    \\\"    mlflow.log_artifact(fi_path)\\\\n\\\",\\n+    \\\"    plt.close()\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# 2) Multi-class ROC Curves\\\\n\\\",\\n+    \\\"# Binarize labels for one-vs-rest\\\\n\\\",\\n+    \\\"    classes = np.unique(y_test)\\\\n\\\",\\n+    \\\"    y_test_bin = label_binarize(y_test, classes=classes)\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    for idx, cls in enumerate(classes):\\\\n\\\",\\n+    \\\"        disp = RocCurveDisplay.from_predictions(\\\\n\\\",\\n+    \\\"            y_test_bin[:, idx], \\\\n\\\",\\n+    \\\"            y_proba[:, idx],\\\\n\\\",\\n+    \\\"            name=f\\\\\\\"ROC for class {cls}\\\\\\\"\\\\n\\\",\\n+    \\\"        )\\\\n\\\",\\n+    \\\"        roc_path = os.path.join(plot_dir, f\\\\\\\"roc_curve_cls_{cls}.png\\\\\\\")\\\\n\\\",\\n+    \\\"        disp.figure_.savefig(roc_path)\\\\n\\\",\\n+    \\\"        mlflow.log_artifact(roc_path)\\\\n\\\",\\n+    \\\"        plt.close(disp.figure_)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # 3) Multi-class Precision-Recall Curves\\\\n\\\",\\n+    \\\"    for idx, cls in enumerate(classes):\\\\n\\\",\\n+    \\\"        disp = PrecisionRecallDisplay.from_predictions(\\\\n\\\",\\n+    \\\"            y_test_bin[:, idx], \\\\n\\\",\\n+    \\\"            y_proba[:, idx],\\\\n\\\",\\n+    \\\"            name=f\\\\\\\"PR curve for class {cls}\\\\\\\"\\\\n\\\",\\n+    \\\"        )\\\\n\\\",\\n+    \\\"        pr_path = os.path.join(plot_dir, f\\\\\\\"pr_curve_cls_{cls}.png\\\\\\\")\\\\n\\\",\\n+    \\\"        disp.figure_.savefig(pr_path)\\\\n\\\",\\n+    \\\"        mlflow.log_artifact(pr_path)\\\\n\\\",\\n+    \\\"        plt.close(disp.figure_)\\\\n\\\",\\n+    \\\"        \\\\n\\\",\\n+    \\\"    # \\u2705 Confusion Matrix Plot\\\\n\\\",\\n+    \\\"    cm_path = os.path.join(plot_dir, \\\\\\\"confusion_matrix.png\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    cm = confusion_matrix(y_test, y_pred)\\\\n\\\",\\n+    \\\"    plt.figure(figsize=(6, 6))\\\\n\\\",\\n+    \\\"    sns.heatmap(cm, annot=True, fmt=\\\\\\\"d\\\\\\\", cmap=\\\\\\\"Blues\\\\\\\")\\\\n\\\",\\n+    \\\"    plt.title(\\\\\\\"Confusion Matrix\\\\\\\")\\\\n\\\",\\n+    \\\"    plt.xlabel(\\\\\\\"Predicted\\\\\\\")\\\\n\\\",\\n+    \\\"    plt.ylabel(\\\\\\\"Actual\\\\\\\")\\\\n\\\",\\n+    \\\"    plt.savefig(cm_path)\\\\n\\\",\\n+    \\\"    mlflow.log_artifact(cm_path)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # \\u2705 SHAP Summary\\\\n\\\",\\n+    \\\"    shap_path = os.path.join(plot_dir, \\\\\\\"shap_summary.png\\\\\\\")\\\\n\\\",\\n+    \\\"    explainer = shap.TreeExplainer(model)\\\\n\\\",\\n+    \\\"    shap_values = explainer.shap_values(X_test)\\\\n\\\",\\n+    \\\"    shap.summary_plot(shap_values, X_test, show=False)\\\\n\\\",\\n+    \\\"    plt.savefig(shap_path)\\\\n\\\",\\n+    \\\"    mlflow.log_artifact(shap_path)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    # \\u2500\\u2500\\u2500 1) Build a .pkl filename (you can include your model_name for clarity)\\\\n\\\",\\n+    \\\"    pkl_path = f\\\\\\\"Trained_models/{model_name}.pkl\\\\\\\"\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    # \\u2500\\u2500\\u2500 2) Serialize your trained model to disk\\\\n\\\",\\n+    \\\"    with open(pkl_path, \\\\\\\"wb\\\\\\\") as f:\\\\n\\\",\\n+    \\\"        pickle.dump(model, f)\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    # \\u2500\\u2500\\u2500 3) Log that pickle file as an MLflow artifact\\\\n\\\",\\n+    \\\"    #     It will appear under Artifacts \\u2192 models/RandomForest_Iris_vYYYYMMDD_HHMMSS.pkl\\\\n\\\",\\n+    \\\"    mlflow.log_artifact(pkl_path, artifact_path=model_name)\\\\n\\\",\\n+    \\\"        \\\\n\\\",\\n+    \\\"    def get_latest_commit_hash(repo_path=\\\\\\\".\\\\\\\"):\\\\n\\\",\\n+    \\\"        # returns the full SHA of HEAD\\\\n\\\",\\n+    \\\"        res = subprocess.run(\\\\n\\\",\\n+    \\\"            [\\\\\\\"git\\\\\\\", \\\\\\\"-C\\\\\\\", repo_path, \\\\\\\"rev-parse\\\\\\\", \\\\\\\"HEAD\\\\\\\"],\\\\n\\\",\\n+    \\\"            capture_output=True, text=True, check=True)\\\\n\\\",\\n+    \\\"        \\\\n\\\",\\n+    \\\"        return res.stdout.strip()\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    def get_remote_url(repo_path=\\\\\\\".\\\\\\\", remote=\\\\\\\"origin\\\\\\\"):\\\\n\\\",\\n+    \\\"        # returns something like git@github.com:user/repo.git or https://...\\\\n\\\",\\n+    \\\"        res = subprocess.run(\\\\n\\\",\\n+    \\\"            [\\\\\\\"git\\\\\\\", \\\\\\\"-C\\\\\\\", repo_path, \\\\\\\"config\\\\\\\", \\\\\\\"--get\\\\\\\", f\\\\\\\"remote.{remote}.url\\\\\\\"],\\\\n\\\",\\n+    \\\"            capture_output=True, text=True, check=True\\\\n\\\",\\n+    \\\"        )\\\\n\\\",\\n+    \\\"        return res.stdout.strip()\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    def make_commit_link(remote_url, commit_hash):\\\\n\\\",\\n+    \\\"        # handle GitHub/GitLab convention; strip \\u201c.git\\u201d if present\\\\n\\\",\\n+    \\\"        base = remote_url.rstrip(\\\\\\\".git\\\\\\\")\\\\n\\\",\\n+    \\\"        # if SSH form (git@github.com:owner/repo), convert to https\\\\n\\\",\\n+    \\\"        if base.startswith(\\\\\\\"git@\\\\\\\"):\\\\n\\\",\\n+    \\\"            base = base.replace(\\\\\\\":\\\\\\\", \\\\\\\"/\\\\\\\").replace(\\\\\\\"git@\\\\\\\", \\\\\\\"https://\\\\\\\")\\\\n\\\",\\n+    \\\"        return f\\\\\\\"{base}/commit/{commit_hash}\\\\\\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    def simple_commit_and_push_and_log(repo_path=\\\\\\\".\\\\\\\", message=\\\\\\\"Auto commit\\\\\\\", remote=\\\\\\\"origin\\\\\\\", branch=\\\\\\\"main\\\\\\\"):\\\\n\\\",\\n+    \\\"    # 1) Check for changes\\\\n\\\",\\n+    \\\"        status = subprocess.run(\\\\n\\\",\\n+    \\\"            [\\\\\\\"git\\\\\\\", \\\\\\\"-C\\\\\\\", repo_path, \\\\\\\"status\\\\\\\", \\\\\\\"--porcelain\\\\\\\"],\\\\n\\\",\\n+    \\\"            capture_output=True, text=True\\\\n\\\",\\n+    \\\"        )\\\\n\\\",\\n+    \\\"        if not status.stdout.strip():\\\\n\\\",\\n+    \\\"            print(\\\\\\\"\\ud83d\\udfe1 No changes to commit.\\\\\\\")\\\\n\\\",\\n+    \\\"            return None, None\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"        # 2) Stage everything\\\\n\\\",\\n+    \\\"        add = subprocess.run(\\\\n\\\",\\n+    \\\"            [\\\\\\\"git\\\\\\\", \\\\\\\"-C\\\\\\\", repo_path, \\\\\\\"add\\\\\\\", \\\\\\\"--all\\\\\\\"],\\\\n\\\",\\n+    \\\"            capture_output=True, text=True\\\\n\\\",\\n+    \\\"        )\\\\n\\\",\\n+    \\\"        if add.returncode:\\\\n\\\",\\n+    \\\"            print(\\\\\\\"\\u274c git add failed:\\\\\\\\n\\\\\\\", add.stderr)\\\\n\\\",\\n+    \\\"            return None, None\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"        # 3) Commit\\\\n\\\",\\n+    \\\"        commit = subprocess.run(\\\\n\\\",\\n+    \\\"            [\\\\\\\"git\\\\\\\", \\\\\\\"-C\\\\\\\", repo_path, \\\\\\\"commit\\\\\\\", \\\\\\\"-m\\\\\\\", message],\\\\n\\\",\\n+    \\\"            capture_output=True, text=True\\\\n\\\",\\n+    \\\"        )\\\\n\\\",\\n+    \\\"        if commit.returncode:\\\\n\\\",\\n+    \\\"            print(\\\\\\\"\\u274c git commit failed:\\\\\\\\n\\\\\\\", commit.stderr)\\\\n\\\",\\n+    \\\"            return None, None\\\\n\\\",\\n+    \\\"        print(\\\\\\\"\\u2705 Commit successful.\\\\\\\")\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"        # 4) Push\\\\n\\\",\\n+    \\\"        push = subprocess.run(\\\\n\\\",\\n+    \\\"            [\\\\\\\"git\\\\\\\", \\\\\\\"-C\\\\\\\", repo_path, \\\\\\\"push\\\\\\\", \\\\\\\"-u\\\\\\\", remote, branch],\\\\n\\\",\\n+    \\\"            capture_output=True, text=True\\\\n\\\",\\n+    \\\"        )\\\\n\\\",\\n+    \\\"        if push.returncode:\\\\n\\\",\\n+    \\\"            print(\\\\\\\"\\u274c git push failed:\\\\\\\\n\\\\\\\", push.stderr)\\\\n\\\",\\n+    \\\"        else:\\\\n\\\",\\n+    \\\"            print(\\\\\\\"\\ud83d\\ude80 Push successful.\\\\\\\")\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"        # 5) Retrieve hash & remote URL\\\\n\\\",\\n+    \\\"        sha = get_latest_commit_hash(repo_path)\\\\n\\\",\\n+    \\\"        url = get_remote_url(repo_path, remote)\\\\n\\\",\\n+    \\\"        link = make_commit_link(url, sha)\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"        return sha, link\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"      \\\\n\\\",\\n+    \\\"    sha, link = simple_commit_and_push_and_log(\\\\n\\\",\\n+    \\\"        repo_path=\\\\\\\".\\\\\\\",\\\\n\\\",\\n+    \\\"        message=\\\\\\\"Auto commit after successful training\\\\\\\"\\\\n\\\",\\n+    \\\"    )\\\\n\\\",\\n+    \\\"    if sha and link:\\\\n\\\",\\n+    \\\"        diff_text = subprocess.check_output(\\\\n\\\",\\n+    \\\"            [\\\\\\\"git\\\\\\\", \\\\\\\"-C\\\\\\\", \\\\\\\".\\\\\\\", \\\\\\\"diff\\\\\\\", previous_commit_hash, sha],\\\\n\\\",\\n+    \\\"            encoding=\\\\\\\"utf-8\\\\\\\",\\\\n\\\",\\n+    \\\"            errors=\\\\\\\"ignore\\\\\\\"    # or \\\\\\\"replace\\\\\\\"\\\\n\\\",\\n+    \\\"        )\\\\n\\\",\\n+    \\\"                \\\\n\\\",\\n+    \\\"        # 1) Get your repo\\u2019s remote URL and normalize to HTTPS\\\\n\\\",\\n+    \\\"        remote_url = subprocess.check_output(\\\\n\\\",\\n+    \\\"            [\\\\\\\"git\\\\\\\", \\\\\\\"config\\\\\\\", \\\\\\\"--get\\\\\\\", \\\\\\\"remote.origin.url\\\\\\\"],\\\\n\\\",\\n+    \\\"            text=True\\\\n\\\",\\n+    \\\"        ).strip().rstrip(\\\\\\\".git\\\\\\\")\\\\n\\\",\\n+    \\\"        if remote_url.startswith(\\\\\\\"git@\\\\\\\"):\\\\n\\\",\\n+    \\\"            # git@github.com:owner/repo.git \\u2192 https://github.com/owner/repo\\\\n\\\",\\n+    \\\"            remote_url = remote_url.replace(\\\\\\\":\\\\\\\", \\\\\\\"/\\\\\\\").replace(\\\\\\\"git@\\\\\\\", \\\\\\\"https://\\\\\\\")\\\\n\\\",\\n+    \\\"        \\\\n\\\",\\n+    \\\"        # 2) Build commit URLs\\\\n\\\",\\n+    \\\"        previous_commit_url  = f\\\\\\\"{remote_url}/commit/{previous_commit_hash}\\\\\\\"\\\\n\\\",\\n+    \\\"        current_commit_url = f\\\\\\\"{remote_url}/commit/{sha}\\\\\\\"\\\\n\\\",\\n+    \\\"        diff_data = {\\\\n\\\",\\n+    \\\"            \\\\\\\"previous_commit\\\\\\\":  previous_commit_hash,\\\\n\\\",\\n+    \\\"            \\\\\\\"previous_commit_url\\\\\\\":previous_commit_url,\\\\n\\\",\\n+    \\\"            \\\\\\\"current_commit_url\\\\\\\":current_commit_url,\\\\n\\\",\\n+    \\\"            \\\\\\\"current_commit\\\\\\\": sha,\\\\n\\\",\\n+    \\\"            \\\\\\\"diff\\\\\\\": diff_text\\\\n\\\",\\n+    \\\"        }\\\\n\\\",\\n+    \\\"        mlflow.log_dict(\\\\n\\\",\\n+    \\\"            diff_data,\\\\n\\\",\\n+    \\\"            artifact_file=\\\\\\\"commit_diff.json\\\\\\\"\\\\n\\\",\\n+    \\\"        )\\\\n\\\",\\n+    \\\"        mlflow.set_tag(\\\\\\\"git_previous_commit_hash\\\\\\\", previous_commit_hash)\\\\n\\\",\\n+    \\\"        mlflow.set_tag(\\\\\\\"git_current_commit_hash\\\\\\\", sha)\\\\n\\\",\\n+    \\\"        mlflow.set_tag(\\\\\\\"git__current_commit_url\\\\\\\", link) \\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    client   = MlflowClient()\\\\n\\\",\\n+    \\\"    run_id    = run.info.run_id\\\\n\\\",\\n+    \\\"    run_info  = client.get_run(run_id).info\\\\n\\\",\\n+    \\\"    run_data  = client.get_run(run_id).data\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    # 1) params, metrics, tags\\\\n\\\",\\n+    \\\"    params  = dict(run_data.params)\\\\n\\\",\\n+    \\\"    metrics = dict(run_data.metrics)\\\\n\\\",\\n+    \\\"    tags    = dict(run_data.tags)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # (4) List artifacts under a specific subfolder\\\\n\\\",\\n+    \\\"    run_meta     = client.get_run(run_id).info\\\\n\\\",\\n+    \\\"    artifact_uri = run_meta.artifact_uri  # base URI for all artifacts\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    artifact_meta = []\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    def _gather(path=\\\\\\\"\\\\\\\"):\\\\n\\\",\\n+    \\\"        for af in client.list_artifacts(run_id, path):\\\\n\\\",\\n+    \\\"            # If it\\u2019s a directory, recurse\\\\n\\\",\\n+    \\\"            if af.is_dir:\\\\n\\\",\\n+    \\\"                _gather(af.path)\\\\n\\\",\\n+    \\\"                continue\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"            rel_path = af.path\\\\n\\\",\\n+    \\\"            uri      = f\\\\\\\"{artifact_uri}/{rel_path}\\\\\\\"\\\\n\\\",\\n+    \\\"            lower    = rel_path.lower()\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"            # 1) Text files \\u2192 download & embed contents\\\\n\\\",\\n+    \\\"            if lower.endswith((\\\\\\\".json\\\\\\\", \\\\\\\".txt\\\\\\\", \\\\\\\".patch\\\\\\\")):\\\\n\\\",\\n+    \\\"                local = client.download_artifacts(run_id, rel_path)\\\\n\\\",\\n+    \\\"                with open(local, \\\\\\\"r\\\\\\\", encoding=\\\\\\\"utf-8\\\\\\\") as f:\\\\n\\\",\\n+    \\\"                    content = f.read()\\\\n\\\",\\n+    \\\"                artifact_meta.append({\\\\n\\\",\\n+    \\\"                    \\\\\\\"path\\\\\\\":    rel_path,\\\\n\\\",\\n+    \\\"                    \\\\\\\"type\\\\\\\":    \\\\\\\"text\\\\\\\",\\\\n\\\",\\n+    \\\"                    \\\\\\\"content\\\\\\\": content\\\\n\\\",\\n+    \\\"                })\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"            # 2) Images \\u2192 surface a clickable URI\\\\n\\\",\\n+    \\\"            elif lower.endswith((\\\\\\\".png\\\\\\\", \\\\\\\".jpg\\\\\\\", \\\\\\\".jpeg\\\\\\\", \\\\\\\".svg\\\\\\\")):\\\\n\\\",\\n+    \\\"                artifact_meta.append({\\\\n\\\",\\n+    \\\"                    \\\\\\\"path\\\\\\\": rel_path,\\\\n\\\",\\n+    \\\"                    \\\\\\\"type\\\\\\\": \\\\\\\"image\\\\\\\",\\\\n\\\",\\n+    \\\"                    \\\\\\\"uri\\\\\\\":  uri\\\\n\\\",\\n+    \\\"                })\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"            # 3) Everything else \\u2192 just link\\\\n\\\",\\n+    \\\"            else:\\\\n\\\",\\n+    \\\"                artifact_meta.append({\\\\n\\\",\\n+    \\\"                    \\\\\\\"path\\\\\\\": rel_path,\\\\n\\\",\\n+    \\\"                    \\\\\\\"type\\\\\\\": \\\\\\\"other\\\\\\\",\\\\n\\\",\\n+    \\\"                    \\\\\\\"uri\\\\\\\":  uri\\\\n\\\",\\n+    \\\"                })\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    # Run the gather\\\\n\\\",\\n+    \\\"    _gather()\\\\n\\\",\\n+    \\\"     \\\\n\\\",\\n+    \\\"    summary = {\\\\n\\\",\\n+    \\\"        \\\\\\\"run_id\\\\\\\":         run_id,\\\\n\\\",\\n+    \\\"        \\\\\\\"run_name\\\\\\\": run_info.run_name,\\\\n\\\",\\n+    \\\"        \\\\\\\"experiment_id\\\\\\\":  run_info.experiment_id,\\\\n\\\",\\n+    \\\"        \\\\\\\"start_time\\\\\\\":     run_info.start_time,\\\\n\\\",\\n+    \\\"        \\\\\\\"end_time\\\\\\\":       run_info.end_time,\\\\n\\\",\\n+    \\\"        \\\\\\\"params\\\\\\\":         params,\\\\n\\\",\\n+    \\\"        \\\\\\\"metrics\\\\\\\":        metrics,\\\\n\\\",\\n+    \\\"        \\\\\\\"tags\\\\\\\":           tags,\\\\n\\\",\\n+    \\\"        \\\\\\\"artifacts\\\\\\\":      artifact_meta\\\\n\\\",\\n+    \\\"    }\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # 1) Determine notebook directory (where your .ipynb lives)\\\\n\\\",\\n+    \\\"    notebook_dir = os.getcwd()\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    # \\u2705 Create a subdirectory inside MODEL_PROVENANCE for the model\\\\n\\\",\\n+    \\\"    summary_dir = os.path.join(os.getcwd(), \\\\\\\"MODEL_PROVENANCE\\\\\\\", model_name)\\\\n\\\",\\n+    \\\"    os.makedirs(summary_dir, exist_ok=True)\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"   # 2) Pick a filename based on your model_name\\\\n\\\",\\n+    \\\"    summary_filename   = f\\\\\\\"{model_name}_run_summary.json\\\\\\\"\\\\n\\\",\\n+    \\\"    summary_local_path = os.path.join(summary_dir, summary_filename)\\\\n\\\",\\n+    \\\"   # 3) Write the JSON locally\\\\n\\\",\\n+    \\\"    with open(summary_local_path, \\\\\\\"w\\\\\\\", encoding=\\\\\\\"utf-8\\\\\\\") as f:\\\\n\\\",\\n+    \\\"        json.dump(summary, f, indent=2)\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    # 4) (Optional) Mirror it into MLflow artifacts under a single folder\\\\n\\\",\\n+    \\\"    mlflow.log_artifact(summary_local_path, artifact_path=\\\\\\\"run_summaries\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    mlflow.end_run()\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"d0c4e1b2-9fa9-4606-8128-6ac66b5c6e78\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"what does it create: \\\\n\\\",\\n+    \\\"lable_mapping in the current dir\\\\n\\\",\\n+    \\\"provenence file :REPO/notebooks/RQ_notebooks/MODEL_PROVENANCE/RandomForest_Iris_v20250425_120045_run_summary.json\\\\n\\\",\\n+    \\\"plots based on run:REPO/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120045/shap_summary.png\\\\n\\\",\\n+    \\\"mlrun:REPO/notebooks/RQ_notebooks/mlrunlogs/mlflow.db/615223710259862608/5d1fa0fc65af47128f3200628b1afaea\\\\n\\\",\\n+    \\\"trained model:REPO/notebooks/RQ_notebooks/Trained_models/RandomForest_Iris_v20250425_120852.pkl\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"7a5e3bbb-0288-47d0-9dc4-2855d7e4801a\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"1. Standards-compliant export (JSON-LD + Turtle)\\\\n\\\",\\n+    \\\"I already have your plain run_summary.json , wrap it in a JSON-LD context that maps your fields into PROV-O terms, then use rdflib to emit Turtle:\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": null,\\n+   \\\"id\\\": \\\"28ed1cfb-930a-4f17-a48f-30e4cffb7f3e\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [],\\n+   \\\"source\\\": [\\n+    \\\"import json\\\\n\\\",\\n+    \\\"import pandas as pd\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# Load the JSON file\\\\n\\\",\\n+    \\\"json_path = \\\\\\\"/mnt/data/REPO/notebooks/RQ_notebooks/MODEL_PROVENANCE/RandomForest_Iris_v20250425_125653/RandomForest_Iris_v20250425_125653_run_summary.json\\\\\\\"\\\\n\\\",\\n+    \\\"with open(json_path, \\\\\\\"r\\\\\\\", encoding=\\\\\\\"utf-8\\\\\\\") as file:\\\\n\\\",\\n+    \\\"    data = json.load(file)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# Extract justification tags\\\\n\\\",\\n+    \\\"justifications = {\\\\n\\\",\\n+    \\\"    k: v for k, v in data.get(\\\\\\\"tags\\\\\\\", {}).items()\\\\n\\\",\\n+    \\\"    if k.startswith(\\\\\\\"justification_\\\\\\\")\\\\n\\\",\\n+    \\\"}\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# Create a DataFrame\\\\n\\\",\\n+    \\\"justification_df = pd.DataFrame([\\\\n\\\",\\n+    \\\"    {\\\\\\\"Decision\\\\\\\": k.replace(\\\\\\\"justification_\\\\\\\", \\\\\\\"\\\\\\\"), \\\\\\\"Justification\\\\\\\": v}\\\\n\\\",\\n+    \\\"    for k, v in justifications.items()\\\\n\\\",\\n+    \\\"])\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"import ace_tools as tools; tools.display_dataframe_to_user(name=\\\\\\\"Researcher Justifications\\\\\\\", dataframe=justification_df)\\\\n\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 66,\\n+   \\\"id\\\": \\\"5cf88da4-69f8-4982-a594-28cf25e4f79a\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"Converted RandomForest_Iris_v20250425_121328_run_summary.json \\u2192 RandomForest_Iris_v20250425_121328.jsonld, RandomForest_Iris_v20250425_121328.ttl\\\\n\\\"\\n+     ]\\n+    }\\n+   ],\\n+   \\\"source\\\": [\\n+    \\\"\\\\n\\\",\\n+    \\\"def iso8601(ms):\\\\n\\\",\\n+    \\\"    \\\\\\\"\\\\\\\"\\\\\\\"Convert milliseconds since epoch to ISO8601 UTC.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\",\\n+    \\\"    return datetime.fromtimestamp(ms / 1000, tz=timezone.utc).isoformat()\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"for json_path in glob.glob(\\\\\\\"MODEL_PROVENANCE/*/*_run_summary.json\\\\\\\"):\\\\n\\\",\\n+    \\\"    basename   = os.path.basename(json_path)\\\\n\\\",\\n+    \\\"    model_name = basename.rsplit(\\\\\\\"_run_summary.json\\\\\\\", 1)[0]\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    with open(json_path, \\\\\\\"r\\\\\\\", encoding=\\\\\\\"utf-8\\\\\\\") as f:\\\\n\\\",\\n+    \\\"        summary = json.load(f)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    #\\u2013\\u2013 Minimal override context: keep all your flat fields as-is,\\\\n\\\",\\n+    \\\"    #\\u2013\\u2013 and only map the actual PROV terms to their IRIs.\\\\n\\\",\\n+    \\\"    ctx = {\\\\n\\\",\\n+    \\\"        # keep these flat\\\\n\\\",\\n+    \\\"        \\\\\\\"run_id\\\\\\\":       { \\\\\\\"@id\\\\\\\": \\\\\\\"run_id\\\\\\\" },\\\\n\\\",\\n+    \\\"        \\\\\\\"run_name\\\\\\\":     { \\\\\\\"@id\\\\\\\": \\\\\\\"run_name\\\\\\\" },\\\\n\\\",\\n+    \\\"        \\\\\\\"experiment_id\\\\\\\":{ \\\\\\\"@id\\\\\\\": \\\\\\\"experiment_id\\\\\\\" },\\\\n\\\",\\n+    \\\"        \\\\\\\"params\\\\\\\":       { \\\\\\\"@id\\\\\\\": \\\\\\\"params\\\\\\\" },\\\\n\\\",\\n+    \\\"        \\\\\\\"metrics\\\\\\\":      { \\\\\\\"@id\\\\\\\": \\\\\\\"metrics\\\\\\\" },\\\\n\\\",\\n+    \\\"        \\\\\\\"artifacts\\\\\\\":    { \\\\\\\"@id\\\\\\\": \\\\\\\"artifacts\\\\\\\" },\\\\n\\\",\\n+    \\\"        \\\\\\\"tags\\\\\\\":         { \\\\\\\"@id\\\\\\\": \\\\\\\"tags\\\\\\\" },\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"        # provenance namespace\\\\n\\\",\\n+    \\\"        \\\\\\\"prov\\\\\\\": \\\\\\\"http://www.w3.org/ns/prov#\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"xsd\\\\\\\":  \\\\\\\"http://www.w3.org/2001/XMLSchema#\\\\\\\",\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"        # map your timestamp fields into PROV\\\\n\\\",\\n+    \\\"        \\\\\\\"start_time\\\\\\\": { \\\\\\\"@id\\\\\\\": \\\\\\\"prov:startedAtTime\\\\\\\", \\\\\\\"@type\\\\\\\": \\\\\\\"xsd:dateTime\\\\\\\" },\\\\n\\\",\\n+    \\\"        \\\\\\\"end_time\\\\\\\":   { \\\\\\\"@id\\\\\\\": \\\\\\\"prov:endedAtTime\\\\\\\",   \\\\\\\"@type\\\\\\\": \\\\\\\"xsd:dateTime\\\\\\\" },\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"        # PROV-used/generated\\\\n\\\",\\n+    \\\"        \\\\\\\"used\\\\\\\":      { \\\\\\\"@id\\\\\\\": \\\\\\\"prov:used\\\\\\\",      \\\\\\\"@type\\\\\\\": \\\\\\\"@id\\\\\\\" },\\\\n\\\",\\n+    \\\"        \\\\\\\"generated\\\\\\\": { \\\\\\\"@id\\\\\\\": \\\\\\\"prov:generated\\\\\\\", \\\\\\\"@type\\\\\\\": \\\\\\\"@id\\\\\\\" },\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"        # JSON-LD boilerplate\\\\n\\\",\\n+    \\\"        \\\\\\\"@id\\\\\\\":   \\\\\\\"@id\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"@type\\\\\\\": \\\\\\\"@type\\\\\\\"\\\\n\\\",\\n+    \\\"    }\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    #\\u2013\\u2013 Build JSON-LD document, re-using your original keys verbatim\\\\n\\\",\\n+    \\\"    doc = {\\\\n\\\",\\n+    \\\"        \\\\\\\"@context\\\\\\\":      ctx,\\\\n\\\",\\n+    \\\"        \\\\\\\"run_id\\\\\\\":        summary[\\\\\\\"run_id\\\\\\\"],\\\\n\\\",\\n+    \\\"        \\\\\\\"run_name\\\\\\\":      summary.get(\\\\\\\"run_name\\\\\\\"),\\\\n\\\",\\n+    \\\"        \\\\\\\"experiment_id\\\\\\\": summary.get(\\\\\\\"experiment_id\\\\\\\"),\\\\n\\\",\\n+    \\\"        \\\\\\\"params\\\\\\\":        summary.get(\\\\\\\"params\\\\\\\", {}),\\\\n\\\",\\n+    \\\"        \\\\\\\"metrics\\\\\\\":       summary.get(\\\\\\\"metrics\\\\\\\", {}),\\\\n\\\",\\n+    \\\"        \\\\\\\"artifacts\\\\\\\":     summary.get(\\\\\\\"artifacts\\\\\\\", []),\\\\n\\\",\\n+    \\\"        \\\\\\\"tags\\\\\\\":          summary.get(\\\\\\\"tags\\\\\\\", {}),\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"        # PROV fields:\\\\n\\\",\\n+    \\\"        \\\\\\\"start_time\\\\\\\": iso8601(summary[\\\\\\\"start_time\\\\\\\"])\\\\n\\\",\\n+    \\\"    }\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    if summary.get(\\\\\\\"end_time\\\\\\\") is not None:\\\\n\\\",\\n+    \\\"        doc[\\\\\\\"end_time\\\\\\\"] = iso8601(summary[\\\\\\\"end_time\\\\\\\"])\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # for used/generated, just point at your dataset/model URIs\\\\n\\\",\\n+    \\\"    # (or blank-node them if you prefer richer structure)\\\\n\\\",\\n+    \\\"    doc[\\\\\\\"used\\\\\\\"] = summary.get(\\\\\\\"tags\\\\\\\", {}).get(\\\\\\\"dataset_uri\\\\\\\") or []\\\\n\\\",\\n+    \\\"    doc[\\\\\\\"generated\\\\\\\"] = [\\\\n\\\",\\n+    \\\"        art.get(\\\\\\\"uri\\\\\\\") or art.get(\\\\\\\"path\\\\\\\")\\\\n\\\",\\n+    \\\"        for art in summary.get(\\\\\\\"artifacts\\\\\\\", [])\\\\n\\\",\\n+    \\\"    ]\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    #\\u2013\\u2013 write JSON-LD\\\\n\\\",\\n+    \\\"    out_jsonld = os.path.join(\\\\\\\"MODEL_PROVENANCE\\\\\\\", model_name, f\\\\\\\"{model_name}.jsonld\\\\\\\")\\\\n\\\",\\n+    \\\"    with open(out_jsonld, \\\\\\\"w\\\\\\\", encoding=\\\\\\\"utf-8\\\\\\\") as f:\\\\n\\\",\\n+    \\\"        json.dump(doc, f, indent=2)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    #\\u2013\\u2013 parse & serialize to Turtle\\\\n\\\",\\n+    \\\"    g = Graph().parse(data=json.dumps(doc), format=\\\\\\\"json-ld\\\\\\\")\\\\n\\\",\\n+    \\\"    out_ttl = os.path.join(\\\\\\\"MODEL_PROVENANCE\\\\\\\", model_name, f\\\\\\\"{model_name}.ttl\\\\\\\")\\\\n\\\",\\n+    \\\"    g.serialize(destination=out_ttl, format=\\\\\\\"turtle\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    print(f\\\\\\\"Converted {basename} \\u2192 {os.path.basename(out_jsonld)}, {os.path.basename(out_ttl)}\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"83d6d524-01da-4f20-8131-0d4a3ac005e2\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"This code programatically, finds diff between generated Json file and created JsonLD and .TTL file to make it easier to understand if there is any discrepency\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 67,\\n+   \\\"id\\\": \\\"77a420c0-230d-41c0-9b63-f3dbbca1e670\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"== JSON-LD vs TTL ==\\\\n\\\",\\n+      \\\"Change summary:\\\\n\\\",\\n+      \\\"type\\\\n\\\",\\n+      \\\"changed    1 \\\\n\\\",\\n+      \\\"\\\\n\\\",\\n+      \\\"First 10 \\u2018changed\\u2019 entries:\\\\n\\\",\\n+      \\\"Top-level adds/removes:\\\\n\\\",\\n+      \\\"Empty DataFrame\\\\n\\\",\\n+      \\\"Columns: [path, type, a, b]\\\\n\\\",\\n+      \\\"Index: []\\\\n\\\",\\n+      \\\"\\\\n\\\",\\n+      \\\"== JSON vs JSON-LD ==\\\\n\\\",\\n+      \\\"Change summary:\\\\n\\\",\\n+      \\\"type\\\\n\\\",\\n+      \\\"added      3\\\\n\\\",\\n+      \\\"removed    1\\\\n\\\",\\n+      \\\"changed    1 \\\\n\\\",\\n+      \\\"\\\\n\\\",\\n+      \\\"First 10 \\u2018changed\\u2019 entries:\\\\n\\\",\\n+      \\\"Top-level adds/removes:\\\\n\\\",\\n+      \\\"Empty DataFrame\\\\n\\\",\\n+      \\\"Columns: [path, type, a, b]\\\\n\\\",\\n+      \\\"Index: []\\\\n\\\"\\n+     ]\\n+    }\\n+   ],\\n+   \\\"source\\\": [\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"def load_as_dict(path):\\\\n\\\",\\n+    \\\"    if path.endswith((\\\\\\\".ttl\\\\\\\", \\\\\\\".turtle\\\\\\\")):\\\\n\\\",\\n+    \\\"        g = Graph()\\\\n\\\",\\n+    \\\"        g.parse(path, format=\\\\\\\"turtle\\\\\\\")\\\\n\\\",\\n+    \\\"        # normalize to JSON-LD dict\\\\n\\\",\\n+    \\\"        return json.loads(g.serialize(format=\\\\\\\"json-ld\\\\\\\", indent=2))\\\\n\\\",\\n+    \\\"    else:\\\\n\\\",\\n+    \\\"        with open(path, encoding=\\\\\\\"utf-8\\\\\\\") as f:\\\\n\\\",\\n+    \\\"            return json.load(f)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"def compare_json(a, b, path=\\\\\\\"\\\\\\\"):\\\\n\\\",\\n+    \\\"    diffs = []\\\\n\\\",\\n+    \\\"    if isinstance(a, dict) and isinstance(b, dict):\\\\n\\\",\\n+    \\\"        all_keys = set(a) | set(b)\\\\n\\\",\\n+    \\\"        for k in all_keys:\\\\n\\\",\\n+    \\\"            new_path = f\\\\\\\"{path}/{k}\\\\\\\" if path else k\\\\n\\\",\\n+    \\\"            if k not in a:\\\\n\\\",\\n+    \\\"                diffs.append({\\\\\\\"path\\\\\\\": new_path, \\\\\\\"type\\\\\\\": \\\\\\\"added\\\\\\\",   \\\\\\\"a\\\\\\\": None,    \\\\\\\"b\\\\\\\": b[k]})\\\\n\\\",\\n+    \\\"            elif k not in b:\\\\n\\\",\\n+    \\\"                diffs.append({\\\\\\\"path\\\\\\\": new_path, \\\\\\\"type\\\\\\\": \\\\\\\"removed\\\\\\\", \\\\\\\"a\\\\\\\": a[k],   \\\\\\\"b\\\\\\\": None})\\\\n\\\",\\n+    \\\"            else:\\\\n\\\",\\n+    \\\"                diffs.extend(compare_json(a[k], b[k], new_path))\\\\n\\\",\\n+    \\\"    elif isinstance(a, list) and isinstance(b, list):\\\\n\\\",\\n+    \\\"        for i, (ia, ib) in enumerate(zip(a, b)):\\\\n\\\",\\n+    \\\"            diffs.extend(compare_json(ia, ib, f\\\\\\\"{path}[{i}]\\\\\\\"))\\\\n\\\",\\n+    \\\"        # handle length mismatches\\\\n\\\",\\n+    \\\"        if len(a) < len(b):\\\\n\\\",\\n+    \\\"            for i in range(len(a), len(b)):\\\\n\\\",\\n+    \\\"                diffs.append({\\\\\\\"path\\\\\\\": f\\\\\\\"{path}[{i}]\\\\\\\", \\\\\\\"type\\\\\\\": \\\\\\\"added\\\\\\\",   \\\\\\\"a\\\\\\\": None,  \\\\\\\"b\\\\\\\": b[i]})\\\\n\\\",\\n+    \\\"        elif len(a) > len(b):\\\\n\\\",\\n+    \\\"            for i in range(len(b), len(a)):\\\\n\\\",\\n+    \\\"                diffs.append({\\\\\\\"path\\\\\\\": f\\\\\\\"{path}[{i}]\\\\\\\", \\\\\\\"type\\\\\\\": \\\\\\\"removed\\\\\\\", \\\\\\\"a\\\\\\\": a[i],  \\\\\\\"b\\\\\\\": None})\\\\n\\\",\\n+    \\\"    else:\\\\n\\\",\\n+    \\\"        if a != b:\\\\n\\\",\\n+    \\\"            diffs.append({\\\\\\\"path\\\\\\\": path, \\\\\\\"type\\\\\\\": \\\\\\\"changed\\\\\\\", \\\\\\\"a\\\\\\\": a, \\\\\\\"b\\\\\\\": b})\\\\n\\\",\\n+    \\\"    return diffs\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# --- Usage example -----------------------------------------------\\\\n\\\",\\n+    \\\"# REPO/notebooks/RQ_notebooks/MODEL_PROVENANCE/RandomForest_Iris_v20250425_121328/RandomForest_Iris_v20250425_121328_run_summary.json\\\\n\\\",\\n+    \\\"# # Compare JSON-LD vs Turtle:\\\\n\\\",\\n+    \\\"# a = load_as_dict(\\\\\\\"MODEL_PROVENANCE/RandomForest_Iris_v20250423_230422_run_summary.json\\\\\\\")\\\\n\\\",\\n+    \\\"# b = load_as_dict(\\\\\\\"MODEL_PROVENANCE/RandomForest_Iris_v20250423_230422.ttl\\\\\\\")\\\\n\\\",\\n+    \\\"# diffs_jsonld_vs_ttl = compare_json(a, b)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# # Compare JSON vs JSON-LD:\\\\n\\\",\\n+    \\\"# c = load_as_dict(\\\\\\\"MODEL_PROVENANCE/RandomForest_Iris_v20250423_230422_run_summary.json\\\\\\\")\\\\n\\\",\\n+    \\\"# d = load_as_dict(\\\\\\\"MODEL_PROVENANCE/RandomForest_Iris_v20250423_230422.jsonld\\\\\\\")\\\\n\\\",\\n+    \\\"# diffs_json_vs_jsonld = compare_json(c, d)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# Define base directory\\\\n\\\",\\n+    \\\"base_dir = os.path.join(\\\\\\\"MODEL_PROVENANCE\\\\\\\", model_name)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# Build full paths for the files to compare\\\\n\\\",\\n+    \\\"summary_json    = os.path.join(base_dir, f\\\\\\\"{model_name}_run_summary.json\\\\\\\")\\\\n\\\",\\n+    \\\"turtle_file     = os.path.join(base_dir, f\\\\\\\"{model_name}.ttl\\\\\\\")\\\\n\\\",\\n+    \\\"jsonld_file     = os.path.join(base_dir, f\\\\\\\"{model_name}.jsonld\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# Load files\\\\n\\\",\\n+    \\\"a = load_as_dict(summary_json)\\\\n\\\",\\n+    \\\"b = load_as_dict(turtle_file)\\\\n\\\",\\n+    \\\"c = load_as_dict(summary_json)\\\\n\\\",\\n+    \\\"d = load_as_dict(jsonld_file)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# Perform comparisons\\\\n\\\",\\n+    \\\"diffs_jsonld_vs_ttl = compare_json(a, b)\\\\n\\\",\\n+    \\\"diffs_json_vs_jsonld = compare_json(c, d)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# Build DataFrames for interactive inspection\\\\n\\\",\\n+    \\\"df1 = pd.DataFrame(diffs_jsonld_vs_ttl)\\\\n\\\",\\n+    \\\"df2 = pd.DataFrame(diffs_json_vs_jsonld)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# --- Summaries & Filtering ---------------------------------------\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"def summarize_and_preview(df, preview_n=10):\\\\n\\\",\\n+    \\\"    print(\\\\\\\"Change summary:\\\\\\\")\\\\n\\\",\\n+    \\\"    print(df['type'].value_counts().to_string(), \\\\\\\"\\\\\\\\n\\\\\\\")\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    print(f\\\\\\\"First {preview_n} \\u2018changed\\u2019 entries:\\\\\\\")\\\\n\\\",\\n+    \\\"    # print(df[df['type']==\\\\\\\"changed\\\\\\\"].head(preview_n).to_string(index=False), \\\\\\\"\\\\\\\\n\\\\\\\")\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    # Top\\u2010level (one slash) adds/removes\\\\n\\\",\\n+    \\\"    top = df[df['path'].str.count(\\\\\\\"/\\\\\\\") == 1]\\\\n\\\",\\n+    \\\"    print(\\\\\\\"Top-level adds/removes:\\\\\\\")\\\\n\\\",\\n+    \\\"    print(top[top['type'].isin(['added','removed'])].to_string(index=False))\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"print(\\\\\\\"== JSON-LD vs TTL ==\\\\\\\")\\\\n\\\",\\n+    \\\"summarize_and_preview(df1)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"print(\\\\\\\"\\\\\\\\n== JSON vs JSON-LD ==\\\\\\\")\\\\n\\\",\\n+    \\\"summarize_and_preview(df2)\\\\n\\\",\\n+    \\\"\\\\n\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 68,\\n+   \\\"id\\\": \\\"41af9d6e-c683-45f9-bac1-296611b4d0b9\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"Removed in JSON-LD comparison:\\\\n\\\",\\n+      \\\"    path\\\\n\\\",\\n+      \\\"end_time\\\\n\\\",\\n+      \\\"\\\\n\\\",\\n+      \\\"Added in JSON-LD comparison:\\\\n\\\",\\n+      \\\"     path\\\\n\\\",\\n+      \\\" @context\\\\n\\\",\\n+      \\\"     used\\\\n\\\",\\n+      \\\"generated\\\\n\\\"\\n+     ]\\n+    }\\n+   ],\\n+   \\\"source\\\": [\\n+    \\\"# show all the removed paths (in JSON but not in JSON-LD)\\\\n\\\",\\n+    \\\"print(\\\\\\\"Removed in JSON-LD comparison:\\\\\\\")\\\\n\\\",\\n+    \\\"print(df2[df2['type']==\\\\\\\"removed\\\\\\\"][['path']].to_string(index=False))\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# show all the added paths (in JSON-LD but not in JSON)\\\\n\\\",\\n+    \\\"print(\\\\\\\"\\\\\\\\nAdded in JSON-LD comparison:\\\\\\\")\\\\n\\\",\\n+    \\\"print(df2[df2['type']==\\\\\\\"added\\\\\\\"][['path']].to_string(index=False))\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 69,\\n+   \\\"id\\\": \\\"f0d6f92a-5cd9-4c78-9c2a-0cd3247137c6\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"Removed in .ttl comparison:\\\\n\\\",\\n+      \\\"Empty DataFrame\\\\n\\\",\\n+      \\\"Columns: [path]\\\\n\\\",\\n+      \\\"Index: []\\\\n\\\",\\n+      \\\"\\\\n\\\",\\n+      \\\"Added in .ttl comparison:\\\\n\\\",\\n+      \\\"Empty DataFrame\\\\n\\\",\\n+      \\\"Columns: [path]\\\\n\\\",\\n+      \\\"Index: []\\\\n\\\"\\n+     ]\\n+    }\\n+   ],\\n+   \\\"source\\\": [\\n+    \\\"# show all the removed paths (in JSON but not in JSON-LD)\\\\n\\\",\\n+    \\\"print(\\\\\\\"Removed in .ttl comparison:\\\\\\\")\\\\n\\\",\\n+    \\\"print(df1[df1['type']==\\\\\\\"removed\\\\\\\"][['path']].to_string(index=False))\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# show all the added paths (in JSON-LD but not in JSON)\\\\n\\\",\\n+    \\\"print(\\\\\\\"\\\\\\\\nAdded in .ttl comparison:\\\\\\\")\\\\n\\\",\\n+    \\\"print(df1[df1['type']==\\\\\\\"added\\\\\\\"][['path']].to_string(index=False))\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"69efd0d0-9277-4efa-88cf-d2fd1b90d74c\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"Checks for completeness and mapping and time taken, needs work #TODO\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 70,\\n+   \\\"id\\\": \\\"165a13eb-7679-4f4c-b346-24f25da72cce\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\\\n\\\",\\n+      \\\"0/0 runs passed completeness checks (0.0%).\\\\n\\\",\\n+      \\\"\\\\n\\\",\\n+      \\\"Mapping integrity: 0/0 runs have zero diffs \\u2014 0.0%\\\\n\\\",\\n+      \\\"Overall quality score: 0.0%\\\\n\\\",\\n+      \\\"\\\\n\\\",\\n+      \\\"Benchmarking train_and_log() overhead:\\\\n\\\",\\n+      \\\"  \\u2022 No MLflow : 0.502s\\\\n\\\",\\n+      \\\"  \\u2022 With MLflow: 0.601s\\\\n\\\"\\n+     ]\\n+    }\\n+   ],\\n+   \\\"source\\\": [\\n+    \\\"\\\\n\\\",\\n+    \\\"# \\u2500\\u2500 User configuration \\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# Which keys must appear in every run_summary.json?\\\\n\\\",\\n+    \\\"REQUIRED_TOPLEVEL = {\\\\n\\\",\\n+    \\\"    \\\\\\\"run_id\\\\\\\", \\\\\\\"start_time\\\\\\\", \\\\\\\"end_time\\\\\\\",\\\\n\\\",\\n+    \\\"    \\\\\\\"params\\\\\\\", \\\\\\\"metrics\\\\\\\", \\\\\\\"tags\\\\\\\", \\\\\\\"artifacts\\\\\\\"\\\\n\\\",\\n+    \\\"}\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# A couple of sub-fields we also want to spot-check:\\\\n\\\",\\n+    \\\"REQUIRED_PARAMS  = {\\\\\\\"random_state\\\\\\\"}\\\\n\\\",\\n+    \\\"REQUIRED_METRICS = {\\\\\\\"accuracy\\\\\\\"}\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"JSON_SUMMARIES = glob.glob(\\\\\\\"MODEL_PROVENANCE/*_run_summary.json\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# \\u2500\\u2500 Helpers \\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"def iso8601(ms):\\\\n\\\",\\n+    \\\"    return datetime.fromtimestamp(ms/1000, tz=timezone.utc).isoformat()\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"def load_json(path):\\\\n\\\",\\n+    \\\"    with open(path, \\\\\\\"r\\\\\\\", encoding=\\\\\\\"utf-8\\\\\\\") as f:\\\\n\\\",\\n+    \\\"        return json.load(f)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"def write_json(path, obj):\\\\n\\\",\\n+    \\\"    with open(path, \\\\\\\"w\\\\\\\", encoding=\\\\\\\"utf-8\\\\\\\") as f:\\\\n\\\",\\n+    \\\"        json.dump(obj, f, indent=2)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"def convert_to_jsonld_and_ttl(summary, basename):\\\\n\\\",\\n+    \\\"    # build @context\\\\n\\\",\\n+    \\\"    ctx = {\\\\n\\\",\\n+    \\\"        \\\\\\\"prov\\\\\\\":    \\\\\\\"http://www.w3.org/ns/prov#\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"xsd\\\\\\\":     \\\\\\\"http://www.w3.org/2001/XMLSchema#\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"run\\\\\\\":     \\\\\\\"prov:Activity\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"start\\\\\\\":   \\\\\\\"prov:startedAtTime\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"end\\\\\\\":     \\\\\\\"prov:endedAtTime\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"used\\\\\\\":    \\\\\\\"prov:used\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"gen\\\\\\\":     \\\\\\\"prov:generated\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"param\\\\\\\":   \\\\\\\"prov:hadParameter\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"metric\\\\\\\":  \\\\\\\"prov:hadQuality\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"entity\\\\\\\":  \\\\\\\"prov:Entity\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"label\\\\\\\":   \\\\\\\"prov:label\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"value\\\\\\\":   \\\\\\\"prov:value\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"version\\\\\\\": \\\\\\\"prov:hadRevision\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"id\\\\\\\":      \\\\\\\"@id\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"type\\\\\\\":    \\\\\\\"@type\\\\\\\"\\\\n\\\",\\n+    \\\"    }\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    jsonld = {\\\\n\\\",\\n+    \\\"        \\\\\\\"@context\\\\\\\": ctx,\\\\n\\\",\\n+    \\\"        \\\\\\\"@id\\\\\\\":      f\\\\\\\"urn:run:{summary['run_id']}\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"@type\\\\\\\":    \\\\\\\"run\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"start\\\\\\\": {\\\\n\\\",\\n+    \\\"            \\\\\\\"@type\\\\\\\":  \\\\\\\"xsd:dateTime\\\\\\\",\\\\n\\\",\\n+    \\\"            \\\\\\\"@value\\\\\\\": iso8601(summary[\\\\\\\"start_time\\\\\\\"])\\\\n\\\",\\n+    \\\"        }\\\\n\\\",\\n+    \\\"    }\\\\n\\\",\\n+    \\\"    if summary.get(\\\\\\\"end_time\\\\\\\") is not None:\\\\n\\\",\\n+    \\\"        jsonld[\\\\\\\"end\\\\\\\"] = {\\\\n\\\",\\n+    \\\"            \\\\\\\"@type\\\\\\\":  \\\\\\\"xsd:dateTime\\\\\\\",\\\\n\\\",\\n+    \\\"            \\\\\\\"@value\\\\\\\": iso8601(summary[\\\\\\\"end_time\\\\\\\"])\\\\n\\\",\\n+    \\\"        }\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # params\\\\n\\\",\\n+    \\\"    jsonld[\\\\\\\"param\\\\\\\"] = [\\\\n\\\",\\n+    \\\"        {\\\\\\\"@type\\\\\\\":\\\\\\\"entity\\\\\\\",\\\\\\\"label\\\\\\\":k,\\\\\\\"value\\\\\\\":str(v)}\\\\n\\\",\\n+    \\\"        for k,v in summary.get(\\\\\\\"params\\\\\\\",{}).items()\\\\n\\\",\\n+    \\\"    ]\\\\n\\\",\\n+    \\\"    # metrics\\\\n\\\",\\n+    \\\"    jsonld[\\\\\\\"metric\\\\\\\"] = [\\\\n\\\",\\n+    \\\"        {\\\\\\\"@type\\\\\\\":\\\\\\\"entity\\\\\\\",\\\\\\\"label\\\\\\\":k,\\\\n\\\",\\n+    \\\"         \\\\\\\"value\\\\\\\":{\\\\\\\"@type\\\\\\\":\\\\\\\"xsd:decimal\\\\\\\",\\\\\\\"@value\\\\\\\":v}}\\\\n\\\",\\n+    \\\"        for k,v in summary.get(\\\\\\\"metrics\\\\\\\",{}).items()\\\\n\\\",\\n+    \\\"    ]\\\\n\\\",\\n+    \\\"    # artifacts\\\\n\\\",\\n+    \\\"    jsonld[\\\\\\\"gen\\\\\\\"] = [\\\\n\\\",\\n+    \\\"        {\\\\n\\\",\\n+    \\\"            \\\\\\\"@type\\\\\\\":\\\\\\\"entity\\\\\\\",\\\\n\\\",\\n+    \\\"            \\\\\\\"label\\\\\\\": art.get(\\\\\\\"path\\\\\\\") or art.get(\\\\\\\"label\\\\\\\"),\\\\n\\\",\\n+    \\\"            \\\\\\\"prov:location\\\\\\\": (\\\\n\\\",\\n+    \\\"                art.get(\\\\\\\"uri\\\\\\\")\\\\n\\\",\\n+    \\\"                or (art.get(\\\\\\\"content\\\\\\\",\\\\\\\"\\\\\\\")[:30]+\\\\\\\"\\u2026\\\\\\\")\\\\n\\\",\\n+    \\\"                if isinstance(art.get(\\\\\\\"content\\\\\\\"),str)\\\\n\\\",\\n+    \\\"                else \\\\\\\"\\\\\\\"\\\\n\\\",\\n+    \\\"            )\\\\n\\\",\\n+    \\\"        }\\\\n\\\",\\n+    \\\"        for art in summary.get(\\\\\\\"artifacts\\\\\\\",[])\\\\n\\\",\\n+    \\\"    ]\\\\n\\\",\\n+    \\\"    # dataset used\\\\n\\\",\\n+    \\\"    jsonld[\\\\\\\"used\\\\\\\"] = {\\\\n\\\",\\n+    \\\"        \\\\\\\"@type\\\\\\\":\\\\\\\"entity\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"label\\\\\\\": summary[\\\\\\\"tags\\\\\\\"].get(\\\\\\\"dataset_name\\\\\\\"),\\\\n\\\",\\n+    \\\"        \\\\\\\"version\\\\\\\": summary[\\\\\\\"tags\\\\\\\"].get(\\\\\\\"dataset_version\\\\\\\")\\\\n\\\",\\n+    \\\"    }\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # write JSON-LD\\\\n\\\",\\n+    \\\"    out_jsonld = f\\\\\\\"MODEL_PROVENANCE/{basename}.jsonld\\\\\\\"\\\\n\\\",\\n+    \\\"    write_json(out_jsonld, jsonld)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # serialize TTL\\\\n\\\",\\n+    \\\"    g = Graph().parse(data=json.dumps(jsonld), format=\\\\\\\"json-ld\\\\\\\")\\\\n\\\",\\n+    \\\"    out_ttl = f\\\\\\\"MODEL_PROVENANCE/{basename}.ttl\\\\\\\"\\\\n\\\",\\n+    \\\"    g.serialize(destination=out_ttl, format=\\\\\\\"turtle\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    return out_jsonld, out_ttl\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"def normalize_jsonld(js):\\\\n\\\",\\n+    \\\"    \\\\\\\"\\\\\\\"\\\\\\\"Simple deep-sort so compare_json doesn\\u2019t trip over ordering.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\",\\n+    \\\"    if isinstance(js, dict):\\\\n\\\",\\n+    \\\"        return {k: normalize_jsonld(js[k]) for k in sorted(js)}\\\\n\\\",\\n+    \\\"    if isinstance(js, list):\\\\n\\\",\\n+    \\\"        return sorted((normalize_jsonld(el) for el in js),\\\\n\\\",\\n+    \\\"                      key=lambda x: json.dumps(x, sort_keys=True))\\\\n\\\",\\n+    \\\"    return js\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"def diff_roundtrip(orig_json, jsonld_path, ttl_path):\\\\n\\\",\\n+    \\\"    orig = load_json(orig_json)\\\\n\\\",\\n+    \\\"    ld   = load_json(jsonld_path)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # parse TTL back to JSON-LD\\\\n\\\",\\n+    \\\"    g = Graph().parse(ttl_path, format=\\\\\\\"turtle\\\\\\\")\\\\n\\\",\\n+    \\\"    ttl_as_ld = json.loads(g.serialize(format=\\\\\\\"json-ld\\\\\\\"))\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # normalize\\\\n\\\",\\n+    \\\"    nl = normalize_jsonld(ld)\\\\n\\\",\\n+    \\\"    nt = normalize_jsonld(ttl_as_ld)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    return {\\\\n\\\",\\n+    \\\"        \\\\\\\"orig_vs_jsonld\\\\\\\":   compare_json(orig, ld),\\\\n\\\",\\n+    \\\"        \\\\\\\"jsonld_vs_ttl_ld\\\\\\\": compare_json(nl, nt)\\\\n\\\",\\n+    \\\"    }\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# \\u2500\\u2500 Main flow \\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"def main():\\\\n\\\",\\n+    \\\"    ok = 0\\\\n\\\",\\n+    \\\"    total = len(JSON_SUMMARIES)\\\\n\\\",\\n+    \\\"    missing_reports = []\\\\n\\\",\\n+    \\\"    cases = {}  # store diff results per run\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    for js_path in JSON_SUMMARIES:\\\\n\\\",\\n+    \\\"        summary = load_json(js_path)\\\\n\\\",\\n+    \\\"        base    = os.path.basename(js_path).split(\\\\\\\"_run_summary.json\\\\\\\")[0]\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"        # 1) completeness check\\\\n\\\",\\n+    \\\"        if not REQUIRED_TOPLEVEL.issubset(summary):\\\\n\\\",\\n+    \\\"            missing = REQUIRED_TOPLEVEL - set(summary)\\\\n\\\",\\n+    \\\"            missing_reports.append((js_path, f\\\\\\\"missing fields {missing}\\\\\\\"))\\\\n\\\",\\n+    \\\"            continue\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"        if not (REQUIRED_PARAMS <= summary[\\\\\\\"params\\\\\\\"].keys()):\\\\n\\\",\\n+    \\\"            missing_reports.append((js_path, f\\\\\\\"params missing {REQUIRED_PARAMS - summary['params'].keys()}\\\\\\\"))\\\\n\\\",\\n+    \\\"            continue\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"        if not (REQUIRED_METRICS <= summary[\\\\\\\"metrics\\\\\\\"].keys()):\\\\n\\\",\\n+    \\\"            missing_reports.append((js_path, f\\\\\\\"metrics missing {REQUIRED_METRICS - summary['metrics'].keys()}\\\\\\\"))\\\\n\\\",\\n+    \\\"            continue\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"        ok += 1\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"        # 2) convert\\\\n\\\",\\n+    \\\"        jsonld_path, ttl_path = convert_to_jsonld_and_ttl(summary, base)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"        # 3) diff\\\\n\\\",\\n+    \\\"        diffs = diff_roundtrip(js_path, jsonld_path, ttl_path)\\\\n\\\",\\n+    \\\"        cases[base] = diffs\\\\n\\\",\\n+    \\\"        print(f\\\\\\\"\\\\\\\\n\\u2500\\u2500 {base} diffs \\u2500\\u2500\\\\\\\")\\\\n\\\",\\n+    \\\"        print(\\\\\\\"  \\u2022 JSON \\u2192 JSON-LD:\\\\\\\", len(diffs[\\\\\\\"orig_vs_jsonld\\\\\\\"]), \\\\\\\"differences\\\\\\\")\\\\n\\\",\\n+    \\\"        print(\\\\\\\"  \\u2022 JSON-LD \\u2192 TTL \\u2192 JSON-LD:\\\\\\\", len(diffs[\\\\\\\"jsonld_vs_ttl_ld\\\\\\\"]), \\\\\\\"differences\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # 4) completeness summary\\\\n\\\",\\n+    \\\"    completeness_pct = (100 * ok / total) if total else 0\\\\n\\\",\\n+    \\\"    print(f\\\\\\\"\\\\\\\\n{ok}/{total} runs passed completeness checks ({completeness_pct:.1f}%).\\\\\\\")\\\\n\\\",\\n+    \\\"    if missing_reports:\\\\n\\\",\\n+    \\\"        print(\\\\\\\"\\\\\\\\nFailures:\\\\\\\")\\\\n\\\",\\n+    \\\"        for path, reason in missing_reports:\\\\n\\\",\\n+    \\\"            print(f\\\\\\\" \\u2022 {path}: {reason}\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # 5) integrity check\\\\n\\\",\\n+    \\\"    total_runs = len(cases)\\\\n\\\",\\n+    \\\"    zero_diff_runs = sum(\\\\n\\\",\\n+    \\\"        1\\\\n\\\",\\n+    \\\"        for diffs in cases.values()\\\\n\\\",\\n+    \\\"        if not diffs[\\\\\\\"orig_vs_jsonld\\\\\\\"] and not diffs[\\\\\\\"jsonld_vs_ttl_ld\\\\\\\"]\\\\n\\\",\\n+    \\\"    )\\\\n\\\",\\n+    \\\"    integrity_pct = (100 * zero_diff_runs / total_runs) if total_runs else 0\\\\n\\\",\\n+    \\\"    print(f\\\\\\\"\\\\\\\\nMapping integrity: {zero_diff_runs}/{total_runs} runs have zero diffs \\u2014 {integrity_pct:.1f}%\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # 6) overall quality score\\\\n\\\",\\n+    \\\"    overall_score = (completeness_pct + integrity_pct) / 2\\\\n\\\",\\n+    \\\"    print(f\\\\\\\"Overall quality score: {overall_score:.1f}%\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # 7) Benchmark your training fn\\\\n\\\",\\n+    \\\"    print(\\\\\\\"\\\\\\\\nBenchmarking train_and_log() overhead:\\\\\\\")\\\\n\\\",\\n+    \\\"    def train_and_log(use_mlflow=False):\\\\n\\\",\\n+    \\\"        # \\u2190 your real instrumentation + fit logic here\\\\n\\\",\\n+    \\\"        time.sleep(0.5 + (0.1 if use_mlflow else 0))  # stub\\\\n\\\",\\n+    \\\"        return\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    for flag in (False, True):\\\\n\\\",\\n+    \\\"        start = time.time()\\\\n\\\",\\n+    \\\"        train_and_log(use_mlflow=flag)\\\\n\\\",\\n+    \\\"        elapsed = time.time() - start\\\\n\\\",\\n+    \\\"        label = \\\\\\\"With MLflow\\\\\\\" if flag else \\\\\\\"No MLflow\\\\\\\"\\\\n\\\",\\n+    \\\"        print(f\\\\\\\"  \\u2022 {label:10s}: {elapsed:.3f}s\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"if __name__ == \\\\\\\"__main__\\\\\\\":\\\\n\\\",\\n+    \\\"    main()\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"5883f673-371e-415e-a73e-5c9c88b56fb1\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"RQ2  implementation\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 72,\\n+   \\\"id\\\": \\\"6d07ac1c-ea80-4787-bcb9-da047d12167d\\\",\\n+   \\\"metadata\\\": {\\n+    \\\"scrolled\\\": true\\n+   },\\n+   \\\"outputs\\\": [\\n+    {\\n+     \\\"data\\\": {\\n+      \\\"text/plain\\\": [\\n+       \\\"Index(['run_id', 'param_bootstrap', 'param_ccp_alpha', 'param_class_weight',\\\\n\\\",\\n+       \\\"       'param_columns_raw', 'param_criterion', 'param_database.description',\\\\n\\\",\\n+       \\\"       'param_database.id', 'param_database.name', 'param_database.owner',\\\\n\\\",\\n+       \\\"       'param_dataset.authors', 'param_dataset.doi', 'param_dataset.published',\\\\n\\\",\\n+       \\\"       'param_dataset.publisher', 'param_dataset.title',\\\\n\\\",\\n+       \\\"       'param_dropped_columns', 'param_feature_names',\\\\n\\\",\\n+       \\\"       'param_matplotlib_version', 'param_max_depth', 'param_max_features',\\\\n\\\",\\n+       \\\"       'param_max_leaf_nodes', 'param_max_samples',\\\\n\\\",\\n+       \\\"       'param_min_impurity_decrease', 'param_min_samples_leaf',\\\\n\\\",\\n+       \\\"       'param_min_samples_split', 'param_min_weight_fraction_leaf',\\\\n\\\",\\n+       \\\"       'param_numpy_version', 'param_n_estimators', 'param_n_features',\\\\n\\\",\\n+       \\\"       'param_n_features_final', 'param_n_jobs', 'param_n_records',\\\\n\\\",\\n+       \\\"       'param_n_test_samples', 'param_n_train_samples', 'param_oob_score',\\\\n\\\",\\n+       \\\"       'param_os_platform', 'param_pandas_version', 'param_python_version',\\\\n\\\",\\n+       \\\"       'param_random_state', 'param_retrieval_time', 'param_seaborn_version',\\\\n\\\",\\n+       \\\"       'param_shap_version', 'param_sklearn_version', 'param_test_size',\\\\n\\\",\\n+       \\\"       'param_verbose', 'param_warm_start', 'metric_accuracy',\\\\n\\\",\\n+       \\\"       'metric_accuracy_score_X_test', 'metric_dbrepo.num_deletes',\\\\n\\\",\\n+       \\\"       'metric_dbrepo.num_inserts', 'metric_dbrepo.row_count_end',\\\\n\\\",\\n+       \\\"       'metric_dbrepo.row_count_start', 'metric_f1_macro',\\\\n\\\",\\n+       \\\"       'metric_f1_score_X_test', 'metric_precision_macro',\\\\n\\\",\\n+       \\\"       'metric_precision_score_X_test', 'metric_recall_macro',\\\\n\\\",\\n+       \\\"       'metric_recall_score_X_test', 'metric_roc_auc',\\\\n\\\",\\n+       \\\"       'metric_roc_auc_score_X_test', 'metric_training_accuracy_score',\\\\n\\\",\\n+       \\\"       'metric_training_f1_score', 'metric_training_log_loss',\\\\n\\\",\\n+       \\\"       'metric_training_precision_score', 'metric_training_recall_score',\\\\n\\\",\\n+       \\\"       'metric_training_roc_auc', 'metric_training_score', 'tag_dataset_id',\\\\n\\\",\\n+       \\\"       'tag_dataset_name', 'tag_dataset_version', 'tag_data_source',\\\\n\\\",\\n+       \\\"       'tag_dbrepo.admin_email', 'tag_dbrepo.base_url',\\\\n\\\",\\n+       \\\"       'tag_dbrepo.granularity', 'tag_dbrepo.protocol_version',\\\\n\\\",\\n+       \\\"       'tag_dbrepo.repository_name', 'tag_dbrepo.table_last_modified',\\\\n\\\",\\n+       \\\"       'tag_estimator_class', 'tag_estimator_name',\\\\n\\\",\\n+       \\\"       'tag_git_current_commit_hash', 'tag_git_previous_commit_hash',\\\\n\\\",\\n+       \\\"       'tag_git__current_commit_url', 'tag_mlflow.log-model.history',\\\\n\\\",\\n+       \\\"       'tag_mlflow.runName', 'tag_mlflow.source.name',\\\\n\\\",\\n+       \\\"       'tag_mlflow.source.type', 'tag_mlflow.user', 'tag_model_name',\\\\n\\\",\\n+       \\\"       'tag_notebook_name', 'tag_target_name', 'tag_training_end_time',\\\\n\\\",\\n+       \\\"       'tag_training_start_time'],\\\\n\\\",\\n+       \\\"      dtype='object')\\\"\\n+      ]\\n+     },\\n+     \\\"execution_count\\\": 72,\\n+     \\\"metadata\\\": {},\\n+     \\\"output_type\\\": \\\"execute_result\\\"\\n+    }\\n+   ],\\n+   \\\"source\\\": [\\n+    \\\"\\\\n\\\",\\n+    \\\"# Load all run summary JSON files\\\\n\\\",\\n+    \\\"files = glob.glob(\\\\\\\"MODEL_PROVENANCE/*/*_run_summary.json\\\\\\\")\\\\n\\\",\\n+    \\\"rows = []\\\\n\\\",\\n+    \\\"for f in files:\\\\n\\\",\\n+    \\\"    with open(f) as fh:\\\\n\\\",\\n+    \\\"        summary = json.load(fh)\\\\n\\\",\\n+    \\\"    # Flatten parameters and metrics\\\\n\\\",\\n+    \\\"    row = {\\\\\\\"run_id\\\\\\\": summary[\\\\\\\"run_id\\\\\\\"]}\\\\n\\\",\\n+    \\\"    row.update({f\\\\\\\"param_{k}\\\\\\\": v for k, v in summary.get(\\\\\\\"params\\\\\\\", {}).items()})\\\\n\\\",\\n+    \\\"    row.update({f\\\\\\\"metric_{k}\\\\\\\": v for k, v in summary.get(\\\\\\\"metrics\\\\\\\", {}).items()})\\\\n\\\",\\n+    \\\"    row.update({f\\\\\\\"tag_{k}\\\\\\\": v for k, v in summary.get(\\\\\\\"tags\\\\\\\", {}).items()})\\\\n\\\",\\n+    \\\"    rows.append(row)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# Create DataFrame\\\\n\\\",\\n+    \\\"df = pd.DataFrame(rows)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# Display the DataFrame\\\\n\\\",\\n+    \\\"df.columns\\\\n\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"ba148da6-6ce5-45cf-a985-f164a53c969b\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"1) Tracing preprocessing steps\\\\n\\\",\\n+    \\\":\\\\n\\\",\\n+    \\\"Here are the top 4 Iris\\u2010focused preprocessing\\u2010tracing use cases I\\u2019d tackle first:\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"Reconstruct a run\\u2019s exact preprocessing\\\\n\\\",\\n+    \\\"Fetch a run\\u2019s run_id, columns_raw, dropped_columns, feature_names and test_size so you can replay the exact data pull & split.\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"Feature\\u2010drop impact analysis\\\\n\\\",\\n+    \\\"Identify runs where one or more measurements (e.g. petalwidthcm) were dropped and compare their test accuracies.\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"Best feature subset discovery\\\\n\\\",\\n+    \\\"Group runs by which features they used (sepals only vs petals only vs both) and rank them by test F1 or accuracy.\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"Common steps in high-accuracy runs\\\\n\\\",\\n+    \\\"Filter for runs with accuracy_score_X_test \\u2265 0.95 and list the shared preprocessing settings (dropped columns, test_size, etc.).\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 73,\\n+   \\\"id\\\": \\\"6e147555-afbf-4bba-b6da-7e90ff391920\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [\\n+    {\\n+     \\\"name\\\": \\\"stderr\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"2025/04/25 12:23:44 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'df84c36b36cc4ebd90a999db3ebc4ad4', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"[{'run_id': '28f01e38b7f04d2f948fe21f57f41d0c', 'param_dataset.title': 'Scikit-Learn Iris', 'param_columns_raw': \\\\\\\"['id', 'sepallengthcm', 'sepalwidthcm', 'petallengthcm', 'petalwidthcm', 'species']\\\\\\\", 'param_dropped_columns': \\\\\\\"['id']\\\\\\\", 'param_feature_names': \\\\\\\"['sepallengthcm', 'sepalwidthcm', 'petallengthcm', 'petalwidthcm']\\\\\\\", 'param_dataset.authors': '[\\\\\\\"Marshall Michael\\\\\\\"]', 'param_dataset.doi': '10.5281/ZENODO.1404173', 'param_dataset.published': '2018-8-27', 'param_test_size': '0.2', 'param_criterion': 'entropy', 'param_max_depth': '12', 'param_max_leaf_nodes': 'None', 'param_max_samples': 'None', 'metric_accuracy': 1.0, 'metric_f1_macro': 1.0, 'metric_roc_auc': 1.0}]\\\\n\\\",\\n+      \\\"[]\\\\n\\\",\\n+      \\\"[{'param_dropped_columns': \\\\\\\"['id']\\\\\\\", 'param_test_size': '0.2', 'param_feature_names': \\\\\\\"['sepallengthcm', 'sepalwidthcm', 'petallengthcm', 'petalwidthcm']\\\\\\\"}]\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"data\\\": {\\n+      \\\"application/vnd.jupyter.widget-view+json\\\": {\\n+       \\\"model_id\\\": \\\"d931b602947d4db8872f254d48e22027\\\",\\n+       \\\"version_major\\\": 2,\\n+       \\\"version_minor\\\": 0\\n+      },\\n+      \\\"text/plain\\\": [\\n+       \\\"Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]\\\"\\n+      ]\\n+     },\\n+     \\\"metadata\\\": {},\\n+     \\\"output_type\\\": \\\"display_data\\\"\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stderr\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"2025/04/25 12:23:52 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '41261519e1a643c5b1335701aee1bf95', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"{'features': ['sepallengthcm', 'sepalwidthcm'], 'accuracy': 0.7666666666666667}\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"data\\\": {\\n+      \\\"application/vnd.jupyter.widget-view+json\\\": {\\n+       \\\"model_id\\\": \\\"83ff1224205a4a8eb0c351a7f299dd93\\\",\\n+       \\\"version_major\\\": 2,\\n+       \\\"version_minor\\\": 0\\n+      },\\n+      \\\"text/plain\\\": [\\n+       \\\"Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]\\\"\\n+      ]\\n+     },\\n+     \\\"metadata\\\": {},\\n+     \\\"output_type\\\": \\\"display_data\\\"\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stderr\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"2025/04/25 12:23:58 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'e0955d231fa6488e9339086b5845064c', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"data\\\": {\\n+      \\\"application/vnd.jupyter.widget-view+json\\\": {\\n+       \\\"model_id\\\": \\\"1eaa6c141e064593b73b6c72ce0b00cf\\\",\\n+       \\\"version_major\\\": 2,\\n+       \\\"version_minor\\\": 0\\n+      },\\n+      \\\"text/plain\\\": [\\n+       \\\"Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]\\\"\\n+      ]\\n+     },\\n+     \\\"metadata\\\": {},\\n+     \\\"output_type\\\": \\\"display_data\\\"\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stderr\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"2025/04/25 12:24:04 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '21d299b426ac42a0ad799604e9e7ff88', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"{'dropped_feature': 'petallengthcm', 'baseline_acc': 1.0, 'dropped_acc': 0.9666666666666667, 'impact': 0.033333333333333326}\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"data\\\": {\\n+      \\\"application/vnd.jupyter.widget-view+json\\\": {\\n+       \\\"model_id\\\": \\\"4c04ce12f62f49a29f48509b1483f16b\\\",\\n+       \\\"version_major\\\": 2,\\n+       \\\"version_minor\\\": 0\\n+      },\\n+      \\\"text/plain\\\": [\\n+       \\\"Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]\\\"\\n+      ]\\n+     },\\n+     \\\"metadata\\\": {},\\n+     \\\"output_type\\\": \\\"display_data\\\"\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stderr\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"2025/04/25 12:24:10 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '8ca4591a1b53402f854187104d1e7ee0', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"data\\\": {\\n+      \\\"application/vnd.jupyter.widget-view+json\\\": {\\n+       \\\"model_id\\\": \\\"66bf06c45648410daa144c12f85658c6\\\",\\n+       \\\"version_major\\\": 2,\\n+       \\\"version_minor\\\": 0\\n+      },\\n+      \\\"text/plain\\\": [\\n+       \\\"Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]\\\"\\n+      ]\\n+     },\\n+     \\\"metadata\\\": {},\\n+     \\\"output_type\\\": \\\"display_data\\\"\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stderr\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"2025/04/25 12:24:16 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '0c8a66e5e4b244f9a6a8e9fa02d26828', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"data\\\": {\\n+      \\\"application/vnd.jupyter.widget-view+json\\\": {\\n+       \\\"model_id\\\": \\\"0d71b6d9b58d4e5a9db241baeaa79d53\\\",\\n+       \\\"version_major\\\": 2,\\n+       \\\"version_minor\\\": 0\\n+      },\\n+      \\\"text/plain\\\": [\\n+       \\\"Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]\\\"\\n+      ]\\n+     },\\n+     \\\"metadata\\\": {},\\n+     \\\"output_type\\\": \\\"display_data\\\"\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stderr\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"2025/04/25 12:24:22 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '53994143a51e481abd23e988be2466b1', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"data\\\": {\\n+      \\\"application/vnd.jupyter.widget-view+json\\\": {\\n+       \\\"model_id\\\": \\\"3fa13db4a66940d59cf37a30cb7a3cbc\\\",\\n+       \\\"version_major\\\": 2,\\n+       \\\"version_minor\\\": 0\\n+      },\\n+      \\\"text/plain\\\": [\\n+       \\\"Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]\\\"\\n+      ]\\n+     },\\n+     \\\"metadata\\\": {},\\n+     \\\"output_type\\\": \\\"display_data\\\"\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stderr\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"2025/04/25 12:24:28 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '35588f1cd8c34ce28770848de714d3c4', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"data\\\": {\\n+      \\\"application/vnd.jupyter.widget-view+json\\\": {\\n+       \\\"model_id\\\": \\\"273c026f2e0b464f98090472792b3a87\\\",\\n+       \\\"version_major\\\": 2,\\n+       \\\"version_minor\\\": 0\\n+      },\\n+      \\\"text/plain\\\": [\\n+       \\\"Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]\\\"\\n+      ]\\n+     },\\n+     \\\"metadata\\\": {},\\n+     \\\"output_type\\\": \\\"display_data\\\"\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"[{'dropped_feature': 'sepallengthcm', 'baseline_acc': 1.0, 'dropped_acc': 1.0, 'impact': 0.0}, {'dropped_feature': 'sepalwidthcm', 'baseline_acc': 1.0, 'dropped_acc': 1.0, 'impact': 0.0}, {'dropped_feature': 'petallengthcm', 'baseline_acc': 1.0, 'dropped_acc': 0.9666666666666667, 'impact': 0.0333}, {'dropped_feature': 'petalwidthcm', 'baseline_acc': 1.0, 'dropped_acc': 0.9666666666666667, 'impact': 0.0333}]\\\\n\\\"\\n+     ]\\n+    }\\n+   ],\\n+   \\\"source\\\": [\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# Helper to get the \\u201cofficial\\u201d feature_names from your summary DF\\\\n\\\",\\n+    \\\"def _get_all_features(df):\\\\n\\\",\\n+    \\\"    # assumes every row has the same param_feature_names\\\\n\\\",\\n+    \\\"    raw = df.loc[0, 'param_feature_names']\\\\n\\\",\\n+    \\\"    return ast.literal_eval(raw)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# Train & eval RF on just these columns of Iris\\\\n\\\",\\n+    \\\"def evaluate_subset(features, test_size=0.2, random_state=42, n_estimators=200):\\\\n\\\",\\n+    \\\"    iris = load_iris()\\\\n\\\",\\n+    \\\"    X = pd.DataFrame(iris.data, columns=iris.feature_names)\\\\n\\\",\\n+    \\\"    # map sklearn\\u2019s names to your param names, e.g. \\\\\\\"sepal length (cm)\\\\\\\" \\u2192 \\\\\\\"sepallengthcm\\\\\\\"\\\\n\\\",\\n+    \\\"    canon = _get_all_features(df)\\\\n\\\",\\n+    \\\"    mapping = dict(zip(iris.feature_names, canon))\\\\n\\\",\\n+    \\\"    X = X.rename(columns=mapping)\\\\n\\\",\\n+    \\\"    X_sub = X[features]\\\\n\\\",\\n+    \\\"    y = iris.target\\\\n\\\",\\n+    \\\"    Xtr, Xte, ytr, yte = train_test_split(X_sub, y, test_size=test_size, random_state=random_state)\\\\n\\\",\\n+    \\\"    m = RandomForestClassifier(n_estimators=n_estimators, random_state=random_state)\\\\n\\\",\\n+    \\\"    m.fit(Xtr, ytr)\\\\n\\\",\\n+    \\\"    return accuracy_score(yte, m.predict(Xte))\\\\n\\\",\\n+    \\\"def trace_preprocessing(df, run_id=None):\\\\n\\\",\\n+    \\\"    cols = ['run_id',\\\\n\\\",\\n+    \\\"            'param_dataset.title',\\\\n\\\",\\n+    \\\"            'param_columns_raw',\\\\n\\\",\\n+    \\\"            'param_dropped_columns',\\\\n\\\",\\n+    \\\"            'param_feature_names',\\\\n\\\",\\n+    \\\"            'param_dataset.authors', 'param_dataset.doi', 'param_dataset.published',\\\\n\\\",\\n+    \\\"            'param_test_size',\\\\n\\\",\\n+    \\\"            'param_criterion',\\\\n\\\",\\n+    \\\"            'param_max_depth','param_max_leaf_nodes', 'param_max_samples',\\\\n\\\",\\n+    \\\"           'metric_accuracy','metric_f1_macro','metric_roc_auc']\\\\n\\\",\\n+    \\\"    if run_id is None:\\\\n\\\",\\n+    \\\"        subset = df.loc[:, cols]\\\\n\\\",\\n+    \\\"    else:\\\\n\\\",\\n+    \\\"        subset = df.loc[df['run_id'] == run_id, cols]\\\\n\\\",\\n+    \\\"    return subset.to_dict(orient='records')\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"def drop_impact(df, feature, **_):\\\\n\\\",\\n+    \\\"    all_feats = _get_all_features(df)\\\\n\\\",\\n+    \\\"    baseline = evaluate_subset(all_feats)\\\\n\\\",\\n+    \\\"    without = [f for f in all_feats if f!=feature]\\\\n\\\",\\n+    \\\"    dropped = evaluate_subset(without)\\\\n\\\",\\n+    \\\"    return {\\\\n\\\",\\n+    \\\"      'dropped_feature': feature,\\\\n\\\",\\n+    \\\"      'baseline_acc': baseline,\\\\n\\\",\\n+    \\\"      'dropped_acc': dropped,\\\\n\\\",\\n+    \\\"      'impact': baseline - dropped\\\\n\\\",\\n+    \\\"    }\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"def drop_impact_all(df: pd.DataFrame) -> List[Dict[str, Any]]:\\\\n\\\",\\n+    \\\"    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\",\\n+    \\\"    Compute drop-impact for every feature in the dataset.\\\\n\\\",\\n+    \\\"    Returns list of dicts with dropped_feature, baseline_acc, dropped_acc, impact.\\\\n\\\",\\n+    \\\"    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\",\\n+    \\\"    feats = _get_all_features(df)\\\\n\\\",\\n+    \\\"    baseline = evaluate_subset(feats)\\\\n\\\",\\n+    \\\"    summary = []\\\\n\\\",\\n+    \\\"    for feat in feats:\\\\n\\\",\\n+    \\\"        without = [f for f in feats if f != feat]\\\\n\\\",\\n+    \\\"        acc = evaluate_subset(without)\\\\n\\\",\\n+    \\\"        summary.append({\\\\n\\\",\\n+    \\\"            'dropped_feature': feat,\\\\n\\\",\\n+    \\\"            'baseline_acc': baseline,\\\\n\\\",\\n+    \\\"            'dropped_acc': acc,\\\\n\\\",\\n+    \\\"            'impact': round(baseline - acc, 4)\\\\n\\\",\\n+    \\\"        })\\\\n\\\",\\n+    \\\"    return summary\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"def best_feature_subset(df, features, **_):\\\\n\\\",\\n+    \\\"    acc = evaluate_subset(features)\\\\n\\\",\\n+    \\\"    return {'features': features, 'accuracy': acc}\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"def common_high_accuracy(df: pd.DataFrame, threshold: float = 0.95) -> List[Dict[str, Any]]:\\\\n\\\",\\n+    \\\"    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\",\\n+    \\\"    Filter runs with test accuracy >= threshold and list unique shared preprocessing settings.\\\\n\\\",\\n+    \\\"    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\",\\n+    \\\"    high = df[df['metric_accuracy_score_X_test'] >= threshold]\\\\n\\\",\\n+    \\\"    cols = ['param_dropped_columns', 'param_test_size', 'param_feature_names']\\\\n\\\",\\n+    \\\"    return high[cols].drop_duplicates().to_dict(orient='records')\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# --------------------------------------------\\\\n\\\",\\n+    \\\"# Use Case Registry with parameter order for minimal input\\\\n\\\",\\n+    \\\"# --------------------------------------------\\\\n\\\",\\n+    \\\"USE_CASES = {\\\\n\\\",\\n+    \\\"    'trace_preprocessing': {\\\\n\\\",\\n+    \\\"        'func': trace_preprocessing,\\\\n\\\",\\n+    \\\"        'required_params': [],            # none strictly required\\\\n\\\",\\n+    \\\"        'optional_params': ['run_id'],    # run_id can be supplied or not\\\\n\\\",\\n+    \\\"    },\\\\n\\\",\\n+    \\\"    'drop_impact': {\\\\n\\\",\\n+    \\\"        'func': drop_impact,\\\\n\\\",\\n+    \\\"        'required_params': ['feature'],\\\\n\\\",\\n+    \\\"        'optional_params': [],\\\\n\\\",\\n+    \\\"    },\\\\n\\\",\\n+    \\\"     'drop_impact_all': {\\\\n\\\",\\n+    \\\"        'func': drop_impact_all,\\\\n\\\",\\n+    \\\"        'required_params': [],\\\\n\\\",\\n+    \\\"        'optional_params': [],\\\\n\\\",\\n+    \\\"    },\\\\n\\\",\\n+    \\\"    'best_feature_subset': {\\\\n\\\",\\n+    \\\"        'func': best_feature_subset,\\\\n\\\",\\n+    \\\"        'required_params': ['features'],\\\\n\\\",\\n+    \\\"        'optional_params': [],\\\\n\\\",\\n+    \\\"    },\\\\n\\\",\\n+    \\\"    'common_high_accuracy': {\\\\n\\\",\\n+    \\\"        'func': common_high_accuracy,\\\\n\\\",\\n+    \\\"        'required_params': ['threshold'],\\\\n\\\",\\n+    \\\"        'optional_params': [],\\\\n\\\",\\n+    \\\"    },\\\\n\\\",\\n+    \\\"}\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"def call_use_case(df, use_case_name, **kwargs):\\\\n\\\",\\n+    \\\"    if use_case_name not in USE_CASES:\\\\n\\\",\\n+    \\\"        raise ValueError(f\\\\\\\"Unknown use case: {use_case_name}\\\\\\\")\\\\n\\\",\\n+    \\\"    case = USE_CASES[use_case_name]\\\\n\\\",\\n+    \\\"    func = case['func']\\\\n\\\",\\n+    \\\"    # check required\\\\n\\\",\\n+    \\\"    missing = [p for p in case['required_params'] if p not in kwargs]\\\\n\\\",\\n+    \\\"    if missing:\\\\n\\\",\\n+    \\\"        raise ValueError(f\\\\\\\"{use_case_name} missing required params: {missing}\\\\\\\")\\\\n\\\",\\n+    \\\"    # build args\\\\n\\\",\\n+    \\\"    args = {p: kwargs[p] for p in case['required_params']}\\\\n\\\",\\n+    \\\"    for p in case['optional_params']:\\\\n\\\",\\n+    \\\"        args[p] = kwargs.get(p)\\\\n\\\",\\n+    \\\"    return func(df, **args)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# --------------------------------------------\\\\n\\\",\\n+    \\\"# Example Usage\\\\n\\\",\\n+    \\\"# --------------------------------------------\\\\n\\\",\\n+    \\\"if __name__ == '__main__':\\\\n\\\",\\n+    \\\"   # # 1) trace_preprocessing for all runs\\\\n\\\",\\n+    \\\"    print(call_use_case(df, 'trace_preprocessing'))\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    # 2) trace_preprocessing for a single run_id\\\\n\\\",\\n+    \\\"    print(call_use_case(df, 'trace_preprocessing', run_id='361daa12f99f4129a06cd20b78dd6fa7'))\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # 5) common_high_accuracy\\\\n\\\",\\n+    \\\"    print(call_use_case(df, 'common_high_accuracy', threshold=0.99))\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # 4) Best\\u2010subset on just sepals:\\\\n\\\",\\n+    \\\"    print(call_use_case(df, 'best_feature_subset', features=['sepallengthcm','sepalwidthcm']))\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # 3) Drop\\u2010impact for \\u201cpetallengthcm\\u201d:\\\\n\\\",\\n+    \\\"    print(call_use_case(df, 'drop_impact', feature='petallengthcm'))\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    print(call_use_case(df, 'drop_impact_all'))  # summary for all features\\\\n\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"96f912d6-0e84-4155-858a-9668bef63f6e\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\" \\u2022 Detecting models trained with deprecated code versions\\\\n\\\",\\n+    \\\" \\u2022 Mapping models to specific datasets used during training\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 74,\\n+   \\\"id\\\": \\\"34a02c9a-5459-478f-a3c5-7f7a58ff22b0\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"[{'param_dataset.doi': '10.5281/ZENODO.1404173',\\\\n\\\",\\n+      \\\"  'param_dataset.published': '2018-8-27',\\\\n\\\",\\n+      \\\"  'param_dataset.publisher': 'Zenodo',\\\\n\\\",\\n+      \\\"  'param_dataset.title': 'Scikit-Learn Iris',\\\\n\\\",\\n+      \\\"  'run_id': '28f01e38b7f04d2f948fe21f57f41d0c',\\\\n\\\",\\n+      \\\"  'tag_model_name': 'RandomForest_Iris_v20250425_121328'}]\\\\n\\\"\\n+     ]\\n+    }\\n+   ],\\n+   \\\"source\\\": [\\n+    \\\"\\\\n\\\",\\n+    \\\"def detect_deprecated_code(df: pd.DataFrame, deprecated_commits: List[str], **_) -> List[Dict[str, Any]]:\\\\n\\\",\\n+    \\\"    # we know the column is called tag_git_current_commit_hash\\\\n\\\",\\n+    \\\"    commit_col = 'tag_git_current_commit_hash'\\\\n\\\",\\n+    \\\"    if commit_col not in df.columns:\\\\n\\\",\\n+    \\\"        raise KeyError(f\\\\\\\"Missing {commit_col} in DataFrame\\\\\\\")\\\\n\\\",\\n+    \\\"    out = df[df[commit_col].isin(deprecated_commits)]\\\\n\\\",\\n+    \\\"    # include run_id and notebook/runName for context\\\\n\\\",\\n+    \\\"    cols = ['run_id', commit_col, 'tag_notebook_name', 'tag_mlflow.runName']\\\\n\\\",\\n+    \\\"    # drop any that don\\u2019t exist\\\\n\\\",\\n+    \\\"    cols = [c for c in cols if c in df.columns]\\\\n\\\",\\n+    \\\"    return out[cols].to_dict(orient='records')\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"def map_model_dataset(df: pd.DataFrame, **_) -> List[Dict[str, Any]]:\\\\n\\\",\\n+    \\\"    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\",\\n+    \\\"    For each run, return its model name (or run_id) alongside the dataset\\\\n\\\",\\n+    \\\"    title, DOI, published date and publisher.\\\\n\\\",\\n+    \\\"    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\",\\n+    \\\"    # pick whichever model-name column you have\\\\n\\\",\\n+    \\\"    model_col = 'tag_model_name' if 'tag_model_name' in df.columns else 'param_model_name'\\\\n\\\",\\n+    \\\"    cols = [\\\\n\\\",\\n+    \\\"        'run_id',\\\\n\\\",\\n+    \\\"        model_col,\\\\n\\\",\\n+    \\\"        'param_dataset.title',\\\\n\\\",\\n+    \\\"        'param_dataset.doi',\\\\n\\\",\\n+    \\\"        'param_dataset.published',\\\\n\\\",\\n+    \\\"        'param_dataset.publisher'\\\\n\\\",\\n+    \\\"    ]\\\\n\\\",\\n+    \\\"    # filter out any columns that don\\u2019t actually exist\\\\n\\\",\\n+    \\\"    cols = [c for c in cols if c in df.columns]\\\\n\\\",\\n+    \\\"    return df[cols].to_dict(orient='records')\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# --------------------------------------------\\\\n\\\",\\n+    \\\"# Extend Use-Case Registry\\\\n\\\",\\n+    \\\"# --------------------------------------------\\\\n\\\",\\n+    \\\"USE_CASES.update({\\\\n\\\",\\n+    \\\"    'detect_deprecated_code': {\\\\n\\\",\\n+    \\\"        'func': detect_deprecated_code,\\\\n\\\",\\n+    \\\"        'required_params': ['deprecated_commits'],\\\\n\\\",\\n+    \\\"        'optional_params': []\\\\n\\\",\\n+    \\\"    },\\\\n\\\",\\n+    \\\"    'map_model_dataset': {\\\\n\\\",\\n+    \\\"        'func': map_model_dataset,\\\\n\\\",\\n+    \\\"        'required_params': [],\\\\n\\\",\\n+    \\\"        'optional_params': []\\\\n\\\",\\n+    \\\"    },\\\\n\\\",\\n+    \\\"})\\\\n\\\",\\n+    \\\"# 1) Detect runs on deprecated commits:\\\\n\\\",\\n+    \\\"deprecated = [\\\\n\\\",\\n+    \\\"    \\\\\\\"a07434af4f547af2daab044d6873eb7081162293\\\\\\\",\\\\n\\\",\\n+    \\\"    \\\\\\\"d329c92495e196ec0f39fbb19dfdd367131a77d9\\\\\\\"\\\\n\\\",\\n+    \\\"]\\\\n\\\",\\n+    \\\"# print(call_use_case(df, \\\\\\\"detect_deprecated_code\\\\\\\", deprecated_commits=deprecated))\\\\n\\\",\\n+    \\\"pprint(call_use_case(df, 'map_model_dataset'))\\\\n\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"c52607ad-5849-4a2d-97ef-e8fc1ca16dc7\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"Goal: Notify collaborators who have forked the GitHub repo if their fork is outdated (i.e., behind the current commit used to train a model).\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"f29c8ad9-00bb-4c1e-ac3b-ee6861991acd\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"\\ud83e\\udde0 What We Need\\\\n\\\",\\n+    \\\"Current training run\\u2019s Git commit hash\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"GitHub API to fetch all forks of your repo\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"Compare each fork\\u2019s main or master branch head commit\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"Create an issue on their fork or on your repo tagging them if they\\u2019re behind\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"c72bed50-fb56-442d-a21e-bb7991892d07\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\": Notify via issues on your own repo\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 75,\\n+   \\\"id\\\": \\\"852f147c-9d0a-4d7f-a4ab-545d1e2375fb\\\",\\n+   \\\"metadata\\\": {\\n+    \\\"scrolled\\\": true\\n+   },\\n+   \\\"outputs\\\": [\\n+    {\\n+     \\\"name\\\": \\\"stdin\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"Do you want to notify collaborators whose forks are behind? (y/N):  N\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"No action taken.\\\\n\\\"\\n+     ]\\n+    }\\n+   ],\\n+   \\\"source\\\": [\\n+    \\\"def notify_outdated_forks():\\\\n\\\",\\n+    \\\"    load_dotenv()\\\\n\\\",\\n+    \\\"    token     = os.getenv(\\\\\\\"THESIS_TOKEN\\\\\\\")\\\\n\\\",\\n+    \\\"    owner     = \\\\\\\"reema-dass26\\\\\\\"\\\\n\\\",\\n+    \\\"    repo      = \\\\\\\"REPO\\\\\\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    if not token:\\\\n\\\",\\n+    \\\"        print(\\\\\\\"\\u26a0\\ufe0f GITHUB_TOKEN not set.\\\\\\\")\\\\n\\\",\\n+    \\\"        return\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    headers = {\\\\n\\\",\\n+    \\\"        \\\\\\\"Authorization\\\\\\\": f\\\\\\\"token {token}\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"Accept\\\\\\\":        \\\\\\\"application/vnd.github.v3+json\\\\\\\"\\\\n\\\",\\n+    \\\"    }\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # 1) Get latest upstream commit\\\\n\\\",\\n+    \\\"    main_commits = requests.get(\\\\n\\\",\\n+    \\\"        f\\\\\\\"https://api.github.com/repos/{owner}/{repo}/commits\\\\\\\",\\\\n\\\",\\n+    \\\"        headers=headers,\\\\n\\\",\\n+    \\\"        params={\\\\\\\"per_page\\\\\\\": 1}\\\\n\\\",\\n+    \\\"    )\\\\n\\\",\\n+    \\\"    main_commits.raise_for_status()\\\\n\\\",\\n+    \\\"    new_commit_hash = main_commits.json()[0][\\\\\\\"sha\\\\\\\"]\\\\n\\\",\\n+    \\\"    print(f\\\\\\\"Latest upstream commit: {new_commit_hash}\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # 2) List forks\\\\n\\\",\\n+    \\\"    forks_resp = requests.get(f\\\\\\\"https://api.github.com/repos/{owner}/{repo}/forks\\\\\\\", headers=headers)\\\\n\\\",\\n+    \\\"    forks_resp.raise_for_status()\\\\n\\\",\\n+    \\\"    forks = forks_resp.json()\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # 3) Compare each fork\\\\n\\\",\\n+    \\\"    outdated = []\\\\n\\\",\\n+    \\\"    for fork in forks:\\\\n\\\",\\n+    \\\"        fork_owner = fork[\\\\\\\"owner\\\\\\\"][\\\\\\\"login\\\\\\\"]\\\\n\\\",\\n+    \\\"        fork_comm = requests.get(\\\\n\\\",\\n+    \\\"            fork[\\\\\\\"url\\\\\\\"] + \\\\\\\"/commits\\\\\\\",\\\\n\\\",\\n+    \\\"            headers=headers,\\\\n\\\",\\n+    \\\"            params={\\\\\\\"per_page\\\\\\\": 1}\\\\n\\\",\\n+    \\\"        )\\\\n\\\",\\n+    \\\"        if fork_comm.status_code != 200:\\\\n\\\",\\n+    \\\"            print(f\\\\\\\"\\u00a0\\u00a0\\u2013 could not fetch commits for {fork_owner}, skipping.\\\\\\\")\\\\n\\\",\\n+    \\\"            continue\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"        fork_sha = fork_comm.json()[0][\\\\\\\"sha\\\\\\\"]\\\\n\\\",\\n+    \\\"        if fork_sha != new_commit_hash:\\\\n\\\",\\n+    \\\"            outdated.append(f\\\\\\\"@{fork_owner}\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # 4) Open an issue if any are behind\\\\n\\\",\\n+    \\\"    if outdated:\\\\n\\\",\\n+    \\\"        title = \\\\\\\"\\ud83d\\udd14 Notification: Your fork is behind the latest commit\\\\\\\"\\\\n\\\",\\n+    \\\"        body  = (\\\\n\\\",\\n+    \\\"            f\\\\\\\"Hi {' '.join(outdated)},\\\\\\\\n\\\\\\\\n\\\\\\\"\\\\n\\\",\\n+    \\\"            f\\\\\\\"The main repository has been updated to commit `{new_commit_hash}`.\\\\\\\\n\\\\\\\"\\\\n\\\",\\n+    \\\"            \\\\\\\"Please consider pulling the latest changes to stay in sync.\\\\\\\\n\\\\\\\\n\\\\\\\"\\\\n\\\",\\n+    \\\"            \\\\\\\"Thanks!\\\\\\\"\\\\n\\\",\\n+    \\\"        )\\\\n\\\",\\n+    \\\"        issues_url = f\\\\\\\"https://api.github.com/repos/{owner}/{repo}/issues\\\\\\\"\\\\n\\\",\\n+    \\\"        resp = requests.post(\\\\n\\\",\\n+    \\\"        issues_url,\\\\n\\\",\\n+    \\\"        headers=headers,\\\\n\\\",\\n+    \\\"        json={\\\\\\\"title\\\\\\\": title, \\\\\\\"body\\\\\\\": body}\\\\n\\\",\\n+    \\\"    )\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # DEBUGGING OUTPUT\\\\n\\\",\\n+    \\\"    print(f\\\\\\\"\\u2192 POST {issues_url}\\\\\\\")\\\\n\\\",\\n+    \\\"    print(\\\\\\\"\\u2192 Status code:\\\\\\\", resp.status_code)\\\\n\\\",\\n+    \\\"    print(\\\\\\\"\\u2192 Response headers:\\\\\\\", resp.headers)\\\\n\\\",\\n+    \\\"    try:\\\\n\\\",\\n+    \\\"        data = resp.json()\\\\n\\\",\\n+    \\\"        print(\\\\\\\"\\u2192 Response JSON:\\\\\\\", data)\\\\n\\\",\\n+    \\\"        print(\\\\\\\"\\u2192 html_url field:\\\\\\\", data.get(\\\\\\\"html_url\\\\\\\"))\\\\n\\\",\\n+    \\\"    except ValueError:\\\\n\\\",\\n+    \\\"        print(\\\\\\\"\\u2192 No JSON response body; raw text:\\\\\\\", resp.text)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"if __name__ == \\\\\\\"__main__\\\\\\\":\\\\n\\\",\\n+    \\\"    answer = input(\\\\\\\"Do you want to notify collaborators whose forks are behind? (y/N): \\\\\\\").strip().lower()\\\\n\\\",\\n+    \\\"    if answer in (\\\\\\\"y\\\\\\\", \\\\\\\"yes\\\\\\\"):\\\\n\\\",\\n+    \\\"        notify_outdated_forks()\\\\n\\\",\\n+    \\\"    else:\\\\n\\\",\\n+    \\\"        print(\\\\\\\"No action taken.\\\\\\\")\\\\n\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"cda31f16-fbe9-40ce-ac1b-9ebc898c8820\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"INVENIO INTEGRETION to upload the necessary files and publish\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": null,\\n+   \\\"id\\\": \\\"c2e5a7fc-3b03-45c8-bc90-817ea5ba7352\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [],\\n+   \\\"source\\\": [\\n+    \\\"############################################################################################\\\\n\\\",\\n+    \\\"# TEST CODE FOR INVENIO INTEGRETION\\\\n\\\",\\n+    \\\"#############################################################################################\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# API_BASE = \\\\\\\"https://127.0.0.1:5000\\\\\\\"\\\\n\\\",\\n+    \\\"# TOKEN    = \\\\\\\"8LnqJuz3TsBHffnDJ3isPLHYHtRbWrC0M667Nb5haEbnXpWqGbFRyfDApymr\\\\\\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# # 1) Test read\\u2010scope by listing records (no size param or size=1)\\\\n\\\",\\n+    \\\"# resp = requests.get(\\\\n\\\",\\n+    \\\"#     f\\\\\\\"{API_BASE}/api/records\\\\\\\",\\\\n\\\",\\n+    \\\"#     headers={\\\\\\\"Authorization\\\\\\\": f\\\\\\\"Bearer {TOKEN}\\\\\\\"},\\\\n\\\",\\n+    \\\"#     verify=False\\\\n\\\",\\n+    \\\"# )\\\\n\\\",\\n+    \\\"# print(resp.status_code)\\\\n\\\",\\n+    \\\"# # should be 200 and a JSON page of records\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# # or explicitly:\\\\n\\\",\\n+    \\\"# resp = requests.get(\\\\n\\\",\\n+    \\\"#     f\\\\\\\"{API_BASE}/api/records?size=1\\\\\\\",\\\\n\\\",\\n+    \\\"#     headers={\\\\\\\"Authorization\\\\\\\": f\\\\\\\"Bearer {TOKEN}\\\\\\\"},\\\\n\\\",\\n+    \\\"#     verify=False\\\\n\\\",\\n+    \\\"# )\\\\n\\\",\\n+    \\\"# print(resp.status_code, resp.json())\\\\n\\\",\\n+    \\\"# #################################################################################################\\\\n\\\",\\n+    \\\"# API_BASE = \\\\\\\"https://127.0.0.1:5000\\\\\\\"\\\\n\\\",\\n+    \\\"# TOKEN    = \\\\\\\"8LnqJuz3TsBHffnDJ3isPLHYHtRbWrC0M667Nb5haEbnXpWqGbFRyfDApymr\\\\\\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# resp = requests.options(\\\\n\\\",\\n+    \\\"#     f\\\\\\\"{API_BASE}/api/records\\\\\\\",\\\\n\\\",\\n+    \\\"#     headers={\\\\\\\"Authorization\\\\\\\": f\\\\\\\"Bearer {TOKEN}\\\\\\\"},\\\\n\\\",\\n+    \\\"#     verify=False\\\\n\\\",\\n+    \\\"# )\\\\n\\\",\\n+    \\\"# print(\\\\\\\"Allowed methods:\\\\\\\", resp.headers.get(\\\\\\\"Allow\\\\\\\"))\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": null,\\n+   \\\"id\\\": \\\"7e5b2cc5-ecf3-4e13-8cac-47f57f12cbdd\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [],\\n+   \\\"source\\\": [\\n+    \\\"\\\\n\\\",\\n+    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n+    \\\"# Configuration\\\\n\\\",\\n+    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n+    \\\"API_BASE   = \\\\\\\"https://127.0.0.1:5000\\\\\\\"\\\\n\\\",\\n+    \\\"TOKEN      = \\\\\\\"8LnqJuz3TsBHffnDJ3isPLHYHtRbWrC0M667Nb5haEbnXpWqGbFRyfDApymr\\\\\\\"\\\\n\\\",\\n+    \\\"VERIFY_SSL = False  # only for self\\u2010signed dev\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"HEADERS_JSON = {\\\\n\\\",\\n+    \\\"    \\\\\\\"Accept\\\\\\\":        \\\\\\\"application/json\\\\\\\",\\\\n\\\",\\n+    \\\"    \\\\\\\"Content-Type\\\\\\\":  \\\\\\\"application/json\\\\\\\",\\\\n\\\",\\n+    \\\"    \\\\\\\"Authorization\\\\\\\": f\\\\\\\"Bearer {TOKEN}\\\\\\\",\\\\n\\\",\\n+    \\\"}\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"HEADERS_OCTET = {\\\\n\\\",\\n+    \\\"    \\\\\\\"Content-Type\\\\\\\":  \\\\\\\"application/octet-stream\\\\\\\",\\\\n\\\",\\n+    \\\"    \\\\\\\"Authorization\\\\\\\": f\\\\\\\"Bearer {TOKEN}\\\\\\\",\\\\n\\\",\\n+    \\\"}\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# The folders you want to walk & upload:\\\\n\\\",\\n+    \\\"TO_UPLOAD = [\\\\\\\"Trained_models\\\\\\\", \\\\\\\"plots\\\\\\\", \\\\\\\"MODEL_PROVENANCE\\\\\\\"]\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n+    \\\"# 1) Create draft with ALL required metadata\\\\n\\\",\\n+    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n+    \\\"def create_draft():\\\\n\\\",\\n+    \\\"    payload = {\\\\n\\\",\\n+    \\\"  \\\\\\\"metadata\\\\\\\": {\\\\n\\\",\\n+    \\\"    \\\\\\\"title\\\\\\\":            \\\\\\\"RandomForest Iris Model Artifacts\\\\\\\",\\\\n\\\",\\n+    \\\"    \\\\\\\"creators\\\\\\\": [ {\\\\n\\\",\\n+    \\\"      \\\\\\\"person_or_org\\\\\\\": {\\\\n\\\",\\n+    \\\"        \\\\\\\"type\\\\\\\":        \\\\\\\"personal\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"given_name\\\\\\\":  \\\\\\\"Reema\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"family_name\\\\\\\": \\\\\\\"Dass\\\\\\\"\\\\n\\\",\\n+    \\\"      }\\\\n\\\",\\n+    \\\"    } ],\\\\n\\\",\\n+    \\\"    \\\\\\\"publication_date\\\\\\\": \\\\\\\"2025-04-24\\\\\\\",\\\\n\\\",\\n+    \\\"    \\\\\\\"resource_type\\\\\\\":    { \\\\\\\"id\\\\\\\": \\\\\\\"software\\\\\\\" },\\\\n\\\",\\n+    \\\"    \\\\\\\"access\\\\\\\": {\\\\n\\\",\\n+    \\\"      \\\\\\\"record\\\\\\\": \\\\\\\"public\\\\\\\",\\\\n\\\",\\n+    \\\"      \\\\\\\"files\\\\\\\":  \\\\\\\"public\\\\\\\"\\\\n\\\",\\n+    \\\"    }\\\\n\\\",\\n+    \\\"  }\\\\n\\\",\\n+    \\\"}\\\\n\\\",\\n+    \\\"    r = requests.post(f\\\\\\\"{API_BASE}/api/records\\\\\\\",\\\\n\\\",\\n+    \\\"                      headers=HEADERS_JSON,\\\\n\\\",\\n+    \\\"                      json=payload,\\\\n\\\",\\n+    \\\"                      verify=VERIFY_SSL)\\\\n\\\",\\n+    \\\"    r.raise_for_status()\\\\n\\\",\\n+    \\\"    draft = r.json()\\\\n\\\",\\n+    \\\"    print(\\\\\\\"\\u2705 Draft created:\\\\\\\", draft[\\\\\\\"id\\\\\\\"])\\\\n\\\",\\n+    \\\"    return draft[\\\\\\\"id\\\\\\\"], draft[\\\\\\\"links\\\\\\\"]\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n+    \\\"# 2) Register, upload and commit a single file\\\\n\\\",\\n+    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n+    \\\"def upload_and_commit(links, key, path):\\\\n\\\",\\n+    \\\"    # 2a) register the filename in the draft\\\\n\\\",\\n+    \\\"    r1 = requests.post(links[\\\\\\\"files\\\\\\\"],\\\\n\\\",\\n+    \\\"                       headers=HEADERS_JSON,\\\\n\\\",\\n+    \\\"                       json=[{\\\\\\\"key\\\\\\\": key}],\\\\n\\\",\\n+    \\\"                       verify=VERIFY_SSL)\\\\n\\\",\\n+    \\\"    r1.raise_for_status()\\\\n\\\",\\n+    \\\"    entry = next(e for e in r1.json()[\\\\\\\"entries\\\\\\\"] if e[\\\\\\\"key\\\\\\\"] == key)\\\\n\\\",\\n+    \\\"    file_links = entry[\\\\\\\"links\\\\\\\"]\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # 2b) upload the bytes\\\\n\\\",\\n+    \\\"    with open(path, \\\\\\\"rb\\\\\\\") as fp:\\\\n\\\",\\n+    \\\"        r2 = requests.put(file_links[\\\\\\\"content\\\\\\\"],\\\\n\\\",\\n+    \\\"                          headers=HEADERS_OCTET,\\\\n\\\",\\n+    \\\"                          data=fp,\\\\n\\\",\\n+    \\\"                          verify=VERIFY_SSL)\\\\n\\\",\\n+    \\\"    r2.raise_for_status()\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # 2c) commit the upload\\\\n\\\",\\n+    \\\"    r3 = requests.post(file_links[\\\\\\\"commit\\\\\\\"],\\\\n\\\",\\n+    \\\"                       headers=HEADERS_JSON,\\\\n\\\",\\n+    \\\"                       verify=VERIFY_SSL)\\\\n\\\",\\n+    \\\"    r3.raise_for_status()\\\\n\\\",\\n+    \\\"    print(f\\\\\\\"  \\u2022 Uploaded {key}\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n+    \\\"# 3) Walk each folder and upload every file\\\\n\\\",\\n+    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n+    \\\"def upload_folder(links):\\\\n\\\",\\n+    \\\"    for folder in TO_UPLOAD:\\\\n\\\",\\n+    \\\"        if not os.path.isdir(folder):\\\\n\\\",\\n+    \\\"            print(f\\\\\\\"\\u26a0\\ufe0f Skipping missing folder {folder}\\\\\\\")\\\\n\\\",\\n+    \\\"            continue\\\\n\\\",\\n+    \\\"        base = os.path.dirname(folder) or folder\\\\n\\\",\\n+    \\\"        for root, _, files in os.walk(folder):\\\\n\\\",\\n+    \\\"            for fn in files:\\\\n\\\",\\n+    \\\"                local = os.path.join(root, fn)\\\\n\\\",\\n+    \\\"                # create a POSIX\\u2010style key preserving subfolders\\\\n\\\",\\n+    \\\"                key = os.path.relpath(local, start=base).replace(os.sep, \\\\\\\"/\\\\\\\")\\\\n\\\",\\n+    \\\"                upload_and_commit(links, key, local)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n+    \\\"# 4) Publish the draft\\\\n\\\",\\n+    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n+    \\\"def publish(links):\\\\n\\\",\\n+    \\\"    r = requests.post(links[\\\\\\\"publish\\\\\\\"],\\\\n\\\",\\n+    \\\"                      headers=HEADERS_JSON,\\\\n\\\",\\n+    \\\"                      verify=VERIFY_SSL)\\\\n\\\",\\n+    \\\"    if not r.ok:\\\\n\\\",\\n+    \\\"        print(\\\\\\\"\\u274c Publish failed:\\\\\\\", r.status_code, r.text)\\\\n\\\",\\n+    \\\"        try: print(r.json())\\\\n\\\",\\n+    \\\"        except: pass\\\\n\\\",\\n+    \\\"        r.raise_for_status()\\\\n\\\",\\n+    \\\"    print(\\\\\\\"\\u2705 Published:\\\\\\\", r.json()[\\\\\\\"id\\\\\\\"])\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n+    \\\"# 5) Fetch metadata and save to a file\\\\n\\\",\\n+    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n+    \\\"def fetch_metadata(record_id):\\\\n\\\",\\n+    \\\"    r = requests.get(f\\\\\\\"{API_BASE}/api/records/{record_id}\\\\\\\",\\\\n\\\",\\n+    \\\"                     headers=HEADERS_JSON,\\\\n\\\",\\n+    \\\"                     verify=VERIFY_SSL)\\\\n\\\",\\n+    \\\"    r.raise_for_status()\\\\n\\\",\\n+    \\\"    metadata = r.json()\\\\n\\\",\\n+    \\\"    print(\\\\\\\"\\u2705 Metadata fetched successfully\\\\\\\")\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    # Save the metadata to a file\\\\n\\\",\\n+    \\\"    with open(f\\\\\\\"metadata_{record_id}.json\\\\\\\", \\\\\\\"w\\\\\\\") as f:\\\\n\\\",\\n+    \\\"        json.dump(metadata, f, indent=4)\\\\n\\\",\\n+    \\\"    print(f\\\\\\\"\\u2705 Metadata saved as metadata_{record_id}.json\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n+    \\\"# Main\\\\n\\\",\\n+    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n+    \\\"if __name__ == \\\\\\\"__main__\\\\\\\":\\\\n\\\",\\n+    \\\"    recid, links = create_draft()\\\\n\\\",\\n+    \\\"    upload_folder(links)\\\\n\\\",\\n+    \\\"    publish(links)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # Fetch and save metadata after publishing\\\\n\\\",\\n+    \\\"    print(fetch_metadata(recid))\\\\n\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"2f7423f2-0ff3-4104-913e-50eeb32d9d0f\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"METADATA EXTRACTION FROM INVENIO:\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": null,\\n+   \\\"id\\\": \\\"0013878b-37da-4a22-9586-3773531bfd01\\\",\\n+   \\\"metadata\\\": {\\n+    \\\"scrolled\\\": true\\n+   },\\n+   \\\"outputs\\\": [],\\n+   \\\"source\\\": [\\n+    \\\"\\\\n\\\",\\n+    \\\"# Function to dynamically extract and structure metadata from the original JSON\\\\n\\\",\\n+    \\\"def extract_metadata(metadata):\\\\n\\\",\\n+    \\\"    # Debug: Check if metadata is loaded correctly\\\\n\\\",\\n+    \\\"    print(\\\\\\\"Debug: Metadata loaded successfully\\\\\\\")\\\\n\\\",\\n+    \\\"    print(metadata.get(\\\\\\\"id\\\\\\\", \\\\\\\"\\\\\\\"))  # Check if 'id' is being fetched\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # Check if the required fields are in the metadata\\\\n\\\",\\n+    \\\"    print(\\\\\\\"Debug: Extracting fields from metadata...\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    extracted_data = {\\\\n\\\",\\n+    \\\"        \\\\\\\"invenio_metadata\\\\\\\": {\\\\n\\\",\\n+    \\\"            \\\\\\\"id\\\\\\\": metadata.get(\\\\\\\"id\\\\\\\", \\\\\\\"\\\\\\\"),\\\\n\\\",\\n+    \\\"            \\\\\\\"title\\\\\\\": metadata.get(\\\\\\\"metadata\\\\\\\", {}).get(\\\\\\\"title\\\\\\\", \\\\\\\"\\\\\\\"),\\\\n\\\",\\n+    \\\"            \\\\\\\"creator\\\\\\\": \\\\\\\", \\\\\\\".join([creator[\\\\\\\"person_or_org\\\\\\\"].get(\\\\\\\"name\\\\\\\", \\\\\\\"\\\\\\\") for creator in metadata.get(\\\\\\\"metadata\\\\\\\", {}).get(\\\\\\\"creators\\\\\\\", [])]),\\\\n\\\",\\n+    \\\"            \\\\\\\"publication_date\\\\\\\": metadata.get(\\\\\\\"metadata\\\\\\\", {}).get(\\\\\\\"publication_date\\\\\\\", \\\\\\\"\\\\\\\"),\\\\n\\\",\\n+    \\\"            \\\\\\\"files\\\\\\\": [],  # Initialize 'files' as a list\\\\n\\\",\\n+    \\\"            \\\\\\\"pids\\\\\\\": metadata.get(\\\\\\\"pids\\\\\\\", {}),\\\\n\\\",\\n+    \\\"            \\\\\\\"version_info\\\\\\\": metadata.get(\\\\\\\"versions\\\\\\\", {}),\\\\n\\\",\\n+    \\\"            \\\\\\\"status\\\\\\\": metadata.get(\\\\\\\"status\\\\\\\", \\\\\\\"\\\\\\\"),\\\\n\\\",\\n+    \\\"            \\\\\\\"views\\\\\\\": metadata.get(\\\\\\\"stats\\\\\\\", {}).get(\\\\\\\"this_version\\\\\\\", {}).get(\\\\\\\"views\\\\\\\", 0),\\\\n\\\",\\n+    \\\"            \\\\\\\"downloads\\\\\\\": metadata.get(\\\\\\\"stats\\\\\\\", {}).get(\\\\\\\"this_version\\\\\\\", {}).get(\\\\\\\"downloads\\\\\\\", 0),\\\\n\\\",\\n+    \\\"        }\\\\n\\\",\\n+    \\\"    }\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # Extract file details from the metadata\\\\n\\\",\\n+    \\\"    for key, file_info in metadata.get(\\\\\\\"files\\\\\\\", {}).get(\\\\\\\"entries\\\\\\\", {}).items():\\\\n\\\",\\n+    \\\"        file_detail = {\\\\n\\\",\\n+    \\\"            \\\\\\\"key\\\\\\\": key,\\\\n\\\",\\n+    \\\"            \\\\\\\"url\\\\\\\": file_info[\\\\\\\"links\\\\\\\"].get(\\\\\\\"content\\\\\\\", \\\\\\\"\\\\\\\"),\\\\n\\\",\\n+    \\\"            \\\\\\\"size\\\\\\\": file_info.get(\\\\\\\"size\\\\\\\", 0),\\\\n\\\",\\n+    \\\"            \\\\\\\"mimetype\\\\\\\": file_info.get(\\\\\\\"mimetype\\\\\\\", \\\\\\\"\\\\\\\"),\\\\n\\\",\\n+    \\\"            \\\\\\\"checksum\\\\\\\": file_info.get(\\\\\\\"checksum\\\\\\\", \\\\\\\"\\\\\\\"),\\\\n\\\",\\n+    \\\"            \\\\\\\"metadata\\\\\\\": file_info.get(\\\\\\\"metadata\\\\\\\", {}),\\\\n\\\",\\n+    \\\"        }\\\\n\\\",\\n+    \\\"        extracted_data[\\\\\\\"invenio_metadata\\\\\\\"][\\\\\\\"files\\\\\\\"].append(file_detail)  # Append to the 'files' list\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    return extracted_data\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# Load the original metadata from the JSON file (replace with your actual file path)\\\\n\\\",\\n+    \\\"with open('metadata_p8a8y-1bn93.json', 'r') as f: \\\\n\\\",\\n+    \\\"    original_metadata = json.load(f)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# Debugging: print out the first part of the original metadata to verify its structure\\\\n\\\",\\n+    \\\"print(\\\\\\\"Debug: Original Metadata (start):\\\\\\\", json.dumps(original_metadata, indent=4)[:1000])  # Print only the start for review\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# Extract relevant details dynamically\\\\n\\\",\\n+    \\\"extracted_metadata = extract_metadata(original_metadata)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# Debugging: print the extracted metadata to verify it's correct\\\\n\\\",\\n+    \\\"print(\\\\\\\"Debug: Extracted Metadata:\\\\\\\", json.dumps(extracted_metadata, indent=4))\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# Load the existing JSON file (replace with your actual file path)\\\\n\\\",\\n+    \\\"with open('MODEL_PROVENANCE/RandomForest_Iris_v20250424_111946_run_summary.json', 'r') as f:\\\\n\\\",\\n+    \\\"    existing_metadata = json.load(f)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# Add the extracted metadata as a new node\\\\n\\\",\\n+    \\\"existing_metadata.update(extracted_metadata)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# Save the updated metadata back to the file\\\\n\\\",\\n+    \\\"with open('updated_metadata.json', 'w') as f:\\\\n\\\",\\n+    \\\"    json.dump(existing_metadata, f, indent=4)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"print(\\\\\\\"\\u2705 New dynamic metadata added successfully!\\\\\\\")\\\\n\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": null,\\n+   \\\"id\\\": \\\"38a807a7-6ecd-4ea7-93ac-78c0f853825c\\\",\\n+   \\\"metadata\\\": {\\n+    \\\"scrolled\\\": true\\n+   },\\n+   \\\"outputs\\\": [],\\n+   \\\"source\\\": [\\n+    \\\"# import mlflow\\\\n\\\",\\n+    \\\"# import mlflow.sklearn\\\\n\\\",\\n+    \\\"# from sklearn.datasets import load_iris\\\\n\\\",\\n+    \\\"# from sklearn.ensemble import RandomForestClassifier\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# X, y = load_iris(return_X_y=True)\\\\n\\\",\\n+    \\\"# mlflow.sklearn.autolog()\\\\n\\\",\\n+    \\\"# with mlflow.start_run() as run:\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"#     model = RandomForestClassifier(**hyperparams)\\\\n\\\",\\n+    \\\"#     model.fit(X_train, y_train)\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": null,\\n+   \\\"id\\\": \\\"570fa169-a5e2-47b3-b7f5-44f9577f22ad\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [],\\n+   \\\"source\\\": []\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 34,\\n+   \\\"id\\\": \\\"f67b7a46-a70d-44ea-976c-322a1a795311\\\",\\n+   \\\"metadata\\\": {\\n+    \\\"scrolled\\\": true\\n+   },\\n+   \\\"outputs\\\": [],\\n+   \\\"source\\\": [\\n+    \\\"import json\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"with open(\\\\\\\"MODEL_PROVENANCE/RandomForest_Iris_v20250425_132526/RandomForest_Iris_v20250425_132526_run_summary.json\\\\\\\", \\\\\\\"r\\\\\\\") as f1:\\\\n\\\",\\n+    \\\"    json1_with_sklearn = json.load(f1)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"with open(\\\\\\\"MODEL_PROVENANCE/RandomForest_Iris_v20250425_125653/RandomForest_Iris_v20250425_125653_run_summary.json\\\\\\\", \\\\\\\"r\\\\\\\") as f2:\\\\n\\\",\\n+    \\\"    json2 = json.load(f2)\\\\n\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 35,\\n+   \\\"id\\\": \\\"4211bdef-5785-472d-8ea5-0bc24a3faf3c\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [],\\n+   \\\"source\\\": [\\n+    \\\"keys1 = set(json1_with_sklearn.keys())\\\\n\\\",\\n+    \\\"keys2 = set(json2.keys())\\\\n\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 36,\\n+   \\\"id\\\": \\\"9d4d71f2-ef66-4e04-9d9b-c4b381d45590\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [],\\n+   \\\"source\\\": [\\n+    \\\"only_in_file1 = keys1 - keys2\\\\n\\\",\\n+    \\\"only_in_file2 = keys2 - keys1\\\\n\\\",\\n+    \\\"common_keys   = keys1 & keys2\\\\n\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 37,\\n+   \\\"id\\\": \\\"a51fb61b-d0f6-407e-8563-8a24060e06c2\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\u2705 Common Keys: {'end_time', 'start_time', 'experiment_id', 'run_name', 'artifacts', 'run_id', 'params', 'tags', 'metrics'}\\\\n\\\",\\n+      \\\"\\ud83d\\udd34 Keys only in file1: set()\\\\n\\\",\\n+      \\\"\\ud83d\\udd35 Keys only in file2: set()\\\\n\\\"\\n+     ]\\n+    }\\n+   ],\\n+   \\\"source\\\": [\\n+    \\\"print(\\\\\\\"\\u2705 Common Keys:\\\\\\\", common_keys)\\\\n\\\",\\n+    \\\"print(\\\\\\\"\\ud83d\\udd34 Keys only in file1:\\\\\\\", only_in_file1)\\\\n\\\",\\n+    \\\"print(\\\\\\\"\\ud83d\\udd35 Keys only in file2:\\\\\\\", only_in_file2)\\\\n\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 38,\\n+   \\\"id\\\": \\\"39c248fd-10d1-4229-b60f-4373b4b3214f\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [],\\n+   \\\"source\\\": [\\n+    \\\"def get_all_keys(d, prefix=''):\\\\n\\\",\\n+    \\\"    keys = set()\\\\n\\\",\\n+    \\\"    for k, v in d.items():\\\\n\\\",\\n+    \\\"        full_key = f\\\\\\\"{prefix}.{k}\\\\\\\" if prefix else k\\\\n\\\",\\n+    \\\"        keys.add(full_key)\\\\n\\\",\\n+    \\\"        if isinstance(v, dict):\\\\n\\\",\\n+    \\\"            keys.update(get_all_keys(v, full_key))\\\\n\\\",\\n+    \\\"    return keys\\\\n\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 39,\\n+   \\\"id\\\": \\\"83618982-c802-4ffa-b7e5-c018d36fe517\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [],\\n+   \\\"source\\\": [\\n+    \\\"keys1 = get_all_keys(json1_with_sklearn)\\\\n\\\",\\n+    \\\"keys2 = get_all_keys(json2)\\\\n\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 40,\\n+   \\\"id\\\": \\\"549ce528-5a49-476c-9546-a8bbc7fa466d\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\u2705 Common Keys: {'tags.justification_n_jobs', 'params.min_samples_split', 'run_name', 'tags.justification_dataset_version', 'tags.estimator_name', 'tags.justification_random_state', 'params.n_estimators', 'metrics.training_log_loss', 'params.max_features', 'params.max_leaf_nodes', 'tags.justification_verbose', 'tags.target_name', 'tags.estimator_class', 'tags.justification_test_split', 'params.database.description', 'metrics.training_roc_auc', 'tags.justification_metric_choice', 'params.dropped_columns', 'tags.dataset_name', 'experiment_id', 'tags.mlflow.source.name', 'tags', 'metrics.dbrepo.row_count_end', 'params.max_depth', 'params.database.id', 'params.n_test_samples', 'params.random_state', 'tags.justification_threshold_accuracy', 'tags.justification_max_features', 'params.verbose', 'tags.mlflow.log-model.history', 'tags.notebook_name', 'tags.justification_oob_score', 'params.n_train_samples', 'params.feature_names', 'tags.training_end_time', 'tags.justification_max_depth', 'params.ccp_alpha', 'tags.dataset_id', 'metrics.training_score', 'params.test_size', 'params.retrieval_time', 'params.dataset.title', 'tags.dbrepo.repository_name', 'params.bootstrap', 'tags.git_previous_commit_hash', 'params.min_impurity_decrease', 'params.min_weight_fraction_leaf', 'tags.dbrepo.granularity', 'params.max_samples', 'tags.model_name', 'params.n_features_final', 'params.oob_score', 'params.database.name', 'metrics.dbrepo.num_inserts', 'tags.mlflow.user', 'params.dataset.authors', 'params.class_weight', 'tags.justification_min_samples_split', 'artifacts', 'metrics', 'tags.justification_model_choice', 'tags.justification_criterion', 'tags.training_start_time', 'tags.justification_n_estimators', 'tags.justification_drop_column_X', 'metrics.dbrepo.num_deletes', 'tags.git__current_commit_url', 'params.dataset.publisher', 'tags.justification_class_weight', 'metrics.training_accuracy_score', 'tags.dataset_version', 'params.columns_raw', 'tags.dbrepo.table_last_modified', 'tags.dbrepo.base_url', 'params.n_features', 'tags.dbrepo.protocol_version', 'params.database.owner', 'end_time', 'start_time', 'tags.justification_experiment_name', 'metrics.training_f1_score', 'params', 'metrics.dbrepo.row_count_start', 'params.n_jobs', 'tags.dbrepo.admin_email', 'tags.justification_target_variable', 'params.criterion', 'tags.data_source', 'params.n_records', 'run_id', 'metrics.training_precision_score', 'params.dataset.doi', 'params.min_samples_leaf', 'tags.justification_bootstrap', 'tags.git_current_commit_hash', 'tags.mlflow.runName', 'metrics.training_recall_score', 'tags.justification_min_samples_leaf', 'params.dataset.published', 'tags.mlflow.source.type', 'params.warm_start'}\\\\n\\\",\\n+      \\\"\\ud83d\\udd34 Keys only in file1: set()\\\\n\\\",\\n+      \\\"\\ud83d\\udd35 Keys only in file2: {'metrics.f1_score_X_test', 'metrics.roc_auc_score_X_test', 'metrics.recall_score_X_test', 'params.sklearn_version', 'metrics.precision_macro', 'metrics.f1_macro', 'metrics.roc_auc', 'params.os_platform', 'metrics.recall_macro', 'params.shap_version', 'params.matplotlib_version', 'metrics.accuracy', 'metrics.precision_score_X_test', 'metrics.accuracy_score_X_test', 'params.pandas_version', 'params.numpy_version', 'params.seaborn_version', 'params.python_version'}\\\\n\\\"\\n+     ]\\n+    }\\n+   ],\\n+   \\\"source\\\": [\\n+    \\\"only_in_file1 = keys1 - keys2\\\\n\\\",\\n+    \\\"only_in_file2 = keys2 - keys1\\\\n\\\",\\n+    \\\"common_keys   = keys1 & keys2\\\\n\\\",\\n+    \\\"print(\\\\\\\"\\u2705 Common Keys:\\\\\\\", common_keys)\\\\n\\\",\\n+    \\\"print(\\\\\\\"\\ud83d\\udd34 Keys only in file1:\\\\\\\", only_in_file1)\\\\n\\\",\\n+    \\\"print(\\\\\\\"\\ud83d\\udd35 Keys only in file2:\\\\\\\", only_in_file2)\\\\n\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": null,\\n+   \\\"id\\\": \\\"c7e158ee-7016-43dc-9570-dc522f07d3c2\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [],\\n+   \\\"source\\\": []\\n+  }\\n+ ],\\n+ \\\"metadata\\\": {\\n+  \\\"kernelspec\\\": {\\n+   \\\"display_name\\\": \\\"Python 3 (ipykernel)\\\",\\n+   \\\"language\\\": \\\"python\\\",\\n+   \\\"name\\\": \\\"python3\\\"\\n+  },\\n+  \\\"language_info\\\": {\\n+   \\\"codemirror_mode\\\": {\\n+    \\\"name\\\": \\\"ipython\\\",\\n+    \\\"version\\\": 3\\n+   },\\n+   \\\"file_extension\\\": \\\".py\\\",\\n+   \\\"mimetype\\\": \\\"text/x-python\\\",\\n+   \\\"name\\\": \\\"python\\\",\\n+   \\\"nbconvert_exporter\\\": \\\"python\\\",\\n+   \\\"pygments_lexer\\\": \\\"ipython3\\\",\\n+   \\\"version\\\": \\\"3.11.5\\\"\\n+  }\\n+ },\\n+ \\\"nbformat\\\": 4,\\n+ \\\"nbformat_minor\\\": 5\\n+}\\ndiff --git a/notebooks/RQ_notebooks/RQ3.ipynb b/notebooks/RQ_notebooks/RQ3_draft.ipynb\\nsimilarity index 100%\\nrename from notebooks/RQ_notebooks/RQ3.ipynb\\nrename to notebooks/RQ_notebooks/RQ3_draft.ipynb\\ndiff --git a/notebooks/RQ_notebooks/Trained_models/RandomForest_Iris_v20250425_120852.pkl b/notebooks/RQ_notebooks/Trained_models/RandomForest_Iris_v20250425_120852.pkl\\nnew file mode 100644\\nindex 0000000..650175a\\nBinary files /dev/null and b/notebooks/RQ_notebooks/Trained_models/RandomForest_Iris_v20250425_120852.pkl differ\\ndiff --git a/notebooks/RQ_notebooks/Trained_models/RandomForest_Iris_v20250425_121328.pkl b/notebooks/RQ_notebooks/Trained_models/RandomForest_Iris_v20250425_121328.pkl\\nnew file mode 100644\\nindex 0000000..044631a\\nBinary files /dev/null and b/notebooks/RQ_notebooks/Trained_models/RandomForest_Iris_v20250425_121328.pkl differ\\ndiff --git a/notebooks/RQ_notebooks/Trained_models/RandomForest_Iris_v20250425_125653.pkl b/notebooks/RQ_notebooks/Trained_models/RandomForest_Iris_v20250425_125653.pkl\\nnew file mode 100644\\nindex 0000000..9bcac96\\nBinary files /dev/null and b/notebooks/RQ_notebooks/Trained_models/RandomForest_Iris_v20250425_125653.pkl differ\\ndiff --git a/notebooks/RQ_notebooks/Trained_models/RandomForest_Iris_v20250425_131407.pkl b/notebooks/RQ_notebooks/Trained_models/RandomForest_Iris_v20250425_131407.pkl\\nnew file mode 100644\\nindex 0000000..648e779\\nBinary files /dev/null and b/notebooks/RQ_notebooks/Trained_models/RandomForest_Iris_v20250425_131407.pkl differ\\ndiff --git a/notebooks/RQ_notebooks/Trained_models/RandomForest_Iris_v20250425_132526.pkl b/notebooks/RQ_notebooks/Trained_models/RandomForest_Iris_v20250425_132526.pkl\\nnew file mode 100644\\nindex 0000000..c675f79\\nBinary files /dev/null and b/notebooks/RQ_notebooks/Trained_models/RandomForest_Iris_v20250425_132526.pkl differ\\ndiff --git a/notebooks/RQ_notebooks/Trained_models/RandomForest_Iris_v20250425_135553.pkl b/notebooks/RQ_notebooks/Trained_models/RandomForest_Iris_v20250425_135553.pkl\\nnew file mode 100644\\nindex 0000000..b4be913\\nBinary files /dev/null and b/notebooks/RQ_notebooks/Trained_models/RandomForest_Iris_v20250425_135553.pkl differ\\ndiff --git a/notebooks/RQ_notebooks/all_runs_provenance.csv b/notebooks/RQ_notebooks/all_runs_provenance.csv\\ndeleted file mode 100644\\nindex 2784e45..0000000\\n--- a/notebooks/RQ_notebooks/all_runs_provenance.csv\\n+++ /dev/null\\n@@ -1,6 +0,0 @@\\n-run_id,run_name,experiment_id,start_time,end_time,n_artifacts,params__bootstrap,params__ccp_alpha,params__class_weight,params__columns_raw,params__criterion,params__database.description,params__database.id,params__database.name,params__database.owner,params__dataset.authors,params__dataset.doi,params__dataset.published,params__dataset.publisher,params__dataset.title,params__dropped_columns,params__feature_names,params__matplotlib_version,params__max_depth,params__max_features,params__max_leaf_nodes,params__max_samples,params__min_impurity_decrease,params__min_samples_leaf,params__min_samples_split,params__min_weight_fraction_leaf,params__numpy_version,params__n_estimators,params__n_features,params__n_features_final,params__n_jobs,params__n_records,params__n_test_samples,params__n_train_samples,params__oob_score,params__os_platform,params__pandas_version,params__python_version,params__random_state,params__retrieval_time,params__seaborn_version,params__shap_version,params__sklearn_version,params__test_size,params__verbose,params__warm_start,metrics__accuracy,metrics__accuracy_score_X_test,metrics__dbrepo.num_deletes,metrics__dbrepo.num_inserts,metrics__dbrepo.row_count_end,metrics__dbrepo.row_count_start,metrics__f1_macro,metrics__f1_score_X_test,metrics__precision_macro,metrics__precision_score_X_test,metrics__recall_macro,metrics__recall_score_X_test,metrics__roc_auc,metrics__roc_auc_score_X_test,metrics__training_accuracy_score,metrics__training_f1_score,metrics__training_log_loss,metrics__training_precision_score,metrics__training_recall_score,metrics__training_roc_auc,metrics__training_score,tags__dataset_id,tags__dataset_name,tags__dataset_version,tags__data_source,tags__dbrepo.admin_email,tags__dbrepo.base_url,tags__dbrepo.granularity,tags__dbrepo.protocol_version,tags__dbrepo.repository_name,tags__dbrepo.table_last_modified,tags__estimator_class,tags__estimator_name,tags__git_current_commit_hash,tags__git_previous_commit_hash,tags__git__current_commit_url,tags__mlflow.log-model.history,tags__mlflow.runName,tags__mlflow.source.name,tags__mlflow.source.type,tags__mlflow.user,tags__model_name,tags__notebook_name,tags__target_name,tags__training_end_time,tags__training_start_time\\n-361daa12f99f4129a06cd20b78dd6fa7,flawless-kit-371,615223710259862608,2025-04-23 21:04:21.262000+00:00,,23,True,0.0,None,\\\"['id', 'sepallengthcm', 'sepalwidthcm', 'petallengthcm', 'petalwidthcm', 'species']\\\",entropy,None,c3a42d17-42b7-43c9-a504-2363fb4c9c8d,Iris,reema,\\\"[\\\"\\\"Marshall Michael\\\"\\\"]\\\",10.5281/ZENODO.1404173,2018-8-27,Zenodo,Scikit-Learn Iris,[],\\\"['sepallengthcm', 'sepalwidthcm', 'petallengthcm', 'petalwidthcm']\\\",3.7.2,12,sqrt,None,None,0.0,2,5,0.0,1.24.4,200,4,4,-1,150,30,120,False,Windows 10,2.2.3,3.11.5,42,2025-04-23T21:04:22.410093,0.12.2,0.47.1,1.3.0,0.2,1,False,1.0,1.0,0.0,1.0,150.0,150.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9666666666666667,0.9666666666666667,0.0653522301195834,0.9674588284344383,0.9666666666666667,0.9987492182614135,0.9666666666666667,iris_local,Iris,1.0.0,http://localhost/api/database/c3a42d17-42b7-43c9-a504-2363fb4c9c8d/table/5315e7da-64fb-4fdb-b493-95b4138c765f/data?size=100000&page=0,noreply@localhost,http://localhost,YYYY-MM-DDThh:mm:ssZ,2.0,Database Repository,2025-04-23T20:42:29.501Z,sklearn.ensemble._forest.RandomForestClassifier,RandomForestClassifier,d329c92495e196ec0f39fbb19dfdd367131a77d9,a07434af4f547af2daab044d6873eb7081162293,https://github.com/reema-dass26/REPO/commit/d329c92495e196ec0f39fbb19dfdd367131a77d9,\\\"[{\\\"\\\"run_id\\\"\\\": \\\"\\\"361daa12f99f4129a06cd20b78dd6fa7\\\"\\\", \\\"\\\"artifact_path\\\"\\\": \\\"\\\"model\\\"\\\", \\\"\\\"utc_time_created\\\"\\\": \\\"\\\"2025-04-23 21:04:23.264719\\\"\\\", \\\"\\\"model_uuid\\\"\\\": \\\"\\\"5788ebda55b2492fb25d01738dae4022\\\"\\\", \\\"\\\"flavors\\\"\\\": {\\\"\\\"python_function\\\"\\\": {\\\"\\\"model_path\\\"\\\": \\\"\\\"model.pkl\\\"\\\", \\\"\\\"predict_fn\\\"\\\": \\\"\\\"predict\\\"\\\", \\\"\\\"loader_module\\\"\\\": \\\"\\\"mlflow.sklearn\\\"\\\", \\\"\\\"python_version\\\"\\\": \\\"\\\"3.11.5\\\"\\\", \\\"\\\"env\\\"\\\": {\\\"\\\"conda\\\"\\\": \\\"\\\"conda.yaml\\\"\\\", \\\"\\\"virtualenv\\\"\\\": \\\"\\\"python_env.yaml\\\"\\\"}}, \\\"\\\"sklearn\\\"\\\": {\\\"\\\"pickled_model\\\"\\\": \\\"\\\"model.pkl\\\"\\\", \\\"\\\"sklearn_version\\\"\\\": \\\"\\\"1.3.0\\\"\\\", \\\"\\\"serialization_format\\\"\\\": \\\"\\\"cloudpickle\\\"\\\", \\\"\\\"code\\\"\\\": null}}}]\\\",flawless-kit-371,C:\\\\Users\\\\reema\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\site-packages\\\\ipykernel_launcher.py,LOCAL,reema,RandomForest_Iris_v20250423_230422,RQ1.ipynb,\\\"[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n- 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\\n- 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\\n- 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\\n- 2 2]\\\",2025-04-23T23:04:30.472556,2025-04-23T23:04:22.449390\\ndiff --git a/notebooks/RQ_notebooks/config.toml b/notebooks/RQ_notebooks/config.toml\\ndeleted file mode 100644\\nindex e1ec245..0000000\\n--- a/notebooks/RQ_notebooks/config.toml\\n+++ /dev/null\\n@@ -1,7 +0,0 @@\\n-[theme]\\n-base = \\\"dark\\\"\\n-primaryColor = \\\"#00d4ff\\\"\\n-backgroundColor = \\\"#0e1117\\\"\\n-secondaryBackgroundColor = \\\"#262730\\\"\\n-textColor = \\\"#fafafa\\\"\\n-font = \\\"monospace\\\"\\ndiff --git a/notebooks/RQ_notebooks/infra_flow.html b/notebooks/RQ_notebooks/infra_flow.html\\ndeleted file mode 100644\\nindex 0fe8f57..0000000\\n--- a/notebooks/RQ_notebooks/infra_flow.html\\n+++ /dev/null\\n@@ -1,127 +0,0 @@\\n-<html>\\n-    <head>\\n-        <meta charset=\\\"utf-8\\\">\\n-        \\n-            <script src=\\\"lib/bindings/utils.js\\\"></script>\\n-            <link rel=\\\"stylesheet\\\" href=\\\"https://cdnjs.cloudflare.com/ajax/libs/vis-network/9.1.2/dist/dist/vis-network.min.css\\\" integrity=\\\"sha512-WgxfT5LWjfszlPHXRmBWHkV2eceiWTOBvrKCNbdgDYTHrT2AeLCGbF4sZlZw3UMN3WtL0tGUoIAKsu8mllg/XA==\\\" crossorigin=\\\"anonymous\\\" referrerpolicy=\\\"no-referrer\\\" />\\n-            <script src=\\\"https://cdnjs.cloudflare.com/ajax/libs/vis-network/9.1.2/dist/vis-network.min.js\\\" integrity=\\\"sha512-LnvoEWDFrqGHlHmDD2101OrLcbsfkrzoSpvtSQtxK3RMnRV0eOkhhBN2dXHKRrUU8p2DGRTk35n4O8nWSVe1mQ==\\\" crossorigin=\\\"anonymous\\\" referrerpolicy=\\\"no-referrer\\\"></script>\\n-            \\n-        \\n-<center>\\n-<h1></h1>\\n-</center>\\n-\\n-<!-- <link rel=\\\"stylesheet\\\" href=\\\"../node_modules/vis/dist/vis.min.css\\\" type=\\\"text/css\\\" />\\n-<script type=\\\"text/javascript\\\" src=\\\"../node_modules/vis/dist/vis.js\\\"> </script>-->\\n-        <link\\n-          href=\\\"https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta3/dist/css/bootstrap.min.css\\\"\\n-          rel=\\\"stylesheet\\\"\\n-          integrity=\\\"sha384-eOJMYsd53ii+scO/bJGFsiCZc+5NDVN2yr8+0RDqr0Ql0h+rP48ckxlpbzKgwra6\\\"\\n-          crossorigin=\\\"anonymous\\\"\\n-        />\\n-        <script\\n-          src=\\\"https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta3/dist/js/bootstrap.bundle.min.js\\\"\\n-          integrity=\\\"sha384-JEW9xMcG8R+pH31jmWH6WWP0WintQrMb4s7ZOdauHnUtxwoG2vI5DkLtS3qm9Ekf\\\"\\n-          crossorigin=\\\"anonymous\\\"\\n-        ></script>\\n-\\n-\\n-        <center>\\n-          <h1></h1>\\n-        </center>\\n-        <style type=\\\"text/css\\\">\\n-\\n-             #mynetwork {\\n-                 width: 100%;\\n-                 height: 500px;\\n-                 background-color: #ffffff;\\n-                 border: 1px solid lightgray;\\n-                 position: relative;\\n-                 float: left;\\n-             }\\n-\\n-             \\n-\\n-             \\n-\\n-             \\n-        </style>\\n-    </head>\\n-\\n-\\n-    <body>\\n-        <div class=\\\"card\\\" style=\\\"width: 100%\\\">\\n-            \\n-            \\n-            <div id=\\\"mynetwork\\\" class=\\\"card-body\\\"></div>\\n-        </div>\\n-\\n-        \\n-        \\n-\\n-        <script type=\\\"text/javascript\\\">\\n-\\n-              // initialize global variables.\\n-              var edges;\\n-              var nodes;\\n-              var allNodes;\\n-              var allEdges;\\n-              var nodeColors;\\n-              var originalNodes;\\n-              var network;\\n-              var container;\\n-              var options, data;\\n-              var filter = {\\n-                  item : '',\\n-                  property : '',\\n-                  value : []\\n-              };\\n-\\n-              \\n-\\n-              \\n-\\n-              // This method is responsible for drawing the graph, returns the drawn network\\n-              function drawGraph() {\\n-                  var container = document.getElementById('mynetwork');\\n-\\n-                  \\n-\\n-                  // parsing and collecting nodes and edges from the python\\n-                  nodes = new vis.DataSet([{\\\"color\\\": \\\"#97c2fc\\\", \\\"id\\\": \\\"DBRepo (Structured Repository)\\\", \\\"label\\\": \\\"DBRepo (Structured Repository)\\\", \\\"shape\\\": \\\"dot\\\", \\\"size\\\": 10}, {\\\"color\\\": \\\"#97c2fc\\\", \\\"id\\\": \\\"Virtual Research Environment (VRE)\\\", \\\"label\\\": \\\"Virtual Research Environment (VRE)\\\", \\\"shape\\\": \\\"dot\\\", \\\"size\\\": 10}, {\\\"color\\\": \\\"#97c2fc\\\", \\\"id\\\": \\\"Invenio (Unstructured Repository)\\\", \\\"label\\\": \\\"Invenio (Unstructured Repository)\\\", \\\"shape\\\": \\\"dot\\\", \\\"size\\\": 10}, {\\\"color\\\": \\\"#97c2fc\\\", \\\"id\\\": \\\"JupyterHub (Computational Layer)\\\", \\\"label\\\": \\\"JupyterHub (Computational Layer)\\\", \\\"shape\\\": \\\"dot\\\", \\\"size\\\": 10}, {\\\"color\\\": \\\"#97c2fc\\\", \\\"id\\\": \\\"GitHub (Version Control)\\\", \\\"label\\\": \\\"GitHub (Version Control)\\\", \\\"shape\\\": \\\"dot\\\", \\\"size\\\": 10}, {\\\"color\\\": \\\"#97c2fc\\\", \\\"id\\\": \\\"Interactive Visualization\\\", \\\"label\\\": \\\"Interactive Visualization\\\", \\\"shape\\\": \\\"dot\\\", \\\"size\\\": 10}, {\\\"color\\\": \\\"#97c2fc\\\", \\\"id\\\": \\\"Metadata Extraction\\\", \\\"label\\\": \\\"Metadata Extraction\\\", \\\"shape\\\": \\\"dot\\\", \\\"size\\\": 10}, {\\\"color\\\": \\\"#97c2fc\\\", \\\"id\\\": \\\"Provenance JSON\\\", \\\"label\\\": \\\"Provenance JSON\\\", \\\"shape\\\": \\\"dot\\\", \\\"size\\\": 10}]);\\n-                  edges = new vis.DataSet([{\\\"arrows\\\": \\\"to\\\", \\\"from\\\": \\\"DBRepo (Structured Repository)\\\", \\\"to\\\": \\\"Virtual Research Environment (VRE)\\\", \\\"width\\\": 1}, {\\\"arrows\\\": \\\"to\\\", \\\"from\\\": \\\"Invenio (Unstructured Repository)\\\", \\\"to\\\": \\\"Virtual Research Environment (VRE)\\\", \\\"width\\\": 1}, {\\\"arrows\\\": \\\"to\\\", \\\"from\\\": \\\"JupyterHub (Computational Layer)\\\", \\\"to\\\": \\\"Virtual Research Environment (VRE)\\\", \\\"width\\\": 1}, {\\\"arrows\\\": \\\"to\\\", \\\"from\\\": \\\"GitHub (Version Control)\\\", \\\"to\\\": \\\"Virtual Research Environment (VRE)\\\", \\\"width\\\": 1}, {\\\"arrows\\\": \\\"to\\\", \\\"from\\\": \\\"Virtual Research Environment (VRE)\\\", \\\"to\\\": \\\"Interactive Visualization\\\", \\\"width\\\": 1}, {\\\"arrows\\\": \\\"to\\\", \\\"from\\\": \\\"Metadata Extraction\\\", \\\"to\\\": \\\"Provenance JSON\\\", \\\"width\\\": 1}, {\\\"arrows\\\": \\\"to\\\", \\\"from\\\": \\\"Provenance JSON\\\", \\\"to\\\": \\\"Interactive Visualization\\\", \\\"width\\\": 1}]);\\n-\\n-                  nodeColors = {};\\n-                  allNodes = nodes.get({ returnType: \\\"Object\\\" });\\n-                  for (nodeId in allNodes) {\\n-                    nodeColors[nodeId] = allNodes[nodeId].color;\\n-                  }\\n-                  allEdges = edges.get({ returnType: \\\"Object\\\" });\\n-                  // adding nodes and edges to the graph\\n-                  data = {nodes: nodes, edges: edges};\\n-\\n-                  var options = {\\\"nodes\\\": {\\\"font\\\": {\\\"size\\\": 14}, \\\"shape\\\": \\\"box\\\", \\\"color\\\": {\\\"background\\\": \\\"#add8e6\\\"}}, \\\"edges\\\": {\\\"arrows\\\": {\\\"to\\\": {\\\"enabled\\\": true}}, \\\"smooth\\\": {\\\"type\\\": \\\"cubicBezier\\\"}}, \\\"physics\\\": {\\\"enabled\\\": true, \\\"barnesHut\\\": {\\\"gravitationalConstant\\\": -20000}}};\\n-\\n-                  \\n-\\n-\\n-                  \\n-\\n-                  network = new vis.Network(container, data, options);\\n-\\n-                  \\n-\\n-                  \\n-\\n-                  \\n-\\n-\\n-                  \\n-\\n-                  return network;\\n-\\n-              }\\n-              drawGraph();\\n-        </script>\\n-    </body>\\n-</html>\\n\\\\ No newline at end of file\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120045/confusion_matrix.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120045/confusion_matrix.png\\nnew file mode 100644\\nindex 0000000..5bf98dd\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120045/confusion_matrix.png differ\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120045/feature_importances.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120045/feature_importances.png\\nnew file mode 100644\\nindex 0000000..65481a2\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120045/feature_importances.png differ\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120045/pr_curve_cls_0.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120045/pr_curve_cls_0.png\\nnew file mode 100644\\nindex 0000000..a8d230a\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120045/pr_curve_cls_0.png differ\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120045/pr_curve_cls_1.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120045/pr_curve_cls_1.png\\nnew file mode 100644\\nindex 0000000..b36796e\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120045/pr_curve_cls_1.png differ\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120045/pr_curve_cls_2.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120045/pr_curve_cls_2.png\\nnew file mode 100644\\nindex 0000000..86bc90f\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120045/pr_curve_cls_2.png differ\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120045/roc_curve_cls_0.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120045/roc_curve_cls_0.png\\nnew file mode 100644\\nindex 0000000..5ae6a09\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120045/roc_curve_cls_0.png differ\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120045/roc_curve_cls_1.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120045/roc_curve_cls_1.png\\nnew file mode 100644\\nindex 0000000..7d3f039\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120045/roc_curve_cls_1.png differ\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120045/roc_curve_cls_2.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120045/roc_curve_cls_2.png\\nnew file mode 100644\\nindex 0000000..24b4468\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120045/roc_curve_cls_2.png differ\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120045/shap_summary.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120045/shap_summary.png\\nnew file mode 100644\\nindex 0000000..d6c6ef0\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120045/shap_summary.png differ\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120852/confusion_matrix.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120852/confusion_matrix.png\\nnew file mode 100644\\nindex 0000000..5bf98dd\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120852/confusion_matrix.png differ\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120852/feature_importances.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120852/feature_importances.png\\nnew file mode 100644\\nindex 0000000..65481a2\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120852/feature_importances.png differ\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120852/pr_curve_cls_0.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120852/pr_curve_cls_0.png\\nnew file mode 100644\\nindex 0000000..a8d230a\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120852/pr_curve_cls_0.png differ\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120852/pr_curve_cls_1.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120852/pr_curve_cls_1.png\\nnew file mode 100644\\nindex 0000000..b36796e\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120852/pr_curve_cls_1.png differ\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120852/pr_curve_cls_2.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120852/pr_curve_cls_2.png\\nnew file mode 100644\\nindex 0000000..86bc90f\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120852/pr_curve_cls_2.png differ\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120852/roc_curve_cls_0.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120852/roc_curve_cls_0.png\\nnew file mode 100644\\nindex 0000000..5ae6a09\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120852/roc_curve_cls_0.png differ\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120852/roc_curve_cls_1.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120852/roc_curve_cls_1.png\\nnew file mode 100644\\nindex 0000000..7d3f039\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120852/roc_curve_cls_1.png differ\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120852/roc_curve_cls_2.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120852/roc_curve_cls_2.png\\nnew file mode 100644\\nindex 0000000..24b4468\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120852/roc_curve_cls_2.png differ\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120852/shap_summary.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120852/shap_summary.png\\nnew file mode 100644\\nindex 0000000..294954e\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120852/shap_summary.png differ\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_121328/confusion_matrix.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_121328/confusion_matrix.png\\nnew file mode 100644\\nindex 0000000..5bf98dd\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_121328/confusion_matrix.png differ\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_121328/feature_importances.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_121328/feature_importances.png\\nnew file mode 100644\\nindex 0000000..65481a2\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_121328/feature_importances.png differ\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_121328/pr_curve_cls_0.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_121328/pr_curve_cls_0.png\\nnew file mode 100644\\nindex 0000000..a8d230a\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_121328/pr_curve_cls_0.png differ\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_121328/pr_curve_cls_1.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_121328/pr_curve_cls_1.png\\nnew file mode 100644\\nindex 0000000..b36796e\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_121328/pr_curve_cls_1.png differ\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_121328/pr_curve_cls_2.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_121328/pr_curve_cls_2.png\\nnew file mode 100644\\nindex 0000000..86bc90f\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_121328/pr_curve_cls_2.png differ\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_121328/roc_curve_cls_0.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_121328/roc_curve_cls_0.png\\nnew file mode 100644\\nindex 0000000..5ae6a09\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_121328/roc_curve_cls_0.png differ\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_121328/roc_curve_cls_1.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_121328/roc_curve_cls_1.png\\nnew file mode 100644\\nindex 0000000..7d3f039\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_121328/roc_curve_cls_1.png differ\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_121328/roc_curve_cls_2.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_121328/roc_curve_cls_2.png\\nnew file mode 100644\\nindex 0000000..24b4468\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_121328/roc_curve_cls_2.png differ\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_121328/shap_summary.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_121328/shap_summary.png\\nnew file mode 100644\\nindex 0000000..8cdf7ae\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_121328/shap_summary.png differ\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_125653/confusion_matrix.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_125653/confusion_matrix.png\\nnew file mode 100644\\nindex 0000000..5bf98dd\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_125653/confusion_matrix.png differ\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_125653/feature_importances.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_125653/feature_importances.png\\nnew file mode 100644\\nindex 0000000..65481a2\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_125653/feature_importances.png differ\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_125653/pr_curve_cls_0.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_125653/pr_curve_cls_0.png\\nnew file mode 100644\\nindex 0000000..a8d230a\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_125653/pr_curve_cls_0.png differ\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_125653/pr_curve_cls_1.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_125653/pr_curve_cls_1.png\\nnew file mode 100644\\nindex 0000000..b36796e\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_125653/pr_curve_cls_1.png differ\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_125653/pr_curve_cls_2.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_125653/pr_curve_cls_2.png\\nnew file mode 100644\\nindex 0000000..86bc90f\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_125653/pr_curve_cls_2.png differ\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_125653/roc_curve_cls_0.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_125653/roc_curve_cls_0.png\\nnew file mode 100644\\nindex 0000000..5ae6a09\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_125653/roc_curve_cls_0.png differ\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_125653/roc_curve_cls_1.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_125653/roc_curve_cls_1.png\\nnew file mode 100644\\nindex 0000000..7d3f039\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_125653/roc_curve_cls_1.png differ\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_125653/roc_curve_cls_2.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_125653/roc_curve_cls_2.png\\nnew file mode 100644\\nindex 0000000..24b4468\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_125653/roc_curve_cls_2.png differ\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_125653/shap_summary.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_125653/shap_summary.png\\nnew file mode 100644\\nindex 0000000..86ac865\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_125653/shap_summary.png differ\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_131407/confusion_matrix.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_131407/confusion_matrix.png\\nnew file mode 100644\\nindex 0000000..5bf98dd\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_131407/confusion_matrix.png differ\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_131407/feature_importances.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_131407/feature_importances.png\\nnew file mode 100644\\nindex 0000000..65481a2\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_131407/feature_importances.png differ\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_131407/pr_curve_cls_0.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_131407/pr_curve_cls_0.png\\nnew file mode 100644\\nindex 0000000..a8d230a\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_131407/pr_curve_cls_0.png differ\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_131407/pr_curve_cls_1.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_131407/pr_curve_cls_1.png\\nnew file mode 100644\\nindex 0000000..b36796e\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_131407/pr_curve_cls_1.png differ\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_131407/pr_curve_cls_2.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_131407/pr_curve_cls_2.png\\nnew file mode 100644\\nindex 0000000..86bc90f\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_131407/pr_curve_cls_2.png differ\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_131407/roc_curve_cls_0.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_131407/roc_curve_cls_0.png\\nnew file mode 100644\\nindex 0000000..5ae6a09\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_131407/roc_curve_cls_0.png differ\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_131407/roc_curve_cls_1.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_131407/roc_curve_cls_1.png\\nnew file mode 100644\\nindex 0000000..7d3f039\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_131407/roc_curve_cls_1.png differ\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_131407/roc_curve_cls_2.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_131407/roc_curve_cls_2.png\\nnew file mode 100644\\nindex 0000000..24b4468\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_131407/roc_curve_cls_2.png differ\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_131407/shap_summary.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_131407/shap_summary.png\\nnew file mode 100644\\nindex 0000000..4ed1b76\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_131407/shap_summary.png differ\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_132526/confusion_matrix.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_132526/confusion_matrix.png\\nnew file mode 100644\\nindex 0000000..5bf98dd\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_132526/confusion_matrix.png differ\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_132526/feature_importances.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_132526/feature_importances.png\\nnew file mode 100644\\nindex 0000000..65481a2\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_132526/feature_importances.png differ\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_132526/pr_curve_cls_0.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_132526/pr_curve_cls_0.png\\nnew file mode 100644\\nindex 0000000..a8d230a\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_132526/pr_curve_cls_0.png differ\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_132526/pr_curve_cls_1.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_132526/pr_curve_cls_1.png\\nnew file mode 100644\\nindex 0000000..b36796e\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_132526/pr_curve_cls_1.png differ\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_132526/pr_curve_cls_2.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_132526/pr_curve_cls_2.png\\nnew file mode 100644\\nindex 0000000..86bc90f\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_132526/pr_curve_cls_2.png differ\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_132526/roc_curve_cls_0.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_132526/roc_curve_cls_0.png\\nnew file mode 100644\\nindex 0000000..5ae6a09\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_132526/roc_curve_cls_0.png differ\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_132526/roc_curve_cls_1.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_132526/roc_curve_cls_1.png\\nnew file mode 100644\\nindex 0000000..7d3f039\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_132526/roc_curve_cls_1.png differ\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_132526/roc_curve_cls_2.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_132526/roc_curve_cls_2.png\\nnew file mode 100644\\nindex 0000000..24b4468\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_132526/roc_curve_cls_2.png differ\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_132526/shap_summary.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_132526/shap_summary.png\\nnew file mode 100644\\nindex 0000000..86c9184\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_132526/shap_summary.png differ\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_135553/confusion_matrix.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_135553/confusion_matrix.png\\nnew file mode 100644\\nindex 0000000..5bf98dd\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_135553/confusion_matrix.png differ\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_135553/feature_importances.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_135553/feature_importances.png\\nnew file mode 100644\\nindex 0000000..65481a2\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_135553/feature_importances.png differ\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_135553/pr_curve_cls_0.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_135553/pr_curve_cls_0.png\\nnew file mode 100644\\nindex 0000000..a8d230a\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_135553/pr_curve_cls_0.png differ\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_135553/pr_curve_cls_1.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_135553/pr_curve_cls_1.png\\nnew file mode 100644\\nindex 0000000..b36796e\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_135553/pr_curve_cls_1.png differ\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_135553/pr_curve_cls_2.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_135553/pr_curve_cls_2.png\\nnew file mode 100644\\nindex 0000000..86bc90f\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_135553/pr_curve_cls_2.png differ\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_135553/roc_curve_cls_0.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_135553/roc_curve_cls_0.png\\nnew file mode 100644\\nindex 0000000..5ae6a09\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_135553/roc_curve_cls_0.png differ\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_135553/roc_curve_cls_1.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_135553/roc_curve_cls_1.png\\nnew file mode 100644\\nindex 0000000..7d3f039\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_135553/roc_curve_cls_1.png differ\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_135553/roc_curve_cls_2.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_135553/roc_curve_cls_2.png\\nnew file mode 100644\\nindex 0000000..24b4468\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_135553/roc_curve_cls_2.png differ\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_135553/shap_summary.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_135553/shap_summary.png\\nnew file mode 100644\\nindex 0000000..09ae3c3\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_135553/shap_summary.png differ\\ndiff --git a/notebooks/RQ_notebooks/ref_for creating venv.ipynb b/notebooks/RQ_notebooks/ref_for creating venv.ipynb\\ndeleted file mode 100644\\nindex b6923ef..0000000\\n--- a/notebooks/RQ_notebooks/ref_for creating venv.ipynb\\t\\n+++ /dev/null\\n@@ -1,74 +0,0 @@\\n-{\\n- \\\"cells\\\": [\\n-  {\\n-   \\\"cell_type\\\": \\\"code\\\",\\n-   \\\"execution_count\\\": 4,\\n-   \\\"id\\\": \\\"02474ffc-32c9-44fa-8317-46211ed44b6d\\\",\\n-   \\\"metadata\\\": {},\\n-   \\\"outputs\\\": [\\n-    {\\n-     \\\"name\\\": \\\"stdout\\\",\\n-     \\\"output_type\\\": \\\"stream\\\",\\n-     \\\"text\\\": [\\n-      \\\"Conda environment created successfully.\\\\n\\\",\\n-      \\\"ipykernel installed successfully.\\\\n\\\",\\n-      \\\"Kernel added to Jupyter successfully.\\\\n\\\"\\n-     ]\\n-    }\\n-   ],\\n-   \\\"source\\\": [\\n-    \\\"# import subprocess\\\\n\\\",\\n-    \\\"# import sys\\\\n\\\",\\n-    \\\"# import os\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# # Step 1: Create the conda environment\\\\n\\\",\\n-    \\\"# def create_conda_env():\\\\n\\\",\\n-    \\\"#     try:\\\\n\\\",\\n-    \\\"#         subprocess.check_call([sys.executable, \\\\\\\"-m\\\\\\\", \\\\\\\"conda\\\\\\\", \\\\\\\"create\\\\\\\", \\\\\\\"-n\\\\\\\", \\\\\\\"thesis-env\\\\\\\", \\\\\\\"python=3.10\\\\\\\", \\\\\\\"-y\\\\\\\"])\\\\n\\\",\\n-    \\\"#         print(\\\\\\\"Conda environment created successfully.\\\\\\\")\\\\n\\\",\\n-    \\\"#     except subprocess.CalledProcessError as e:\\\\n\\\",\\n-    \\\"#         print(f\\\\\\\"Error creating conda environment: {e}\\\\\\\")\\\\n\\\",\\n-    \\\"#         raise\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# # Step 2: Install ipykernel and add the conda environment to Jupyter\\\\n\\\",\\n-    \\\"# def install_ipykernel_and_add_to_jupyter():\\\\n\\\",\\n-    \\\"#     try:\\\\n\\\",\\n-    \\\"#         # Activate the conda environment using subprocess and install ipykernel\\\\n\\\",\\n-    \\\"#         subprocess.check_call([sys.executable, \\\\\\\"-m\\\\\\\", \\\\\\\"conda\\\\\\\", \\\\\\\"run\\\\\\\", \\\\\\\"-n\\\\\\\", \\\\\\\"thesis-env\\\\\\\", \\\\\\\"pip\\\\\\\", \\\\\\\"install\\\\\\\", \\\\\\\"ipykernel\\\\\\\"])\\\\n\\\",\\n-    \\\"#         print(\\\\\\\"ipykernel installed successfully.\\\\\\\")\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"#         # Add the conda environment to Jupyter as a new kernel\\\\n\\\",\\n-    \\\"#         subprocess.check_call([sys.executable, \\\\\\\"-m\\\\\\\", \\\\\\\"conda\\\\\\\", \\\\\\\"run\\\\\\\", \\\\\\\"-n\\\\\\\", \\\\\\\"thesis-env\\\\\\\", \\\\\\\"python\\\\\\\", \\\\\\\"-m\\\\\\\", \\\\\\\"ipykernel\\\\\\\", \\\\\\\"install\\\\\\\", \\\\\\\"--user\\\\\\\", \\\\\\\"--name=thesis-env\\\\\\\", \\\\\\\"--display-name=Python (thesis-env)\\\\\\\"])\\\\n\\\",\\n-    \\\"#         print(\\\\\\\"Kernel added to Jupyter successfully.\\\\\\\")\\\\n\\\",\\n-    \\\"#     except subprocess.CalledProcessError as e:\\\\n\\\",\\n-    \\\"#         print(f\\\\\\\"Error installing ipykernel or adding kernel to Jupyter: {e}\\\\\\\")\\\\n\\\",\\n-    \\\"#         raise\\\\n\\\",\\n-    \\\"\\\\n\\\",\\n-    \\\"# # Run the functions to create the environment and add it to Jupyter\\\\n\\\",\\n-    \\\"# create_conda_env()\\\\n\\\",\\n-    \\\"# install_ipykernel_and_add_to_jupyter()\\\\n\\\"\\n-   ]\\n-  }\\n- ],\\n- \\\"metadata\\\": {\\n-  \\\"kernelspec\\\": {\\n-   \\\"display_name\\\": \\\"Python 3 (ipykernel)\\\",\\n-   \\\"language\\\": \\\"python\\\",\\n-   \\\"name\\\": \\\"python3\\\"\\n-  },\\n-  \\\"language_info\\\": {\\n-   \\\"codemirror_mode\\\": {\\n-    \\\"name\\\": \\\"ipython\\\",\\n-    \\\"version\\\": 3\\n-   },\\n-   \\\"file_extension\\\": \\\".py\\\",\\n-   \\\"mimetype\\\": \\\"text/x-python\\\",\\n-   \\\"name\\\": \\\"python\\\",\\n-   \\\"nbconvert_exporter\\\": \\\"python\\\",\\n-   \\\"pygments_lexer\\\": \\\"ipython3\\\",\\n-   \\\"version\\\": \\\"3.11.5\\\"\\n-  }\\n- },\\n- \\\"nbformat\\\": 4,\\n- \\\"nbformat_minor\\\": 5\\n-}\\ndiff --git a/notebooks/RQ_notebooks/vizualization.py b/notebooks/RQ_notebooks/vizualization.py\\nindex a858d33..898d7a0 100644\\n--- a/notebooks/RQ_notebooks/vizualization.py\\n+++ b/notebooks/RQ_notebooks/vizualization.py\\n@@ -19,7 +19,8 @@ import streamlit.components.v1 as components\\n import networkx as nx\\n from streamlit_agraph import agraph, Node, Edge, Config\\n import time\\n-\\n+from datetime import datetime\\n+import re\\n \\n st.set_page_config(\\n     page_title=\\\"Building Bridges in Research: Integrating Provenance and Data Management in Virtual Research Environments\\\",\\n@@ -213,7 +214,42 @@ USE_CASES = {\\n         'optional_params': [],\\n     },\\n }\\n-\\n+# \\u2014\\u2014 Find latest run summary with justification data \\u2014\\u2014\\n+\\n+def get_latest_justification_summary(base_dir=\\\"MODEL_PROVENANCE\\\"):\\n+    folders = [d for d in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, d))]\\n+    timestamped_folders = []\\n+    for folder in folders:\\n+        match = re.search(r'_(v\\\\d{8}_\\\\d{6})', folder)\\n+        if match:\\n+            try:\\n+                timestamp = datetime.strptime(match.group(1), \\\"v%Y%m%d_%H%M%S\\\")\\n+                timestamped_folders.append((timestamp, folder))\\n+            except ValueError:\\n+                continue\\n+\\n+    if not timestamped_folders:\\n+        raise FileNotFoundError(\\\"No timestamped folders found in MODEL_PROVENANCE\\\")\\n+\\n+    latest_folder = max(timestamped_folders)[1]\\n+    file_path = os.path.join(base_dir, latest_folder, f\\\"{latest_folder}_run_summary.json\\\")\\n+    return file_path\\n+\\n+# \\u2014\\u2014 Load justifications and return as DataFrame \\u2014\\u2014\\n+\\n+def load_justification_table(path):\\n+    with open(path, \\\"r\\\") as f:\\n+        js = json.load(f)\\n+\\n+    justifications = {\\n+        k: v for k, v in js.get(\\\"tags\\\", {}).items()\\n+        if k.startswith(\\\"justification_\\\")\\n+    }\\n+    rows = [\\n+        {\\\"Decision\\\": k.replace(\\\"justification_\\\", \\\"\\\"), \\\"Justification\\\": v}\\n+        for k, v in justifications.items()\\n+    ]\\n+    return pd.DataFrame(rows)\\n # -------- Load the metadata (flattened like before) ----------\\n @st.cache_data\\n def load_data():\\n@@ -278,10 +314,13 @@ with st.sidebar:\\n             \\\"\\ud83d\\udef0\\ufe0f Provenance Trace\\\",\\n             \\\"\\u26a0\\ufe0f Deprecated Code Check\\\",\\n             \\\"\\ud83e\\udded Model-Dataset Mapping\\\",\\n-            \\\"\\ud83d\\udce3 Notify Outdated Forks\\\"\\n+            \\\"\\ud83d\\udce3 Notify Outdated Forks\\\",\\n+            \\\"\\ud83d\\udcd8 Researcher Justifications\\\",\\n+            \\\"\\ud83d\\udcda Invenio Metadata\\\"\\n+\\n         ],\\n         icons=[\\n-            \\\"house\\\", \\\"database\\\", \\\"gear\\\", \\\"bar-chart\\\", \\\"globe\\\", \\\"link\\\", \\\"exclamation-triangle\\\",\\\"map\\\", \\\"megaphone\\\" \\n+            \\\"house\\\", \\\"database\\\", \\\"gear\\\", \\\"bar-chart\\\", \\\"globe\\\", \\\"link\\\", \\\"exclamation-triangle\\\",\\\"map\\\", \\\"megaphone\\\" , \\\"book\\\"\\n         ],\\n         menu_icon=\\\"cast\\\",\\n         default_index=0,\\n@@ -874,3 +913,61 @@ Detect whether collaborators' forks of your GitHub repository are out-of-date wi\\n \\n                 except Exception as e:\\n                     st.error(f\\\"An error occurred: {e}\\\")\\n+elif selected == \\\"\\ud83d\\udcd8 Researcher Justifications\\\":\\n+    st.title(\\\"\\ud83d\\udcd8 Researcher Justifications\\\")\\n+    st.markdown(\\\"\\\"\\\"\\n+    This section displays all recorded **justifications** provided by the researcher \\n+    for specific modeling decisions, such as hyperparameter choices, dataset version, and evaluation criteria.\\n+    \\n+    \\ud83e\\udde0 These justifications help ensure **transparency**, **explainability**, and support for reproducibility.\\n+    \\\"\\\"\\\")\\n+\\n+    try:\\n+        latest_path = get_latest_justification_summary()\\n+        st.success(f\\\"Loaded: `{latest_path}`\\\")\\n+\\n+        df_just = load_justification_table(latest_path)\\n+        st.write(\\\"### Justification Table\\\")\\n+        st.dataframe(df_just, use_container_width=True)\\n+    except Exception as e:\\n+        st.error(f\\\"Failed to load justification data: {e}\\\")\\n+elif selected == \\\"\\ud83d\\udcda Invenio Metadata\\\":\\n+    st.title(\\\"\\ud83d\\udcda Invenio Metadata\\\")\\n+    st.markdown(\\\"\\\"\\\"\\n+    View metadata fetched from publication repositories (e.g., Zenodo or DBRepo).\\n+    \\n+    \\ud83d\\udd0d This includes:\\n+    - Title, creators, publication date\\n+    - PID and status info\\n+    - Files and stats (views/downloads)\\n+    \\\"\\\"\\\")\\n+\\n+    # Get model name for the latest run\\n+    latest_dir = max(glob.glob(\\\"MODEL_PROVENANCE/*\\\"), key=os.path.getmtime)\\n+    model_name = os.path.basename(latest_dir)\\n+    summary_path = os.path.join(latest_dir, f\\\"{model_name}_run_summary.json\\\")\\n+\\n+    try:\\n+        with open(summary_path, \\\"r\\\") as f:\\n+            run_data = json.load(f)\\n+        invenio_meta = run_data.get(\\\"invenio_metadata\\\", {})\\n+\\n+        if invenio_meta:\\n+            df_view = pd.DataFrame([{\\n+                \\\"Title\\\": invenio_meta.get(\\\"title\\\", \\\"\\\"),\\n+                \\\"Creator\\\": invenio_meta.get(\\\"creator\\\", \\\"\\\"),\\n+                \\\"Published\\\": invenio_meta.get(\\\"publication_date\\\", \\\"\\\"),\\n+                \\\"Status\\\": invenio_meta.get(\\\"status\\\", \\\"\\\"),\\n+                \\\"Views\\\": invenio_meta.get(\\\"views\\\", 0),\\n+                \\\"Downloads\\\": invenio_meta.get(\\\"downloads\\\", 0)\\n+            }])\\n+            st.dataframe(df_view)\\n+\\n+            st.markdown(\\\"#### \\ud83d\\udcc1 Files in Publication\\\")\\n+            st.json(invenio_meta.get(\\\"files\\\", []))\\n+        else:\\n+            st.warning(\\\"\\u2139\\ufe0f No `invenio_metadata` found in the run summary.\\\")\\n+\\n+    except Exception as e:\\n+        st.error(f\\\"Error loading Invenio metadata: {e}\\\")\\n+\\n\"\n}"
        },
        {
            "path": "confusion_matrix.png",
            "type": "image",
            "uri": "file:///C:/Users/reema/REPO/notebooks/RQ_notebooks/mlrunlogs/mlflow.db/615223710259862608/3ec1102377b049589537b68a9494fbfc/artifacts/confusion_matrix.png"
        },
        {
            "path": "estimator.html",
            "type": "other",
            "uri": "file:///C:/Users/reema/REPO/notebooks/RQ_notebooks/mlrunlogs/mlflow.db/615223710259862608/3ec1102377b049589537b68a9494fbfc/artifacts/estimator.html"
        },
        {
            "path": "feature_importances.png",
            "type": "image",
            "uri": "file:///C:/Users/reema/REPO/notebooks/RQ_notebooks/mlrunlogs/mlflow.db/615223710259862608/3ec1102377b049589537b68a9494fbfc/artifacts/feature_importances.png"
        },
        {
            "path": "label_mapping.json",
            "type": "text",
            "content": "{\n  \"0\": \"Iris-setosa\",\n  \"1\": \"Iris-versicolor\",\n  \"2\": \"Iris-virginica\"\n}"
        },
        {
            "path": "metric_info.json",
            "type": "text",
            "content": "{\n  \"accuracy_score_X_test\": \"accuracy_score(y_true=y_test, y_pred=y_pred)\",\n  \"f1_score_X_test\": \"f1_score(y_true=y_test, y_pred=y_pred, average='macro')\",\n  \"precision_score_X_test\": \"precision_score(y_true=y_test, y_pred=y_pred, average='macro')\",\n  \"recall_score_X_test\": \"recall_score(y_true=y_test, y_pred=y_pred, average='macro')\",\n  \"roc_auc_score_X_test\": \"roc_auc_score(y_true=y_test, y_score=y_proba, multi_class='ovr')\"\n}"
        },
        {
            "path": "model/MLmodel",
            "type": "other",
            "uri": "file:///C:/Users/reema/REPO/notebooks/RQ_notebooks/mlrunlogs/mlflow.db/615223710259862608/3ec1102377b049589537b68a9494fbfc/artifacts/model/MLmodel"
        },
        {
            "path": "model/conda.yaml",
            "type": "other",
            "uri": "file:///C:/Users/reema/REPO/notebooks/RQ_notebooks/mlrunlogs/mlflow.db/615223710259862608/3ec1102377b049589537b68a9494fbfc/artifacts/model/conda.yaml"
        },
        {
            "path": "model/input_example.json",
            "type": "text",
            "content": "{\"columns\": [\"sepallengthcm\", \"sepalwidthcm\", \"petallengthcm\", \"petalwidthcm\"], \"data\": [[4.6, 3.6, 1.0, 0.2], [5.7, 4.4, 1.5, 0.4], [6.7, 3.1, 4.4, 1.4], [4.8, 3.4, 1.6, 0.2], [4.4, 3.2, 1.3, 0.2]]}"
        },
        {
            "path": "model/model.pkl",
            "type": "other",
            "uri": "file:///C:/Users/reema/REPO/notebooks/RQ_notebooks/mlrunlogs/mlflow.db/615223710259862608/3ec1102377b049589537b68a9494fbfc/artifacts/model/model.pkl"
        },
        {
            "path": "model/python_env.yaml",
            "type": "other",
            "uri": "file:///C:/Users/reema/REPO/notebooks/RQ_notebooks/mlrunlogs/mlflow.db/615223710259862608/3ec1102377b049589537b68a9494fbfc/artifacts/model/python_env.yaml"
        },
        {
            "path": "model/requirements.txt",
            "type": "text",
            "content": "mlflow==2.21.2\nbackports-functools-lru-cache==1.6.4\nbackports-tempfile==1.0\ncloudpickle==2.2.1\njaraco-classes==3.2.1\njaraco-collections==5.1.0\nlz4==4.3.2\nnumpy==1.24.4\npathlib==1.0.1\npsutil==5.9.5\nscikit-learn==1.3.0\nscipy==1.11.1"
        },
        {
            "path": "model/serving_input_example.json",
            "type": "text",
            "content": "{\n  \"dataframe_split\": {\n    \"columns\": [\n      \"sepallengthcm\",\n      \"sepalwidthcm\",\n      \"petallengthcm\",\n      \"petalwidthcm\"\n    ],\n    \"data\": [\n      [\n        4.6,\n        3.6,\n        1.0,\n        0.2\n      ],\n      [\n        5.7,\n        4.4,\n        1.5,\n        0.4\n      ],\n      [\n        6.7,\n        3.1,\n        4.4,\n        1.4\n      ],\n      [\n        4.8,\n        3.4,\n        1.6,\n        0.2\n      ],\n      [\n        4.4,\n        3.2,\n        1.3,\n        0.2\n      ]\n    ]\n  }\n}"
        },
        {
            "path": "pr_curve_cls_0.png",
            "type": "image",
            "uri": "file:///C:/Users/reema/REPO/notebooks/RQ_notebooks/mlrunlogs/mlflow.db/615223710259862608/3ec1102377b049589537b68a9494fbfc/artifacts/pr_curve_cls_0.png"
        },
        {
            "path": "pr_curve_cls_1.png",
            "type": "image",
            "uri": "file:///C:/Users/reema/REPO/notebooks/RQ_notebooks/mlrunlogs/mlflow.db/615223710259862608/3ec1102377b049589537b68a9494fbfc/artifacts/pr_curve_cls_1.png"
        },
        {
            "path": "pr_curve_cls_2.png",
            "type": "image",
            "uri": "file:///C:/Users/reema/REPO/notebooks/RQ_notebooks/mlrunlogs/mlflow.db/615223710259862608/3ec1102377b049589537b68a9494fbfc/artifacts/pr_curve_cls_2.png"
        },
        {
            "path": "public_datasetRepository_metadata.json",
            "type": "text",
            "content": "{\n  \"zenodo\": {\n    \"title\": \"Scikit-Learn Iris\",\n    \"doi\": \"10.5281/ZENODO.1404173\",\n    \"authors\": [\n      \"Marshall Michael\"\n    ],\n    \"published\": \"2018-8-27\",\n    \"publisher\": \"Zenodo\"\n  }\n}"
        },
        {
            "path": "roc_curve_cls_0.png",
            "type": "image",
            "uri": "file:///C:/Users/reema/REPO/notebooks/RQ_notebooks/mlrunlogs/mlflow.db/615223710259862608/3ec1102377b049589537b68a9494fbfc/artifacts/roc_curve_cls_0.png"
        },
        {
            "path": "roc_curve_cls_1.png",
            "type": "image",
            "uri": "file:///C:/Users/reema/REPO/notebooks/RQ_notebooks/mlrunlogs/mlflow.db/615223710259862608/3ec1102377b049589537b68a9494fbfc/artifacts/roc_curve_cls_1.png"
        },
        {
            "path": "roc_curve_cls_2.png",
            "type": "image",
            "uri": "file:///C:/Users/reema/REPO/notebooks/RQ_notebooks/mlrunlogs/mlflow.db/615223710259862608/3ec1102377b049589537b68a9494fbfc/artifacts/roc_curve_cls_2.png"
        },
        {
            "path": "shap_summary.png",
            "type": "image",
            "uri": "file:///C:/Users/reema/REPO/notebooks/RQ_notebooks/mlrunlogs/mlflow.db/615223710259862608/3ec1102377b049589537b68a9494fbfc/artifacts/shap_summary.png"
        },
        {
            "path": "training_confusion_matrix.png",
            "type": "image",
            "uri": "file:///C:/Users/reema/REPO/notebooks/RQ_notebooks/mlrunlogs/mlflow.db/615223710259862608/3ec1102377b049589537b68a9494fbfc/artifacts/training_confusion_matrix.png"
        }
    ],
    "invenio_metadata": {
        "id": "892h2-fq661",
        "title": "RandomForest Iris Model Artifacts",
        "creator": "Dass, Reema",
        "publication_date": "2025-04-24",
        "files": [
            {
                "key": "RandomForest_Iris_v20250423_230422.pkl",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250423_230422.pkl/content",
                "size": 282910,
                "mimetype": "application/octet-stream",
                "checksum": "md5:a9f9e15b9c808d94c8e5737089beaa7d",
                "metadata": {}
            },
            {
                "key": "RandomForest_Iris_v20250425_125653.pkl",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250425_125653.pkl/content",
                "size": 282910,
                "mimetype": "application/octet-stream",
                "checksum": "md5:503fdd8a19da9f48029eccc32d473a36",
                "metadata": {}
            },
            {
                "key": "RandomForest_Iris_v20250425_125653/shap_summary.png",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250425_125653/shap_summary.png/content",
                "size": 16924,
                "mimetype": "image/png",
                "checksum": "md5:c4e3880c2cb22888e1993b7a97175805",
                "metadata": {
                    "width": 1150,
                    "height": 660
                }
            },
            {
                "key": "RandomForest_Iris_v20250424_111946.pkl",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250424_111946.pkl/content",
                "size": 282910,
                "mimetype": "application/octet-stream",
                "checksum": "md5:5055123396a01237596e771a2621a82f",
                "metadata": {}
            },
            {
                "key": "RandomForest_Iris_v20250423_230422/confusion_matrix.png",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250423_230422/confusion_matrix.png/content",
                "size": 14453,
                "mimetype": "image/png",
                "checksum": "md5:41c356960df1b924d7db4d4a5cc9b254",
                "metadata": {
                    "width": 600,
                    "height": 600
                }
            },
            {
                "key": "RandomForest_Iris_v20250425_120852.pkl",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250425_120852.pkl/content",
                "size": 282910,
                "mimetype": "application/octet-stream",
                "checksum": "md5:214b9e28ebd664d48d52a269b61e7750",
                "metadata": {}
            },
            {
                "key": "RandomForest_Iris_v20250425_131407.pkl",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250425_131407.pkl/content",
                "size": 282910,
                "mimetype": "application/octet-stream",
                "checksum": "md5:4b6351b3c25f9bdef00df77469b7b75b",
                "metadata": {}
            },
            {
                "key": "RandomForest_Iris_v20250425_121328.pkl",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250425_121328.pkl/content",
                "size": 282910,
                "mimetype": "application/octet-stream",
                "checksum": "md5:60867f4e9ac5b2d61f5900c0c8b569ed",
                "metadata": {}
            },
            {
                "key": "RandomForest_Iris_v20250423_230422/pr_curve_cls_0.png",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250423_230422/pr_curve_cls_0.png/content",
                "size": 20358,
                "mimetype": "image/png",
                "checksum": "md5:30a6a3742bcbd69750bc5fd30aea58d2",
                "metadata": {
                    "width": 640,
                    "height": 480
                }
            },
            {
                "key": "RandomForest_Iris_v20250425_132526.pkl",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250425_132526.pkl/content",
                "size": 282910,
                "mimetype": "application/octet-stream",
                "checksum": "md5:b6a1c65f187364627feb3aeba7c67c5a",
                "metadata": {}
            },
            {
                "key": "RandomForest_Iris_v20250423_230422/feature_importances.png",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250423_230422/feature_importances.png/content",
                "size": 19167,
                "mimetype": "image/png",
                "checksum": "md5:1702afd2578c67988efdcf1f28fe1b04",
                "metadata": {
                    "width": 800,
                    "height": 600
                }
            },
            {
                "key": "RandomForest_Iris_v20250423_230422/pr_curve_cls_1.png",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250423_230422/pr_curve_cls_1.png/content",
                "size": 20226,
                "mimetype": "image/png",
                "checksum": "md5:7f396723afbfa90eb3d5f3e850f52c80",
                "metadata": {
                    "width": 640,
                    "height": 480
                }
            },
            {
                "key": "RandomForest_Iris_v20250423_230422/pr_curve_cls_2.png",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250423_230422/pr_curve_cls_2.png/content",
                "size": 19809,
                "mimetype": "image/png",
                "checksum": "md5:22a124dad652fd24fb3a5691abcae494",
                "metadata": {
                    "width": 640,
                    "height": 480
                }
            },
            {
                "key": "RandomForest_Iris_v20250423_230422/roc_curve_cls_1.png",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250423_230422/roc_curve_cls_1.png/content",
                "size": 20143,
                "mimetype": "image/png",
                "checksum": "md5:917e9847fda527b030c0bcad8f2a2ea3",
                "metadata": {
                    "width": 640,
                    "height": 480
                }
            },
            {
                "key": "RandomForest_Iris_v20250423_230422/roc_curve_cls_0.png",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250423_230422/roc_curve_cls_0.png/content",
                "size": 20100,
                "mimetype": "image/png",
                "checksum": "md5:f6d5e559a27d81fb010b416bddc2fb02",
                "metadata": {
                    "width": 640,
                    "height": 480
                }
            },
            {
                "key": "RandomForest_Iris_v20250423_230422/roc_curve_cls_2.png",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250423_230422/roc_curve_cls_2.png/content",
                "size": 20227,
                "mimetype": "image/png",
                "checksum": "md5:c076643c49b9ae7ba3cf0794b18f74db",
                "metadata": {
                    "width": 640,
                    "height": 480
                }
            },
            {
                "key": "RandomForest_Iris_v20250423_230422/shap_summary.png",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250423_230422/shap_summary.png/content",
                "size": 16939,
                "mimetype": "image/png",
                "checksum": "md5:ac330a1d4feeb8463ca1e9551303c4c8",
                "metadata": {
                    "width": 1150,
                    "height": 660
                }
            },
            {
                "key": "RandomForest_Iris_v20250424_110923/confusion_matrix.png",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250424_110923/confusion_matrix.png/content",
                "size": 14453,
                "mimetype": "image/png",
                "checksum": "md5:41c356960df1b924d7db4d4a5cc9b254",
                "metadata": {
                    "width": 600,
                    "height": 600
                }
            },
            {
                "key": "RandomForest_Iris_v20250424_110923/feature_importances.png",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250424_110923/feature_importances.png/content",
                "size": 19167,
                "mimetype": "image/png",
                "checksum": "md5:1702afd2578c67988efdcf1f28fe1b04",
                "metadata": {
                    "width": 800,
                    "height": 600
                }
            },
            {
                "key": "RandomForest_Iris_v20250424_110923/pr_curve_cls_0.png",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250424_110923/pr_curve_cls_0.png/content",
                "size": 20358,
                "mimetype": "image/png",
                "checksum": "md5:30a6a3742bcbd69750bc5fd30aea58d2",
                "metadata": {
                    "width": 640,
                    "height": 480
                }
            },
            {
                "key": "RandomForest_Iris_v20250424_110923/pr_curve_cls_1.png",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250424_110923/pr_curve_cls_1.png/content",
                "size": 20226,
                "mimetype": "image/png",
                "checksum": "md5:7f396723afbfa90eb3d5f3e850f52c80",
                "metadata": {
                    "width": 640,
                    "height": 480
                }
            },
            {
                "key": "RandomForest_Iris_v20250424_110923/pr_curve_cls_2.png",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250424_110923/pr_curve_cls_2.png/content",
                "size": 19809,
                "mimetype": "image/png",
                "checksum": "md5:22a124dad652fd24fb3a5691abcae494",
                "metadata": {
                    "width": 640,
                    "height": 480
                }
            },
            {
                "key": "RandomForest_Iris_v20250424_110923/roc_curve_cls_0.png",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250424_110923/roc_curve_cls_0.png/content",
                "size": 20100,
                "mimetype": "image/png",
                "checksum": "md5:f6d5e559a27d81fb010b416bddc2fb02",
                "metadata": {
                    "width": 640,
                    "height": 480
                }
            },
            {
                "key": "RandomForest_Iris_v20250424_110923/roc_curve_cls_1.png",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250424_110923/roc_curve_cls_1.png/content",
                "size": 20143,
                "mimetype": "image/png",
                "checksum": "md5:917e9847fda527b030c0bcad8f2a2ea3",
                "metadata": {
                    "width": 640,
                    "height": 480
                }
            },
            {
                "key": "RandomForest_Iris_v20250425_120045/roc_curve_cls_2.png",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250425_120045/roc_curve_cls_2.png/content",
                "size": 20227,
                "mimetype": "image/png",
                "checksum": "md5:c076643c49b9ae7ba3cf0794b18f74db",
                "metadata": {
                    "width": 640,
                    "height": 480
                }
            },
            {
                "key": "RandomForest_Iris_v20250424_110923/roc_curve_cls_2.png",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250424_110923/roc_curve_cls_2.png/content",
                "size": 20227,
                "mimetype": "image/png",
                "checksum": "md5:c076643c49b9ae7ba3cf0794b18f74db",
                "metadata": {
                    "width": 640,
                    "height": 480
                }
            },
            {
                "key": "RandomForest_Iris_v20250425_131407/confusion_matrix.png",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250425_131407/confusion_matrix.png/content",
                "size": 14453,
                "mimetype": "image/png",
                "checksum": "md5:41c356960df1b924d7db4d4a5cc9b254",
                "metadata": {
                    "width": 600,
                    "height": 600
                }
            },
            {
                "key": "RandomForest_Iris_v20250424_111946/roc_curve_cls_1.png",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250424_111946/roc_curve_cls_1.png/content",
                "size": 20143,
                "mimetype": "image/png",
                "checksum": "md5:917e9847fda527b030c0bcad8f2a2ea3",
                "metadata": {
                    "width": 640,
                    "height": 480
                }
            },
            {
                "key": "RandomForest_Iris_v20250424_110923/shap_summary.png",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250424_110923/shap_summary.png/content",
                "size": 16821,
                "mimetype": "image/png",
                "checksum": "md5:28ee8be9c0dbf6dc16c4acd70b42273d",
                "metadata": {
                    "width": 1150,
                    "height": 660
                }
            },
            {
                "key": "RandomForest_Iris_v20250425_120045/pr_curve_cls_1.png",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250425_120045/pr_curve_cls_1.png/content",
                "size": 20226,
                "mimetype": "image/png",
                "checksum": "md5:7f396723afbfa90eb3d5f3e850f52c80",
                "metadata": {
                    "width": 640,
                    "height": 480
                }
            },
            {
                "key": "RandomForest_Iris_v20250424_111946/confusion_matrix.png",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250424_111946/confusion_matrix.png/content",
                "size": 14453,
                "mimetype": "image/png",
                "checksum": "md5:41c356960df1b924d7db4d4a5cc9b254",
                "metadata": {
                    "width": 600,
                    "height": 600
                }
            },
            {
                "key": "RandomForest_Iris_v20250424_111946/roc_curve_cls_2.png",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250424_111946/roc_curve_cls_2.png/content",
                "size": 20227,
                "mimetype": "image/png",
                "checksum": "md5:c076643c49b9ae7ba3cf0794b18f74db",
                "metadata": {
                    "width": 640,
                    "height": 480
                }
            },
            {
                "key": "RandomForest_Iris_v20250424_111946/feature_importances.png",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250424_111946/feature_importances.png/content",
                "size": 19167,
                "mimetype": "image/png",
                "checksum": "md5:1702afd2578c67988efdcf1f28fe1b04",
                "metadata": {
                    "width": 800,
                    "height": 600
                }
            },
            {
                "key": "RandomForest_Iris_v20250424_111946/pr_curve_cls_0.png",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250424_111946/pr_curve_cls_0.png/content",
                "size": 20358,
                "mimetype": "image/png",
                "checksum": "md5:30a6a3742bcbd69750bc5fd30aea58d2",
                "metadata": {
                    "width": 640,
                    "height": 480
                }
            },
            {
                "key": "RandomForest_Iris_v20250424_111946/pr_curve_cls_1.png",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250424_111946/pr_curve_cls_1.png/content",
                "size": 20226,
                "mimetype": "image/png",
                "checksum": "md5:7f396723afbfa90eb3d5f3e850f52c80",
                "metadata": {
                    "width": 640,
                    "height": 480
                }
            },
            {
                "key": "RandomForest_Iris_v20250424_111946/shap_summary.png",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250424_111946/shap_summary.png/content",
                "size": 16885,
                "mimetype": "image/png",
                "checksum": "md5:ac7959b6085a30cab3d8778a32d54d1a",
                "metadata": {
                    "width": 1150,
                    "height": 660
                }
            },
            {
                "key": "RandomForest_Iris_v20250424_111946/pr_curve_cls_2.png",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250424_111946/pr_curve_cls_2.png/content",
                "size": 19809,
                "mimetype": "image/png",
                "checksum": "md5:22a124dad652fd24fb3a5691abcae494",
                "metadata": {
                    "width": 640,
                    "height": 480
                }
            },
            {
                "key": "RandomForest_Iris_v20250424_111946/roc_curve_cls_0.png",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250424_111946/roc_curve_cls_0.png/content",
                "size": 20100,
                "mimetype": "image/png",
                "checksum": "md5:f6d5e559a27d81fb010b416bddc2fb02",
                "metadata": {
                    "width": 640,
                    "height": 480
                }
            },
            {
                "key": "RandomForest_Iris_v20250425_120045/pr_curve_cls_2.png",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250425_120045/pr_curve_cls_2.png/content",
                "size": 19809,
                "mimetype": "image/png",
                "checksum": "md5:22a124dad652fd24fb3a5691abcae494",
                "metadata": {
                    "width": 640,
                    "height": 480
                }
            },
            {
                "key": "RandomForest_Iris_v20250425_120045/confusion_matrix.png",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250425_120045/confusion_matrix.png/content",
                "size": 14453,
                "mimetype": "image/png",
                "checksum": "md5:41c356960df1b924d7db4d4a5cc9b254",
                "metadata": {
                    "width": 600,
                    "height": 600
                }
            },
            {
                "key": "RandomForest_Iris_v20250425_120045/feature_importances.png",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250425_120045/feature_importances.png/content",
                "size": 19167,
                "mimetype": "image/png",
                "checksum": "md5:1702afd2578c67988efdcf1f28fe1b04",
                "metadata": {
                    "width": 800,
                    "height": 600
                }
            },
            {
                "key": "RandomForest_Iris_v20250425_120045/roc_curve_cls_0.png",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250425_120045/roc_curve_cls_0.png/content",
                "size": 20100,
                "mimetype": "image/png",
                "checksum": "md5:f6d5e559a27d81fb010b416bddc2fb02",
                "metadata": {
                    "width": 640,
                    "height": 480
                }
            },
            {
                "key": "RandomForest_Iris_v20250425_120045/pr_curve_cls_0.png",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250425_120045/pr_curve_cls_0.png/content",
                "size": 20358,
                "mimetype": "image/png",
                "checksum": "md5:30a6a3742bcbd69750bc5fd30aea58d2",
                "metadata": {
                    "width": 640,
                    "height": 480
                }
            },
            {
                "key": "RandomForest_Iris_v20250425_120045/shap_summary.png",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250425_120045/shap_summary.png/content",
                "size": 16956,
                "mimetype": "image/png",
                "checksum": "md5:947b8f3bd89ebe22e3285c9be6a128e7",
                "metadata": {
                    "width": 1150,
                    "height": 660
                }
            },
            {
                "key": "RandomForest_Iris_v20250425_120045/roc_curve_cls_1.png",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250425_120045/roc_curve_cls_1.png/content",
                "size": 20143,
                "mimetype": "image/png",
                "checksum": "md5:917e9847fda527b030c0bcad8f2a2ea3",
                "metadata": {
                    "width": 640,
                    "height": 480
                }
            },
            {
                "key": "RandomForest_Iris_v20250425_120852/pr_curve_cls_0.png",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250425_120852/pr_curve_cls_0.png/content",
                "size": 20358,
                "mimetype": "image/png",
                "checksum": "md5:30a6a3742bcbd69750bc5fd30aea58d2",
                "metadata": {
                    "width": 640,
                    "height": 480
                }
            },
            {
                "key": "RandomForest_Iris_v20250425_120852/confusion_matrix.png",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250425_120852/confusion_matrix.png/content",
                "size": 14453,
                "mimetype": "image/png",
                "checksum": "md5:41c356960df1b924d7db4d4a5cc9b254",
                "metadata": {
                    "width": 600,
                    "height": 600
                }
            },
            {
                "key": "RandomForest_Iris_v20250425_120852/pr_curve_cls_2.png",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250425_120852/pr_curve_cls_2.png/content",
                "size": 19809,
                "mimetype": "image/png",
                "checksum": "md5:22a124dad652fd24fb3a5691abcae494",
                "metadata": {
                    "width": 640,
                    "height": 480
                }
            },
            {
                "key": "RandomForest_Iris_v20250425_120852/feature_importances.png",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250425_120852/feature_importances.png/content",
                "size": 19167,
                "mimetype": "image/png",
                "checksum": "md5:1702afd2578c67988efdcf1f28fe1b04",
                "metadata": {
                    "width": 800,
                    "height": 600
                }
            },
            {
                "key": "RandomForest_Iris_v20250425_120852/pr_curve_cls_1.png",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250425_120852/pr_curve_cls_1.png/content",
                "size": 20226,
                "mimetype": "image/png",
                "checksum": "md5:7f396723afbfa90eb3d5f3e850f52c80",
                "metadata": {
                    "width": 640,
                    "height": 480
                }
            },
            {
                "key": "RandomForest_Iris_v20250425_120852/shap_summary.png",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250425_120852/shap_summary.png/content",
                "size": 16894,
                "mimetype": "image/png",
                "checksum": "md5:f12c188270e92acb9354fafec7b579d9",
                "metadata": {
                    "width": 1150,
                    "height": 660
                }
            },
            {
                "key": "RandomForest_Iris_v20250425_120852/roc_curve_cls_0.png",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250425_120852/roc_curve_cls_0.png/content",
                "size": 20100,
                "mimetype": "image/png",
                "checksum": "md5:f6d5e559a27d81fb010b416bddc2fb02",
                "metadata": {
                    "width": 640,
                    "height": 480
                }
            },
            {
                "key": "RandomForest_Iris_v20250425_120852/roc_curve_cls_1.png",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250425_120852/roc_curve_cls_1.png/content",
                "size": 20143,
                "mimetype": "image/png",
                "checksum": "md5:917e9847fda527b030c0bcad8f2a2ea3",
                "metadata": {
                    "width": 640,
                    "height": 480
                }
            },
            {
                "key": "RandomForest_Iris_v20250425_120852/roc_curve_cls_2.png",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250425_120852/roc_curve_cls_2.png/content",
                "size": 20227,
                "mimetype": "image/png",
                "checksum": "md5:c076643c49b9ae7ba3cf0794b18f74db",
                "metadata": {
                    "width": 640,
                    "height": 480
                }
            },
            {
                "key": "RandomForest_Iris_v20250425_121328/confusion_matrix.png",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250425_121328/confusion_matrix.png/content",
                "size": 14453,
                "mimetype": "image/png",
                "checksum": "md5:41c356960df1b924d7db4d4a5cc9b254",
                "metadata": {
                    "width": 600,
                    "height": 600
                }
            },
            {
                "key": "RandomForest_Iris_v20250425_121328/feature_importances.png",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250425_121328/feature_importances.png/content",
                "size": 19167,
                "mimetype": "image/png",
                "checksum": "md5:1702afd2578c67988efdcf1f28fe1b04",
                "metadata": {
                    "width": 800,
                    "height": 600
                }
            },
            {
                "key": "RandomForest_Iris_v20250425_121328/pr_curve_cls_0.png",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250425_121328/pr_curve_cls_0.png/content",
                "size": 20358,
                "mimetype": "image/png",
                "checksum": "md5:30a6a3742bcbd69750bc5fd30aea58d2",
                "metadata": {
                    "width": 640,
                    "height": 480
                }
            },
            {
                "key": "RandomForest_Iris_v20250425_121328/pr_curve_cls_1.png",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250425_121328/pr_curve_cls_1.png/content",
                "size": 20226,
                "mimetype": "image/png",
                "checksum": "md5:7f396723afbfa90eb3d5f3e850f52c80",
                "metadata": {
                    "width": 640,
                    "height": 480
                }
            },
            {
                "key": "RandomForest_Iris_v20250425_121328/pr_curve_cls_2.png",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250425_121328/pr_curve_cls_2.png/content",
                "size": 19809,
                "mimetype": "image/png",
                "checksum": "md5:22a124dad652fd24fb3a5691abcae494",
                "metadata": {
                    "width": 640,
                    "height": 480
                }
            },
            {
                "key": "RandomForest_Iris_v20250425_125653/pr_curve_cls_1.png",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250425_125653/pr_curve_cls_1.png/content",
                "size": 20226,
                "mimetype": "image/png",
                "checksum": "md5:7f396723afbfa90eb3d5f3e850f52c80",
                "metadata": {
                    "width": 640,
                    "height": 480
                }
            },
            {
                "key": "RandomForest_Iris_v20250425_131407/feature_importances.png",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250425_131407/feature_importances.png/content",
                "size": 19167,
                "mimetype": "image/png",
                "checksum": "md5:1702afd2578c67988efdcf1f28fe1b04",
                "metadata": {
                    "width": 800,
                    "height": 600
                }
            },
            {
                "key": "RandomForest_Iris_v20250425_121328/roc_curve_cls_0.png",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250425_121328/roc_curve_cls_0.png/content",
                "size": 20100,
                "mimetype": "image/png",
                "checksum": "md5:f6d5e559a27d81fb010b416bddc2fb02",
                "metadata": {
                    "width": 640,
                    "height": 480
                }
            },
            {
                "key": "RandomForest_Iris_v20250425_121328/roc_curve_cls_1.png",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250425_121328/roc_curve_cls_1.png/content",
                "size": 20143,
                "mimetype": "image/png",
                "checksum": "md5:917e9847fda527b030c0bcad8f2a2ea3",
                "metadata": {
                    "width": 640,
                    "height": 480
                }
            },
            {
                "key": "RandomForest_Iris_v20250425_125653/pr_curve_cls_2.png",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250425_125653/pr_curve_cls_2.png/content",
                "size": 19809,
                "mimetype": "image/png",
                "checksum": "md5:22a124dad652fd24fb3a5691abcae494",
                "metadata": {
                    "width": 640,
                    "height": 480
                }
            },
            {
                "key": "RandomForest_Iris_v20250425_121328/roc_curve_cls_2.png",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250425_121328/roc_curve_cls_2.png/content",
                "size": 20227,
                "mimetype": "image/png",
                "checksum": "md5:c076643c49b9ae7ba3cf0794b18f74db",
                "metadata": {
                    "width": 640,
                    "height": 480
                }
            },
            {
                "key": "RandomForest_Iris_v20250425_131407/pr_curve_cls_0.png",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250425_131407/pr_curve_cls_0.png/content",
                "size": 20358,
                "mimetype": "image/png",
                "checksum": "md5:30a6a3742bcbd69750bc5fd30aea58d2",
                "metadata": {
                    "width": 640,
                    "height": 480
                }
            },
            {
                "key": "RandomForest_Iris_v20250425_132526/confusion_matrix.png",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250425_132526/confusion_matrix.png/content",
                "size": 14453,
                "mimetype": "image/png",
                "checksum": "md5:41c356960df1b924d7db4d4a5cc9b254",
                "metadata": {
                    "width": 600,
                    "height": 600
                }
            },
            {
                "key": "RandomForest_Iris_v20250425_121328/shap_summary.png",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250425_121328/shap_summary.png/content",
                "size": 16902,
                "mimetype": "image/png",
                "checksum": "md5:561d748d419e76e466f5dbd7bcc43a5e",
                "metadata": {
                    "width": 1150,
                    "height": 660
                }
            },
            {
                "key": "RandomForest_Iris_v20250425_131407/roc_curve_cls_1.png",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250425_131407/roc_curve_cls_1.png/content",
                "size": 20143,
                "mimetype": "image/png",
                "checksum": "md5:917e9847fda527b030c0bcad8f2a2ea3",
                "metadata": {
                    "width": 640,
                    "height": 480
                }
            },
            {
                "key": "RandomForest_Iris_v20250425_125653/confusion_matrix.png",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250425_125653/confusion_matrix.png/content",
                "size": 14453,
                "mimetype": "image/png",
                "checksum": "md5:41c356960df1b924d7db4d4a5cc9b254",
                "metadata": {
                    "width": 600,
                    "height": 600
                }
            },
            {
                "key": "RandomForest_Iris_v20250425_131407/pr_curve_cls_1.png",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250425_131407/pr_curve_cls_1.png/content",
                "size": 20226,
                "mimetype": "image/png",
                "checksum": "md5:7f396723afbfa90eb3d5f3e850f52c80",
                "metadata": {
                    "width": 640,
                    "height": 480
                }
            },
            {
                "key": "RandomForest_Iris_v20250425_125653/roc_curve_cls_0.png",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250425_125653/roc_curve_cls_0.png/content",
                "size": 20100,
                "mimetype": "image/png",
                "checksum": "md5:f6d5e559a27d81fb010b416bddc2fb02",
                "metadata": {
                    "width": 640,
                    "height": 480
                }
            },
            {
                "key": "RandomForest_Iris_v20250425_125653/feature_importances.png",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250425_125653/feature_importances.png/content",
                "size": 19167,
                "mimetype": "image/png",
                "checksum": "md5:1702afd2578c67988efdcf1f28fe1b04",
                "metadata": {
                    "width": 800,
                    "height": 600
                }
            },
            {
                "key": "RandomForest_Iris_v20250425_125653/pr_curve_cls_0.png",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250425_125653/pr_curve_cls_0.png/content",
                "size": 20358,
                "mimetype": "image/png",
                "checksum": "md5:30a6a3742bcbd69750bc5fd30aea58d2",
                "metadata": {
                    "width": 640,
                    "height": 480
                }
            },
            {
                "key": "RandomForest_Iris_v20250425_131407/pr_curve_cls_2.png",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250425_131407/pr_curve_cls_2.png/content",
                "size": 19809,
                "mimetype": "image/png",
                "checksum": "md5:22a124dad652fd24fb3a5691abcae494",
                "metadata": {
                    "width": 640,
                    "height": 480
                }
            },
            {
                "key": "RandomForest_Iris_v20250425_125653/roc_curve_cls_1.png",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250425_125653/roc_curve_cls_1.png/content",
                "size": 20143,
                "mimetype": "image/png",
                "checksum": "md5:917e9847fda527b030c0bcad8f2a2ea3",
                "metadata": {
                    "width": 640,
                    "height": 480
                }
            },
            {
                "key": "RandomForest_Iris_v20250425_125653/roc_curve_cls_2.png",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250425_125653/roc_curve_cls_2.png/content",
                "size": 20227,
                "mimetype": "image/png",
                "checksum": "md5:c076643c49b9ae7ba3cf0794b18f74db",
                "metadata": {
                    "width": 640,
                    "height": 480
                }
            },
            {
                "key": "RandomForest_Iris_v20250425_131407/roc_curve_cls_0.png",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250425_131407/roc_curve_cls_0.png/content",
                "size": 20100,
                "mimetype": "image/png",
                "checksum": "md5:f6d5e559a27d81fb010b416bddc2fb02",
                "metadata": {
                    "width": 640,
                    "height": 480
                }
            },
            {
                "key": "RandomForest_Iris_v20250425_131407/roc_curve_cls_2.png",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250425_131407/roc_curve_cls_2.png/content",
                "size": 20227,
                "mimetype": "image/png",
                "checksum": "md5:c076643c49b9ae7ba3cf0794b18f74db",
                "metadata": {
                    "width": 640,
                    "height": 480
                }
            },
            {
                "key": "RandomForest_Iris_v20250425_131407/shap_summary.png",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250425_131407/shap_summary.png/content",
                "size": 17008,
                "mimetype": "image/png",
                "checksum": "md5:962f647d7a0bc282c20bb437abfdc8dc",
                "metadata": {
                    "width": 1150,
                    "height": 660
                }
            },
            {
                "key": "RandomForest_Iris_v20250425_132526/feature_importances.png",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250425_132526/feature_importances.png/content",
                "size": 19167,
                "mimetype": "image/png",
                "checksum": "md5:1702afd2578c67988efdcf1f28fe1b04",
                "metadata": {
                    "width": 800,
                    "height": 600
                }
            },
            {
                "key": "RandomForest_Iris_v20250425_132526/pr_curve_cls_1.png",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250425_132526/pr_curve_cls_1.png/content",
                "size": 20226,
                "mimetype": "image/png",
                "checksum": "md5:7f396723afbfa90eb3d5f3e850f52c80",
                "metadata": {
                    "width": 640,
                    "height": 480
                }
            },
            {
                "key": "RandomForest_Iris_v20250425_132526/pr_curve_cls_0.png",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250425_132526/pr_curve_cls_0.png/content",
                "size": 20358,
                "mimetype": "image/png",
                "checksum": "md5:30a6a3742bcbd69750bc5fd30aea58d2",
                "metadata": {
                    "width": 640,
                    "height": 480
                }
            },
            {
                "key": "RandomForest_Iris_v20250425_132526/roc_curve_cls_2.png",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250425_132526/roc_curve_cls_2.png/content",
                "size": 20227,
                "mimetype": "image/png",
                "checksum": "md5:c076643c49b9ae7ba3cf0794b18f74db",
                "metadata": {
                    "width": 640,
                    "height": 480
                }
            },
            {
                "key": "RandomForest_Iris_v20250425_132526/pr_curve_cls_2.png",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250425_132526/pr_curve_cls_2.png/content",
                "size": 19809,
                "mimetype": "image/png",
                "checksum": "md5:22a124dad652fd24fb3a5691abcae494",
                "metadata": {
                    "width": 640,
                    "height": 480
                }
            },
            {
                "key": "RandomForest_Iris_v20250425_132526/roc_curve_cls_0.png",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250425_132526/roc_curve_cls_0.png/content",
                "size": 20100,
                "mimetype": "image/png",
                "checksum": "md5:f6d5e559a27d81fb010b416bddc2fb02",
                "metadata": {
                    "width": 640,
                    "height": 480
                }
            },
            {
                "key": "RandomForest_Iris_v20250425_132526/roc_curve_cls_1.png",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250425_132526/roc_curve_cls_1.png/content",
                "size": 20143,
                "mimetype": "image/png",
                "checksum": "md5:917e9847fda527b030c0bcad8f2a2ea3",
                "metadata": {
                    "width": 640,
                    "height": 480
                }
            },
            {
                "key": "RandomForest_Iris_v20250425_132526/shap_summary.png",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250425_132526/shap_summary.png/content",
                "size": 16895,
                "mimetype": "image/png",
                "checksum": "md5:61612dfdc6c720e2119793f8b7894e0d",
                "metadata": {
                    "width": 1150,
                    "height": 660
                }
            },
            {
                "key": "RandomForest_Iris_v20250425_121328/RandomForest_Iris_v20250425_121328.jsonld",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250425_121328/RandomForest_Iris_v20250425_121328.jsonld/content",
                "size": 518344,
                "mimetype": "application/ld+json",
                "checksum": "md5:e8360b51ecada17283945efd57c69e02",
                "metadata": {}
            },
            {
                "key": "RandomForest_Iris_v20250425_121328/RandomForest_Iris_v20250425_121328.ttl",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250425_121328/RandomForest_Iris_v20250425_121328.ttl/content",
                "size": 3956,
                "mimetype": "text/turtle",
                "checksum": "md5:22947fc45785a5ad0efde3bcbd22dad6",
                "metadata": {}
            },
            {
                "key": "RandomForest_Iris_v20250425_121328/RandomForest_Iris_v20250425_121328_run_summary.json",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250425_121328/RandomForest_Iris_v20250425_121328_run_summary.json/content",
                "size": 514598,
                "mimetype": "application/json",
                "checksum": "md5:d13e9eb667aa5553eaa390ed6d8fae6e",
                "metadata": {}
            },
            {
                "key": "RandomForest_Iris_v20250425_132526/.ipynb_checkpoints/RandomForest_Iris_v20250425_132526_run_summary-checkpoint.json",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250425_132526/.ipynb_checkpoints/RandomForest_Iris_v20250425_132526_run_summary-checkpoint.json/content",
                "size": 458338,
                "mimetype": "application/json",
                "checksum": "md5:9f04a508c236f0bf8b1e7e1e7d76754f",
                "metadata": {}
            },
            {
                "key": "RandomForest_Iris_v20250425_121328/.ipynb_checkpoints/RandomForest_Iris_v20250425_121328_run_summary-checkpoint.json",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250425_121328/.ipynb_checkpoints/RandomForest_Iris_v20250425_121328_run_summary-checkpoint.json/content",
                "size": 514598,
                "mimetype": "application/json",
                "checksum": "md5:d13e9eb667aa5553eaa390ed6d8fae6e",
                "metadata": {}
            },
            {
                "key": "RandomForest_Iris_v20250425_125653/RandomForest_Iris_v20250425_125653_run_summary.json",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250425_125653/RandomForest_Iris_v20250425_125653_run_summary.json/content",
                "size": 1428164,
                "mimetype": "application/json",
                "checksum": "md5:a0068133533b9000a9a8289c34f7a84a",
                "metadata": {}
            },
            {
                "key": "RandomForest_Iris_v20250425_125653/.ipynb_checkpoints/RandomForest_Iris_v20250425_125653_run_summary-checkpoint.json",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250425_125653/.ipynb_checkpoints/RandomForest_Iris_v20250425_125653_run_summary-checkpoint.json/content",
                "size": 1428164,
                "mimetype": "application/json",
                "checksum": "md5:a0068133533b9000a9a8289c34f7a84a",
                "metadata": {}
            },
            {
                "key": "RandomForest_Iris_v20250425_131407/RandomForest_Iris_v20250425_131407_run_summary.json",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250425_131407/RandomForest_Iris_v20250425_131407_run_summary.json/content",
                "size": 427113,
                "mimetype": "application/json",
                "checksum": "md5:18b6e91f48a83949834f99aa1395490a",
                "metadata": {}
            },
            {
                "key": "RandomForest_Iris_v20250425_131407/.ipynb_checkpoints/RandomForest_Iris_v20250425_131407_run_summary-checkpoint.json",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250425_131407/.ipynb_checkpoints/RandomForest_Iris_v20250425_131407_run_summary-checkpoint.json/content",
                "size": 427113,
                "mimetype": "application/json",
                "checksum": "md5:18b6e91f48a83949834f99aa1395490a",
                "metadata": {}
            },
            {
                "key": "RandomForest_Iris_v20250425_132526/RandomForest_Iris_v20250425_132526_run_summary.json",
                "url": "https://127.0.0.1:5000/api/records/892h2-fq661/files/RandomForest_Iris_v20250425_132526/RandomForest_Iris_v20250425_132526_run_summary.json/content",
                "size": 458338,
                "mimetype": "application/json",
                "checksum": "md5:9f04a508c236f0bf8b1e7e1e7d76754f",
                "metadata": {}
            }
        ],
        "pids": {
            "oai": {
                "identifier": "oai:my-site.com:892h2-fq661",
                "provider": "oai"
            }
        },
        "version_info": {
            "is_latest": true,
            "is_latest_draft": true,
            "index": 1
        },
        "status": "published",
        "views": 0,
        "downloads": 0
    }
}