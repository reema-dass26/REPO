{
  "run_id": "78e6e34ac94a460a893791a3e02f6da7",
  "run_name": "melodic-ape-533",
  "experiment_id": "615223710259862608",
  "start_time": 1745580325746,
  "end_time": null,
  "params": {
    "bootstrap": "True",
    "ccp_alpha": "0.0",
    "class_weight": "None",
    "columns_raw": "['id', 'sepallengthcm', 'sepalwidthcm', 'petallengthcm', 'petalwidthcm', 'species']",
    "criterion": "entropy",
    "database.description": "None",
    "database.id": "c3a42d17-42b7-43c9-a504-2363fb4c9c8d",
    "database.name": "Iris",
    "database.owner": "reema",
    "dataset.authors": "[\"Marshall Michael\"]",
    "dataset.doi": "10.5281/ZENODO.1404173",
    "dataset.published": "2018-8-27",
    "dataset.publisher": "Zenodo",
    "dataset.title": "Scikit-Learn Iris",
    "dropped_columns": "['id']",
    "feature_names": "['sepallengthcm', 'sepalwidthcm', 'petallengthcm', 'petalwidthcm']",
    "max_depth": "12",
    "max_features": "sqrt",
    "max_leaf_nodes": "None",
    "max_samples": "None",
    "min_impurity_decrease": "0.0",
    "min_samples_leaf": "2",
    "min_samples_split": "5",
    "min_weight_fraction_leaf": "0.0",
    "n_estimators": "200",
    "n_features": "4",
    "n_features_final": "4",
    "n_jobs": "-1",
    "n_records": "150",
    "n_test_samples": "30",
    "n_train_samples": "120",
    "oob_score": "False",
    "random_state": "42",
    "retrieval_time": "2025-04-25T11:25:26.931097",
    "test_size": "0.2",
    "verbose": "1",
    "warm_start": "False"
  },
  "metrics": {
    "dbrepo.num_deletes": 0.0,
    "dbrepo.num_inserts": 1.0,
    "dbrepo.row_count_end": 150.0,
    "dbrepo.row_count_start": 150.0,
    "training_accuracy_score": 0.9666666666666667,
    "training_f1_score": 0.9666666666666667,
    "training_log_loss": 0.0653522301195834,
    "training_precision_score": 0.9674588284344383,
    "training_recall_score": 0.9666666666666667,
    "training_roc_auc": 0.9987492182614135,
    "training_score": 0.9666666666666667
  },
  "tags": {
    "dataset_id": "iris_local",
    "dataset_name": "Iris",
    "dataset_version": "1.0.0",
    "data_source": "http://localhost/api/database/c3a42d17-42b7-43c9-a504-2363fb4c9c8d/table/5315e7da-64fb-4fdb-b493-95b4138c765f/data?size=100000&page=0",
    "dbrepo.admin_email": "noreply@localhost",
    "dbrepo.base_url": "http://localhost",
    "dbrepo.granularity": "YYYY-MM-DDThh:mm:ssZ",
    "dbrepo.protocol_version": "2.0",
    "dbrepo.repository_name": "Database Repository",
    "dbrepo.table_last_modified": "2025-04-23T20:42:29.501Z",
    "estimator_class": "sklearn.ensemble._forest.RandomForestClassifier",
    "estimator_name": "RandomForestClassifier",
    "git_current_commit_hash": "4099a1b42d88ef4110c602fed60c287e29045892",
    "git_previous_commit_hash": "e67d756afe694e01d42bbac8ab69de73007f473a",
    "git__current_commit_url": "https://github.com/reema-dass26/REPO/commit/4099a1b42d88ef4110c602fed60c287e29045892",
    "justification_bootstrap": "test",
    "justification_class_weight": "test",
    "justification_criterion": "test",
    "justification_dataset_version": "test",
    "justification_drop_column_X": "test",
    "justification_experiment_name": "test",
    "justification_max_depth": "test",
    "justification_max_features": "test",
    "justification_metric_choice": "test",
    "justification_min_samples_leaf": "test",
    "justification_min_samples_split": "test",
    "justification_model_choice": "test",
    "justification_n_estimators": "test",
    "justification_n_jobs": "test",
    "justification_oob_score": "test",
    "justification_random_state": "test",
    "justification_target_variable": "test",
    "justification_test_split": "test",
    "justification_threshold_accuracy": "test",
    "justification_verbose": "test",
    "mlflow.log-model.history": "[{\"run_id\": \"78e6e34ac94a460a893791a3e02f6da7\", \"artifact_path\": \"model\", \"utc_time_created\": \"2025-04-25 11:25:44.415033\", \"model_uuid\": \"bacd170bceb646058657e4e6590b9f0f\", \"flavors\": {\"python_function\": {\"model_path\": \"model.pkl\", \"predict_fn\": \"predict\", \"loader_module\": \"mlflow.sklearn\", \"python_version\": \"3.11.5\", \"env\": {\"conda\": \"conda.yaml\", \"virtualenv\": \"python_env.yaml\"}}, \"sklearn\": {\"pickled_model\": \"model.pkl\", \"sklearn_version\": \"1.3.0\", \"serialization_format\": \"cloudpickle\", \"code\": null}}}]",
    "mlflow.runName": "melodic-ape-533",
    "mlflow.source.name": "C:\\Users\\reema\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel_launcher.py",
    "mlflow.source.type": "LOCAL",
    "mlflow.user": "reema",
    "model_name": "RandomForest_Iris_v20250425_132526",
    "notebook_name": "RQ1.ipynb",
    "target_name": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]",
    "training_end_time": "2025-04-25T13:25:50.886665",
    "training_start_time": "2025-04-25T13:25:26.973629"
  },
  "artifacts": [
    {
      "path": "RandomForest_Iris_v20250425_132526/RandomForest_Iris_v20250425_132526.pkl",
      "type": "other",
      "uri": "file:///C:/Users/reema/REPO/notebooks/RQ_notebooks/mlrunlogs/mlflow.db/615223710259862608/78e6e34ac94a460a893791a3e02f6da7/artifacts/RandomForest_Iris_v20250425_132526/RandomForest_Iris_v20250425_132526.pkl"
    },
    {
      "path": "commit_diff.json",
      "type": "text",
      "content": "{\n  \"previous_commit\": \"e67d756afe694e01d42bbac8ab69de73007f473a\",\n  \"previous_commit_url\": \"https://github.com/reema-dass26/REPO/commit/e67d756afe694e01d42bbac8ab69de73007f473a\",\n  \"current_commit_url\": \"https://github.com/reema-dass26/REPO/commit/4099a1b42d88ef4110c602fed60c287e29045892\",\n  \"current_commit\": \"4099a1b42d88ef4110c602fed60c287e29045892\",\n  \"diff\": \"diff --git a/notebooks/RQ_notebooks/RQ1_updated-Backup.ipynb b/notebooks/RQ_notebooks/RQ1_updated-Backup.ipynb\\nnew file mode 100644\\nindex 0000000..1ff819b\\n--- /dev/null\\n+++ b/notebooks/RQ_notebooks/RQ1_updated-Backup.ipynb\\n@@ -0,0 +1,3270 @@\\n+{\\n+ \\\"cells\\\": [\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 8,\\n+   \\\"id\\\": \\\"12fa6f59-927c-4003-964f-83e53793fd36\\\",\\n+   \\\"metadata\\\": {\\n+    \\\"scrolled\\\": true\\n+   },\\n+   \\\"outputs\\\": [],\\n+   \\\"source\\\": [\\n+    \\\"# TODO: atm the mlflow autolog isnt capturing metrics n params\\\\n\\\",\\n+    \\\"# and sklearn.autolog throws error( posted the issue on github)\\\\n\\\",\\n+    \\\"# Ideally, I should be able to fetch most of the imp detail via MLFLOW AUTOLOG. will check that later in time\\\\n\\\",\\n+    \\\"#============================\\\\n\\\",\\n+    \\\"# \\ud83e\\udde0 MLflow Autologging\\\\n\\\",\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# mlflow.autolog(log_input_examples=True, log_model_signatures=True)\\\\n\\\",\\n+    \\\"# mlflow.sklearn.autolog() \\\\n\\\",\\n+    \\\"# mlflow.sklearn.autolog(\\\\n\\\",\\n+    \\\"#     log_input_examples=True,\\\\n\\\",\\n+    \\\"#     log_model_signatures=True,\\\\n\\\",\\n+    \\\"#     log_post_training_metrics=True,        # calls model.score() \\u2192 accuracy\\\\n\\\",\\n+    \\\"#     disable_for_unsupported_versions=True,  # skips if versions still wonky\\\\n\\\",\\n+    \\\"#     exclusive=True                          # only patch the sklearn integration\\\\n\\\",\\n+    \\\"# )\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 9,\\n+   \\\"id\\\": \\\"1ce1a579-f08b-40bd-b4db-21b388aaea74\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [],\\n+   \\\"source\\\": [\\n+    \\\"\\\\n\\\",\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"# \\u2699\\ufe0f Install Dependencies (if needed )\\\\n\\\",\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"# !pip install mlflow scikit-learn pandas numpy matplotlib seaborn shap requests GitPython\\\\n\\\",\\n+    \\\"# !pip install --upgrade threadpoolctl\\\\n\\\",\\n+    \\\"# !pip install setuptools\\\\n\\\",\\n+    \\\"# !pip install ace_tools \\\\n\\\",\\n+    \\\"# !pip install rdflib\\\\n\\\",\\n+    \\\"# !pip install streamlit-option-menu\\\\n\\\",\\n+    \\\"# !pip install streamlit-agraph\\\\n\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"1ca4f0ae-39ee-4b22-b013-dfb1fa1b5694\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"LIBRARY IMPORTS:\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 51,\\n+   \\\"id\\\": \\\"8ca332e5-6501-4310-920b-2b769477b46e\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [],\\n+   \\\"source\\\": [\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"# \\ud83d\\udce6 Standard Library Imports\\\\n\\\",\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"import os\\\\n\\\",\\n+    \\\"import glob\\\\n\\\",\\n+    \\\"import io\\\\n\\\",\\n+    \\\"import json\\\\n\\\",\\n+    \\\"import time\\\\n\\\",\\n+    \\\"import ast\\\\n\\\",\\n+    \\\"import pickle\\\\n\\\",\\n+    \\\"import platform\\\\n\\\",\\n+    \\\"import subprocess\\\\n\\\",\\n+    \\\"from datetime import datetime, timezone\\\\n\\\",\\n+    \\\"from pprint import pprint\\\\n\\\",\\n+    \\\"from typing import List, Dict, Any\\\\n\\\",\\n+    \\\"import xml.etree.ElementTree as ET\\\\n\\\",\\n+    \\\"import urllib.parse\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"# \\ud83d\\udcca Data and Visualization\\\\n\\\",\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"import pandas as pd\\\\n\\\",\\n+    \\\"import numpy as np\\\\n\\\",\\n+    \\\"import seaborn as sns\\\\n\\\",\\n+    \\\"import matplotlib\\\\n\\\",\\n+    \\\"import matplotlib.pyplot as plt\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"# \\ud83e\\udd16 Machine Learning\\\\n\\\",\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"import sklearn\\\\n\\\",\\n+    \\\"from sklearn.datasets import load_iris\\\\n\\\",\\n+    \\\"from sklearn.ensemble import RandomForestClassifier\\\\n\\\",\\n+    \\\"from sklearn.model_selection import train_test_split\\\\n\\\",\\n+    \\\"from sklearn.preprocessing import LabelEncoder, label_binarize\\\\n\\\",\\n+    \\\"from sklearn.metrics import (\\\\n\\\",\\n+    \\\"    accuracy_score,\\\\n\\\",\\n+    \\\"    roc_auc_score,\\\\n\\\",\\n+    \\\"    confusion_matrix,\\\\n\\\",\\n+    \\\"    precision_score,\\\\n\\\",\\n+    \\\"    recall_score,\\\\n\\\",\\n+    \\\"    f1_score,\\\\n\\\",\\n+    \\\"    RocCurveDisplay,\\\\n\\\",\\n+    \\\"    PrecisionRecallDisplay\\\\n\\\",\\n+    \\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"# \\ud83d\\udd2c Experiment Tracking\\\\n\\\",\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"import mlflow\\\\n\\\",\\n+    \\\"import mlflow.sklearn\\\\n\\\",\\n+    \\\"from mlflow import MlflowClient\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"# \\ud83c\\udf10 Web / API / Networking\\\\n\\\",\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"import requests\\\\n\\\",\\n+    \\\"from dotenv import load_dotenv\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"# \\ud83e\\uddea Git & Version Control\\\\n\\\",\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"import git\\\\n\\\",\\n+    \\\"from git import Repo, GitCommandError\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"# \\ud83e\\udde0 SHAP for Explainability\\\\n\\\",\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"import shap\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"# \\ud83e\\uddec RDF & Provenance (rdflib)\\\\n\\\",\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"from rdflib import Graph, URIRef, Literal\\\\n\\\",\\n+    \\\"from rdflib.namespace import PROV, XSD\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"# \\u2699\\ufe0f System Monitoring\\\\n\\\",\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"import psutil\\\\n\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"61d4d6b8-34a9-47b5-974d-5927c0ee2256\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"DBREPO INTEGRETION\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 32,\\n+   \\\"id\\\": \\\"8e3570e2-9a60-45b4-8653-28060071e728\\\",\\n+   \\\"metadata\\\": {\\n+    \\\"scrolled\\\": true\\n+   },\\n+   \\\"outputs\\\": [\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"API Response: [{'id': '1', 'sepallengthcm': '5.100000000000000000', 'sepalwidthcm': '3.500000000000000000', 'petallengthcm': '1.400000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '2', 'sepallengthcm': '4.900000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '1.400000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '3', 'sepallengthcm': '4.700000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '1.300000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '4', 'sepallengthcm': '4.600000000000000000', 'sepalwidthcm': '3.100000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '5', 'sepallengthcm': '5.000000000000000000', 'sepalwidthcm': '3.600000000000000000', 'petallengthcm': '1.400000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '6', 'sepallengthcm': '5.400000000000000000', 'sepalwidthcm': '3.900000000000000000', 'petallengthcm': '1.700000000000000000', 'petalwidthcm': '0.400000000000000000', 'species': 'Iris-setosa'}, {'id': '7', 'sepallengthcm': '4.600000000000000000', 'sepalwidthcm': '3.400000000000000000', 'petallengthcm': '1.400000000000000000', 'petalwidthcm': '0.300000000000000000', 'species': 'Iris-setosa'}, {'id': '8', 'sepallengthcm': '5.000000000000000000', 'sepalwidthcm': '3.400000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '9', 'sepallengthcm': '4.400000000000000000', 'sepalwidthcm': '2.900000000000000000', 'petallengthcm': '1.400000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '10', 'sepallengthcm': '4.900000000000000000', 'sepalwidthcm': '3.100000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.100000000000000000', 'species': 'Iris-setosa'}, {'id': '11', 'sepallengthcm': '5.400000000000000000', 'sepalwidthcm': '3.700000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '12', 'sepallengthcm': '4.800000000000000000', 'sepalwidthcm': '3.400000000000000000', 'petallengthcm': '1.600000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '13', 'sepallengthcm': '4.800000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '1.400000000000000000', 'petalwidthcm': '0.100000000000000000', 'species': 'Iris-setosa'}, {'id': '14', 'sepallengthcm': '4.300000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '1.100000000000000000', 'petalwidthcm': '0.100000000000000000', 'species': 'Iris-setosa'}, {'id': '15', 'sepallengthcm': '5.800000000000000000', 'sepalwidthcm': '4.000000000000000000', 'petallengthcm': '1.200000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '16', 'sepallengthcm': '5.700000000000000000', 'sepalwidthcm': '4.400000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.400000000000000000', 'species': 'Iris-setosa'}, {'id': '17', 'sepallengthcm': '5.400000000000000000', 'sepalwidthcm': '3.900000000000000000', 'petallengthcm': '1.300000000000000000', 'petalwidthcm': '0.400000000000000000', 'species': 'Iris-setosa'}, {'id': '18', 'sepallengthcm': '5.100000000000000000', 'sepalwidthcm': '3.500000000000000000', 'petallengthcm': '1.400000000000000000', 'petalwidthcm': '0.300000000000000000', 'species': 'Iris-setosa'}, {'id': '19', 'sepallengthcm': '5.700000000000000000', 'sepalwidthcm': '3.800000000000000000', 'petallengthcm': '1.700000000000000000', 'petalwidthcm': '0.300000000000000000', 'species': 'Iris-setosa'}, {'id': '20', 'sepallengthcm': '5.100000000000000000', 'sepalwidthcm': '3.800000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.300000000000000000', 'species': 'Iris-setosa'}, {'id': '21', 'sepallengthcm': '5.400000000000000000', 'sepalwidthcm': '3.400000000000000000', 'petallengthcm': '1.700000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '22', 'sepallengthcm': '5.100000000000000000', 'sepalwidthcm': '3.700000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.400000000000000000', 'species': 'Iris-setosa'}, {'id': '23', 'sepallengthcm': '4.600000000000000000', 'sepalwidthcm': '3.600000000000000000', 'petallengthcm': '1.000000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '24', 'sepallengthcm': '5.100000000000000000', 'sepalwidthcm': '3.300000000000000000', 'petallengthcm': '1.700000000000000000', 'petalwidthcm': '0.500000000000000000', 'species': 'Iris-setosa'}, {'id': '25', 'sepallengthcm': '4.800000000000000000', 'sepalwidthcm': '3.400000000000000000', 'petallengthcm': '1.900000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '26', 'sepallengthcm': '5.000000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '1.600000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '27', 'sepallengthcm': '5.000000000000000000', 'sepalwidthcm': '3.400000000000000000', 'petallengthcm': '1.600000000000000000', 'petalwidthcm': '0.400000000000000000', 'species': 'Iris-setosa'}, {'id': '28', 'sepallengthcm': '5.200000000000000000', 'sepalwidthcm': '3.500000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '29', 'sepallengthcm': '5.200000000000000000', 'sepalwidthcm': '3.400000000000000000', 'petallengthcm': '1.400000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '30', 'sepallengthcm': '4.700000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '1.600000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '31', 'sepallengthcm': '4.800000000000000000', 'sepalwidthcm': '3.100000000000000000', 'petallengthcm': '1.600000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '32', 'sepallengthcm': '5.400000000000000000', 'sepalwidthcm': '3.400000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.400000000000000000', 'species': 'Iris-setosa'}, {'id': '33', 'sepallengthcm': '5.200000000000000000', 'sepalwidthcm': '4.100000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.100000000000000000', 'species': 'Iris-setosa'}, {'id': '34', 'sepallengthcm': '5.500000000000000000', 'sepalwidthcm': '4.200000000000000000', 'petallengthcm': '1.400000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '35', 'sepallengthcm': '4.900000000000000000', 'sepalwidthcm': '3.100000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.100000000000000000', 'species': 'Iris-setosa'}, {'id': '36', 'sepallengthcm': '5.000000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '1.200000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '37', 'sepallengthcm': '5.500000000000000000', 'sepalwidthcm': '3.500000000000000000', 'petallengthcm': '1.300000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '38', 'sepallengthcm': '4.900000000000000000', 'sepalwidthcm': '3.100000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.100000000000000000', 'species': 'Iris-setosa'}, {'id': '39', 'sepallengthcm': '4.400000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '1.300000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '40', 'sepallengthcm': '5.100000000000000000', 'sepalwidthcm': '3.400000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '41', 'sepallengthcm': '5.000000000000000000', 'sepalwidthcm': '3.500000000000000000', 'petallengthcm': '1.300000000000000000', 'petalwidthcm': '0.300000000000000000', 'species': 'Iris-setosa'}, {'id': '42', 'sepallengthcm': '4.500000000000000000', 'sepalwidthcm': '2.300000000000000000', 'petallengthcm': '1.300000000000000000', 'petalwidthcm': '0.300000000000000000', 'species': 'Iris-setosa'}, {'id': '43', 'sepallengthcm': '4.400000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '1.300000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '44', 'sepallengthcm': '5.000000000000000000', 'sepalwidthcm': '3.500000000000000000', 'petallengthcm': '1.600000000000000000', 'petalwidthcm': '0.600000000000000000', 'species': 'Iris-setosa'}, {'id': '45', 'sepallengthcm': '5.100000000000000000', 'sepalwidthcm': '3.800000000000000000', 'petallengthcm': '1.900000000000000000', 'petalwidthcm': '0.400000000000000000', 'species': 'Iris-setosa'}, {'id': '46', 'sepallengthcm': '4.800000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '1.400000000000000000', 'petalwidthcm': '0.300000000000000000', 'species': 'Iris-setosa'}, {'id': '47', 'sepallengthcm': '5.100000000000000000', 'sepalwidthcm': '3.800000000000000000', 'petallengthcm': '1.600000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '48', 'sepallengthcm': '4.600000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '1.400000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '49', 'sepallengthcm': '5.300000000000000000', 'sepalwidthcm': '3.700000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '50', 'sepallengthcm': '5.000000000000000000', 'sepalwidthcm': '3.300000000000000000', 'petallengthcm': '1.400000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '51', 'sepallengthcm': '7.000000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '4.700000000000000000', 'petalwidthcm': '1.400000000000000000', 'species': 'Iris-versicolor'}, {'id': '52', 'sepallengthcm': '6.400000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '4.500000000000000000', 'petalwidthcm': '1.500000000000000000', 'species': 'Iris-versicolor'}, {'id': '53', 'sepallengthcm': '6.900000000000000000', 'sepalwidthcm': '3.100000000000000000', 'petallengthcm': '4.900000000000000000', 'petalwidthcm': '1.500000000000000000', 'species': 'Iris-versicolor'}, {'id': '54', 'sepallengthcm': '5.500000000000000000', 'sepalwidthcm': '2.300000000000000000', 'petallengthcm': '4.000000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '55', 'sepallengthcm': '6.500000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '4.600000000000000000', 'petalwidthcm': '1.500000000000000000', 'species': 'Iris-versicolor'}, {'id': '56', 'sepallengthcm': '5.700000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '4.500000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '57', 'sepallengthcm': '6.300000000000000000', 'sepalwidthcm': '3.300000000000000000', 'petallengthcm': '4.700000000000000000', 'petalwidthcm': '1.600000000000000000', 'species': 'Iris-versicolor'}, {'id': '58', 'sepallengthcm': '4.900000000000000000', 'sepalwidthcm': '2.400000000000000000', 'petallengthcm': '3.300000000000000000', 'petalwidthcm': '1.000000000000000000', 'species': 'Iris-versicolor'}, {'id': '59', 'sepallengthcm': '6.600000000000000000', 'sepalwidthcm': '2.900000000000000000', 'petallengthcm': '4.600000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '60', 'sepallengthcm': '5.200000000000000000', 'sepalwidthcm': '2.700000000000000000', 'petallengthcm': '3.900000000000000000', 'petalwidthcm': '1.400000000000000000', 'species': 'Iris-versicolor'}, {'id': '61', 'sepallengthcm': '5.000000000000000000', 'sepalwidthcm': '2.000000000000000000', 'petallengthcm': '3.500000000000000000', 'petalwidthcm': '1.000000000000000000', 'species': 'Iris-versicolor'}, {'id': '62', 'sepallengthcm': '5.900000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '4.200000000000000000', 'petalwidthcm': '1.500000000000000000', 'species': 'Iris-versicolor'}, {'id': '63', 'sepallengthcm': '6.000000000000000000', 'sepalwidthcm': '2.200000000000000000', 'petallengthcm': '4.000000000000000000', 'petalwidthcm': '1.000000000000000000', 'species': 'Iris-versicolor'}, {'id': '64', 'sepallengthcm': '6.100000000000000000', 'sepalwidthcm': '2.900000000000000000', 'petallengthcm': '4.700000000000000000', 'petalwidthcm': '1.400000000000000000', 'species': 'Iris-versicolor'}, {'id': '65', 'sepallengthcm': '5.600000000000000000', 'sepalwidthcm': '2.900000000000000000', 'petallengthcm': '3.600000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '66', 'sepallengthcm': '6.700000000000000000', 'sepalwidthcm': '3.100000000000000000', 'petallengthcm': '4.400000000000000000', 'petalwidthcm': '1.400000000000000000', 'species': 'Iris-versicolor'}, {'id': '67', 'sepallengthcm': '5.600000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '4.500000000000000000', 'petalwidthcm': '1.500000000000000000', 'species': 'Iris-versicolor'}, {'id': '68', 'sepallengthcm': '5.800000000000000000', 'sepalwidthcm': '2.700000000000000000', 'petallengthcm': '4.100000000000000000', 'petalwidthcm': '1.000000000000000000', 'species': 'Iris-versicolor'}, {'id': '69', 'sepallengthcm': '6.200000000000000000', 'sepalwidthcm': '2.200000000000000000', 'petallengthcm': '4.500000000000000000', 'petalwidthcm': '1.500000000000000000', 'species': 'Iris-versicolor'}, {'id': '70', 'sepallengthcm': '5.600000000000000000', 'sepalwidthcm': '2.500000000000000000', 'petallengthcm': '3.900000000000000000', 'petalwidthcm': '1.100000000000000000', 'species': 'Iris-versicolor'}, {'id': '71', 'sepallengthcm': '5.900000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '4.800000000000000000', 'petalwidthcm': '1.800000000000000000', 'species': 'Iris-versicolor'}, {'id': '72', 'sepallengthcm': '6.100000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '4.000000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '73', 'sepallengthcm': '6.300000000000000000', 'sepalwidthcm': '2.500000000000000000', 'petallengthcm': '4.900000000000000000', 'petalwidthcm': '1.500000000000000000', 'species': 'Iris-versicolor'}, {'id': '74', 'sepallengthcm': '6.100000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '4.700000000000000000', 'petalwidthcm': '1.200000000000000000', 'species': 'Iris-versicolor'}, {'id': '75', 'sepallengthcm': '6.400000000000000000', 'sepalwidthcm': '2.900000000000000000', 'petallengthcm': '4.300000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '76', 'sepallengthcm': '6.600000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '4.400000000000000000', 'petalwidthcm': '1.400000000000000000', 'species': 'Iris-versicolor'}, {'id': '77', 'sepallengthcm': '6.800000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '4.800000000000000000', 'petalwidthcm': '1.400000000000000000', 'species': 'Iris-versicolor'}, {'id': '78', 'sepallengthcm': '6.700000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '5.000000000000000000', 'petalwidthcm': '1.700000000000000000', 'species': 'Iris-versicolor'}, {'id': '79', 'sepallengthcm': '6.000000000000000000', 'sepalwidthcm': '2.900000000000000000', 'petallengthcm': '4.500000000000000000', 'petalwidthcm': '1.500000000000000000', 'species': 'Iris-versicolor'}, {'id': '80', 'sepallengthcm': '5.700000000000000000', 'sepalwidthcm': '2.600000000000000000', 'petallengthcm': '3.500000000000000000', 'petalwidthcm': '1.000000000000000000', 'species': 'Iris-versicolor'}, {'id': '81', 'sepallengthcm': '5.500000000000000000', 'sepalwidthcm': '2.400000000000000000', 'petallengthcm': '3.800000000000000000', 'petalwidthcm': '1.100000000000000000', 'species': 'Iris-versicolor'}, {'id': '82', 'sepallengthcm': '5.500000000000000000', 'sepalwidthcm': '2.400000000000000000', 'petallengthcm': '3.700000000000000000', 'petalwidthcm': '1.000000000000000000', 'species': 'Iris-versicolor'}, {'id': '83', 'sepallengthcm': '5.800000000000000000', 'sepalwidthcm': '2.700000000000000000', 'petallengthcm': '3.900000000000000000', 'petalwidthcm': '1.200000000000000000', 'species': 'Iris-versicolor'}, {'id': '84', 'sepallengthcm': '6.000000000000000000', 'sepalwidthcm': '2.700000000000000000', 'petallengthcm': '5.100000000000000000', 'petalwidthcm': '1.600000000000000000', 'species': 'Iris-versicolor'}, {'id': '85', 'sepallengthcm': '5.400000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '4.500000000000000000', 'petalwidthcm': '1.500000000000000000', 'species': 'Iris-versicolor'}, {'id': '86', 'sepallengthcm': '6.000000000000000000', 'sepalwidthcm': '3.400000000000000000', 'petallengthcm': '4.500000000000000000', 'petalwidthcm': '1.600000000000000000', 'species': 'Iris-versicolor'}, {'id': '87', 'sepallengthcm': '6.700000000000000000', 'sepalwidthcm': '3.100000000000000000', 'petallengthcm': '4.700000000000000000', 'petalwidthcm': '1.500000000000000000', 'species': 'Iris-versicolor'}, {'id': '88', 'sepallengthcm': '6.300000000000000000', 'sepalwidthcm': '2.300000000000000000', 'petallengthcm': '4.400000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '89', 'sepallengthcm': '5.600000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '4.100000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '90', 'sepallengthcm': '5.500000000000000000', 'sepalwidthcm': '2.500000000000000000', 'petallengthcm': '4.000000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '91', 'sepallengthcm': '5.500000000000000000', 'sepalwidthcm': '2.600000000000000000', 'petallengthcm': '4.400000000000000000', 'petalwidthcm': '1.200000000000000000', 'species': 'Iris-versicolor'}, {'id': '92', 'sepallengthcm': '6.100000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '4.600000000000000000', 'petalwidthcm': '1.400000000000000000', 'species': 'Iris-versicolor'}, {'id': '93', 'sepallengthcm': '5.800000000000000000', 'sepalwidthcm': '2.600000000000000000', 'petallengthcm': '4.000000000000000000', 'petalwidthcm': '1.200000000000000000', 'species': 'Iris-versicolor'}, {'id': '94', 'sepallengthcm': '5.000000000000000000', 'sepalwidthcm': '2.300000000000000000', 'petallengthcm': '3.300000000000000000', 'petalwidthcm': '1.000000000000000000', 'species': 'Iris-versicolor'}, {'id': '95', 'sepallengthcm': '5.600000000000000000', 'sepalwidthcm': '2.700000000000000000', 'petallengthcm': '4.200000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '96', 'sepallengthcm': '5.700000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '4.200000000000000000', 'petalwidthcm': '1.200000000000000000', 'species': 'Iris-versicolor'}, {'id': '97', 'sepallengthcm': '5.700000000000000000', 'sepalwidthcm': '2.900000000000000000', 'petallengthcm': '4.200000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '98', 'sepallengthcm': '6.200000000000000000', 'sepalwidthcm': '2.900000000000000000', 'petallengthcm': '4.300000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '99', 'sepallengthcm': '5.100000000000000000', 'sepalwidthcm': '2.500000000000000000', 'petallengthcm': '3.000000000000000000', 'petalwidthcm': '1.100000000000000000', 'species': 'Iris-versicolor'}, {'id': '100', 'sepallengthcm': '5.700000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '4.100000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '101', 'sepallengthcm': '6.300000000000000000', 'sepalwidthcm': '3.300000000000000000', 'petallengthcm': '6.000000000000000000', 'petalwidthcm': '2.500000000000000000', 'species': 'Iris-virginica'}, {'id': '102', 'sepallengthcm': '5.800000000000000000', 'sepalwidthcm': '2.700000000000000000', 'petallengthcm': '5.100000000000000000', 'petalwidthcm': '1.900000000000000000', 'species': 'Iris-virginica'}, {'id': '103', 'sepallengthcm': '7.100000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '5.900000000000000000', 'petalwidthcm': '2.100000000000000000', 'species': 'Iris-virginica'}, {'id': '104', 'sepallengthcm': '6.300000000000000000', 'sepalwidthcm': '2.900000000000000000', 'petallengthcm': '5.600000000000000000', 'petalwidthcm': '1.800000000000000000', 'species': 'Iris-virginica'}, {'id': '105', 'sepallengthcm': '6.500000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '5.800000000000000000', 'petalwidthcm': '2.200000000000000000', 'species': 'Iris-virginica'}, {'id': '106', 'sepallengthcm': '7.600000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '6.600000000000000000', 'petalwidthcm': '2.100000000000000000', 'species': 'Iris-virginica'}, {'id': '107', 'sepallengthcm': '4.900000000000000000', 'sepalwidthcm': '2.500000000000000000', 'petallengthcm': '4.500000000000000000', 'petalwidthcm': '1.700000000000000000', 'species': 'Iris-virginica'}, {'id': '108', 'sepallengthcm': '7.300000000000000000', 'sepalwidthcm': '2.900000000000000000', 'petallengthcm': '6.300000000000000000', 'petalwidthcm': '1.800000000000000000', 'species': 'Iris-virginica'}, {'id': '109', 'sepallengthcm': '6.700000000000000000', 'sepalwidthcm': '2.500000000000000000', 'petallengthcm': '5.800000000000000000', 'petalwidthcm': '1.800000000000000000', 'species': 'Iris-virginica'}, {'id': '110', 'sepallengthcm': '7.200000000000000000', 'sepalwidthcm': '3.600000000000000000', 'petallengthcm': '6.100000000000000000', 'petalwidthcm': '2.500000000000000000', 'species': 'Iris-virginica'}, {'id': '111', 'sepallengthcm': '6.500000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '5.100000000000000000', 'petalwidthcm': '2.000000000000000000', 'species': 'Iris-virginica'}, {'id': '112', 'sepallengthcm': '6.400000000000000000', 'sepalwidthcm': '2.700000000000000000', 'petallengthcm': '5.300000000000000000', 'petalwidthcm': '1.900000000000000000', 'species': 'Iris-virginica'}, {'id': '113', 'sepallengthcm': '6.800000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '5.500000000000000000', 'petalwidthcm': '2.100000000000000000', 'species': 'Iris-virginica'}, {'id': '114', 'sepallengthcm': '5.700000000000000000', 'sepalwidthcm': '2.500000000000000000', 'petallengthcm': '5.000000000000000000', 'petalwidthcm': '2.000000000000000000', 'species': 'Iris-virginica'}, {'id': '115', 'sepallengthcm': '5.800000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '5.100000000000000000', 'petalwidthcm': '2.400000000000000000', 'species': 'Iris-virginica'}, {'id': '116', 'sepallengthcm': '6.400000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '5.300000000000000000', 'petalwidthcm': '2.300000000000000000', 'species': 'Iris-virginica'}, {'id': '117', 'sepallengthcm': '6.500000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '5.500000000000000000', 'petalwidthcm': '1.800000000000000000', 'species': 'Iris-virginica'}, {'id': '118', 'sepallengthcm': '7.700000000000000000', 'sepalwidthcm': '3.800000000000000000', 'petallengthcm': '6.700000000000000000', 'petalwidthcm': '2.200000000000000000', 'species': 'Iris-virginica'}, {'id': '119', 'sepallengthcm': '7.700000000000000000', 'sepalwidthcm': '2.600000000000000000', 'petallengthcm': '6.900000000000000000', 'petalwidthcm': '2.300000000000000000', 'species': 'Iris-virginica'}, {'id': '120', 'sepallengthcm': '6.000000000000000000', 'sepalwidthcm': '2.200000000000000000', 'petallengthcm': '5.000000000000000000', 'petalwidthcm': '1.500000000000000000', 'species': 'Iris-virginica'}, {'id': '121', 'sepallengthcm': '6.900000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '5.700000000000000000', 'petalwidthcm': '2.300000000000000000', 'species': 'Iris-virginica'}, {'id': '122', 'sepallengthcm': '5.600000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '4.900000000000000000', 'petalwidthcm': '2.000000000000000000', 'species': 'Iris-virginica'}, {'id': '123', 'sepallengthcm': '7.700000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '6.700000000000000000', 'petalwidthcm': '2.000000000000000000', 'species': 'Iris-virginica'}, {'id': '124', 'sepallengthcm': '6.300000000000000000', 'sepalwidthcm': '2.700000000000000000', 'petallengthcm': '4.900000000000000000', 'petalwidthcm': '1.800000000000000000', 'species': 'Iris-virginica'}, {'id': '125', 'sepallengthcm': '6.700000000000000000', 'sepalwidthcm': '3.300000000000000000', 'petallengthcm': '5.700000000000000000', 'petalwidthcm': '2.100000000000000000', 'species': 'Iris-virginica'}, {'id': '126', 'sepallengthcm': '7.200000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '6.000000000000000000', 'petalwidthcm': '1.800000000000000000', 'species': 'Iris-virginica'}, {'id': '127', 'sepallengthcm': '6.200000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '4.800000000000000000', 'petalwidthcm': '1.800000000000000000', 'species': 'Iris-virginica'}, {'id': '128', 'sepallengthcm': '6.100000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '4.900000000000000000', 'petalwidthcm': '1.800000000000000000', 'species': 'Iris-virginica'}, {'id': '129', 'sepallengthcm': '6.400000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '5.600000000000000000', 'petalwidthcm': '2.100000000000000000', 'species': 'Iris-virginica'}, {'id': '130', 'sepallengthcm': '7.200000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '5.800000000000000000', 'petalwidthcm': '1.600000000000000000', 'species': 'Iris-virginica'}, {'id': '131', 'sepallengthcm': '7.400000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '6.100000000000000000', 'petalwidthcm': '1.900000000000000000', 'species': 'Iris-virginica'}, {'id': '132', 'sepallengthcm': '7.900000000000000000', 'sepalwidthcm': '3.800000000000000000', 'petallengthcm': '6.400000000000000000', 'petalwidthcm': '2.000000000000000000', 'species': 'Iris-virginica'}, {'id': '133', 'sepallengthcm': '6.400000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '5.600000000000000000', 'petalwidthcm': '2.200000000000000000', 'species': 'Iris-virginica'}, {'id': '134', 'sepallengthcm': '6.300000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '5.100000000000000000', 'petalwidthcm': '1.500000000000000000', 'species': 'Iris-virginica'}, {'id': '135', 'sepallengthcm': '6.100000000000000000', 'sepalwidthcm': '2.600000000000000000', 'petallengthcm': '5.600000000000000000', 'petalwidthcm': '1.400000000000000000', 'species': 'Iris-virginica'}, {'id': '136', 'sepallengthcm': '7.700000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '6.100000000000000000', 'petalwidthcm': '2.300000000000000000', 'species': 'Iris-virginica'}, {'id': '137', 'sepallengthcm': '6.300000000000000000', 'sepalwidthcm': '3.400000000000000000', 'petallengthcm': '5.600000000000000000', 'petalwidthcm': '2.400000000000000000', 'species': 'Iris-virginica'}, {'id': '138', 'sepallengthcm': '6.400000000000000000', 'sepalwidthcm': '3.100000000000000000', 'petallengthcm': '5.500000000000000000', 'petalwidthcm': '1.800000000000000000', 'species': 'Iris-virginica'}, {'id': '139', 'sepallengthcm': '6.000000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '4.800000000000000000', 'petalwidthcm': '1.800000000000000000', 'species': 'Iris-virginica'}, {'id': '140', 'sepallengthcm': '6.900000000000000000', 'sepalwidthcm': '3.100000000000000000', 'petallengthcm': '5.400000000000000000', 'petalwidthcm': '2.100000000000000000', 'species': 'Iris-virginica'}, {'id': '141', 'sepallengthcm': '6.700000000000000000', 'sepalwidthcm': '3.100000000000000000', 'petallengthcm': '5.600000000000000000', 'petalwidthcm': '2.400000000000000000', 'species': 'Iris-virginica'}, {'id': '142', 'sepallengthcm': '6.900000000000000000', 'sepalwidthcm': '3.100000000000000000', 'petallengthcm': '5.100000000000000000', 'petalwidthcm': '2.300000000000000000', 'species': 'Iris-virginica'}, {'id': '143', 'sepallengthcm': '5.800000000000000000', 'sepalwidthcm': '2.700000000000000000', 'petallengthcm': '5.100000000000000000', 'petalwidthcm': '1.900000000000000000', 'species': 'Iris-virginica'}, {'id': '144', 'sepallengthcm': '6.800000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '5.900000000000000000', 'petalwidthcm': '2.300000000000000000', 'species': 'Iris-virginica'}, {'id': '145', 'sepallengthcm': '6.700000000000000000', 'sepalwidthcm': '3.300000000000000000', 'petallengthcm': '5.700000000000000000', 'petalwidthcm': '2.500000000000000000', 'species': 'Iris-virginica'}, {'id': '146', 'sepallengthcm': '6.700000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '5.200000000000000000', 'petalwidthcm': '2.300000000000000000', 'species': 'Iris-virginica'}, {'id': '147', 'sepallengthcm': '6.300000000000000000', 'sepalwidthcm': '2.500000000000000000', 'petallengthcm': '5.000000000000000000', 'petalwidthcm': '1.900000000000000000', 'species': 'Iris-virginica'}, {'id': '148', 'sepallengthcm': '6.500000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '5.200000000000000000', 'petalwidthcm': '2.000000000000000000', 'species': 'Iris-virginica'}, {'id': '149', 'sepallengthcm': '6.200000000000000000', 'sepalwidthcm': '3.400000000000000000', 'petallengthcm': '5.400000000000000000', 'petalwidthcm': '2.300000000000000000', 'species': 'Iris-virginica'}, {'id': '150', 'sepallengthcm': '5.900000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '5.100000000000000000', 'petalwidthcm': '1.800000000000000000', 'species': 'Iris-virginica'}]\\\\n\\\",\\n+      \\\"<built-in method count of list object at 0x000001B2518C1700>\\\\n\\\"\\n+     ]\\n+    }\\n+   ],\\n+   \\\"source\\\": [\\n+    \\\"# API endpoint URL\\\\n\\\",\\n+    \\\"API_URL = \\\\\\\"http://localhost/api/database/c3a42d17-42b7-43c9-a504-2363fb4c9c8d/table/5315e7da-64fb-4fdb-b493-95b4138c765f/data?size=100000&page=0\\\\\\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# Define the headers\\\\n\\\",\\n+    \\\"headers = {\\\\n\\\",\\n+    \\\"    \\\\\\\"Accept\\\\\\\": \\\\\\\"application/json\\\\\\\"  # Specify the expected response format\\\\n\\\",\\n+    \\\"}\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"try:\\\\n\\\",\\n+    \\\"    # Send a GET request to the API with the Accept header\\\\n\\\",\\n+    \\\"    response = requests.get(API_URL, headers=headers)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # Check if the request was successful\\\\n\\\",\\n+    \\\"    if response.status_code == 200:\\\\n\\\",\\n+    \\\"        # Parse the JSON response\\\\n\\\",\\n+    \\\"        dataset = response.json()\\\\n\\\",\\n+    \\\"        print(\\\\\\\"API Response:\\\\\\\", dataset)\\\\n\\\",\\n+    \\\"        print( dataset.count)\\\\n\\\",\\n+    \\\"    else:\\\\n\\\",\\n+    \\\"        print(f\\\\\\\"Error: Received status code {response.status_code}\\\\\\\")\\\\n\\\",\\n+    \\\"        print(\\\\\\\"Response content:\\\\\\\", response.text)\\\\n\\\",\\n+    \\\"       \\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"except requests.exceptions.RequestException as e:\\\\n\\\",\\n+    \\\"    print(f\\\\\\\"Request failed: {e}\\\\\\\")\\\\n\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"09557f94-325c-4bd6-882a-069a9e3c5ecd\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"replacing dynamic fetching of data When and if DBREPO isnt running \\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 11,\\n+   \\\"id\\\": \\\"ce6e020d-cb80-49ec-8bcc-687b1e08885c\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [],\\n+   \\\"source\\\": [\\n+    \\\"# 1. Read the JSON file id the API isnt available this data is saved locally but the data is from the API endpoint\\\\n\\\",\\n+    \\\"with open(\\\\\\\"iris_data.json\\\\\\\", \\\\\\\"r\\\\\\\") as f:\\\\n\\\",\\n+    \\\"    dataset = json.load(f)\\\\n\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"a6c6007a-2126-4b1a-90ee-3326eb39a362\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"Metadata fetching from db repo API CALLS\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"9165f478-a44e-4125-8929-a8d77fdcb4c5\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"METADATA ON DATABASE LEVEL\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 33,\\n+   \\\"id\\\": \\\"abe912e7-bf9b-4bbd-8e43-6046745ade3f\\\",\\n+   \\\"metadata\\\": {\\n+    \\\"scrolled\\\": true\\n+   },\\n+   \\\"outputs\\\": [],\\n+   \\\"source\\\": [\\n+    \\\"\\\\n\\\",\\n+    \\\"DB_API = \\\\\\\"http://localhost/api/database/{db_id}\\\\\\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"def fetch_db_metadata(db_id: str) -> dict:\\\\n\\\",\\n+    \\\"    url = DB_API.format(db_id=db_id)\\\\n\\\",\\n+    \\\"    try:\\\\n\\\",\\n+    \\\"        resp = requests.get(url)\\\\n\\\",\\n+    \\\"        resp.raise_for_status()\\\\n\\\",\\n+    \\\"        return resp.json()\\\\n\\\",\\n+    \\\"    except requests.exceptions.RequestException as e:\\\\n\\\",\\n+    \\\"        print(f\\\\\\\"[\\u26a0\\ufe0f Error] Failed to fetch DB metadata for {db_id}: {e}\\\\\\\")\\\\n\\\",\\n+    \\\"        return {}  # or return None, depending on what your app prefers\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"def log_db_metadata(db_meta: dict):\\\\n\\\",\\n+    \\\"    # 1) Core DB fields as params, defaulting to empty string if key is missing\\\\n\\\",\\n+    \\\"    mlflow.log_param(\\\\\\\"database.id\\\\\\\",          db_meta.get(\\\\\\\"id\\\\\\\", \\\\\\\"\\\\\\\"))\\\\n\\\",\\n+    \\\"    mlflow.log_param(\\\\\\\"database.name\\\\\\\",        db_meta.get(\\\\\\\"name\\\\\\\", \\\\\\\"\\\\\\\"))\\\\n\\\",\\n+    \\\"    mlflow.log_param(\\\\\\\"database.description\\\\\\\", db_meta.get(\\\\\\\"description\\\\\\\", \\\\\\\"\\\\\\\"))\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # 2) Handle nested keys safely for owner\\\\n\\\",\\n+    \\\"    try:\\\\n\\\",\\n+    \\\"        owner = db_meta.get(\\\\\\\"tables\\\\\\\", [{}])[0].get(\\\\\\\"owner\\\\\\\", {}).get(\\\\\\\"username\\\\\\\", \\\\\\\"\\\\\\\")\\\\n\\\",\\n+    \\\"    except Exception:\\\\n\\\",\\n+    \\\"        owner = \\\\\\\"\\\\\\\"\\\\n\\\",\\n+    \\\"    mlflow.log_param(\\\\\\\"database.owner\\\\\\\", owner)\\\\n\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"53cbd7eb-0d97-4326-9bfc-f6fcee14ef9c\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"MATADATA FROM: <ns0:OAI-PMH xmlns:ns0=\\\\\\\"http://www.openarchives.org/OAI/2.0/\\\\\\\" xmlns:xsi=\\\\\\\"http://www.w3.org/2001/XMLSchema-instance\\\\\\\" xsi:schemaLocation=\\\\\\\"http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd\\\\\\\">\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 34,\\n+   \\\"id\\\": \\\"296f307e-e01b-477a-9406-92cab9f2d7bf\\\",\\n+   \\\"metadata\\\": {\\n+    \\\"scrolled\\\": true\\n+   },\\n+   \\\"outputs\\\": [\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"<ns0:OAI-PMH xmlns:ns0=\\\\\\\"http://www.openarchives.org/OAI/2.0/\\\\\\\" xmlns:xsi=\\\\\\\"http://www.w3.org/2001/XMLSchema-instance\\\\\\\" xsi:schemaLocation=\\\\\\\"http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd\\\\\\\">\\\\n\\\",\\n+      \\\"    <ns0:responseDate>2025-04-25T09:55:50Z</ns0:responseDate>\\\\n\\\",\\n+      \\\"    <ns0:request verb=\\\\\\\"Identify\\\\\\\">https://localhost/api/oai</ns0:request>\\\\n\\\",\\n+      \\\"    <ns0:Identify>\\\\n\\\",\\n+      \\\"    <ns0:repositoryName>Database Repository</ns0:repositoryName>\\\\n\\\",\\n+      \\\"    <ns0:baseURL>http://localhost</ns0:baseURL>\\\\n\\\",\\n+      \\\"    <ns0:protocolVersion>2.0</ns0:protocolVersion>\\\\n\\\",\\n+      \\\"    <ns0:adminEmail>noreply@localhost</ns0:adminEmail>\\\\n\\\",\\n+      \\\"    <ns0:earliestDatestamp />\\\\n\\\",\\n+      \\\"    <ns0:deletedRecord>persistent</ns0:deletedRecord>\\\\n\\\",\\n+      \\\"    <ns0:granularity>YYYY-MM-DDThh:mm:ssZ</ns0:granularity>\\\\n\\\",\\n+      \\\"</ns0:Identify>\\\\n\\\",\\n+      \\\"</ns0:OAI-PMH>\\\\n\\\"\\n+     ]\\n+    }\\n+   ],\\n+   \\\"source\\\": [\\n+    \\\"# 1) Fetch your database metadata\\\\n\\\",\\n+    \\\"db_url = \\\\\\\"http://localhost/api/database/c3a42d17-42b7-43c9-a504-2363fb4c9c8d\\\\\\\"\\\\n\\\",\\n+    \\\"db_resp = requests.get(db_url)\\\\n\\\",\\n+    \\\"db_resp.raise_for_status()\\\\n\\\",\\n+    \\\"db_data = db_resp.json()\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"db_id  = db_data[\\\\\\\"id\\\\\\\"]\\\\n\\\",\\n+    \\\"tbl_id = db_data[\\\\\\\"tables\\\\\\\"][0][\\\\\\\"id\\\\\\\"]\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# 2) Build the OAI-PMH URL, URL-encoding the `set` param\\\\n\\\",\\n+    \\\"set_param   = f\\\\\\\"Databases/{db_id}/Tables/{tbl_id}\\\\\\\"\\\\n\\\",\\n+    \\\"encoded_set = urllib.parse.quote(set_param, safe=\\\\\\\"\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"oai_url = (\\\\n\\\",\\n+    \\\"    \\\\\\\"http://localhost/api/oai\\\\\\\"\\\\n\\\",\\n+    \\\"    f\\\\\\\"?metadataPrefix=oai_dc\\\\\\\"\\\\n\\\",\\n+    \\\"    f\\\\\\\"&from=2025-03-01\\\\\\\"\\\\n\\\",\\n+    \\\"    f\\\\\\\"&until=2025-03-07\\\\\\\"\\\\n\\\",\\n+    \\\"    f\\\\\\\"&set={encoded_set}\\\\\\\"\\\\n\\\",\\n+    \\\"    f\\\\\\\"&resumptionToken=string\\\\\\\"\\\\n\\\",\\n+    \\\"    f\\\\\\\"&fromDate=2025-03-07T19%3A35%3A51.476Z\\\\\\\"\\\\n\\\",\\n+    \\\"    f\\\\\\\"&untilDate=2025-03-07T19%3A35%3A51.476Z\\\\\\\"\\\\n\\\",\\n+    \\\"    f\\\\\\\"&parametersString=string\\\\\\\"\\\\n\\\",\\n+    \\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# 3) Call and parse\\\\n\\\",\\n+    \\\"try:\\\\n\\\",\\n+    \\\"    resp = requests.get(oai_url)\\\\n\\\",\\n+    \\\"    resp.raise_for_status()\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    if \\\\\\\"xml\\\\\\\" in resp.headers.get(\\\\\\\"Content-Type\\\\\\\", \\\\\\\"\\\\\\\"):\\\\n\\\",\\n+    \\\"        root = ET.fromstring(resp.text)\\\\n\\\",\\n+    \\\"        print(ET.tostring(root, encoding=\\\\\\\"utf-8\\\\\\\").decode())\\\\n\\\",\\n+    \\\"    else:\\\\n\\\",\\n+    \\\"        print(\\\\\\\"Non-XML response:\\\\\\\", resp.headers.get(\\\\\\\"Content-Type\\\\\\\"), resp.text)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"except requests.exceptions.RequestException as e:\\\\n\\\",\\n+    \\\"    print(\\\\\\\"Request failed:\\\\\\\", e)\\\\n\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 35,\\n+   \\\"id\\\": \\\"61cc99ab-4a5c-4142-8725-e7c940673ffd\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [],\\n+   \\\"source\\\": [\\n+    \\\"# \\u2026after you fetch & parse your XML into `root`\\u2026\\\\n\\\",\\n+    \\\"ns = {\\\\\\\"oai\\\\\\\": \\\\\\\"http://www.openarchives.org/OAI/2.0/\\\\\\\"}\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"repo_name   = root.findtext(\\\\\\\"oai:Identify/oai:repositoryName\\\\\\\", namespaces=ns) or \\\\\\\"N/A\\\\\\\"\\\\n\\\",\\n+    \\\"base_url    = root.findtext(\\\\\\\"oai:Identify/oai:baseURL\\\\\\\", namespaces=ns) or \\\\\\\"N/A\\\\\\\"\\\\n\\\",\\n+    \\\"protocol    = root.findtext(\\\\\\\"oai:Identify/oai:protocolVersion\\\\\\\", namespaces=ns) or \\\\\\\"N/A\\\\\\\"\\\\n\\\",\\n+    \\\"admin_email = root.findtext(\\\\\\\"oai:Identify/oai:adminEmail\\\\\\\", namespaces=ns) or \\\\\\\"N/A\\\\\\\"\\\\n\\\",\\n+    \\\"gran        = root.findtext(\\\\\\\"oai:Identify/oai:granularity\\\\\\\", namespaces=ns) or \\\\\\\"N/A\\\\\\\"\\\\n\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"74214aa7-c12f-414e-9feb-094a366b855b\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"METADATA ON History Logging\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 36,\\n+   \\\"id\\\": \\\"e9c74e9b-c9b0-4b4a-82eb-2a6e56456508\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"API Response: [{'timestamp': '2025-04-23T20:42:29.501Z', 'event': 'insert', 'total': 150}]\\\\n\\\"\\n+     ]\\n+    }\\n+   ],\\n+   \\\"source\\\": [\\n+    \\\"url = \\\\\\\"http://localhost/api/database/c3a42d17-42b7-43c9-a504-2363fb4c9c8d/table/5315e7da-64fb-4fdb-b493-95b4138c765f/history\\\\\\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"try:\\\\n\\\",\\n+    \\\"    # Send a GET request to the API\\\\n\\\",\\n+    \\\"    response = requests.get(url)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # Check if the request was successful\\\\n\\\",\\n+    \\\"    if response.status_code == 200:\\\\n\\\",\\n+    \\\"        # Parse the JSON response\\\\n\\\",\\n+    \\\"        data = response.json()\\\\n\\\",\\n+    \\\"        print(\\\\\\\"API Response:\\\\\\\", data)\\\\n\\\",\\n+    \\\"    else:\\\\n\\\",\\n+    \\\"        print(f\\\\\\\"Error: Received status code {response.status_code}\\\\\\\")\\\\n\\\",\\n+    \\\"        print(\\\\\\\"Response content:\\\\\\\", response.text)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"except requests.exceptions.RequestException as e:\\\\n\\\",\\n+    \\\"    print(f\\\\\\\"Request failed: {e}\\\\\\\")\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 37,\\n+   \\\"id\\\": \\\"3630c954-5ad2-4759-b9a0-fa6e20e184ef\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [],\\n+   \\\"source\\\": [\\n+    \\\"first   = data[0]\\\\n\\\",\\n+    \\\"last    = data[-1]\\\\n\\\",\\n+    \\\"count_0 = first[\\\\\\\"total\\\\\\\"]    # e.g. 149\\\\n\\\",\\n+    \\\"count_N = last[\\\\\\\"total\\\\\\\"]     # e.g. 149 again, or changed\\\\n\\\",\\n+    \\\"ts_last = last[\\\\\\\"timestamp\\\\\\\"]  # e.g. \\\\\\\"2025-03-28T17:42:38.058Z\\\\\\\"\\\\n\\\",\\n+    \\\"n_insert = sum(1 for ev in data if ev[\\\\\\\"event\\\\\\\"]==\\\\\\\"insert\\\\\\\")\\\\n\\\",\\n+    \\\"n_delete = sum(1 for ev in data if ev[\\\\\\\"event\\\\\\\"]==\\\\\\\"delete\\\\\\\")\\\\n\\\",\\n+    \\\"history = response.json()\\\\n\\\",\\n+    \\\"first, last = history[0], history[-1]\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# summary stats\\\\n\\\",\\n+    \\\"count_start = first[\\\\\\\"total\\\\\\\"]\\\\n\\\",\\n+    \\\"count_end   = last[\\\\\\\"total\\\\\\\"]\\\\n\\\",\\n+    \\\"ts_last     = last[\\\\\\\"timestamp\\\\\\\"]\\\\n\\\",\\n+    \\\"n_insert    = sum(1 for ev in history if ev[\\\\\\\"event\\\\\\\"]==\\\\\\\"insert\\\\\\\")\\\\n\\\",\\n+    \\\"n_delete    = sum(1 for ev in history if ev[\\\\\\\"event\\\\\\\"]==\\\\\\\"delete\\\\\\\")\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"1afd5dad-72d5-42e1-a0fa-b7bd3455937b\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"Dataset metadata fetching from ZONEDO or any public dataset repositories to gain more details\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 38,\\n+   \\\"id\\\": \\\"a7fa122a-c6e5-4b38-842a-dc81590a1f46\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [],\\n+   \\\"source\\\": [\\n+    \\\"\\\\n\\\",\\n+    \\\"def fetch_and_log_dataset_metadata_nested(doi_url: str):\\\\n\\\",\\n+    \\\"    # 1) fetch the CSL+JSON\\\\n\\\",\\n+    \\\"    headers = {\\\\\\\"Accept\\\\\\\": \\\\\\\"application/vnd.citationstyles.csl+json\\\\\\\"}\\\\n\\\",\\n+    \\\"    r = requests.get(doi_url, headers=headers); r.raise_for_status()\\\\n\\\",\\n+    \\\"    meta = r.json()\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # 2) pull out what you care about\\\\n\\\",\\n+    \\\"    authors = [f\\\\\\\"{a.get('family','')} {a.get('given','')}\\\\\\\".strip()\\\\n\\\",\\n+    \\\"               for a in meta.get(\\\\\\\"author\\\\\\\", [])]\\\\n\\\",\\n+    \\\"    pubdate = \\\\\\\"-\\\\\\\".join(str(x) for x in meta.get(\\\\\\\"issued\\\\\\\",{}).get(\\\\\\\"date-parts\\\\\\\",[[]])[0])\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # 3) assemble one nested dict\\\\n\\\",\\n+    \\\"    public_datasetRepository_metadata = {\\\\n\\\",\\n+    \\\"      \\\\\\\"zenodo\\\\\\\": {\\\\n\\\",\\n+    \\\"        \\\\\\\"title\\\\\\\":     meta.get(\\\\\\\"title\\\\\\\"),\\\\n\\\",\\n+    \\\"        \\\\\\\"doi\\\\\\\":       meta.get(\\\\\\\"DOI\\\\\\\"),\\\\n\\\",\\n+    \\\"        \\\\\\\"authors\\\\\\\":   authors,\\\\n\\\",\\n+    \\\"        \\\\\\\"published\\\\\\\": pubdate,\\\\n\\\",\\n+    \\\"        \\\\\\\"publisher\\\\\\\": meta.get(\\\\\\\"publisher\\\\\\\"),\\\\n\\\",\\n+    \\\"      },\\\\n\\\",\\n+    \\\"   \\\\n\\\",\\n+    \\\"    }\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"      # 4) log it as a single JSON artifact\\\\n\\\",\\n+    \\\"    mlflow.log_dict(public_datasetRepository_metadata,\\\\n\\\",\\n+    \\\"                \\\\\\\"public_datasetRepository_metadata.json\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # 2) Flatten and log the important bits as params:\\\\n\\\",\\n+    \\\"    z = public_datasetRepository_metadata[\\\\\\\"zenodo\\\\\\\"]\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    mlflow.log_param(\\\\\\\"dataset.title\\\\\\\",     z[\\\\\\\"title\\\\\\\"])\\\\n\\\",\\n+    \\\"    mlflow.log_param(\\\\\\\"dataset.doi\\\\\\\",       z[\\\\\\\"doi\\\\\\\"])\\\\n\\\",\\n+    \\\"    mlflow.log_param(\\\\\\\"dataset.authors\\\\\\\",   json.dumps(z[\\\\\\\"authors\\\\\\\"]))\\\\n\\\",\\n+    \\\"    mlflow.log_param(\\\\\\\"dataset.published\\\\\\\", z[\\\\\\\"published\\\\\\\"])\\\\n\\\",\\n+    \\\"    mlflow.log_param(\\\\\\\"dataset.publisher\\\\\\\", z[\\\\\\\"publisher\\\\\\\"])\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"   \\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"58c92e13-eb57-418d-b354-83777f88aa98\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"##################################################################\\\\n\\\",\\n+    \\\"# DATA PREPROCESSING STEPS\\\\n\\\",\\n+    \\\"###################################################################\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"9832d0df-af0a-4eee-90d0-fab926e03e85\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"STEP 1: LOAD DATASET\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 39,\\n+   \\\"id\\\": \\\"77402d80-22d1-4bed-9489-768958c3e9fa\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [],\\n+   \\\"source\\\": [\\n+    \\\"# \\u2500\\u2500 2) Load into a DataFrame \\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\\\n\\\",\\n+    \\\"df = pd.DataFrame(dataset)\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"6862e341-3ea1-43f6-a1ac-9a51188fe614\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"STEP2: seperate Dependent and Independent variables and drop unnecessary columns like ID\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 40,\\n+   \\\"id\\\": \\\"01309a7b-53d2-4df4-b334-0f0db8b03333\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"Shapes: (150, 4) (150,)\\\\n\\\"\\n+     ]\\n+    }\\n+   ],\\n+   \\\"source\\\": [\\n+    \\\"target_col = df.columns[-1]      # e.g. \\\\\\\"species\\\\\\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# 2) extract y as the Series of labels\\\\n\\\",\\n+    \\\"y = df[target_col]               # length == n_samples\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# 3) build X by dropping just that one column\\\\n\\\",\\n+    \\\"X = df.drop(columns=[target_col])\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# 4) drop any ID column (case-insensitive)\\\\n\\\",\\n+    \\\"id_cols = [c for c in X.columns if c.lower() == \\\\\\\"id\\\\\\\"]\\\\n\\\",\\n+    \\\"if id_cols:\\\\n\\\",\\n+    \\\"    X = X.drop(columns=id_cols)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# 5) coerce numeric where possible\\\\n\\\",\\n+    \\\"for c in X.columns:\\\\n\\\",\\n+    \\\"    try:\\\\n\\\",\\n+    \\\"        X[c] = pd.to_numeric(X[c])\\\\n\\\",\\n+    \\\"    except Exception:\\\\n\\\",\\n+    \\\"        pass\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"print(\\\\\\\"Shapes:\\\\\\\", X.shape, y.shape)\\\\n\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"367d6256-a30a-4f91-bc64-f20966d828ab\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"STEP3: Label Encoding as the target values are class names\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 41,\\n+   \\\"id\\\": \\\"11f5126d-6a03-48c6-9ecf-39ed0d43688c\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"Classes: ['Iris-setosa' 'Iris-versicolor' 'Iris-virginica']\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"data\\\": {\\n+      \\\"text/plain\\\": [\\n+       \\\"array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\\\\n\\\",\\n+       \\\"       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\\\\n\\\",\\n+       \\\"       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\\\\n\\\",\\n+       \\\"       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\\\\n\\\",\\n+       \\\"       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\\\\n\\\",\\n+       \\\"       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\\\\n\\\",\\n+       \\\"       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\\\"\\n+      ]\\n+     },\\n+     \\\"execution_count\\\": 41,\\n+     \\\"metadata\\\": {},\\n+     \\\"output_type\\\": \\\"execute_result\\\"\\n+    }\\n+   ],\\n+   \\\"source\\\": [\\n+    \\\"\\\\n\\\",\\n+    \\\"le = LabelEncoder()\\\\n\\\",\\n+    \\\"y = le.fit_transform(y)  \\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# now y_enc is a 1d numpy array of ints 0,1,2\\\\n\\\",\\n+    \\\"print(\\\\\\\"Classes:\\\\\\\", le.classes_)  \\\\n\\\",\\n+    \\\"y\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 42,\\n+   \\\"id\\\": \\\"68d0a924-c65f-4a44-a5cc-bbb32d17e96f\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [],\\n+   \\\"source\\\": [\\n+    \\\"# \\u2500\\u2500 4) Cast feature columns to numeric where possible \\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\\\n\\\",\\n+    \\\"for col in X.columns:\\\\n\\\",\\n+    \\\"    try:\\\\n\\\",\\n+    \\\"        X[col] = pd.to_numeric(X[col])   # no errors=\\\\\\\"ignore\\\\\\\"\\\\n\\\",\\n+    \\\"    except ValueError:\\\\n\\\",\\n+    \\\"        # if it can\\u2019t be cast, just leave it as-is\\\\n\\\",\\n+    \\\"        pass\\\\n\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 43,\\n+   \\\"id\\\": \\\"e17f39ce-3322-4626-83a6-079d304bbc04\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [],\\n+   \\\"source\\\": [\\n+    \\\"# \\u2500\\u2500 5) Drop any \\u201cid\\u201d column (case-insensitive) \\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\\\n\\\",\\n+    \\\"dropped = [c for c in X.columns if c.lower() == \\\\\\\"id\\\\\\\"]\\\\n\\\",\\n+    \\\"X = X.drop(columns=dropped, errors=\\\\\\\"ignore\\\\\\\")\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"6fcf2244-14dd-4e3d-b8cf-f7f3ba34f80f\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"# \\ud83d\\udcc2 Setup MLflow\\\\n\\\",\\n+    \\\"# ============================\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 44,\\n+   \\\"id\\\": \\\"cbe91ec0-6447-4586-b7cc-2c1f74d4218f\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [\\n+    {\\n+     \\\"data\\\": {\\n+      \\\"text/plain\\\": [\\n+       \\\"<Experiment: artifact_location='file:///C:/Users/reema/REPO/notebooks/RQ_notebooks/mlrunlogs/mlflow.db/615223710259862608', creation_time=1745329164532, experiment_id='615223710259862608', last_update_time=1745329164532, lifecycle_stage='active', name='RandomForest-Iris-CSV', tags={}>\\\"\\n+      ]\\n+     },\\n+     \\\"execution_count\\\": 44,\\n+     \\\"metadata\\\": {},\\n+     \\\"output_type\\\": \\\"execute_result\\\"\\n+    }\\n+   ],\\n+   \\\"source\\\": [\\n+    \\\"\\\\n\\\",\\n+    \\\"project_dir = os.getcwd()\\\\n\\\",\\n+    \\\"mlflow.set_tracking_uri(\\\\\\\"mlrunlogs/mlflow.db\\\\\\\")\\\\n\\\",\\n+    \\\"mlflow.set_experiment(\\\\\\\"RandomForest-Iris-CSV\\\\\\\")\\\\n\\\",\\n+    \\\"# mlflow.sklearn.autolog()\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"af2c2c5f-cc36-41a3-9643-83ef95b9f55e\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"# \\ud83d\\udd04 Git Commit Hash for previous commit for metadata\\\\n\\\",\\n+    \\\"# ============================\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 45,\\n+   \\\"id\\\": \\\"838dd233-25dc-4725-974d-4da89c257782\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [],\\n+   \\\"source\\\": [\\n+    \\\"\\\\n\\\",\\n+    \\\"repo_dir = \\\\\\\"C:/Users/reema/REPO\\\\\\\"\\\\n\\\",\\n+    \\\"previous_commit_repo = git.Repo(repo_dir)\\\\n\\\",\\n+    \\\"previous_commit_hash = previous_commit_repo.head.object.hexsha\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"430d15ef-3432-4e45-88fb-b7048a5b10a9\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"# Make threadpoolctl safe so MLflow\\u2019s autologger won\\u2019t crash \\u2500\\u2500\\u2500\\\\n\\\",\\n+    \\\"# ============================\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 46,\\n+   \\\"id\\\": \\\"9668451f-4352-4bdc-8b6b-bbe49074212a\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [\\n+    {\\n+     \\\"name\\\": \\\"stderr\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"2025/04/25 11:57:54 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\\\\n\\\",\\n+      \\\"2025/04/25 11:57:54 INFO mlflow.tracking.fluent: Autologging successfully enabled for statsmodels.\\\\n\\\"\\n+     ]\\n+    }\\n+   ],\\n+   \\\"source\\\": [\\n+    \\\"try:\\\\n\\\",\\n+    \\\"    import threadpoolctl\\\\n\\\",\\n+    \\\"    _orig = threadpoolctl.threadpool_info\\\\n\\\",\\n+    \\\"    def _safe_threadpool_info(*args, **kwargs):\\\\n\\\",\\n+    \\\"        try:\\\\n\\\",\\n+    \\\"            return _orig(*args, **kwargs)\\\\n\\\",\\n+    \\\"        except Exception:\\\\n\\\",\\n+    \\\"            return []\\\\n\\\",\\n+    \\\"    threadpoolctl.threadpool_info = _safe_threadpool_info\\\\n\\\",\\n+    \\\"except ImportError:\\\\n\\\",\\n+    \\\"    pass  # if threadpoolctl isn\\u2019t installed, autolog will skip unsupported versions\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# \\u2500\\u2500\\u2500 1) Enable generic autolog (will auto-patch sklearn under the hood) \\u2500\\u2500\\u2500\\\\n\\\",\\n+    \\\"import mlflow\\\\n\\\",\\n+    \\\"mlflow.autolog(\\\\n\\\",\\n+    \\\"    log_input_examples=True,\\\\n\\\",\\n+    \\\"    log_model_signatures=True\\\\n\\\",\\n+    \\\")\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"cba22f52-178f-48e6-a9e0-7ef23a886f01\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"#################################################\\\\n\\\",\\n+    \\\"# Justification LOGGER\\\\n\\\",\\n+    \\\"################################################\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 80,\\n+   \\\"id\\\": \\\"afb626b4-8532-4011-bdc8-7424a6289bb7\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [],\\n+   \\\"source\\\": []\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"9058319a-adba-4a6b-93e9-d17080c0594d\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"# \\ud83d\\ude80 Start MLflow Run \\\\n\\\",\\n+    \\\"# ============================\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 83,\\n+   \\\"id\\\": \\\"14c62f08-a116-4060-9689-f69968e9f240\\\",\\n+   \\\"metadata\\\": {\\n+    \\\"scrolled\\\": true\\n+   },\\n+   \\\"outputs\\\": [\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\\\n\\\",\\n+      \\\"\\ud83d\\udcdd Justification for `n_estimators` (Hyperparameter configuration)\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdin\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\u2192 Why did you choose this value?  GRID SEARCH suggesstion\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\\\n\\\",\\n+      \\\"\\ud83d\\udcdd Justification for `criterion` (Hyperparameter configuration)\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdin\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\u2192 Why did you choose this value?  GRID SEARCH suggesstion\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\\\n\\\",\\n+      \\\"\\ud83d\\udcdd Justification for `max_depth` (Hyperparameter configuration)\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdin\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\u2192 Why did you choose this value?  GRID SEARCH suggesstion\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\\\n\\\",\\n+      \\\"\\ud83d\\udcdd Justification for `min_samples_split` (Hyperparameter configuration)\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdin\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\u2192 Why did you choose this value?  GRID SEARCH suggesstion\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\\\n\\\",\\n+      \\\"\\ud83d\\udcdd Justification for `min_samples_leaf` (Hyperparameter configuration)\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdin\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\u2192 Why did you choose this value?  GRID SEARCH suggesstion\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\\\n\\\",\\n+      \\\"\\ud83d\\udcdd Justification for `max_features` (Hyperparameter configuration)\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdin\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\u2192 Why did you choose this value?  GRID SEARCH suggesstion\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\\\n\\\",\\n+      \\\"\\ud83d\\udcdd Justification for `bootstrap` (Hyperparameter configuration)\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdin\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\u2192 Why did you choose this value?  GRID SEARCH suggesstion\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\\\n\\\",\\n+      \\\"\\ud83d\\udcdd Justification for `oob_score` (Hyperparameter configuration)\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdin\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\u2192 Why did you choose this value?  GRID SEARCH suggesstion\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\\\n\\\",\\n+      \\\"\\ud83d\\udcdd Justification for `class_weight` (Hyperparameter configuration)\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdin\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\u2192 Why did you choose this value?  GRID SEARCH suggesstion\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\\\n\\\",\\n+      \\\"\\ud83d\\udcdd Justification for `random_state` (Hyperparameter configuration)\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdin\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\u2192 Why did you choose this value?  GRID SEARCH suggesstion\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\\\n\\\",\\n+      \\\"\\ud83d\\udcdd Justification for `verbose` (Hyperparameter configuration)\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdin\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\u2192 Why did you choose this value?  GRID SEARCH suggesstion\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\\\n\\\",\\n+      \\\"\\ud83d\\udcdd Justification for `n_jobs` (Hyperparameter configuration)\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdin\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\u2192 Why did you choose this value?  GRID SEARCH suggesstion\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\\\n\\\",\\n+      \\\"\\ud83d\\udcdd Justification for `model_choice`\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdin\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\u2192 Why did you choose RandomForestClassifier for this task?  easy model\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\\\n\\\",\\n+      \\\"\\ud83d\\udcdd Justification for `target_variable`\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdin\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\u2192 Why did you choose this column as the prediction target?  dataset info\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\\\n\\\",\\n+      \\\"\\ud83d\\udcdd Justification for `test_split`\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdin\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\u2192 Why this train/test ratio (e.g., 80/20)?  makes sense\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\\\n\\\",\\n+      \\\"\\ud83d\\udcdd Justification for `metric_choice`\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdin\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\u2192 Why accuracy/f1/ROC-AUC as your evaluation metric?  s\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\\\n\\\",\\n+      \\\"\\ud83d\\udcdd Justification for `threshold_accuracy`\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdin\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\u2192 Why 0.95 as performance threshold?  fluid atm\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\\\n\\\",\\n+      \\\"\\ud83d\\udcdd Justification for `dataset_version`\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdin\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\u2192 Why use this specific dataset version?  its available\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\\\n\\\",\\n+      \\\"\\ud83d\\udcdd Justification for `drop_column_X`\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdin\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\u2192 Why drop any specific columns from the dataset?  id\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\\\n\\\",\\n+      \\\"\\ud83d\\udcdd Justification for `experiment_name`\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdin\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\u2192 Any context behind this experiment name or setup?  makes sense\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stderr\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.0s\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    0.2s\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    0.2s finished\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Done 200 out of 200 | elapsed:    0.0s finished\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Done 200 out of 200 | elapsed:    0.0s finished\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Done 200 out of 200 | elapsed:    0.0s finished\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Done 200 out of 200 | elapsed:    0.0s finished\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Done 200 out of 200 | elapsed:    0.0s finished\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"data\\\": {\\n+      \\\"application/vnd.jupyter.widget-view+json\\\": {\\n+       \\\"model_id\\\": \\\"a64e4f0522d8493995df18aaaba889fc\\\",\\n+       \\\"version_major\\\": 2,\\n+       \\\"version_minor\\\": 0\\n+      },\\n+      \\\"text/plain\\\": [\\n+       \\\"Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]\\\"\\n+      ]\\n+     },\\n+     \\\"metadata\\\": {},\\n+     \\\"output_type\\\": \\\"display_data\\\"\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stderr\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Done 200 out of 200 | elapsed:    0.0s finished\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Done 200 out of 200 | elapsed:    0.0s finished\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Done 200 out of 200 | elapsed:    0.0s finished\\\\n\\\",\\n+      \\\"C:\\\\\\\\Users\\\\\\\\reema\\\\\\\\anaconda3\\\\\\\\Lib\\\\\\\\site-packages\\\\\\\\shap\\\\\\\\plots\\\\\\\\_beeswarm.py:1153: UserWarning: The figure layout has changed to tight\\\\n\\\",\\n+      \\\"  pl.tight_layout()\\\\n\\\",\\n+      \\\"C:\\\\\\\\Users\\\\\\\\reema\\\\\\\\anaconda3\\\\\\\\Lib\\\\\\\\site-packages\\\\\\\\shap\\\\\\\\plots\\\\\\\\_beeswarm.py:761: UserWarning: The figure layout has changed to tight\\\\n\\\",\\n+      \\\"  pl.tight_layout(pad=0, w_pad=0, h_pad=0.0)\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\u2705 Commit successful.\\\\n\\\",\\n+      \\\"\\ud83d\\ude80 Push successful.\\\\n\\\"\\n+     ]\\n+    }\\n+   ],\\n+   \\\"source\\\": [\\n+    \\\"\\\\n\\\",\\n+    \\\"with mlflow.start_run() as run:\\\\n\\\",\\n+    \\\"    #################################################\\\\n\\\",\\n+    \\\"# Justification LOGGER\\\\n\\\",\\n+    \\\"################################################\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    def log_with_justification(log_func, key, value, context=\\\\\\\"\\\\\\\"):\\\\n\\\",\\n+    \\\"        \\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\",\\n+    \\\"        Log a parameter/metric/tag using `log_func` and ask for justification via console.\\\\n\\\",\\n+    \\\"        \\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\",\\n+    \\\"        log_func(key, value)\\\\n\\\",\\n+    \\\"        print(f\\\\\\\"\\\\\\\\n\\ud83d\\udcdd Justification for `{key}` ({context})\\\\\\\")\\\\n\\\",\\n+    \\\"        user_reason = input(\\\\\\\"\\u2192 Why did you choose this value? \\\\\\\")\\\\n\\\",\\n+    \\\"        mlflow.set_tag(f\\\\\\\"justification_{key}\\\\\\\", user_reason or \\\\\\\"No justification provided\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    def log_justification(key: str, question: str):\\\\n\\\",\\n+    \\\"        print(f\\\\\\\"\\\\\\\\n\\ud83d\\udcdd Justification for `{key}`\\\\\\\")\\\\n\\\",\\n+    \\\"        user_reason = input(f\\\\\\\"\\u2192 {question} \\\\\\\")\\\\n\\\",\\n+    \\\"        mlflow.set_tag(f\\\\\\\"justification_{key}\\\\\\\", user_reason or \\\\\\\"No justification provided\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    meta = fetch_and_log_dataset_metadata_nested(\\\\n\\\",\\n+    \\\"            \\\\\\\"https://doi.org/10.5281/zenodo.1404173\\\\\\\",\\\\n\\\",\\n+    \\\"           \\\\n\\\",\\n+    \\\"        )\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    #Datasbase info logging\\\\n\\\",\\n+    \\\"    db_id = \\\\\\\"c3a42d17-42b7-43c9-a504-2363fb4c9c8d\\\\\\\"\\\\n\\\",\\n+    \\\"    db_meta = fetch_db_metadata(db_id)\\\\n\\\",\\n+    \\\"    log_db_metadata(db_meta)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    #OAI metadata logging from api endpoint\\\\n\\\",\\n+    \\\"    # log as tags\\\\n\\\",\\n+    \\\"    mlflow.set_tag(\\\\\\\"dbrepo.repository_name\\\\\\\", repo_name)\\\\n\\\",\\n+    \\\"    mlflow.set_tag(\\\\\\\"dbrepo.base_url\\\\\\\",       base_url)\\\\n\\\",\\n+    \\\"    mlflow.set_tag(\\\\\\\"dbrepo.protocol_version\\\\\\\", protocol)\\\\n\\\",\\n+    \\\"    mlflow.set_tag(\\\\\\\"dbrepo.admin_email\\\\\\\",     admin_email)\\\\n\\\",\\n+    \\\"    mlflow.set_tag(\\\\\\\"dbrepo.granularity\\\\\\\",     gran)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    #From history API logging\\\\n\\\",\\n+    \\\"    # provenance tags\\\\n\\\",\\n+    \\\"    mlflow.set_tag(\\\\\\\"dbrepo.table_last_modified\\\\\\\", ts_last)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # row-count metrics\\\\n\\\",\\n+    \\\"    mlflow.log_metric(\\\\\\\"dbrepo.row_count_start\\\\\\\", count_start)\\\\n\\\",\\n+    \\\"    mlflow.log_metric(\\\\\\\"dbrepo.row_count_end\\\\\\\",   count_end)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # change-event metrics\\\\n\\\",\\n+    \\\"    mlflow.log_metric(\\\\\\\"dbrepo.num_inserts\\\\\\\", n_insert)\\\\n\\\",\\n+    \\\"    mlflow.log_metric(\\\\\\\"dbrepo.num_deletes\\\\\\\", n_delete)\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    # 2) Capture raw metadata\\\\n\\\",\\n+    \\\"    mlflow.set_tag(\\\\\\\"data_source\\\\\\\", API_URL)\\\\n\\\",\\n+    \\\"    mlflow.log_param(\\\\\\\"retrieval_time\\\\\\\", datetime.utcnow().isoformat())\\\\n\\\",\\n+    \\\"    mlflow.log_param(\\\\\\\"n_records\\\\\\\", len(df))\\\\n\\\",\\n+    \\\"    mlflow.log_param(\\\\\\\"columns_raw\\\\\\\", df.columns.tolist())\\\\n\\\",\\n+    \\\"    mlflow.log_param(\\\\\\\"dropped_columns\\\\\\\", id_cols)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # 4) Post\\u2010processing metadata\\\\n\\\",\\n+    \\\"    mlflow.log_param(\\\\\\\"n_features_final\\\\\\\", X.shape[1])\\\\n\\\",\\n+    \\\"    mlflow.log_param(\\\\\\\"feature_names\\\\\\\", X.columns.tolist())\\\\n\\\",\\n+    \\\"    mlflow.set_tag(\\\\\\\"target_name\\\\\\\", y)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"       # Label encoding\\\\n\\\",\\n+    \\\"    label_map = {int(idx): cls for idx, cls in enumerate(le.classes_)}\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    # Save to an in-memory file\\\\n\\\",\\n+    \\\"    buffer = io.StringIO()\\\\n\\\",\\n+    \\\"    json.dump(label_map, buffer, indent=2)\\\\n\\\",\\n+    \\\"    buffer.seek(0)\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    # Log it to MLflow\\\\n\\\",\\n+    \\\"    mlflow.log_text(buffer.getvalue(), artifact_file=\\\\\\\"label_mapping.json\\\\\\\")\\\\n\\\",\\n+    \\\"   \\\\n\\\",\\n+    \\\"    ts = datetime.now().strftime(\\\\\\\"%Y%m%d_%H%M%S\\\\\\\")\\\\n\\\",\\n+    \\\"    model_name = f\\\\\\\"RandomForest_Iris_v{ts}\\\\\\\"\\\\n\\\",\\n+    \\\"    mlflow.set_tag(\\\\\\\"model_name\\\\\\\",model_name)\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    train_start_ts = datetime.now().isoformat()\\\\n\\\",\\n+    \\\"    mlflow.set_tag(\\\\\\\"training_start_time\\\\\\\", train_start_ts)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    test_size    = 0.2\\\\n\\\",\\n+    \\\"    random_state = 42\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    # \\ud83d\\udcc8 Model Training\\\\n\\\",\\n+    \\\"    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    # \\u2500\\u2500 2) Log dataset split params \\u2500\\u2500\\\\n\\\",\\n+    \\\"    mlflow.log_param(\\\\\\\"test_size\\\\\\\", test_size)\\\\n\\\",\\n+    \\\"    mlflow.log_param(\\\\\\\"random_state\\\\\\\", random_state)\\\\n\\\",\\n+    \\\"    mlflow.log_param(\\\\\\\"n_train_samples\\\\\\\", X_train.shape[0])\\\\n\\\",\\n+    \\\"    mlflow.log_param(\\\\\\\"n_test_samples\\\\\\\",  X_test.shape[0])\\\\n\\\",\\n+    \\\"    mlflow.log_param(\\\\\\\"n_features\\\\\\\",      X_train.shape[1])\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"     # 1) Define a more complex hyperparameter dict\\\\n\\\",\\n+    \\\"    hyperparams = {\\\\n\\\",\\n+    \\\"        \\\\\\\"n_estimators\\\\\\\":       200,\\\\n\\\",\\n+    \\\"        \\\\\\\"criterion\\\\\\\":          \\\\\\\"entropy\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"max_depth\\\\\\\":          12,\\\\n\\\",\\n+    \\\"        \\\\\\\"min_samples_split\\\\\\\":  5,\\\\n\\\",\\n+    \\\"        \\\\\\\"min_samples_leaf\\\\\\\":   2,\\\\n\\\",\\n+    \\\"        \\\\\\\"max_features\\\\\\\":       \\\\\\\"sqrt\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"bootstrap\\\\\\\":          True,\\\\n\\\",\\n+    \\\"        \\\\\\\"oob_score\\\\\\\":          False,\\\\n\\\",\\n+    \\\"        \\\\\\\"class_weight\\\\\\\":       None,\\\\n\\\",\\n+    \\\"        \\\\\\\"random_state\\\\\\\":       42,\\\\n\\\",\\n+    \\\"        \\\\\\\"verbose\\\\\\\":            1,\\\\n\\\",\\n+    \\\"        \\\\\\\"n_jobs\\\\\\\":             -1\\\\n\\\",\\n+    \\\"    }\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    # 2) Log them ALL at once\\\\n\\\",\\n+    \\\"    mlflow.log_params(hyperparams)\\\\n\\\",\\n+    \\\"    model = RandomForestClassifier(**hyperparams)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    for key, val in hyperparams.items():\\\\n\\\",\\n+    \\\"        log_with_justification(mlflow.log_param, key, val, context=\\\\\\\"Hyperparameter configuration\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # Prompt for and log justifications for high-level modeling decisions\\\\n\\\",\\n+    \\\"    log_justification(\\\\\\\"model_choice\\\\\\\", \\\\\\\"Why did you choose RandomForestClassifier for this task?\\\\\\\")\\\\n\\\",\\n+    \\\"    log_justification(\\\\\\\"target_variable\\\\\\\", \\\\\\\"Why did you choose this column as the prediction target?\\\\\\\")\\\\n\\\",\\n+    \\\"    log_justification(\\\\\\\"test_split\\\\\\\", \\\\\\\"Why this train/test ratio (e.g., 80/20)?\\\\\\\")\\\\n\\\",\\n+    \\\"    log_justification(\\\\\\\"metric_choice\\\\\\\", \\\\\\\"Why accuracy/f1/ROC-AUC as your evaluation metric?\\\\\\\")\\\\n\\\",\\n+    \\\"    log_justification(\\\\\\\"threshold_accuracy\\\\\\\", \\\\\\\"Why 0.95 as performance threshold?\\\\\\\")\\\\n\\\",\\n+    \\\"    log_justification(\\\\\\\"dataset_version\\\\\\\", \\\\\\\"Why use this specific dataset version?\\\\\\\")\\\\n\\\",\\n+    \\\"    log_justification(\\\\\\\"drop_column_X\\\\\\\", \\\\\\\"Why drop any specific columns from the dataset?\\\\\\\")\\\\n\\\",\\n+    \\\"    log_justification(\\\\\\\"experiment_name\\\\\\\", \\\\\\\"Any context behind this experiment name or setup?\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    model.fit(X_train, y_train)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    train_end_ts = datetime.now().isoformat()\\\\n\\\",\\n+    \\\"    mlflow.set_tag(\\\\\\\"training_end_time\\\\\\\", train_end_ts)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"     # \\u2500\\u2500 6) Predict & log metrics \\u2500\\u2500\\\\n\\\",\\n+    \\\"    y_pred = model.predict(X_test)\\\\n\\\",\\n+    \\\"    y_proba = model.predict_proba(X_test)\\\\n\\\",\\n+    \\\"    acc = accuracy_score(y_test, y_pred)\\\\n\\\",\\n+    \\\"    auc = roc_auc_score(y_test, y_proba, multi_class=\\\\\\\"ovr\\\\\\\")\\\\n\\\",\\n+    \\\"    prec = precision_score(y_test, y_pred, average=\\\\\\\"macro\\\\\\\")\\\\n\\\",\\n+    \\\"    rec  = recall_score(y_test,    y_pred, average=\\\\\\\"macro\\\\\\\")\\\\n\\\",\\n+    \\\"    f1   = f1_score(y_test,      y_pred, average=\\\\\\\"macro\\\\\\\")\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    mlflow.log_metric(\\\\\\\"precision_macro\\\\\\\", prec)\\\\n\\\",\\n+    \\\"    mlflow.log_metric(\\\\\\\"recall_macro\\\\\\\",    rec)\\\\n\\\",\\n+    \\\"    mlflow.log_metric(\\\\\\\"f1_macro\\\\\\\",        f1)\\\\n\\\",\\n+    \\\"    mlflow.log_metric(\\\\\\\"accuracy\\\\\\\", acc)\\\\n\\\",\\n+    \\\"    mlflow.log_metric(\\\\\\\"roc_auc\\\\\\\",   auc)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # \\u2705 Log Environment Automatically\\\\n\\\",\\n+    \\\"    mlflow.log_params({\\\\n\\\",\\n+    \\\"        \\\\\\\"python_version\\\\\\\": platform.python_version(),\\\\n\\\",\\n+    \\\"        \\\\\\\"os_platform\\\\\\\": f\\\\\\\"{platform.system()} {platform.release()}\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"sklearn_version\\\\\\\": sklearn.__version__,\\\\n\\\",\\n+    \\\"        \\\\\\\"pandas_version\\\\\\\": pd.__version__,\\\\n\\\",\\n+    \\\"        \\\\\\\"numpy_version\\\\\\\": np.__version__,\\\\n\\\",\\n+    \\\"        \\\\\\\"matplotlib_version\\\\\\\": matplotlib.__version__,\\\\n\\\",\\n+    \\\"        \\\\\\\"seaborn_version\\\\\\\": sns.__version__,\\\\n\\\",\\n+    \\\"        \\\\\\\"shap_version\\\\\\\": shap.__version__,\\\\n\\\",\\n+    \\\"    })\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # \\u2705 Git and Notebook Metadata\\\\n\\\",\\n+    \\\"    mlflow.set_tag(\\\\\\\"notebook_name\\\\\\\", \\\\\\\"RQ1.ipynb\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # \\u2705 Dataset Metadata Tags\\\\n\\\",\\n+    \\\"    mlflow.set_tag(\\\\\\\"dataset_name\\\\\\\", \\\\\\\"Iris\\\\\\\") #TODO\\\\n\\\",\\n+    \\\"    mlflow.set_tag(\\\\\\\"dataset_version\\\\\\\", \\\\\\\"1.0.0\\\\\\\") #TODO\\\\n\\\",\\n+    \\\"    mlflow.set_tag(\\\\\\\"dataset_id\\\\\\\", \\\\\\\"iris_local\\\\\\\") #TODO\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # \\u2500\\u2500\\u2500 2) Create a folder for this run\\u2019s plots \\u2500\\u2500\\u2500\\\\n\\\",\\n+    \\\"    plot_dir = os.path.join(\\\\\\\"plots\\\\\\\", model_name)\\\\n\\\",\\n+    \\\"    os.makedirs(plot_dir, exist_ok=True)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # 1) Feature Importance Bar Chart\\\\n\\\",\\n+    \\\"    importances = model.feature_importances_\\\\n\\\",\\n+    \\\"    try:\\\\n\\\",\\n+    \\\"        feature_names = X_train.columns\\\\n\\\",\\n+    \\\"    except AttributeError:\\\\n\\\",\\n+    \\\"        feature_names = [f\\\\\\\"f{i}\\\\\\\" for i in range(X_train.shape[1])]\\\\n\\\",\\n+    \\\"    fi_path = os.path.join(plot_dir, \\\\\\\"feature_importances.png\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    plt.figure(figsize=(8, 6))\\\\n\\\",\\n+    \\\"    sns.barplot(x=importances, y=feature_names)\\\\n\\\",\\n+    \\\"    plt.title(\\\\\\\"Feature Importances\\\\\\\")\\\\n\\\",\\n+    \\\"    plt.xlabel(\\\\\\\"Importance\\\\\\\")\\\\n\\\",\\n+    \\\"    plt.ylabel(\\\\\\\"Feature\\\\\\\")\\\\n\\\",\\n+    \\\"    plt.tight_layout()\\\\n\\\",\\n+    \\\"    plt.savefig(fi_path)\\\\n\\\",\\n+    \\\"    mlflow.log_artifact(fi_path)\\\\n\\\",\\n+    \\\"    plt.close()\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# 2) Multi-class ROC Curves\\\\n\\\",\\n+    \\\"# Binarize labels for one-vs-rest\\\\n\\\",\\n+    \\\"    classes = np.unique(y_test)\\\\n\\\",\\n+    \\\"    y_test_bin = label_binarize(y_test, classes=classes)\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    for idx, cls in enumerate(classes):\\\\n\\\",\\n+    \\\"        disp = RocCurveDisplay.from_predictions(\\\\n\\\",\\n+    \\\"            y_test_bin[:, idx], \\\\n\\\",\\n+    \\\"            y_proba[:, idx],\\\\n\\\",\\n+    \\\"            name=f\\\\\\\"ROC for class {cls}\\\\\\\"\\\\n\\\",\\n+    \\\"        )\\\\n\\\",\\n+    \\\"        roc_path = os.path.join(plot_dir, f\\\\\\\"roc_curve_cls_{cls}.png\\\\\\\")\\\\n\\\",\\n+    \\\"        disp.figure_.savefig(roc_path)\\\\n\\\",\\n+    \\\"        mlflow.log_artifact(roc_path)\\\\n\\\",\\n+    \\\"        plt.close(disp.figure_)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # 3) Multi-class Precision-Recall Curves\\\\n\\\",\\n+    \\\"    for idx, cls in enumerate(classes):\\\\n\\\",\\n+    \\\"        disp = PrecisionRecallDisplay.from_predictions(\\\\n\\\",\\n+    \\\"            y_test_bin[:, idx], \\\\n\\\",\\n+    \\\"            y_proba[:, idx],\\\\n\\\",\\n+    \\\"            name=f\\\\\\\"PR curve for class {cls}\\\\\\\"\\\\n\\\",\\n+    \\\"        )\\\\n\\\",\\n+    \\\"        pr_path = os.path.join(plot_dir, f\\\\\\\"pr_curve_cls_{cls}.png\\\\\\\")\\\\n\\\",\\n+    \\\"        disp.figure_.savefig(pr_path)\\\\n\\\",\\n+    \\\"        mlflow.log_artifact(pr_path)\\\\n\\\",\\n+    \\\"        plt.close(disp.figure_)\\\\n\\\",\\n+    \\\"        \\\\n\\\",\\n+    \\\"    # \\u2705 Confusion Matrix Plot\\\\n\\\",\\n+    \\\"    cm_path = os.path.join(plot_dir, \\\\\\\"confusion_matrix.png\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    cm = confusion_matrix(y_test, y_pred)\\\\n\\\",\\n+    \\\"    plt.figure(figsize=(6, 6))\\\\n\\\",\\n+    \\\"    sns.heatmap(cm, annot=True, fmt=\\\\\\\"d\\\\\\\", cmap=\\\\\\\"Blues\\\\\\\")\\\\n\\\",\\n+    \\\"    plt.title(\\\\\\\"Confusion Matrix\\\\\\\")\\\\n\\\",\\n+    \\\"    plt.xlabel(\\\\\\\"Predicted\\\\\\\")\\\\n\\\",\\n+    \\\"    plt.ylabel(\\\\\\\"Actual\\\\\\\")\\\\n\\\",\\n+    \\\"    plt.savefig(cm_path)\\\\n\\\",\\n+    \\\"    mlflow.log_artifact(cm_path)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # \\u2705 SHAP Summary\\\\n\\\",\\n+    \\\"    shap_path = os.path.join(plot_dir, \\\\\\\"shap_summary.png\\\\\\\")\\\\n\\\",\\n+    \\\"    explainer = shap.TreeExplainer(model)\\\\n\\\",\\n+    \\\"    shap_values = explainer.shap_values(X_test)\\\\n\\\",\\n+    \\\"    shap.summary_plot(shap_values, X_test, show=False)\\\\n\\\",\\n+    \\\"    plt.savefig(shap_path)\\\\n\\\",\\n+    \\\"    mlflow.log_artifact(shap_path)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    # \\u2500\\u2500\\u2500 1) Build a .pkl filename (you can include your model_name for clarity)\\\\n\\\",\\n+    \\\"    pkl_path = f\\\\\\\"Trained_models/{model_name}.pkl\\\\\\\"\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    # \\u2500\\u2500\\u2500 2) Serialize your trained model to disk\\\\n\\\",\\n+    \\\"    with open(pkl_path, \\\\\\\"wb\\\\\\\") as f:\\\\n\\\",\\n+    \\\"        pickle.dump(model, f)\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    # \\u2500\\u2500\\u2500 3) Log that pickle file as an MLflow artifact\\\\n\\\",\\n+    \\\"    #     It will appear under Artifacts \\u2192 models/RandomForest_Iris_vYYYYMMDD_HHMMSS.pkl\\\\n\\\",\\n+    \\\"    mlflow.log_artifact(pkl_path, artifact_path=model_name)\\\\n\\\",\\n+    \\\"        \\\\n\\\",\\n+    \\\"    def get_latest_commit_hash(repo_path=\\\\\\\".\\\\\\\"):\\\\n\\\",\\n+    \\\"        # returns the full SHA of HEAD\\\\n\\\",\\n+    \\\"        res = subprocess.run(\\\\n\\\",\\n+    \\\"            [\\\\\\\"git\\\\\\\", \\\\\\\"-C\\\\\\\", repo_path, \\\\\\\"rev-parse\\\\\\\", \\\\\\\"HEAD\\\\\\\"],\\\\n\\\",\\n+    \\\"            capture_output=True, text=True, check=True)\\\\n\\\",\\n+    \\\"        \\\\n\\\",\\n+    \\\"        return res.stdout.strip()\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    def get_remote_url(repo_path=\\\\\\\".\\\\\\\", remote=\\\\\\\"origin\\\\\\\"):\\\\n\\\",\\n+    \\\"        # returns something like git@github.com:user/repo.git or https://...\\\\n\\\",\\n+    \\\"        res = subprocess.run(\\\\n\\\",\\n+    \\\"            [\\\\\\\"git\\\\\\\", \\\\\\\"-C\\\\\\\", repo_path, \\\\\\\"config\\\\\\\", \\\\\\\"--get\\\\\\\", f\\\\\\\"remote.{remote}.url\\\\\\\"],\\\\n\\\",\\n+    \\\"            capture_output=True, text=True, check=True\\\\n\\\",\\n+    \\\"        )\\\\n\\\",\\n+    \\\"        return res.stdout.strip()\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    def make_commit_link(remote_url, commit_hash):\\\\n\\\",\\n+    \\\"        # handle GitHub/GitLab convention; strip \\u201c.git\\u201d if present\\\\n\\\",\\n+    \\\"        base = remote_url.rstrip(\\\\\\\".git\\\\\\\")\\\\n\\\",\\n+    \\\"        # if SSH form (git@github.com:owner/repo), convert to https\\\\n\\\",\\n+    \\\"        if base.startswith(\\\\\\\"git@\\\\\\\"):\\\\n\\\",\\n+    \\\"            base = base.replace(\\\\\\\":\\\\\\\", \\\\\\\"/\\\\\\\").replace(\\\\\\\"git@\\\\\\\", \\\\\\\"https://\\\\\\\")\\\\n\\\",\\n+    \\\"        return f\\\\\\\"{base}/commit/{commit_hash}\\\\\\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    def simple_commit_and_push_and_log(repo_path=\\\\\\\".\\\\\\\", message=\\\\\\\"Auto commit\\\\\\\", remote=\\\\\\\"origin\\\\\\\", branch=\\\\\\\"main\\\\\\\"):\\\\n\\\",\\n+    \\\"    # 1) Check for changes\\\\n\\\",\\n+    \\\"        status = subprocess.run(\\\\n\\\",\\n+    \\\"            [\\\\\\\"git\\\\\\\", \\\\\\\"-C\\\\\\\", repo_path, \\\\\\\"status\\\\\\\", \\\\\\\"--porcelain\\\\\\\"],\\\\n\\\",\\n+    \\\"            capture_output=True, text=True\\\\n\\\",\\n+    \\\"        )\\\\n\\\",\\n+    \\\"        if not status.stdout.strip():\\\\n\\\",\\n+    \\\"            print(\\\\\\\"\\ud83d\\udfe1 No changes to commit.\\\\\\\")\\\\n\\\",\\n+    \\\"            return None, None\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"        # 2) Stage everything\\\\n\\\",\\n+    \\\"        add = subprocess.run(\\\\n\\\",\\n+    \\\"            [\\\\\\\"git\\\\\\\", \\\\\\\"-C\\\\\\\", repo_path, \\\\\\\"add\\\\\\\", \\\\\\\"--all\\\\\\\"],\\\\n\\\",\\n+    \\\"            capture_output=True, text=True\\\\n\\\",\\n+    \\\"        )\\\\n\\\",\\n+    \\\"        if add.returncode:\\\\n\\\",\\n+    \\\"            print(\\\\\\\"\\u274c git add failed:\\\\\\\\n\\\\\\\", add.stderr)\\\\n\\\",\\n+    \\\"            return None, None\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"        # 3) Commit\\\\n\\\",\\n+    \\\"        commit = subprocess.run(\\\\n\\\",\\n+    \\\"            [\\\\\\\"git\\\\\\\", \\\\\\\"-C\\\\\\\", repo_path, \\\\\\\"commit\\\\\\\", \\\\\\\"-m\\\\\\\", message],\\\\n\\\",\\n+    \\\"            capture_output=True, text=True\\\\n\\\",\\n+    \\\"        )\\\\n\\\",\\n+    \\\"        if commit.returncode:\\\\n\\\",\\n+    \\\"            print(\\\\\\\"\\u274c git commit failed:\\\\\\\\n\\\\\\\", commit.stderr)\\\\n\\\",\\n+    \\\"            return None, None\\\\n\\\",\\n+    \\\"        print(\\\\\\\"\\u2705 Commit successful.\\\\\\\")\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"        # 4) Push\\\\n\\\",\\n+    \\\"        push = subprocess.run(\\\\n\\\",\\n+    \\\"            [\\\\\\\"git\\\\\\\", \\\\\\\"-C\\\\\\\", repo_path, \\\\\\\"push\\\\\\\", \\\\\\\"-u\\\\\\\", remote, branch],\\\\n\\\",\\n+    \\\"            capture_output=True, text=True\\\\n\\\",\\n+    \\\"        )\\\\n\\\",\\n+    \\\"        if push.returncode:\\\\n\\\",\\n+    \\\"            print(\\\\\\\"\\u274c git push failed:\\\\\\\\n\\\\\\\", push.stderr)\\\\n\\\",\\n+    \\\"        else:\\\\n\\\",\\n+    \\\"            print(\\\\\\\"\\ud83d\\ude80 Push successful.\\\\\\\")\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"        # 5) Retrieve hash & remote URL\\\\n\\\",\\n+    \\\"        sha = get_latest_commit_hash(repo_path)\\\\n\\\",\\n+    \\\"        url = get_remote_url(repo_path, remote)\\\\n\\\",\\n+    \\\"        link = make_commit_link(url, sha)\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"        return sha, link\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"      \\\\n\\\",\\n+    \\\"    sha, link = simple_commit_and_push_and_log(\\\\n\\\",\\n+    \\\"        repo_path=\\\\\\\".\\\\\\\",\\\\n\\\",\\n+    \\\"        message=\\\\\\\"Auto commit after successful training\\\\\\\"\\\\n\\\",\\n+    \\\"    )\\\\n\\\",\\n+    \\\"    if sha and link:\\\\n\\\",\\n+    \\\"        diff_text = subprocess.check_output(\\\\n\\\",\\n+    \\\"            [\\\\\\\"git\\\\\\\", \\\\\\\"-C\\\\\\\", \\\\\\\".\\\\\\\", \\\\\\\"diff\\\\\\\", previous_commit_hash, sha],\\\\n\\\",\\n+    \\\"            encoding=\\\\\\\"utf-8\\\\\\\",\\\\n\\\",\\n+    \\\"            errors=\\\\\\\"ignore\\\\\\\"    # or \\\\\\\"replace\\\\\\\"\\\\n\\\",\\n+    \\\"        )\\\\n\\\",\\n+    \\\"                \\\\n\\\",\\n+    \\\"        # 1) Get your repo\\u2019s remote URL and normalize to HTTPS\\\\n\\\",\\n+    \\\"        remote_url = subprocess.check_output(\\\\n\\\",\\n+    \\\"            [\\\\\\\"git\\\\\\\", \\\\\\\"config\\\\\\\", \\\\\\\"--get\\\\\\\", \\\\\\\"remote.origin.url\\\\\\\"],\\\\n\\\",\\n+    \\\"            text=True\\\\n\\\",\\n+    \\\"        ).strip().rstrip(\\\\\\\".git\\\\\\\")\\\\n\\\",\\n+    \\\"        if remote_url.startswith(\\\\\\\"git@\\\\\\\"):\\\\n\\\",\\n+    \\\"            # git@github.com:owner/repo.git \\u2192 https://github.com/owner/repo\\\\n\\\",\\n+    \\\"            remote_url = remote_url.replace(\\\\\\\":\\\\\\\", \\\\\\\"/\\\\\\\").replace(\\\\\\\"git@\\\\\\\", \\\\\\\"https://\\\\\\\")\\\\n\\\",\\n+    \\\"        \\\\n\\\",\\n+    \\\"        # 2) Build commit URLs\\\\n\\\",\\n+    \\\"        previous_commit_url  = f\\\\\\\"{remote_url}/commit/{previous_commit_hash}\\\\\\\"\\\\n\\\",\\n+    \\\"        current_commit_url = f\\\\\\\"{remote_url}/commit/{sha}\\\\\\\"\\\\n\\\",\\n+    \\\"        diff_data = {\\\\n\\\",\\n+    \\\"            \\\\\\\"previous_commit\\\\\\\":  previous_commit_hash,\\\\n\\\",\\n+    \\\"            \\\\\\\"previous_commit_url\\\\\\\":previous_commit_url,\\\\n\\\",\\n+    \\\"            \\\\\\\"current_commit_url\\\\\\\":current_commit_url,\\\\n\\\",\\n+    \\\"            \\\\\\\"current_commit\\\\\\\": sha,\\\\n\\\",\\n+    \\\"            \\\\\\\"diff\\\\\\\": diff_text\\\\n\\\",\\n+    \\\"        }\\\\n\\\",\\n+    \\\"        mlflow.log_dict(\\\\n\\\",\\n+    \\\"            diff_data,\\\\n\\\",\\n+    \\\"            artifact_file=\\\\\\\"commit_diff.json\\\\\\\"\\\\n\\\",\\n+    \\\"        )\\\\n\\\",\\n+    \\\"        mlflow.set_tag(\\\\\\\"git_previous_commit_hash\\\\\\\", previous_commit_hash)\\\\n\\\",\\n+    \\\"        mlflow.set_tag(\\\\\\\"git_current_commit_hash\\\\\\\", sha)\\\\n\\\",\\n+    \\\"        mlflow.set_tag(\\\\\\\"git__current_commit_url\\\\\\\", link) \\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    client   = MlflowClient()\\\\n\\\",\\n+    \\\"    run_id    = run.info.run_id\\\\n\\\",\\n+    \\\"    run_info  = client.get_run(run_id).info\\\\n\\\",\\n+    \\\"    run_data  = client.get_run(run_id).data\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    # 1) params, metrics, tags\\\\n\\\",\\n+    \\\"    params  = dict(run_data.params)\\\\n\\\",\\n+    \\\"    metrics = dict(run_data.metrics)\\\\n\\\",\\n+    \\\"    tags    = dict(run_data.tags)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # (4) List artifacts under a specific subfolder\\\\n\\\",\\n+    \\\"    run_meta     = client.get_run(run_id).info\\\\n\\\",\\n+    \\\"    artifact_uri = run_meta.artifact_uri  # base URI for all artifacts\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    artifact_meta = []\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    def _gather(path=\\\\\\\"\\\\\\\"):\\\\n\\\",\\n+    \\\"        for af in client.list_artifacts(run_id, path):\\\\n\\\",\\n+    \\\"            # If it\\u2019s a directory, recurse\\\\n\\\",\\n+    \\\"            if af.is_dir:\\\\n\\\",\\n+    \\\"                _gather(af.path)\\\\n\\\",\\n+    \\\"                continue\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"            rel_path = af.path\\\\n\\\",\\n+    \\\"            uri      = f\\\\\\\"{artifact_uri}/{rel_path}\\\\\\\"\\\\n\\\",\\n+    \\\"            lower    = rel_path.lower()\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"            # 1) Text files \\u2192 download & embed contents\\\\n\\\",\\n+    \\\"            if lower.endswith((\\\\\\\".json\\\\\\\", \\\\\\\".txt\\\\\\\", \\\\\\\".patch\\\\\\\")):\\\\n\\\",\\n+    \\\"                local = client.download_artifacts(run_id, rel_path)\\\\n\\\",\\n+    \\\"                with open(local, \\\\\\\"r\\\\\\\", encoding=\\\\\\\"utf-8\\\\\\\") as f:\\\\n\\\",\\n+    \\\"                    content = f.read()\\\\n\\\",\\n+    \\\"                artifact_meta.append({\\\\n\\\",\\n+    \\\"                    \\\\\\\"path\\\\\\\":    rel_path,\\\\n\\\",\\n+    \\\"                    \\\\\\\"type\\\\\\\":    \\\\\\\"text\\\\\\\",\\\\n\\\",\\n+    \\\"                    \\\\\\\"content\\\\\\\": content\\\\n\\\",\\n+    \\\"                })\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"            # 2) Images \\u2192 surface a clickable URI\\\\n\\\",\\n+    \\\"            elif lower.endswith((\\\\\\\".png\\\\\\\", \\\\\\\".jpg\\\\\\\", \\\\\\\".jpeg\\\\\\\", \\\\\\\".svg\\\\\\\")):\\\\n\\\",\\n+    \\\"                artifact_meta.append({\\\\n\\\",\\n+    \\\"                    \\\\\\\"path\\\\\\\": rel_path,\\\\n\\\",\\n+    \\\"                    \\\\\\\"type\\\\\\\": \\\\\\\"image\\\\\\\",\\\\n\\\",\\n+    \\\"                    \\\\\\\"uri\\\\\\\":  uri\\\\n\\\",\\n+    \\\"                })\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"            # 3) Everything else \\u2192 just link\\\\n\\\",\\n+    \\\"            else:\\\\n\\\",\\n+    \\\"                artifact_meta.append({\\\\n\\\",\\n+    \\\"                    \\\\\\\"path\\\\\\\": rel_path,\\\\n\\\",\\n+    \\\"                    \\\\\\\"type\\\\\\\": \\\\\\\"other\\\\\\\",\\\\n\\\",\\n+    \\\"                    \\\\\\\"uri\\\\\\\":  uri\\\\n\\\",\\n+    \\\"                })\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    # Run the gather\\\\n\\\",\\n+    \\\"    _gather()\\\\n\\\",\\n+    \\\"     \\\\n\\\",\\n+    \\\"    summary = {\\\\n\\\",\\n+    \\\"        \\\\\\\"run_id\\\\\\\":         run_id,\\\\n\\\",\\n+    \\\"        \\\\\\\"run_name\\\\\\\": run_info.run_name,\\\\n\\\",\\n+    \\\"        \\\\\\\"experiment_id\\\\\\\":  run_info.experiment_id,\\\\n\\\",\\n+    \\\"        \\\\\\\"start_time\\\\\\\":     run_info.start_time,\\\\n\\\",\\n+    \\\"        \\\\\\\"end_time\\\\\\\":       run_info.end_time,\\\\n\\\",\\n+    \\\"        \\\\\\\"params\\\\\\\":         params,\\\\n\\\",\\n+    \\\"        \\\\\\\"metrics\\\\\\\":        metrics,\\\\n\\\",\\n+    \\\"        \\\\\\\"tags\\\\\\\":           tags,\\\\n\\\",\\n+    \\\"        \\\\\\\"artifacts\\\\\\\":      artifact_meta\\\\n\\\",\\n+    \\\"    }\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # 1) Determine notebook directory (where your .ipynb lives)\\\\n\\\",\\n+    \\\"    notebook_dir = os.getcwd()\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    # \\u2705 Create a subdirectory inside MODEL_PROVENANCE for the model\\\\n\\\",\\n+    \\\"    summary_dir = os.path.join(os.getcwd(), \\\\\\\"MODEL_PROVENANCE\\\\\\\", model_name)\\\\n\\\",\\n+    \\\"    os.makedirs(summary_dir, exist_ok=True)\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"   # 2) Pick a filename based on your model_name\\\\n\\\",\\n+    \\\"    summary_filename   = f\\\\\\\"{model_name}_run_summary.json\\\\\\\"\\\\n\\\",\\n+    \\\"    summary_local_path = os.path.join(summary_dir, summary_filename)\\\\n\\\",\\n+    \\\"   # 3) Write the JSON locally\\\\n\\\",\\n+    \\\"    with open(summary_local_path, \\\\\\\"w\\\\\\\", encoding=\\\\\\\"utf-8\\\\\\\") as f:\\\\n\\\",\\n+    \\\"        json.dump(summary, f, indent=2)\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    # 4) (Optional) Mirror it into MLflow artifacts under a single folder\\\\n\\\",\\n+    \\\"    mlflow.log_artifact(summary_local_path, artifact_path=\\\\\\\"run_summaries\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    mlflow.end_run()\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"d0c4e1b2-9fa9-4606-8128-6ac66b5c6e78\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"what does it create: \\\\n\\\",\\n+    \\\"lable_mapping in the current dir\\\\n\\\",\\n+    \\\"provenence file :REPO/notebooks/RQ_notebooks/MODEL_PROVENANCE/RandomForest_Iris_v20250425_120045_run_summary.json\\\\n\\\",\\n+    \\\"plots based on run:REPO/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120045/shap_summary.png\\\\n\\\",\\n+    \\\"mlrun:REPO/notebooks/RQ_notebooks/mlrunlogs/mlflow.db/615223710259862608/5d1fa0fc65af47128f3200628b1afaea\\\\n\\\",\\n+    \\\"trained model:REPO/notebooks/RQ_notebooks/Trained_models/RandomForest_Iris_v20250425_120852.pkl\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"7a5e3bbb-0288-47d0-9dc4-2855d7e4801a\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"1. Standards-compliant export (JSON-LD + Turtle)\\\\n\\\",\\n+    \\\"I already have your plain run_summary.json , wrap it in a JSON-LD context that maps your fields into PROV-O terms, then use rdflib to emit Turtle:\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": null,\\n+   \\\"id\\\": \\\"28ed1cfb-930a-4f17-a48f-30e4cffb7f3e\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [],\\n+   \\\"source\\\": [\\n+    \\\"import json\\\\n\\\",\\n+    \\\"import pandas as pd\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# Load the JSON file\\\\n\\\",\\n+    \\\"json_path = \\\\\\\"/mnt/data/REPO/notebooks/RQ_notebooks/MODEL_PROVENANCE/RandomForest_Iris_v20250425_125653/RandomForest_Iris_v20250425_125653_run_summary.json\\\\\\\"\\\\n\\\",\\n+    \\\"with open(json_path, \\\\\\\"r\\\\\\\", encoding=\\\\\\\"utf-8\\\\\\\") as file:\\\\n\\\",\\n+    \\\"    data = json.load(file)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# Extract justification tags\\\\n\\\",\\n+    \\\"justifications = {\\\\n\\\",\\n+    \\\"    k: v for k, v in data.get(\\\\\\\"tags\\\\\\\", {}).items()\\\\n\\\",\\n+    \\\"    if k.startswith(\\\\\\\"justification_\\\\\\\")\\\\n\\\",\\n+    \\\"}\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# Create a DataFrame\\\\n\\\",\\n+    \\\"justification_df = pd.DataFrame([\\\\n\\\",\\n+    \\\"    {\\\\\\\"Decision\\\\\\\": k.replace(\\\\\\\"justification_\\\\\\\", \\\\\\\"\\\\\\\"), \\\\\\\"Justification\\\\\\\": v}\\\\n\\\",\\n+    \\\"    for k, v in justifications.items()\\\\n\\\",\\n+    \\\"])\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"import ace_tools as tools; tools.display_dataframe_to_user(name=\\\\\\\"Researcher Justifications\\\\\\\", dataframe=justification_df)\\\\n\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 66,\\n+   \\\"id\\\": \\\"5cf88da4-69f8-4982-a594-28cf25e4f79a\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"Converted RandomForest_Iris_v20250425_121328_run_summary.json \\u2192 RandomForest_Iris_v20250425_121328.jsonld, RandomForest_Iris_v20250425_121328.ttl\\\\n\\\"\\n+     ]\\n+    }\\n+   ],\\n+   \\\"source\\\": [\\n+    \\\"\\\\n\\\",\\n+    \\\"def iso8601(ms):\\\\n\\\",\\n+    \\\"    \\\\\\\"\\\\\\\"\\\\\\\"Convert milliseconds since epoch to ISO8601 UTC.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\",\\n+    \\\"    return datetime.fromtimestamp(ms / 1000, tz=timezone.utc).isoformat()\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"for json_path in glob.glob(\\\\\\\"MODEL_PROVENANCE/*/*_run_summary.json\\\\\\\"):\\\\n\\\",\\n+    \\\"    basename   = os.path.basename(json_path)\\\\n\\\",\\n+    \\\"    model_name = basename.rsplit(\\\\\\\"_run_summary.json\\\\\\\", 1)[0]\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    with open(json_path, \\\\\\\"r\\\\\\\", encoding=\\\\\\\"utf-8\\\\\\\") as f:\\\\n\\\",\\n+    \\\"        summary = json.load(f)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    #\\u2013\\u2013 Minimal override context: keep all your flat fields as-is,\\\\n\\\",\\n+    \\\"    #\\u2013\\u2013 and only map the actual PROV terms to their IRIs.\\\\n\\\",\\n+    \\\"    ctx = {\\\\n\\\",\\n+    \\\"        # keep these flat\\\\n\\\",\\n+    \\\"        \\\\\\\"run_id\\\\\\\":       { \\\\\\\"@id\\\\\\\": \\\\\\\"run_id\\\\\\\" },\\\\n\\\",\\n+    \\\"        \\\\\\\"run_name\\\\\\\":     { \\\\\\\"@id\\\\\\\": \\\\\\\"run_name\\\\\\\" },\\\\n\\\",\\n+    \\\"        \\\\\\\"experiment_id\\\\\\\":{ \\\\\\\"@id\\\\\\\": \\\\\\\"experiment_id\\\\\\\" },\\\\n\\\",\\n+    \\\"        \\\\\\\"params\\\\\\\":       { \\\\\\\"@id\\\\\\\": \\\\\\\"params\\\\\\\" },\\\\n\\\",\\n+    \\\"        \\\\\\\"metrics\\\\\\\":      { \\\\\\\"@id\\\\\\\": \\\\\\\"metrics\\\\\\\" },\\\\n\\\",\\n+    \\\"        \\\\\\\"artifacts\\\\\\\":    { \\\\\\\"@id\\\\\\\": \\\\\\\"artifacts\\\\\\\" },\\\\n\\\",\\n+    \\\"        \\\\\\\"tags\\\\\\\":         { \\\\\\\"@id\\\\\\\": \\\\\\\"tags\\\\\\\" },\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"        # provenance namespace\\\\n\\\",\\n+    \\\"        \\\\\\\"prov\\\\\\\": \\\\\\\"http://www.w3.org/ns/prov#\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"xsd\\\\\\\":  \\\\\\\"http://www.w3.org/2001/XMLSchema#\\\\\\\",\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"        # map your timestamp fields into PROV\\\\n\\\",\\n+    \\\"        \\\\\\\"start_time\\\\\\\": { \\\\\\\"@id\\\\\\\": \\\\\\\"prov:startedAtTime\\\\\\\", \\\\\\\"@type\\\\\\\": \\\\\\\"xsd:dateTime\\\\\\\" },\\\\n\\\",\\n+    \\\"        \\\\\\\"end_time\\\\\\\":   { \\\\\\\"@id\\\\\\\": \\\\\\\"prov:endedAtTime\\\\\\\",   \\\\\\\"@type\\\\\\\": \\\\\\\"xsd:dateTime\\\\\\\" },\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"        # PROV-used/generated\\\\n\\\",\\n+    \\\"        \\\\\\\"used\\\\\\\":      { \\\\\\\"@id\\\\\\\": \\\\\\\"prov:used\\\\\\\",      \\\\\\\"@type\\\\\\\": \\\\\\\"@id\\\\\\\" },\\\\n\\\",\\n+    \\\"        \\\\\\\"generated\\\\\\\": { \\\\\\\"@id\\\\\\\": \\\\\\\"prov:generated\\\\\\\", \\\\\\\"@type\\\\\\\": \\\\\\\"@id\\\\\\\" },\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"        # JSON-LD boilerplate\\\\n\\\",\\n+    \\\"        \\\\\\\"@id\\\\\\\":   \\\\\\\"@id\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"@type\\\\\\\": \\\\\\\"@type\\\\\\\"\\\\n\\\",\\n+    \\\"    }\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    #\\u2013\\u2013 Build JSON-LD document, re-using your original keys verbatim\\\\n\\\",\\n+    \\\"    doc = {\\\\n\\\",\\n+    \\\"        \\\\\\\"@context\\\\\\\":      ctx,\\\\n\\\",\\n+    \\\"        \\\\\\\"run_id\\\\\\\":        summary[\\\\\\\"run_id\\\\\\\"],\\\\n\\\",\\n+    \\\"        \\\\\\\"run_name\\\\\\\":      summary.get(\\\\\\\"run_name\\\\\\\"),\\\\n\\\",\\n+    \\\"        \\\\\\\"experiment_id\\\\\\\": summary.get(\\\\\\\"experiment_id\\\\\\\"),\\\\n\\\",\\n+    \\\"        \\\\\\\"params\\\\\\\":        summary.get(\\\\\\\"params\\\\\\\", {}),\\\\n\\\",\\n+    \\\"        \\\\\\\"metrics\\\\\\\":       summary.get(\\\\\\\"metrics\\\\\\\", {}),\\\\n\\\",\\n+    \\\"        \\\\\\\"artifacts\\\\\\\":     summary.get(\\\\\\\"artifacts\\\\\\\", []),\\\\n\\\",\\n+    \\\"        \\\\\\\"tags\\\\\\\":          summary.get(\\\\\\\"tags\\\\\\\", {}),\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"        # PROV fields:\\\\n\\\",\\n+    \\\"        \\\\\\\"start_time\\\\\\\": iso8601(summary[\\\\\\\"start_time\\\\\\\"])\\\\n\\\",\\n+    \\\"    }\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    if summary.get(\\\\\\\"end_time\\\\\\\") is not None:\\\\n\\\",\\n+    \\\"        doc[\\\\\\\"end_time\\\\\\\"] = iso8601(summary[\\\\\\\"end_time\\\\\\\"])\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # for used/generated, just point at your dataset/model URIs\\\\n\\\",\\n+    \\\"    # (or blank-node them if you prefer richer structure)\\\\n\\\",\\n+    \\\"    doc[\\\\\\\"used\\\\\\\"] = summary.get(\\\\\\\"tags\\\\\\\", {}).get(\\\\\\\"dataset_uri\\\\\\\") or []\\\\n\\\",\\n+    \\\"    doc[\\\\\\\"generated\\\\\\\"] = [\\\\n\\\",\\n+    \\\"        art.get(\\\\\\\"uri\\\\\\\") or art.get(\\\\\\\"path\\\\\\\")\\\\n\\\",\\n+    \\\"        for art in summary.get(\\\\\\\"artifacts\\\\\\\", [])\\\\n\\\",\\n+    \\\"    ]\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    #\\u2013\\u2013 write JSON-LD\\\\n\\\",\\n+    \\\"    out_jsonld = os.path.join(\\\\\\\"MODEL_PROVENANCE\\\\\\\", model_name, f\\\\\\\"{model_name}.jsonld\\\\\\\")\\\\n\\\",\\n+    \\\"    with open(out_jsonld, \\\\\\\"w\\\\\\\", encoding=\\\\\\\"utf-8\\\\\\\") as f:\\\\n\\\",\\n+    \\\"        json.dump(doc, f, indent=2)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    #\\u2013\\u2013 parse & serialize to Turtle\\\\n\\\",\\n+    \\\"    g = Graph().parse(data=json.dumps(doc), format=\\\\\\\"json-ld\\\\\\\")\\\\n\\\",\\n+    \\\"    out_ttl = os.path.join(\\\\\\\"MODEL_PROVENANCE\\\\\\\", model_name, f\\\\\\\"{model_name}.ttl\\\\\\\")\\\\n\\\",\\n+    \\\"    g.serialize(destination=out_ttl, format=\\\\\\\"turtle\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    print(f\\\\\\\"Converted {basename} \\u2192 {os.path.basename(out_jsonld)}, {os.path.basename(out_ttl)}\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"83d6d524-01da-4f20-8131-0d4a3ac005e2\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"This code programatically, finds diff between generated Json file and created JsonLD and .TTL file to make it easier to understand if there is any discrepency\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 67,\\n+   \\\"id\\\": \\\"77a420c0-230d-41c0-9b63-f3dbbca1e670\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"== JSON-LD vs TTL ==\\\\n\\\",\\n+      \\\"Change summary:\\\\n\\\",\\n+      \\\"type\\\\n\\\",\\n+      \\\"changed    1 \\\\n\\\",\\n+      \\\"\\\\n\\\",\\n+      \\\"First 10 \\u2018changed\\u2019 entries:\\\\n\\\",\\n+      \\\"Top-level adds/removes:\\\\n\\\",\\n+      \\\"Empty DataFrame\\\\n\\\",\\n+      \\\"Columns: [path, type, a, b]\\\\n\\\",\\n+      \\\"Index: []\\\\n\\\",\\n+      \\\"\\\\n\\\",\\n+      \\\"== JSON vs JSON-LD ==\\\\n\\\",\\n+      \\\"Change summary:\\\\n\\\",\\n+      \\\"type\\\\n\\\",\\n+      \\\"added      3\\\\n\\\",\\n+      \\\"removed    1\\\\n\\\",\\n+      \\\"changed    1 \\\\n\\\",\\n+      \\\"\\\\n\\\",\\n+      \\\"First 10 \\u2018changed\\u2019 entries:\\\\n\\\",\\n+      \\\"Top-level adds/removes:\\\\n\\\",\\n+      \\\"Empty DataFrame\\\\n\\\",\\n+      \\\"Columns: [path, type, a, b]\\\\n\\\",\\n+      \\\"Index: []\\\\n\\\"\\n+     ]\\n+    }\\n+   ],\\n+   \\\"source\\\": [\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"def load_as_dict(path):\\\\n\\\",\\n+    \\\"    if path.endswith((\\\\\\\".ttl\\\\\\\", \\\\\\\".turtle\\\\\\\")):\\\\n\\\",\\n+    \\\"        g = Graph()\\\\n\\\",\\n+    \\\"        g.parse(path, format=\\\\\\\"turtle\\\\\\\")\\\\n\\\",\\n+    \\\"        # normalize to JSON-LD dict\\\\n\\\",\\n+    \\\"        return json.loads(g.serialize(format=\\\\\\\"json-ld\\\\\\\", indent=2))\\\\n\\\",\\n+    \\\"    else:\\\\n\\\",\\n+    \\\"        with open(path, encoding=\\\\\\\"utf-8\\\\\\\") as f:\\\\n\\\",\\n+    \\\"            return json.load(f)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"def compare_json(a, b, path=\\\\\\\"\\\\\\\"):\\\\n\\\",\\n+    \\\"    diffs = []\\\\n\\\",\\n+    \\\"    if isinstance(a, dict) and isinstance(b, dict):\\\\n\\\",\\n+    \\\"        all_keys = set(a) | set(b)\\\\n\\\",\\n+    \\\"        for k in all_keys:\\\\n\\\",\\n+    \\\"            new_path = f\\\\\\\"{path}/{k}\\\\\\\" if path else k\\\\n\\\",\\n+    \\\"            if k not in a:\\\\n\\\",\\n+    \\\"                diffs.append({\\\\\\\"path\\\\\\\": new_path, \\\\\\\"type\\\\\\\": \\\\\\\"added\\\\\\\",   \\\\\\\"a\\\\\\\": None,    \\\\\\\"b\\\\\\\": b[k]})\\\\n\\\",\\n+    \\\"            elif k not in b:\\\\n\\\",\\n+    \\\"                diffs.append({\\\\\\\"path\\\\\\\": new_path, \\\\\\\"type\\\\\\\": \\\\\\\"removed\\\\\\\", \\\\\\\"a\\\\\\\": a[k],   \\\\\\\"b\\\\\\\": None})\\\\n\\\",\\n+    \\\"            else:\\\\n\\\",\\n+    \\\"                diffs.extend(compare_json(a[k], b[k], new_path))\\\\n\\\",\\n+    \\\"    elif isinstance(a, list) and isinstance(b, list):\\\\n\\\",\\n+    \\\"        for i, (ia, ib) in enumerate(zip(a, b)):\\\\n\\\",\\n+    \\\"            diffs.extend(compare_json(ia, ib, f\\\\\\\"{path}[{i}]\\\\\\\"))\\\\n\\\",\\n+    \\\"        # handle length mismatches\\\\n\\\",\\n+    \\\"        if len(a) < len(b):\\\\n\\\",\\n+    \\\"            for i in range(len(a), len(b)):\\\\n\\\",\\n+    \\\"                diffs.append({\\\\\\\"path\\\\\\\": f\\\\\\\"{path}[{i}]\\\\\\\", \\\\\\\"type\\\\\\\": \\\\\\\"added\\\\\\\",   \\\\\\\"a\\\\\\\": None,  \\\\\\\"b\\\\\\\": b[i]})\\\\n\\\",\\n+    \\\"        elif len(a) > len(b):\\\\n\\\",\\n+    \\\"            for i in range(len(b), len(a)):\\\\n\\\",\\n+    \\\"                diffs.append({\\\\\\\"path\\\\\\\": f\\\\\\\"{path}[{i}]\\\\\\\", \\\\\\\"type\\\\\\\": \\\\\\\"removed\\\\\\\", \\\\\\\"a\\\\\\\": a[i],  \\\\\\\"b\\\\\\\": None})\\\\n\\\",\\n+    \\\"    else:\\\\n\\\",\\n+    \\\"        if a != b:\\\\n\\\",\\n+    \\\"            diffs.append({\\\\\\\"path\\\\\\\": path, \\\\\\\"type\\\\\\\": \\\\\\\"changed\\\\\\\", \\\\\\\"a\\\\\\\": a, \\\\\\\"b\\\\\\\": b})\\\\n\\\",\\n+    \\\"    return diffs\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# --- Usage example -----------------------------------------------\\\\n\\\",\\n+    \\\"# REPO/notebooks/RQ_notebooks/MODEL_PROVENANCE/RandomForest_Iris_v20250425_121328/RandomForest_Iris_v20250425_121328_run_summary.json\\\\n\\\",\\n+    \\\"# # Compare JSON-LD vs Turtle:\\\\n\\\",\\n+    \\\"# a = load_as_dict(\\\\\\\"MODEL_PROVENANCE/RandomForest_Iris_v20250423_230422_run_summary.json\\\\\\\")\\\\n\\\",\\n+    \\\"# b = load_as_dict(\\\\\\\"MODEL_PROVENANCE/RandomForest_Iris_v20250423_230422.ttl\\\\\\\")\\\\n\\\",\\n+    \\\"# diffs_jsonld_vs_ttl = compare_json(a, b)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# # Compare JSON vs JSON-LD:\\\\n\\\",\\n+    \\\"# c = load_as_dict(\\\\\\\"MODEL_PROVENANCE/RandomForest_Iris_v20250423_230422_run_summary.json\\\\\\\")\\\\n\\\",\\n+    \\\"# d = load_as_dict(\\\\\\\"MODEL_PROVENANCE/RandomForest_Iris_v20250423_230422.jsonld\\\\\\\")\\\\n\\\",\\n+    \\\"# diffs_json_vs_jsonld = compare_json(c, d)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# Define base directory\\\\n\\\",\\n+    \\\"base_dir = os.path.join(\\\\\\\"MODEL_PROVENANCE\\\\\\\", model_name)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# Build full paths for the files to compare\\\\n\\\",\\n+    \\\"summary_json    = os.path.join(base_dir, f\\\\\\\"{model_name}_run_summary.json\\\\\\\")\\\\n\\\",\\n+    \\\"turtle_file     = os.path.join(base_dir, f\\\\\\\"{model_name}.ttl\\\\\\\")\\\\n\\\",\\n+    \\\"jsonld_file     = os.path.join(base_dir, f\\\\\\\"{model_name}.jsonld\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# Load files\\\\n\\\",\\n+    \\\"a = load_as_dict(summary_json)\\\\n\\\",\\n+    \\\"b = load_as_dict(turtle_file)\\\\n\\\",\\n+    \\\"c = load_as_dict(summary_json)\\\\n\\\",\\n+    \\\"d = load_as_dict(jsonld_file)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# Perform comparisons\\\\n\\\",\\n+    \\\"diffs_jsonld_vs_ttl = compare_json(a, b)\\\\n\\\",\\n+    \\\"diffs_json_vs_jsonld = compare_json(c, d)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# Build DataFrames for interactive inspection\\\\n\\\",\\n+    \\\"df1 = pd.DataFrame(diffs_jsonld_vs_ttl)\\\\n\\\",\\n+    \\\"df2 = pd.DataFrame(diffs_json_vs_jsonld)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# --- Summaries & Filtering ---------------------------------------\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"def summarize_and_preview(df, preview_n=10):\\\\n\\\",\\n+    \\\"    print(\\\\\\\"Change summary:\\\\\\\")\\\\n\\\",\\n+    \\\"    print(df['type'].value_counts().to_string(), \\\\\\\"\\\\\\\\n\\\\\\\")\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    print(f\\\\\\\"First {preview_n} \\u2018changed\\u2019 entries:\\\\\\\")\\\\n\\\",\\n+    \\\"    # print(df[df['type']==\\\\\\\"changed\\\\\\\"].head(preview_n).to_string(index=False), \\\\\\\"\\\\\\\\n\\\\\\\")\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    # Top\\u2010level (one slash) adds/removes\\\\n\\\",\\n+    \\\"    top = df[df['path'].str.count(\\\\\\\"/\\\\\\\") == 1]\\\\n\\\",\\n+    \\\"    print(\\\\\\\"Top-level adds/removes:\\\\\\\")\\\\n\\\",\\n+    \\\"    print(top[top['type'].isin(['added','removed'])].to_string(index=False))\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"print(\\\\\\\"== JSON-LD vs TTL ==\\\\\\\")\\\\n\\\",\\n+    \\\"summarize_and_preview(df1)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"print(\\\\\\\"\\\\\\\\n== JSON vs JSON-LD ==\\\\\\\")\\\\n\\\",\\n+    \\\"summarize_and_preview(df2)\\\\n\\\",\\n+    \\\"\\\\n\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 68,\\n+   \\\"id\\\": \\\"41af9d6e-c683-45f9-bac1-296611b4d0b9\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"Removed in JSON-LD comparison:\\\\n\\\",\\n+      \\\"    path\\\\n\\\",\\n+      \\\"end_time\\\\n\\\",\\n+      \\\"\\\\n\\\",\\n+      \\\"Added in JSON-LD comparison:\\\\n\\\",\\n+      \\\"     path\\\\n\\\",\\n+      \\\" @context\\\\n\\\",\\n+      \\\"     used\\\\n\\\",\\n+      \\\"generated\\\\n\\\"\\n+     ]\\n+    }\\n+   ],\\n+   \\\"source\\\": [\\n+    \\\"# show all the removed paths (in JSON but not in JSON-LD)\\\\n\\\",\\n+    \\\"print(\\\\\\\"Removed in JSON-LD comparison:\\\\\\\")\\\\n\\\",\\n+    \\\"print(df2[df2['type']==\\\\\\\"removed\\\\\\\"][['path']].to_string(index=False))\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# show all the added paths (in JSON-LD but not in JSON)\\\\n\\\",\\n+    \\\"print(\\\\\\\"\\\\\\\\nAdded in JSON-LD comparison:\\\\\\\")\\\\n\\\",\\n+    \\\"print(df2[df2['type']==\\\\\\\"added\\\\\\\"][['path']].to_string(index=False))\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 69,\\n+   \\\"id\\\": \\\"f0d6f92a-5cd9-4c78-9c2a-0cd3247137c6\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"Removed in .ttl comparison:\\\\n\\\",\\n+      \\\"Empty DataFrame\\\\n\\\",\\n+      \\\"Columns: [path]\\\\n\\\",\\n+      \\\"Index: []\\\\n\\\",\\n+      \\\"\\\\n\\\",\\n+      \\\"Added in .ttl comparison:\\\\n\\\",\\n+      \\\"Empty DataFrame\\\\n\\\",\\n+      \\\"Columns: [path]\\\\n\\\",\\n+      \\\"Index: []\\\\n\\\"\\n+     ]\\n+    }\\n+   ],\\n+   \\\"source\\\": [\\n+    \\\"# show all the removed paths (in JSON but not in JSON-LD)\\\\n\\\",\\n+    \\\"print(\\\\\\\"Removed in .ttl comparison:\\\\\\\")\\\\n\\\",\\n+    \\\"print(df1[df1['type']==\\\\\\\"removed\\\\\\\"][['path']].to_string(index=False))\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# show all the added paths (in JSON-LD but not in JSON)\\\\n\\\",\\n+    \\\"print(\\\\\\\"\\\\\\\\nAdded in .ttl comparison:\\\\\\\")\\\\n\\\",\\n+    \\\"print(df1[df1['type']==\\\\\\\"added\\\\\\\"][['path']].to_string(index=False))\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"69efd0d0-9277-4efa-88cf-d2fd1b90d74c\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"Checks for completeness and mapping and time taken, needs work #TODO\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 70,\\n+   \\\"id\\\": \\\"165a13eb-7679-4f4c-b346-24f25da72cce\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\\\n\\\",\\n+      \\\"0/0 runs passed completeness checks (0.0%).\\\\n\\\",\\n+      \\\"\\\\n\\\",\\n+      \\\"Mapping integrity: 0/0 runs have zero diffs \\u2014 0.0%\\\\n\\\",\\n+      \\\"Overall quality score: 0.0%\\\\n\\\",\\n+      \\\"\\\\n\\\",\\n+      \\\"Benchmarking train_and_log() overhead:\\\\n\\\",\\n+      \\\"  \\u2022 No MLflow : 0.502s\\\\n\\\",\\n+      \\\"  \\u2022 With MLflow: 0.601s\\\\n\\\"\\n+     ]\\n+    }\\n+   ],\\n+   \\\"source\\\": [\\n+    \\\"\\\\n\\\",\\n+    \\\"# \\u2500\\u2500 User configuration \\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# Which keys must appear in every run_summary.json?\\\\n\\\",\\n+    \\\"REQUIRED_TOPLEVEL = {\\\\n\\\",\\n+    \\\"    \\\\\\\"run_id\\\\\\\", \\\\\\\"start_time\\\\\\\", \\\\\\\"end_time\\\\\\\",\\\\n\\\",\\n+    \\\"    \\\\\\\"params\\\\\\\", \\\\\\\"metrics\\\\\\\", \\\\\\\"tags\\\\\\\", \\\\\\\"artifacts\\\\\\\"\\\\n\\\",\\n+    \\\"}\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# A couple of sub-fields we also want to spot-check:\\\\n\\\",\\n+    \\\"REQUIRED_PARAMS  = {\\\\\\\"random_state\\\\\\\"}\\\\n\\\",\\n+    \\\"REQUIRED_METRICS = {\\\\\\\"accuracy\\\\\\\"}\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"JSON_SUMMARIES = glob.glob(\\\\\\\"MODEL_PROVENANCE/*_run_summary.json\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# \\u2500\\u2500 Helpers \\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"def iso8601(ms):\\\\n\\\",\\n+    \\\"    return datetime.fromtimestamp(ms/1000, tz=timezone.utc).isoformat()\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"def load_json(path):\\\\n\\\",\\n+    \\\"    with open(path, \\\\\\\"r\\\\\\\", encoding=\\\\\\\"utf-8\\\\\\\") as f:\\\\n\\\",\\n+    \\\"        return json.load(f)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"def write_json(path, obj):\\\\n\\\",\\n+    \\\"    with open(path, \\\\\\\"w\\\\\\\", encoding=\\\\\\\"utf-8\\\\\\\") as f:\\\\n\\\",\\n+    \\\"        json.dump(obj, f, indent=2)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"def convert_to_jsonld_and_ttl(summary, basename):\\\\n\\\",\\n+    \\\"    # build @context\\\\n\\\",\\n+    \\\"    ctx = {\\\\n\\\",\\n+    \\\"        \\\\\\\"prov\\\\\\\":    \\\\\\\"http://www.w3.org/ns/prov#\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"xsd\\\\\\\":     \\\\\\\"http://www.w3.org/2001/XMLSchema#\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"run\\\\\\\":     \\\\\\\"prov:Activity\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"start\\\\\\\":   \\\\\\\"prov:startedAtTime\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"end\\\\\\\":     \\\\\\\"prov:endedAtTime\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"used\\\\\\\":    \\\\\\\"prov:used\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"gen\\\\\\\":     \\\\\\\"prov:generated\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"param\\\\\\\":   \\\\\\\"prov:hadParameter\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"metric\\\\\\\":  \\\\\\\"prov:hadQuality\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"entity\\\\\\\":  \\\\\\\"prov:Entity\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"label\\\\\\\":   \\\\\\\"prov:label\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"value\\\\\\\":   \\\\\\\"prov:value\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"version\\\\\\\": \\\\\\\"prov:hadRevision\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"id\\\\\\\":      \\\\\\\"@id\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"type\\\\\\\":    \\\\\\\"@type\\\\\\\"\\\\n\\\",\\n+    \\\"    }\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    jsonld = {\\\\n\\\",\\n+    \\\"        \\\\\\\"@context\\\\\\\": ctx,\\\\n\\\",\\n+    \\\"        \\\\\\\"@id\\\\\\\":      f\\\\\\\"urn:run:{summary['run_id']}\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"@type\\\\\\\":    \\\\\\\"run\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"start\\\\\\\": {\\\\n\\\",\\n+    \\\"            \\\\\\\"@type\\\\\\\":  \\\\\\\"xsd:dateTime\\\\\\\",\\\\n\\\",\\n+    \\\"            \\\\\\\"@value\\\\\\\": iso8601(summary[\\\\\\\"start_time\\\\\\\"])\\\\n\\\",\\n+    \\\"        }\\\\n\\\",\\n+    \\\"    }\\\\n\\\",\\n+    \\\"    if summary.get(\\\\\\\"end_time\\\\\\\") is not None:\\\\n\\\",\\n+    \\\"        jsonld[\\\\\\\"end\\\\\\\"] = {\\\\n\\\",\\n+    \\\"            \\\\\\\"@type\\\\\\\":  \\\\\\\"xsd:dateTime\\\\\\\",\\\\n\\\",\\n+    \\\"            \\\\\\\"@value\\\\\\\": iso8601(summary[\\\\\\\"end_time\\\\\\\"])\\\\n\\\",\\n+    \\\"        }\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # params\\\\n\\\",\\n+    \\\"    jsonld[\\\\\\\"param\\\\\\\"] = [\\\\n\\\",\\n+    \\\"        {\\\\\\\"@type\\\\\\\":\\\\\\\"entity\\\\\\\",\\\\\\\"label\\\\\\\":k,\\\\\\\"value\\\\\\\":str(v)}\\\\n\\\",\\n+    \\\"        for k,v in summary.get(\\\\\\\"params\\\\\\\",{}).items()\\\\n\\\",\\n+    \\\"    ]\\\\n\\\",\\n+    \\\"    # metrics\\\\n\\\",\\n+    \\\"    jsonld[\\\\\\\"metric\\\\\\\"] = [\\\\n\\\",\\n+    \\\"        {\\\\\\\"@type\\\\\\\":\\\\\\\"entity\\\\\\\",\\\\\\\"label\\\\\\\":k,\\\\n\\\",\\n+    \\\"         \\\\\\\"value\\\\\\\":{\\\\\\\"@type\\\\\\\":\\\\\\\"xsd:decimal\\\\\\\",\\\\\\\"@value\\\\\\\":v}}\\\\n\\\",\\n+    \\\"        for k,v in summary.get(\\\\\\\"metrics\\\\\\\",{}).items()\\\\n\\\",\\n+    \\\"    ]\\\\n\\\",\\n+    \\\"    # artifacts\\\\n\\\",\\n+    \\\"    jsonld[\\\\\\\"gen\\\\\\\"] = [\\\\n\\\",\\n+    \\\"        {\\\\n\\\",\\n+    \\\"            \\\\\\\"@type\\\\\\\":\\\\\\\"entity\\\\\\\",\\\\n\\\",\\n+    \\\"            \\\\\\\"label\\\\\\\": art.get(\\\\\\\"path\\\\\\\") or art.get(\\\\\\\"label\\\\\\\"),\\\\n\\\",\\n+    \\\"            \\\\\\\"prov:location\\\\\\\": (\\\\n\\\",\\n+    \\\"                art.get(\\\\\\\"uri\\\\\\\")\\\\n\\\",\\n+    \\\"                or (art.get(\\\\\\\"content\\\\\\\",\\\\\\\"\\\\\\\")[:30]+\\\\\\\"\\u2026\\\\\\\")\\\\n\\\",\\n+    \\\"                if isinstance(art.get(\\\\\\\"content\\\\\\\"),str)\\\\n\\\",\\n+    \\\"                else \\\\\\\"\\\\\\\"\\\\n\\\",\\n+    \\\"            )\\\\n\\\",\\n+    \\\"        }\\\\n\\\",\\n+    \\\"        for art in summary.get(\\\\\\\"artifacts\\\\\\\",[])\\\\n\\\",\\n+    \\\"    ]\\\\n\\\",\\n+    \\\"    # dataset used\\\\n\\\",\\n+    \\\"    jsonld[\\\\\\\"used\\\\\\\"] = {\\\\n\\\",\\n+    \\\"        \\\\\\\"@type\\\\\\\":\\\\\\\"entity\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"label\\\\\\\": summary[\\\\\\\"tags\\\\\\\"].get(\\\\\\\"dataset_name\\\\\\\"),\\\\n\\\",\\n+    \\\"        \\\\\\\"version\\\\\\\": summary[\\\\\\\"tags\\\\\\\"].get(\\\\\\\"dataset_version\\\\\\\")\\\\n\\\",\\n+    \\\"    }\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # write JSON-LD\\\\n\\\",\\n+    \\\"    out_jsonld = f\\\\\\\"MODEL_PROVENANCE/{basename}.jsonld\\\\\\\"\\\\n\\\",\\n+    \\\"    write_json(out_jsonld, jsonld)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # serialize TTL\\\\n\\\",\\n+    \\\"    g = Graph().parse(data=json.dumps(jsonld), format=\\\\\\\"json-ld\\\\\\\")\\\\n\\\",\\n+    \\\"    out_ttl = f\\\\\\\"MODEL_PROVENANCE/{basename}.ttl\\\\\\\"\\\\n\\\",\\n+    \\\"    g.serialize(destination=out_ttl, format=\\\\\\\"turtle\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    return out_jsonld, out_ttl\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"def normalize_jsonld(js):\\\\n\\\",\\n+    \\\"    \\\\\\\"\\\\\\\"\\\\\\\"Simple deep-sort so compare_json doesn\\u2019t trip over ordering.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\",\\n+    \\\"    if isinstance(js, dict):\\\\n\\\",\\n+    \\\"        return {k: normalize_jsonld(js[k]) for k in sorted(js)}\\\\n\\\",\\n+    \\\"    if isinstance(js, list):\\\\n\\\",\\n+    \\\"        return sorted((normalize_jsonld(el) for el in js),\\\\n\\\",\\n+    \\\"                      key=lambda x: json.dumps(x, sort_keys=True))\\\\n\\\",\\n+    \\\"    return js\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"def diff_roundtrip(orig_json, jsonld_path, ttl_path):\\\\n\\\",\\n+    \\\"    orig = load_json(orig_json)\\\\n\\\",\\n+    \\\"    ld   = load_json(jsonld_path)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # parse TTL back to JSON-LD\\\\n\\\",\\n+    \\\"    g = Graph().parse(ttl_path, format=\\\\\\\"turtle\\\\\\\")\\\\n\\\",\\n+    \\\"    ttl_as_ld = json.loads(g.serialize(format=\\\\\\\"json-ld\\\\\\\"))\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # normalize\\\\n\\\",\\n+    \\\"    nl = normalize_jsonld(ld)\\\\n\\\",\\n+    \\\"    nt = normalize_jsonld(ttl_as_ld)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    return {\\\\n\\\",\\n+    \\\"        \\\\\\\"orig_vs_jsonld\\\\\\\":   compare_json(orig, ld),\\\\n\\\",\\n+    \\\"        \\\\\\\"jsonld_vs_ttl_ld\\\\\\\": compare_json(nl, nt)\\\\n\\\",\\n+    \\\"    }\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# \\u2500\\u2500 Main flow \\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"def main():\\\\n\\\",\\n+    \\\"    ok = 0\\\\n\\\",\\n+    \\\"    total = len(JSON_SUMMARIES)\\\\n\\\",\\n+    \\\"    missing_reports = []\\\\n\\\",\\n+    \\\"    cases = {}  # store diff results per run\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    for js_path in JSON_SUMMARIES:\\\\n\\\",\\n+    \\\"        summary = load_json(js_path)\\\\n\\\",\\n+    \\\"        base    = os.path.basename(js_path).split(\\\\\\\"_run_summary.json\\\\\\\")[0]\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"        # 1) completeness check\\\\n\\\",\\n+    \\\"        if not REQUIRED_TOPLEVEL.issubset(summary):\\\\n\\\",\\n+    \\\"            missing = REQUIRED_TOPLEVEL - set(summary)\\\\n\\\",\\n+    \\\"            missing_reports.append((js_path, f\\\\\\\"missing fields {missing}\\\\\\\"))\\\\n\\\",\\n+    \\\"            continue\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"        if not (REQUIRED_PARAMS <= summary[\\\\\\\"params\\\\\\\"].keys()):\\\\n\\\",\\n+    \\\"            missing_reports.append((js_path, f\\\\\\\"params missing {REQUIRED_PARAMS - summary['params'].keys()}\\\\\\\"))\\\\n\\\",\\n+    \\\"            continue\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"        if not (REQUIRED_METRICS <= summary[\\\\\\\"metrics\\\\\\\"].keys()):\\\\n\\\",\\n+    \\\"            missing_reports.append((js_path, f\\\\\\\"metrics missing {REQUIRED_METRICS - summary['metrics'].keys()}\\\\\\\"))\\\\n\\\",\\n+    \\\"            continue\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"        ok += 1\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"        # 2) convert\\\\n\\\",\\n+    \\\"        jsonld_path, ttl_path = convert_to_jsonld_and_ttl(summary, base)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"        # 3) diff\\\\n\\\",\\n+    \\\"        diffs = diff_roundtrip(js_path, jsonld_path, ttl_path)\\\\n\\\",\\n+    \\\"        cases[base] = diffs\\\\n\\\",\\n+    \\\"        print(f\\\\\\\"\\\\\\\\n\\u2500\\u2500 {base} diffs \\u2500\\u2500\\\\\\\")\\\\n\\\",\\n+    \\\"        print(\\\\\\\"  \\u2022 JSON \\u2192 JSON-LD:\\\\\\\", len(diffs[\\\\\\\"orig_vs_jsonld\\\\\\\"]), \\\\\\\"differences\\\\\\\")\\\\n\\\",\\n+    \\\"        print(\\\\\\\"  \\u2022 JSON-LD \\u2192 TTL \\u2192 JSON-LD:\\\\\\\", len(diffs[\\\\\\\"jsonld_vs_ttl_ld\\\\\\\"]), \\\\\\\"differences\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # 4) completeness summary\\\\n\\\",\\n+    \\\"    completeness_pct = (100 * ok / total) if total else 0\\\\n\\\",\\n+    \\\"    print(f\\\\\\\"\\\\\\\\n{ok}/{total} runs passed completeness checks ({completeness_pct:.1f}%).\\\\\\\")\\\\n\\\",\\n+    \\\"    if missing_reports:\\\\n\\\",\\n+    \\\"        print(\\\\\\\"\\\\\\\\nFailures:\\\\\\\")\\\\n\\\",\\n+    \\\"        for path, reason in missing_reports:\\\\n\\\",\\n+    \\\"            print(f\\\\\\\" \\u2022 {path}: {reason}\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # 5) integrity check\\\\n\\\",\\n+    \\\"    total_runs = len(cases)\\\\n\\\",\\n+    \\\"    zero_diff_runs = sum(\\\\n\\\",\\n+    \\\"        1\\\\n\\\",\\n+    \\\"        for diffs in cases.values()\\\\n\\\",\\n+    \\\"        if not diffs[\\\\\\\"orig_vs_jsonld\\\\\\\"] and not diffs[\\\\\\\"jsonld_vs_ttl_ld\\\\\\\"]\\\\n\\\",\\n+    \\\"    )\\\\n\\\",\\n+    \\\"    integrity_pct = (100 * zero_diff_runs / total_runs) if total_runs else 0\\\\n\\\",\\n+    \\\"    print(f\\\\\\\"\\\\\\\\nMapping integrity: {zero_diff_runs}/{total_runs} runs have zero diffs \\u2014 {integrity_pct:.1f}%\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # 6) overall quality score\\\\n\\\",\\n+    \\\"    overall_score = (completeness_pct + integrity_pct) / 2\\\\n\\\",\\n+    \\\"    print(f\\\\\\\"Overall quality score: {overall_score:.1f}%\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # 7) Benchmark your training fn\\\\n\\\",\\n+    \\\"    print(\\\\\\\"\\\\\\\\nBenchmarking train_and_log() overhead:\\\\\\\")\\\\n\\\",\\n+    \\\"    def train_and_log(use_mlflow=False):\\\\n\\\",\\n+    \\\"        # \\u2190 your real instrumentation + fit logic here\\\\n\\\",\\n+    \\\"        time.sleep(0.5 + (0.1 if use_mlflow else 0))  # stub\\\\n\\\",\\n+    \\\"        return\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    for flag in (False, True):\\\\n\\\",\\n+    \\\"        start = time.time()\\\\n\\\",\\n+    \\\"        train_and_log(use_mlflow=flag)\\\\n\\\",\\n+    \\\"        elapsed = time.time() - start\\\\n\\\",\\n+    \\\"        label = \\\\\\\"With MLflow\\\\\\\" if flag else \\\\\\\"No MLflow\\\\\\\"\\\\n\\\",\\n+    \\\"        print(f\\\\\\\"  \\u2022 {label:10s}: {elapsed:.3f}s\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"if __name__ == \\\\\\\"__main__\\\\\\\":\\\\n\\\",\\n+    \\\"    main()\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"5883f673-371e-415e-a73e-5c9c88b56fb1\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"RQ2  implementation\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 72,\\n+   \\\"id\\\": \\\"6d07ac1c-ea80-4787-bcb9-da047d12167d\\\",\\n+   \\\"metadata\\\": {\\n+    \\\"scrolled\\\": true\\n+   },\\n+   \\\"outputs\\\": [\\n+    {\\n+     \\\"data\\\": {\\n+      \\\"text/plain\\\": [\\n+       \\\"Index(['run_id', 'param_bootstrap', 'param_ccp_alpha', 'param_class_weight',\\\\n\\\",\\n+       \\\"       'param_columns_raw', 'param_criterion', 'param_database.description',\\\\n\\\",\\n+       \\\"       'param_database.id', 'param_database.name', 'param_database.owner',\\\\n\\\",\\n+       \\\"       'param_dataset.authors', 'param_dataset.doi', 'param_dataset.published',\\\\n\\\",\\n+       \\\"       'param_dataset.publisher', 'param_dataset.title',\\\\n\\\",\\n+       \\\"       'param_dropped_columns', 'param_feature_names',\\\\n\\\",\\n+       \\\"       'param_matplotlib_version', 'param_max_depth', 'param_max_features',\\\\n\\\",\\n+       \\\"       'param_max_leaf_nodes', 'param_max_samples',\\\\n\\\",\\n+       \\\"       'param_min_impurity_decrease', 'param_min_samples_leaf',\\\\n\\\",\\n+       \\\"       'param_min_samples_split', 'param_min_weight_fraction_leaf',\\\\n\\\",\\n+       \\\"       'param_numpy_version', 'param_n_estimators', 'param_n_features',\\\\n\\\",\\n+       \\\"       'param_n_features_final', 'param_n_jobs', 'param_n_records',\\\\n\\\",\\n+       \\\"       'param_n_test_samples', 'param_n_train_samples', 'param_oob_score',\\\\n\\\",\\n+       \\\"       'param_os_platform', 'param_pandas_version', 'param_python_version',\\\\n\\\",\\n+       \\\"       'param_random_state', 'param_retrieval_time', 'param_seaborn_version',\\\\n\\\",\\n+       \\\"       'param_shap_version', 'param_sklearn_version', 'param_test_size',\\\\n\\\",\\n+       \\\"       'param_verbose', 'param_warm_start', 'metric_accuracy',\\\\n\\\",\\n+       \\\"       'metric_accuracy_score_X_test', 'metric_dbrepo.num_deletes',\\\\n\\\",\\n+       \\\"       'metric_dbrepo.num_inserts', 'metric_dbrepo.row_count_end',\\\\n\\\",\\n+       \\\"       'metric_dbrepo.row_count_start', 'metric_f1_macro',\\\\n\\\",\\n+       \\\"       'metric_f1_score_X_test', 'metric_precision_macro',\\\\n\\\",\\n+       \\\"       'metric_precision_score_X_test', 'metric_recall_macro',\\\\n\\\",\\n+       \\\"       'metric_recall_score_X_test', 'metric_roc_auc',\\\\n\\\",\\n+       \\\"       'metric_roc_auc_score_X_test', 'metric_training_accuracy_score',\\\\n\\\",\\n+       \\\"       'metric_training_f1_score', 'metric_training_log_loss',\\\\n\\\",\\n+       \\\"       'metric_training_precision_score', 'metric_training_recall_score',\\\\n\\\",\\n+       \\\"       'metric_training_roc_auc', 'metric_training_score', 'tag_dataset_id',\\\\n\\\",\\n+       \\\"       'tag_dataset_name', 'tag_dataset_version', 'tag_data_source',\\\\n\\\",\\n+       \\\"       'tag_dbrepo.admin_email', 'tag_dbrepo.base_url',\\\\n\\\",\\n+       \\\"       'tag_dbrepo.granularity', 'tag_dbrepo.protocol_version',\\\\n\\\",\\n+       \\\"       'tag_dbrepo.repository_name', 'tag_dbrepo.table_last_modified',\\\\n\\\",\\n+       \\\"       'tag_estimator_class', 'tag_estimator_name',\\\\n\\\",\\n+       \\\"       'tag_git_current_commit_hash', 'tag_git_previous_commit_hash',\\\\n\\\",\\n+       \\\"       'tag_git__current_commit_url', 'tag_mlflow.log-model.history',\\\\n\\\",\\n+       \\\"       'tag_mlflow.runName', 'tag_mlflow.source.name',\\\\n\\\",\\n+       \\\"       'tag_mlflow.source.type', 'tag_mlflow.user', 'tag_model_name',\\\\n\\\",\\n+       \\\"       'tag_notebook_name', 'tag_target_name', 'tag_training_end_time',\\\\n\\\",\\n+       \\\"       'tag_training_start_time'],\\\\n\\\",\\n+       \\\"      dtype='object')\\\"\\n+      ]\\n+     },\\n+     \\\"execution_count\\\": 72,\\n+     \\\"metadata\\\": {},\\n+     \\\"output_type\\\": \\\"execute_result\\\"\\n+    }\\n+   ],\\n+   \\\"source\\\": [\\n+    \\\"\\\\n\\\",\\n+    \\\"# Load all run summary JSON files\\\\n\\\",\\n+    \\\"files = glob.glob(\\\\\\\"MODEL_PROVENANCE/*/*_run_summary.json\\\\\\\")\\\\n\\\",\\n+    \\\"rows = []\\\\n\\\",\\n+    \\\"for f in files:\\\\n\\\",\\n+    \\\"    with open(f) as fh:\\\\n\\\",\\n+    \\\"        summary = json.load(fh)\\\\n\\\",\\n+    \\\"    # Flatten parameters and metrics\\\\n\\\",\\n+    \\\"    row = {\\\\\\\"run_id\\\\\\\": summary[\\\\\\\"run_id\\\\\\\"]}\\\\n\\\",\\n+    \\\"    row.update({f\\\\\\\"param_{k}\\\\\\\": v for k, v in summary.get(\\\\\\\"params\\\\\\\", {}).items()})\\\\n\\\",\\n+    \\\"    row.update({f\\\\\\\"metric_{k}\\\\\\\": v for k, v in summary.get(\\\\\\\"metrics\\\\\\\", {}).items()})\\\\n\\\",\\n+    \\\"    row.update({f\\\\\\\"tag_{k}\\\\\\\": v for k, v in summary.get(\\\\\\\"tags\\\\\\\", {}).items()})\\\\n\\\",\\n+    \\\"    rows.append(row)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# Create DataFrame\\\\n\\\",\\n+    \\\"df = pd.DataFrame(rows)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# Display the DataFrame\\\\n\\\",\\n+    \\\"df.columns\\\\n\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"ba148da6-6ce5-45cf-a985-f164a53c969b\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"1) Tracing preprocessing steps\\\\n\\\",\\n+    \\\":\\\\n\\\",\\n+    \\\"Here are the top 4 Iris\\u2010focused preprocessing\\u2010tracing use cases I\\u2019d tackle first:\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"Reconstruct a run\\u2019s exact preprocessing\\\\n\\\",\\n+    \\\"Fetch a run\\u2019s run_id, columns_raw, dropped_columns, feature_names and test_size so you can replay the exact data pull & split.\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"Feature\\u2010drop impact analysis\\\\n\\\",\\n+    \\\"Identify runs where one or more measurements (e.g. petalwidthcm) were dropped and compare their test accuracies.\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"Best feature subset discovery\\\\n\\\",\\n+    \\\"Group runs by which features they used (sepals only vs petals only vs both) and rank them by test F1 or accuracy.\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"Common steps in high-accuracy runs\\\\n\\\",\\n+    \\\"Filter for runs with accuracy_score_X_test \\u2265 0.95 and list the shared preprocessing settings (dropped columns, test_size, etc.).\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 73,\\n+   \\\"id\\\": \\\"6e147555-afbf-4bba-b6da-7e90ff391920\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [\\n+    {\\n+     \\\"name\\\": \\\"stderr\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"2025/04/25 12:23:44 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'df84c36b36cc4ebd90a999db3ebc4ad4', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"[{'run_id': '28f01e38b7f04d2f948fe21f57f41d0c', 'param_dataset.title': 'Scikit-Learn Iris', 'param_columns_raw': \\\\\\\"['id', 'sepallengthcm', 'sepalwidthcm', 'petallengthcm', 'petalwidthcm', 'species']\\\\\\\", 'param_dropped_columns': \\\\\\\"['id']\\\\\\\", 'param_feature_names': \\\\\\\"['sepallengthcm', 'sepalwidthcm', 'petallengthcm', 'petalwidthcm']\\\\\\\", 'param_dataset.authors': '[\\\\\\\"Marshall Michael\\\\\\\"]', 'param_dataset.doi': '10.5281/ZENODO.1404173', 'param_dataset.published': '2018-8-27', 'param_test_size': '0.2', 'param_criterion': 'entropy', 'param_max_depth': '12', 'param_max_leaf_nodes': 'None', 'param_max_samples': 'None', 'metric_accuracy': 1.0, 'metric_f1_macro': 1.0, 'metric_roc_auc': 1.0}]\\\\n\\\",\\n+      \\\"[]\\\\n\\\",\\n+      \\\"[{'param_dropped_columns': \\\\\\\"['id']\\\\\\\", 'param_test_size': '0.2', 'param_feature_names': \\\\\\\"['sepallengthcm', 'sepalwidthcm', 'petallengthcm', 'petalwidthcm']\\\\\\\"}]\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"data\\\": {\\n+      \\\"application/vnd.jupyter.widget-view+json\\\": {\\n+       \\\"model_id\\\": \\\"d931b602947d4db8872f254d48e22027\\\",\\n+       \\\"version_major\\\": 2,\\n+       \\\"version_minor\\\": 0\\n+      },\\n+      \\\"text/plain\\\": [\\n+       \\\"Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]\\\"\\n+      ]\\n+     },\\n+     \\\"metadata\\\": {},\\n+     \\\"output_type\\\": \\\"display_data\\\"\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stderr\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"2025/04/25 12:23:52 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '41261519e1a643c5b1335701aee1bf95', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"{'features': ['sepallengthcm', 'sepalwidthcm'], 'accuracy': 0.7666666666666667}\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"data\\\": {\\n+      \\\"application/vnd.jupyter.widget-view+json\\\": {\\n+       \\\"model_id\\\": \\\"83ff1224205a4a8eb0c351a7f299dd93\\\",\\n+       \\\"version_major\\\": 2,\\n+       \\\"version_minor\\\": 0\\n+      },\\n+      \\\"text/plain\\\": [\\n+       \\\"Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]\\\"\\n+      ]\\n+     },\\n+     \\\"metadata\\\": {},\\n+     \\\"output_type\\\": \\\"display_data\\\"\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stderr\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"2025/04/25 12:23:58 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'e0955d231fa6488e9339086b5845064c', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"data\\\": {\\n+      \\\"application/vnd.jupyter.widget-view+json\\\": {\\n+       \\\"model_id\\\": \\\"1eaa6c141e064593b73b6c72ce0b00cf\\\",\\n+       \\\"version_major\\\": 2,\\n+       \\\"version_minor\\\": 0\\n+      },\\n+      \\\"text/plain\\\": [\\n+       \\\"Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]\\\"\\n+      ]\\n+     },\\n+     \\\"metadata\\\": {},\\n+     \\\"output_type\\\": \\\"display_data\\\"\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stderr\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"2025/04/25 12:24:04 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '21d299b426ac42a0ad799604e9e7ff88', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"{'dropped_feature': 'petallengthcm', 'baseline_acc': 1.0, 'dropped_acc': 0.9666666666666667, 'impact': 0.033333333333333326}\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"data\\\": {\\n+      \\\"application/vnd.jupyter.widget-view+json\\\": {\\n+       \\\"model_id\\\": \\\"4c04ce12f62f49a29f48509b1483f16b\\\",\\n+       \\\"version_major\\\": 2,\\n+       \\\"version_minor\\\": 0\\n+      },\\n+      \\\"text/plain\\\": [\\n+       \\\"Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]\\\"\\n+      ]\\n+     },\\n+     \\\"metadata\\\": {},\\n+     \\\"output_type\\\": \\\"display_data\\\"\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stderr\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"2025/04/25 12:24:10 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '8ca4591a1b53402f854187104d1e7ee0', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"data\\\": {\\n+      \\\"application/vnd.jupyter.widget-view+json\\\": {\\n+       \\\"model_id\\\": \\\"66bf06c45648410daa144c12f85658c6\\\",\\n+       \\\"version_major\\\": 2,\\n+       \\\"version_minor\\\": 0\\n+      },\\n+      \\\"text/plain\\\": [\\n+       \\\"Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]\\\"\\n+      ]\\n+     },\\n+     \\\"metadata\\\": {},\\n+     \\\"output_type\\\": \\\"display_data\\\"\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stderr\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"2025/04/25 12:24:16 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '0c8a66e5e4b244f9a6a8e9fa02d26828', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"data\\\": {\\n+      \\\"application/vnd.jupyter.widget-view+json\\\": {\\n+       \\\"model_id\\\": \\\"0d71b6d9b58d4e5a9db241baeaa79d53\\\",\\n+       \\\"version_major\\\": 2,\\n+       \\\"version_minor\\\": 0\\n+      },\\n+      \\\"text/plain\\\": [\\n+       \\\"Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]\\\"\\n+      ]\\n+     },\\n+     \\\"metadata\\\": {},\\n+     \\\"output_type\\\": \\\"display_data\\\"\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stderr\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"2025/04/25 12:24:22 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '53994143a51e481abd23e988be2466b1', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"data\\\": {\\n+      \\\"application/vnd.jupyter.widget-view+json\\\": {\\n+       \\\"model_id\\\": \\\"3fa13db4a66940d59cf37a30cb7a3cbc\\\",\\n+       \\\"version_major\\\": 2,\\n+       \\\"version_minor\\\": 0\\n+      },\\n+      \\\"text/plain\\\": [\\n+       \\\"Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]\\\"\\n+      ]\\n+     },\\n+     \\\"metadata\\\": {},\\n+     \\\"output_type\\\": \\\"display_data\\\"\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stderr\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"2025/04/25 12:24:28 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '35588f1cd8c34ce28770848de714d3c4', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"data\\\": {\\n+      \\\"application/vnd.jupyter.widget-view+json\\\": {\\n+       \\\"model_id\\\": \\\"273c026f2e0b464f98090472792b3a87\\\",\\n+       \\\"version_major\\\": 2,\\n+       \\\"version_minor\\\": 0\\n+      },\\n+      \\\"text/plain\\\": [\\n+       \\\"Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]\\\"\\n+      ]\\n+     },\\n+     \\\"metadata\\\": {},\\n+     \\\"output_type\\\": \\\"display_data\\\"\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"[{'dropped_feature': 'sepallengthcm', 'baseline_acc': 1.0, 'dropped_acc': 1.0, 'impact': 0.0}, {'dropped_feature': 'sepalwidthcm', 'baseline_acc': 1.0, 'dropped_acc': 1.0, 'impact': 0.0}, {'dropped_feature': 'petallengthcm', 'baseline_acc': 1.0, 'dropped_acc': 0.9666666666666667, 'impact': 0.0333}, {'dropped_feature': 'petalwidthcm', 'baseline_acc': 1.0, 'dropped_acc': 0.9666666666666667, 'impact': 0.0333}]\\\\n\\\"\\n+     ]\\n+    }\\n+   ],\\n+   \\\"source\\\": [\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# Helper to get the \\u201cofficial\\u201d feature_names from your summary DF\\\\n\\\",\\n+    \\\"def _get_all_features(df):\\\\n\\\",\\n+    \\\"    # assumes every row has the same param_feature_names\\\\n\\\",\\n+    \\\"    raw = df.loc[0, 'param_feature_names']\\\\n\\\",\\n+    \\\"    return ast.literal_eval(raw)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# Train & eval RF on just these columns of Iris\\\\n\\\",\\n+    \\\"def evaluate_subset(features, test_size=0.2, random_state=42, n_estimators=200):\\\\n\\\",\\n+    \\\"    iris = load_iris()\\\\n\\\",\\n+    \\\"    X = pd.DataFrame(iris.data, columns=iris.feature_names)\\\\n\\\",\\n+    \\\"    # map sklearn\\u2019s names to your param names, e.g. \\\\\\\"sepal length (cm)\\\\\\\" \\u2192 \\\\\\\"sepallengthcm\\\\\\\"\\\\n\\\",\\n+    \\\"    canon = _get_all_features(df)\\\\n\\\",\\n+    \\\"    mapping = dict(zip(iris.feature_names, canon))\\\\n\\\",\\n+    \\\"    X = X.rename(columns=mapping)\\\\n\\\",\\n+    \\\"    X_sub = X[features]\\\\n\\\",\\n+    \\\"    y = iris.target\\\\n\\\",\\n+    \\\"    Xtr, Xte, ytr, yte = train_test_split(X_sub, y, test_size=test_size, random_state=random_state)\\\\n\\\",\\n+    \\\"    m = RandomForestClassifier(n_estimators=n_estimators, random_state=random_state)\\\\n\\\",\\n+    \\\"    m.fit(Xtr, ytr)\\\\n\\\",\\n+    \\\"    return accuracy_score(yte, m.predict(Xte))\\\\n\\\",\\n+    \\\"def trace_preprocessing(df, run_id=None):\\\\n\\\",\\n+    \\\"    cols = ['run_id',\\\\n\\\",\\n+    \\\"            'param_dataset.title',\\\\n\\\",\\n+    \\\"            'param_columns_raw',\\\\n\\\",\\n+    \\\"            'param_dropped_columns',\\\\n\\\",\\n+    \\\"            'param_feature_names',\\\\n\\\",\\n+    \\\"            'param_dataset.authors', 'param_dataset.doi', 'param_dataset.published',\\\\n\\\",\\n+    \\\"            'param_test_size',\\\\n\\\",\\n+    \\\"            'param_criterion',\\\\n\\\",\\n+    \\\"            'param_max_depth','param_max_leaf_nodes', 'param_max_samples',\\\\n\\\",\\n+    \\\"           'metric_accuracy','metric_f1_macro','metric_roc_auc']\\\\n\\\",\\n+    \\\"    if run_id is None:\\\\n\\\",\\n+    \\\"        subset = df.loc[:, cols]\\\\n\\\",\\n+    \\\"    else:\\\\n\\\",\\n+    \\\"        subset = df.loc[df['run_id'] == run_id, cols]\\\\n\\\",\\n+    \\\"    return subset.to_dict(orient='records')\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"def drop_impact(df, feature, **_):\\\\n\\\",\\n+    \\\"    all_feats = _get_all_features(df)\\\\n\\\",\\n+    \\\"    baseline = evaluate_subset(all_feats)\\\\n\\\",\\n+    \\\"    without = [f for f in all_feats if f!=feature]\\\\n\\\",\\n+    \\\"    dropped = evaluate_subset(without)\\\\n\\\",\\n+    \\\"    return {\\\\n\\\",\\n+    \\\"      'dropped_feature': feature,\\\\n\\\",\\n+    \\\"      'baseline_acc': baseline,\\\\n\\\",\\n+    \\\"      'dropped_acc': dropped,\\\\n\\\",\\n+    \\\"      'impact': baseline - dropped\\\\n\\\",\\n+    \\\"    }\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"def drop_impact_all(df: pd.DataFrame) -> List[Dict[str, Any]]:\\\\n\\\",\\n+    \\\"    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\",\\n+    \\\"    Compute drop-impact for every feature in the dataset.\\\\n\\\",\\n+    \\\"    Returns list of dicts with dropped_feature, baseline_acc, dropped_acc, impact.\\\\n\\\",\\n+    \\\"    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\",\\n+    \\\"    feats = _get_all_features(df)\\\\n\\\",\\n+    \\\"    baseline = evaluate_subset(feats)\\\\n\\\",\\n+    \\\"    summary = []\\\\n\\\",\\n+    \\\"    for feat in feats:\\\\n\\\",\\n+    \\\"        without = [f for f in feats if f != feat]\\\\n\\\",\\n+    \\\"        acc = evaluate_subset(without)\\\\n\\\",\\n+    \\\"        summary.append({\\\\n\\\",\\n+    \\\"            'dropped_feature': feat,\\\\n\\\",\\n+    \\\"            'baseline_acc': baseline,\\\\n\\\",\\n+    \\\"            'dropped_acc': acc,\\\\n\\\",\\n+    \\\"            'impact': round(baseline - acc, 4)\\\\n\\\",\\n+    \\\"        })\\\\n\\\",\\n+    \\\"    return summary\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"def best_feature_subset(df, features, **_):\\\\n\\\",\\n+    \\\"    acc = evaluate_subset(features)\\\\n\\\",\\n+    \\\"    return {'features': features, 'accuracy': acc}\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"def common_high_accuracy(df: pd.DataFrame, threshold: float = 0.95) -> List[Dict[str, Any]]:\\\\n\\\",\\n+    \\\"    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\",\\n+    \\\"    Filter runs with test accuracy >= threshold and list unique shared preprocessing settings.\\\\n\\\",\\n+    \\\"    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\",\\n+    \\\"    high = df[df['metric_accuracy_score_X_test'] >= threshold]\\\\n\\\",\\n+    \\\"    cols = ['param_dropped_columns', 'param_test_size', 'param_feature_names']\\\\n\\\",\\n+    \\\"    return high[cols].drop_duplicates().to_dict(orient='records')\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# --------------------------------------------\\\\n\\\",\\n+    \\\"# Use Case Registry with parameter order for minimal input\\\\n\\\",\\n+    \\\"# --------------------------------------------\\\\n\\\",\\n+    \\\"USE_CASES = {\\\\n\\\",\\n+    \\\"    'trace_preprocessing': {\\\\n\\\",\\n+    \\\"        'func': trace_preprocessing,\\\\n\\\",\\n+    \\\"        'required_params': [],            # none strictly required\\\\n\\\",\\n+    \\\"        'optional_params': ['run_id'],    # run_id can be supplied or not\\\\n\\\",\\n+    \\\"    },\\\\n\\\",\\n+    \\\"    'drop_impact': {\\\\n\\\",\\n+    \\\"        'func': drop_impact,\\\\n\\\",\\n+    \\\"        'required_params': ['feature'],\\\\n\\\",\\n+    \\\"        'optional_params': [],\\\\n\\\",\\n+    \\\"    },\\\\n\\\",\\n+    \\\"     'drop_impact_all': {\\\\n\\\",\\n+    \\\"        'func': drop_impact_all,\\\\n\\\",\\n+    \\\"        'required_params': [],\\\\n\\\",\\n+    \\\"        'optional_params': [],\\\\n\\\",\\n+    \\\"    },\\\\n\\\",\\n+    \\\"    'best_feature_subset': {\\\\n\\\",\\n+    \\\"        'func': best_feature_subset,\\\\n\\\",\\n+    \\\"        'required_params': ['features'],\\\\n\\\",\\n+    \\\"        'optional_params': [],\\\\n\\\",\\n+    \\\"    },\\\\n\\\",\\n+    \\\"    'common_high_accuracy': {\\\\n\\\",\\n+    \\\"        'func': common_high_accuracy,\\\\n\\\",\\n+    \\\"        'required_params': ['threshold'],\\\\n\\\",\\n+    \\\"        'optional_params': [],\\\\n\\\",\\n+    \\\"    },\\\\n\\\",\\n+    \\\"}\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"def call_use_case(df, use_case_name, **kwargs):\\\\n\\\",\\n+    \\\"    if use_case_name not in USE_CASES:\\\\n\\\",\\n+    \\\"        raise ValueError(f\\\\\\\"Unknown use case: {use_case_name}\\\\\\\")\\\\n\\\",\\n+    \\\"    case = USE_CASES[use_case_name]\\\\n\\\",\\n+    \\\"    func = case['func']\\\\n\\\",\\n+    \\\"    # check required\\\\n\\\",\\n+    \\\"    missing = [p for p in case['required_params'] if p not in kwargs]\\\\n\\\",\\n+    \\\"    if missing:\\\\n\\\",\\n+    \\\"        raise ValueError(f\\\\\\\"{use_case_name} missing required params: {missing}\\\\\\\")\\\\n\\\",\\n+    \\\"    # build args\\\\n\\\",\\n+    \\\"    args = {p: kwargs[p] for p in case['required_params']}\\\\n\\\",\\n+    \\\"    for p in case['optional_params']:\\\\n\\\",\\n+    \\\"        args[p] = kwargs.get(p)\\\\n\\\",\\n+    \\\"    return func(df, **args)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# --------------------------------------------\\\\n\\\",\\n+    \\\"# Example Usage\\\\n\\\",\\n+    \\\"# --------------------------------------------\\\\n\\\",\\n+    \\\"if __name__ == '__main__':\\\\n\\\",\\n+    \\\"   # # 1) trace_preprocessing for all runs\\\\n\\\",\\n+    \\\"    print(call_use_case(df, 'trace_preprocessing'))\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    # 2) trace_preprocessing for a single run_id\\\\n\\\",\\n+    \\\"    print(call_use_case(df, 'trace_preprocessing', run_id='361daa12f99f4129a06cd20b78dd6fa7'))\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # 5) common_high_accuracy\\\\n\\\",\\n+    \\\"    print(call_use_case(df, 'common_high_accuracy', threshold=0.99))\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # 4) Best\\u2010subset on just sepals:\\\\n\\\",\\n+    \\\"    print(call_use_case(df, 'best_feature_subset', features=['sepallengthcm','sepalwidthcm']))\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # 3) Drop\\u2010impact for \\u201cpetallengthcm\\u201d:\\\\n\\\",\\n+    \\\"    print(call_use_case(df, 'drop_impact', feature='petallengthcm'))\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    print(call_use_case(df, 'drop_impact_all'))  # summary for all features\\\\n\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"96f912d6-0e84-4155-858a-9668bef63f6e\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\" \\u2022 Detecting models trained with deprecated code versions\\\\n\\\",\\n+    \\\" \\u2022 Mapping models to specific datasets used during training\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 74,\\n+   \\\"id\\\": \\\"34a02c9a-5459-478f-a3c5-7f7a58ff22b0\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"[{'param_dataset.doi': '10.5281/ZENODO.1404173',\\\\n\\\",\\n+      \\\"  'param_dataset.published': '2018-8-27',\\\\n\\\",\\n+      \\\"  'param_dataset.publisher': 'Zenodo',\\\\n\\\",\\n+      \\\"  'param_dataset.title': 'Scikit-Learn Iris',\\\\n\\\",\\n+      \\\"  'run_id': '28f01e38b7f04d2f948fe21f57f41d0c',\\\\n\\\",\\n+      \\\"  'tag_model_name': 'RandomForest_Iris_v20250425_121328'}]\\\\n\\\"\\n+     ]\\n+    }\\n+   ],\\n+   \\\"source\\\": [\\n+    \\\"\\\\n\\\",\\n+    \\\"def detect_deprecated_code(df: pd.DataFrame, deprecated_commits: List[str], **_) -> List[Dict[str, Any]]:\\\\n\\\",\\n+    \\\"    # we know the column is called tag_git_current_commit_hash\\\\n\\\",\\n+    \\\"    commit_col = 'tag_git_current_commit_hash'\\\\n\\\",\\n+    \\\"    if commit_col not in df.columns:\\\\n\\\",\\n+    \\\"        raise KeyError(f\\\\\\\"Missing {commit_col} in DataFrame\\\\\\\")\\\\n\\\",\\n+    \\\"    out = df[df[commit_col].isin(deprecated_commits)]\\\\n\\\",\\n+    \\\"    # include run_id and notebook/runName for context\\\\n\\\",\\n+    \\\"    cols = ['run_id', commit_col, 'tag_notebook_name', 'tag_mlflow.runName']\\\\n\\\",\\n+    \\\"    # drop any that don\\u2019t exist\\\\n\\\",\\n+    \\\"    cols = [c for c in cols if c in df.columns]\\\\n\\\",\\n+    \\\"    return out[cols].to_dict(orient='records')\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"def map_model_dataset(df: pd.DataFrame, **_) -> List[Dict[str, Any]]:\\\\n\\\",\\n+    \\\"    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\",\\n+    \\\"    For each run, return its model name (or run_id) alongside the dataset\\\\n\\\",\\n+    \\\"    title, DOI, published date and publisher.\\\\n\\\",\\n+    \\\"    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\",\\n+    \\\"    # pick whichever model-name column you have\\\\n\\\",\\n+    \\\"    model_col = 'tag_model_name' if 'tag_model_name' in df.columns else 'param_model_name'\\\\n\\\",\\n+    \\\"    cols = [\\\\n\\\",\\n+    \\\"        'run_id',\\\\n\\\",\\n+    \\\"        model_col,\\\\n\\\",\\n+    \\\"        'param_dataset.title',\\\\n\\\",\\n+    \\\"        'param_dataset.doi',\\\\n\\\",\\n+    \\\"        'param_dataset.published',\\\\n\\\",\\n+    \\\"        'param_dataset.publisher'\\\\n\\\",\\n+    \\\"    ]\\\\n\\\",\\n+    \\\"    # filter out any columns that don\\u2019t actually exist\\\\n\\\",\\n+    \\\"    cols = [c for c in cols if c in df.columns]\\\\n\\\",\\n+    \\\"    return df[cols].to_dict(orient='records')\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# --------------------------------------------\\\\n\\\",\\n+    \\\"# Extend Use-Case Registry\\\\n\\\",\\n+    \\\"# --------------------------------------------\\\\n\\\",\\n+    \\\"USE_CASES.update({\\\\n\\\",\\n+    \\\"    'detect_deprecated_code': {\\\\n\\\",\\n+    \\\"        'func': detect_deprecated_code,\\\\n\\\",\\n+    \\\"        'required_params': ['deprecated_commits'],\\\\n\\\",\\n+    \\\"        'optional_params': []\\\\n\\\",\\n+    \\\"    },\\\\n\\\",\\n+    \\\"    'map_model_dataset': {\\\\n\\\",\\n+    \\\"        'func': map_model_dataset,\\\\n\\\",\\n+    \\\"        'required_params': [],\\\\n\\\",\\n+    \\\"        'optional_params': []\\\\n\\\",\\n+    \\\"    },\\\\n\\\",\\n+    \\\"})\\\\n\\\",\\n+    \\\"# 1) Detect runs on deprecated commits:\\\\n\\\",\\n+    \\\"deprecated = [\\\\n\\\",\\n+    \\\"    \\\\\\\"a07434af4f547af2daab044d6873eb7081162293\\\\\\\",\\\\n\\\",\\n+    \\\"    \\\\\\\"d329c92495e196ec0f39fbb19dfdd367131a77d9\\\\\\\"\\\\n\\\",\\n+    \\\"]\\\\n\\\",\\n+    \\\"# print(call_use_case(df, \\\\\\\"detect_deprecated_code\\\\\\\", deprecated_commits=deprecated))\\\\n\\\",\\n+    \\\"pprint(call_use_case(df, 'map_model_dataset'))\\\\n\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"c52607ad-5849-4a2d-97ef-e8fc1ca16dc7\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"Goal: Notify collaborators who have forked the GitHub repo if their fork is outdated (i.e., behind the current commit used to train a model).\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"f29c8ad9-00bb-4c1e-ac3b-ee6861991acd\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"\\ud83e\\udde0 What We Need\\\\n\\\",\\n+    \\\"Current training run\\u2019s Git commit hash\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"GitHub API to fetch all forks of your repo\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"Compare each fork\\u2019s main or master branch head commit\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"Create an issue on their fork or on your repo tagging them if they\\u2019re behind\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"c72bed50-fb56-442d-a21e-bb7991892d07\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\": Notify via issues on your own repo\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 75,\\n+   \\\"id\\\": \\\"852f147c-9d0a-4d7f-a4ab-545d1e2375fb\\\",\\n+   \\\"metadata\\\": {\\n+    \\\"scrolled\\\": true\\n+   },\\n+   \\\"outputs\\\": [\\n+    {\\n+     \\\"name\\\": \\\"stdin\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"Do you want to notify collaborators whose forks are behind? (y/N):  N\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"No action taken.\\\\n\\\"\\n+     ]\\n+    }\\n+   ],\\n+   \\\"source\\\": [\\n+    \\\"def notify_outdated_forks():\\\\n\\\",\\n+    \\\"    load_dotenv()\\\\n\\\",\\n+    \\\"    token     = os.getenv(\\\\\\\"THESIS_TOKEN\\\\\\\")\\\\n\\\",\\n+    \\\"    owner     = \\\\\\\"reema-dass26\\\\\\\"\\\\n\\\",\\n+    \\\"    repo      = \\\\\\\"REPO\\\\\\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    if not token:\\\\n\\\",\\n+    \\\"        print(\\\\\\\"\\u26a0\\ufe0f GITHUB_TOKEN not set.\\\\\\\")\\\\n\\\",\\n+    \\\"        return\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    headers = {\\\\n\\\",\\n+    \\\"        \\\\\\\"Authorization\\\\\\\": f\\\\\\\"token {token}\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"Accept\\\\\\\":        \\\\\\\"application/vnd.github.v3+json\\\\\\\"\\\\n\\\",\\n+    \\\"    }\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # 1) Get latest upstream commit\\\\n\\\",\\n+    \\\"    main_commits = requests.get(\\\\n\\\",\\n+    \\\"        f\\\\\\\"https://api.github.com/repos/{owner}/{repo}/commits\\\\\\\",\\\\n\\\",\\n+    \\\"        headers=headers,\\\\n\\\",\\n+    \\\"        params={\\\\\\\"per_page\\\\\\\": 1}\\\\n\\\",\\n+    \\\"    )\\\\n\\\",\\n+    \\\"    main_commits.raise_for_status()\\\\n\\\",\\n+    \\\"    new_commit_hash = main_commits.json()[0][\\\\\\\"sha\\\\\\\"]\\\\n\\\",\\n+    \\\"    print(f\\\\\\\"Latest upstream commit: {new_commit_hash}\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # 2) List forks\\\\n\\\",\\n+    \\\"    forks_resp = requests.get(f\\\\\\\"https://api.github.com/repos/{owner}/{repo}/forks\\\\\\\", headers=headers)\\\\n\\\",\\n+    \\\"    forks_resp.raise_for_status()\\\\n\\\",\\n+    \\\"    forks = forks_resp.json()\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # 3) Compare each fork\\\\n\\\",\\n+    \\\"    outdated = []\\\\n\\\",\\n+    \\\"    for fork in forks:\\\\n\\\",\\n+    \\\"        fork_owner = fork[\\\\\\\"owner\\\\\\\"][\\\\\\\"login\\\\\\\"]\\\\n\\\",\\n+    \\\"        fork_comm = requests.get(\\\\n\\\",\\n+    \\\"            fork[\\\\\\\"url\\\\\\\"] + \\\\\\\"/commits\\\\\\\",\\\\n\\\",\\n+    \\\"            headers=headers,\\\\n\\\",\\n+    \\\"            params={\\\\\\\"per_page\\\\\\\": 1}\\\\n\\\",\\n+    \\\"        )\\\\n\\\",\\n+    \\\"        if fork_comm.status_code != 200:\\\\n\\\",\\n+    \\\"            print(f\\\\\\\"\\u00a0\\u00a0\\u2013 could not fetch commits for {fork_owner}, skipping.\\\\\\\")\\\\n\\\",\\n+    \\\"            continue\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"        fork_sha = fork_comm.json()[0][\\\\\\\"sha\\\\\\\"]\\\\n\\\",\\n+    \\\"        if fork_sha != new_commit_hash:\\\\n\\\",\\n+    \\\"            outdated.append(f\\\\\\\"@{fork_owner}\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # 4) Open an issue if any are behind\\\\n\\\",\\n+    \\\"    if outdated:\\\\n\\\",\\n+    \\\"        title = \\\\\\\"\\ud83d\\udd14 Notification: Your fork is behind the latest commit\\\\\\\"\\\\n\\\",\\n+    \\\"        body  = (\\\\n\\\",\\n+    \\\"            f\\\\\\\"Hi {' '.join(outdated)},\\\\\\\\n\\\\\\\\n\\\\\\\"\\\\n\\\",\\n+    \\\"            f\\\\\\\"The main repository has been updated to commit `{new_commit_hash}`.\\\\\\\\n\\\\\\\"\\\\n\\\",\\n+    \\\"            \\\\\\\"Please consider pulling the latest changes to stay in sync.\\\\\\\\n\\\\\\\\n\\\\\\\"\\\\n\\\",\\n+    \\\"            \\\\\\\"Thanks!\\\\\\\"\\\\n\\\",\\n+    \\\"        )\\\\n\\\",\\n+    \\\"        issues_url = f\\\\\\\"https://api.github.com/repos/{owner}/{repo}/issues\\\\\\\"\\\\n\\\",\\n+    \\\"        resp = requests.post(\\\\n\\\",\\n+    \\\"        issues_url,\\\\n\\\",\\n+    \\\"        headers=headers,\\\\n\\\",\\n+    \\\"        json={\\\\\\\"title\\\\\\\": title, \\\\\\\"body\\\\\\\": body}\\\\n\\\",\\n+    \\\"    )\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # DEBUGGING OUTPUT\\\\n\\\",\\n+    \\\"    print(f\\\\\\\"\\u2192 POST {issues_url}\\\\\\\")\\\\n\\\",\\n+    \\\"    print(\\\\\\\"\\u2192 Status code:\\\\\\\", resp.status_code)\\\\n\\\",\\n+    \\\"    print(\\\\\\\"\\u2192 Response headers:\\\\\\\", resp.headers)\\\\n\\\",\\n+    \\\"    try:\\\\n\\\",\\n+    \\\"        data = resp.json()\\\\n\\\",\\n+    \\\"        print(\\\\\\\"\\u2192 Response JSON:\\\\\\\", data)\\\\n\\\",\\n+    \\\"        print(\\\\\\\"\\u2192 html_url field:\\\\\\\", data.get(\\\\\\\"html_url\\\\\\\"))\\\\n\\\",\\n+    \\\"    except ValueError:\\\\n\\\",\\n+    \\\"        print(\\\\\\\"\\u2192 No JSON response body; raw text:\\\\\\\", resp.text)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"if __name__ == \\\\\\\"__main__\\\\\\\":\\\\n\\\",\\n+    \\\"    answer = input(\\\\\\\"Do you want to notify collaborators whose forks are behind? (y/N): \\\\\\\").strip().lower()\\\\n\\\",\\n+    \\\"    if answer in (\\\\\\\"y\\\\\\\", \\\\\\\"yes\\\\\\\"):\\\\n\\\",\\n+    \\\"        notify_outdated_forks()\\\\n\\\",\\n+    \\\"    else:\\\\n\\\",\\n+    \\\"        print(\\\\\\\"No action taken.\\\\\\\")\\\\n\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"cda31f16-fbe9-40ce-ac1b-9ebc898c8820\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"INVENIO INTEGRETION to upload the necessary files and publish\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": null,\\n+   \\\"id\\\": \\\"c2e5a7fc-3b03-45c8-bc90-817ea5ba7352\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [],\\n+   \\\"source\\\": [\\n+    \\\"############################################################################################\\\\n\\\",\\n+    \\\"# TEST CODE FOR INVENIO INTEGRETION\\\\n\\\",\\n+    \\\"#############################################################################################\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# API_BASE = \\\\\\\"https://127.0.0.1:5000\\\\\\\"\\\\n\\\",\\n+    \\\"# TOKEN    = \\\\\\\"8LnqJuz3TsBHffnDJ3isPLHYHtRbWrC0M667Nb5haEbnXpWqGbFRyfDApymr\\\\\\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# # 1) Test read\\u2010scope by listing records (no size param or size=1)\\\\n\\\",\\n+    \\\"# resp = requests.get(\\\\n\\\",\\n+    \\\"#     f\\\\\\\"{API_BASE}/api/records\\\\\\\",\\\\n\\\",\\n+    \\\"#     headers={\\\\\\\"Authorization\\\\\\\": f\\\\\\\"Bearer {TOKEN}\\\\\\\"},\\\\n\\\",\\n+    \\\"#     verify=False\\\\n\\\",\\n+    \\\"# )\\\\n\\\",\\n+    \\\"# print(resp.status_code)\\\\n\\\",\\n+    \\\"# # should be 200 and a JSON page of records\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# # or explicitly:\\\\n\\\",\\n+    \\\"# resp = requests.get(\\\\n\\\",\\n+    \\\"#     f\\\\\\\"{API_BASE}/api/records?size=1\\\\\\\",\\\\n\\\",\\n+    \\\"#     headers={\\\\\\\"Authorization\\\\\\\": f\\\\\\\"Bearer {TOKEN}\\\\\\\"},\\\\n\\\",\\n+    \\\"#     verify=False\\\\n\\\",\\n+    \\\"# )\\\\n\\\",\\n+    \\\"# print(resp.status_code, resp.json())\\\\n\\\",\\n+    \\\"# #################################################################################################\\\\n\\\",\\n+    \\\"# API_BASE = \\\\\\\"https://127.0.0.1:5000\\\\\\\"\\\\n\\\",\\n+    \\\"# TOKEN    = \\\\\\\"8LnqJuz3TsBHffnDJ3isPLHYHtRbWrC0M667Nb5haEbnXpWqGbFRyfDApymr\\\\\\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# resp = requests.options(\\\\n\\\",\\n+    \\\"#     f\\\\\\\"{API_BASE}/api/records\\\\\\\",\\\\n\\\",\\n+    \\\"#     headers={\\\\\\\"Authorization\\\\\\\": f\\\\\\\"Bearer {TOKEN}\\\\\\\"},\\\\n\\\",\\n+    \\\"#     verify=False\\\\n\\\",\\n+    \\\"# )\\\\n\\\",\\n+    \\\"# print(\\\\\\\"Allowed methods:\\\\\\\", resp.headers.get(\\\\\\\"Allow\\\\\\\"))\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": null,\\n+   \\\"id\\\": \\\"7e5b2cc5-ecf3-4e13-8cac-47f57f12cbdd\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [],\\n+   \\\"source\\\": [\\n+    \\\"\\\\n\\\",\\n+    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n+    \\\"# Configuration\\\\n\\\",\\n+    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n+    \\\"API_BASE   = \\\\\\\"https://127.0.0.1:5000\\\\\\\"\\\\n\\\",\\n+    \\\"TOKEN      = \\\\\\\"8LnqJuz3TsBHffnDJ3isPLHYHtRbWrC0M667Nb5haEbnXpWqGbFRyfDApymr\\\\\\\"\\\\n\\\",\\n+    \\\"VERIFY_SSL = False  # only for self\\u2010signed dev\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"HEADERS_JSON = {\\\\n\\\",\\n+    \\\"    \\\\\\\"Accept\\\\\\\":        \\\\\\\"application/json\\\\\\\",\\\\n\\\",\\n+    \\\"    \\\\\\\"Content-Type\\\\\\\":  \\\\\\\"application/json\\\\\\\",\\\\n\\\",\\n+    \\\"    \\\\\\\"Authorization\\\\\\\": f\\\\\\\"Bearer {TOKEN}\\\\\\\",\\\\n\\\",\\n+    \\\"}\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"HEADERS_OCTET = {\\\\n\\\",\\n+    \\\"    \\\\\\\"Content-Type\\\\\\\":  \\\\\\\"application/octet-stream\\\\\\\",\\\\n\\\",\\n+    \\\"    \\\\\\\"Authorization\\\\\\\": f\\\\\\\"Bearer {TOKEN}\\\\\\\",\\\\n\\\",\\n+    \\\"}\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# The folders you want to walk & upload:\\\\n\\\",\\n+    \\\"TO_UPLOAD = [\\\\\\\"Trained_models\\\\\\\", \\\\\\\"plots\\\\\\\", \\\\\\\"MODEL_PROVENANCE\\\\\\\"]\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n+    \\\"# 1) Create draft with ALL required metadata\\\\n\\\",\\n+    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n+    \\\"def create_draft():\\\\n\\\",\\n+    \\\"    payload = {\\\\n\\\",\\n+    \\\"  \\\\\\\"metadata\\\\\\\": {\\\\n\\\",\\n+    \\\"    \\\\\\\"title\\\\\\\":            \\\\\\\"RandomForest Iris Model Artifacts\\\\\\\",\\\\n\\\",\\n+    \\\"    \\\\\\\"creators\\\\\\\": [ {\\\\n\\\",\\n+    \\\"      \\\\\\\"person_or_org\\\\\\\": {\\\\n\\\",\\n+    \\\"        \\\\\\\"type\\\\\\\":        \\\\\\\"personal\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"given_name\\\\\\\":  \\\\\\\"Reema\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"family_name\\\\\\\": \\\\\\\"Dass\\\\\\\"\\\\n\\\",\\n+    \\\"      }\\\\n\\\",\\n+    \\\"    } ],\\\\n\\\",\\n+    \\\"    \\\\\\\"publication_date\\\\\\\": \\\\\\\"2025-04-24\\\\\\\",\\\\n\\\",\\n+    \\\"    \\\\\\\"resource_type\\\\\\\":    { \\\\\\\"id\\\\\\\": \\\\\\\"software\\\\\\\" },\\\\n\\\",\\n+    \\\"    \\\\\\\"access\\\\\\\": {\\\\n\\\",\\n+    \\\"      \\\\\\\"record\\\\\\\": \\\\\\\"public\\\\\\\",\\\\n\\\",\\n+    \\\"      \\\\\\\"files\\\\\\\":  \\\\\\\"public\\\\\\\"\\\\n\\\",\\n+    \\\"    }\\\\n\\\",\\n+    \\\"  }\\\\n\\\",\\n+    \\\"}\\\\n\\\",\\n+    \\\"    r = requests.post(f\\\\\\\"{API_BASE}/api/records\\\\\\\",\\\\n\\\",\\n+    \\\"                      headers=HEADERS_JSON,\\\\n\\\",\\n+    \\\"                      json=payload,\\\\n\\\",\\n+    \\\"                      verify=VERIFY_SSL)\\\\n\\\",\\n+    \\\"    r.raise_for_status()\\\\n\\\",\\n+    \\\"    draft = r.json()\\\\n\\\",\\n+    \\\"    print(\\\\\\\"\\u2705 Draft created:\\\\\\\", draft[\\\\\\\"id\\\\\\\"])\\\\n\\\",\\n+    \\\"    return draft[\\\\\\\"id\\\\\\\"], draft[\\\\\\\"links\\\\\\\"]\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n+    \\\"# 2) Register, upload and commit a single file\\\\n\\\",\\n+    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n+    \\\"def upload_and_commit(links, key, path):\\\\n\\\",\\n+    \\\"    # 2a) register the filename in the draft\\\\n\\\",\\n+    \\\"    r1 = requests.post(links[\\\\\\\"files\\\\\\\"],\\\\n\\\",\\n+    \\\"                       headers=HEADERS_JSON,\\\\n\\\",\\n+    \\\"                       json=[{\\\\\\\"key\\\\\\\": key}],\\\\n\\\",\\n+    \\\"                       verify=VERIFY_SSL)\\\\n\\\",\\n+    \\\"    r1.raise_for_status()\\\\n\\\",\\n+    \\\"    entry = next(e for e in r1.json()[\\\\\\\"entries\\\\\\\"] if e[\\\\\\\"key\\\\\\\"] == key)\\\\n\\\",\\n+    \\\"    file_links = entry[\\\\\\\"links\\\\\\\"]\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # 2b) upload the bytes\\\\n\\\",\\n+    \\\"    with open(path, \\\\\\\"rb\\\\\\\") as fp:\\\\n\\\",\\n+    \\\"        r2 = requests.put(file_links[\\\\\\\"content\\\\\\\"],\\\\n\\\",\\n+    \\\"                          headers=HEADERS_OCTET,\\\\n\\\",\\n+    \\\"                          data=fp,\\\\n\\\",\\n+    \\\"                          verify=VERIFY_SSL)\\\\n\\\",\\n+    \\\"    r2.raise_for_status()\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # 2c) commit the upload\\\\n\\\",\\n+    \\\"    r3 = requests.post(file_links[\\\\\\\"commit\\\\\\\"],\\\\n\\\",\\n+    \\\"                       headers=HEADERS_JSON,\\\\n\\\",\\n+    \\\"                       verify=VERIFY_SSL)\\\\n\\\",\\n+    \\\"    r3.raise_for_status()\\\\n\\\",\\n+    \\\"    print(f\\\\\\\"  \\u2022 Uploaded {key}\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n+    \\\"# 3) Walk each folder and upload every file\\\\n\\\",\\n+    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n+    \\\"def upload_folder(links):\\\\n\\\",\\n+    \\\"    for folder in TO_UPLOAD:\\\\n\\\",\\n+    \\\"        if not os.path.isdir(folder):\\\\n\\\",\\n+    \\\"            print(f\\\\\\\"\\u26a0\\ufe0f Skipping missing folder {folder}\\\\\\\")\\\\n\\\",\\n+    \\\"            continue\\\\n\\\",\\n+    \\\"        base = os.path.dirname(folder) or folder\\\\n\\\",\\n+    \\\"        for root, _, files in os.walk(folder):\\\\n\\\",\\n+    \\\"            for fn in files:\\\\n\\\",\\n+    \\\"                local = os.path.join(root, fn)\\\\n\\\",\\n+    \\\"                # create a POSIX\\u2010style key preserving subfolders\\\\n\\\",\\n+    \\\"                key = os.path.relpath(local, start=base).replace(os.sep, \\\\\\\"/\\\\\\\")\\\\n\\\",\\n+    \\\"                upload_and_commit(links, key, local)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n+    \\\"# 4) Publish the draft\\\\n\\\",\\n+    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n+    \\\"def publish(links):\\\\n\\\",\\n+    \\\"    r = requests.post(links[\\\\\\\"publish\\\\\\\"],\\\\n\\\",\\n+    \\\"                      headers=HEADERS_JSON,\\\\n\\\",\\n+    \\\"                      verify=VERIFY_SSL)\\\\n\\\",\\n+    \\\"    if not r.ok:\\\\n\\\",\\n+    \\\"        print(\\\\\\\"\\u274c Publish failed:\\\\\\\", r.status_code, r.text)\\\\n\\\",\\n+    \\\"        try: print(r.json())\\\\n\\\",\\n+    \\\"        except: pass\\\\n\\\",\\n+    \\\"        r.raise_for_status()\\\\n\\\",\\n+    \\\"    print(\\\\\\\"\\u2705 Published:\\\\\\\", r.json()[\\\\\\\"id\\\\\\\"])\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n+    \\\"# 5) Fetch metadata and save to a file\\\\n\\\",\\n+    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n+    \\\"def fetch_metadata(record_id):\\\\n\\\",\\n+    \\\"    r = requests.get(f\\\\\\\"{API_BASE}/api/records/{record_id}\\\\\\\",\\\\n\\\",\\n+    \\\"                     headers=HEADERS_JSON,\\\\n\\\",\\n+    \\\"                     verify=VERIFY_SSL)\\\\n\\\",\\n+    \\\"    r.raise_for_status()\\\\n\\\",\\n+    \\\"    metadata = r.json()\\\\n\\\",\\n+    \\\"    print(\\\\\\\"\\u2705 Metadata fetched successfully\\\\\\\")\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    # Save the metadata to a file\\\\n\\\",\\n+    \\\"    with open(f\\\\\\\"metadata_{record_id}.json\\\\\\\", \\\\\\\"w\\\\\\\") as f:\\\\n\\\",\\n+    \\\"        json.dump(metadata, f, indent=4)\\\\n\\\",\\n+    \\\"    print(f\\\\\\\"\\u2705 Metadata saved as metadata_{record_id}.json\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n+    \\\"# Main\\\\n\\\",\\n+    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n+    \\\"if __name__ == \\\\\\\"__main__\\\\\\\":\\\\n\\\",\\n+    \\\"    recid, links = create_draft()\\\\n\\\",\\n+    \\\"    upload_folder(links)\\\\n\\\",\\n+    \\\"    publish(links)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # Fetch and save metadata after publishing\\\\n\\\",\\n+    \\\"    print(fetch_metadata(recid))\\\\n\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"2f7423f2-0ff3-4104-913e-50eeb32d9d0f\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"METADATA EXTRACTION FROM INVENIO:\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": null,\\n+   \\\"id\\\": \\\"0013878b-37da-4a22-9586-3773531bfd01\\\",\\n+   \\\"metadata\\\": {\\n+    \\\"scrolled\\\": true\\n+   },\\n+   \\\"outputs\\\": [],\\n+   \\\"source\\\": [\\n+    \\\"\\\\n\\\",\\n+    \\\"# Function to dynamically extract and structure metadata from the original JSON\\\\n\\\",\\n+    \\\"def extract_metadata(metadata):\\\\n\\\",\\n+    \\\"    # Debug: Check if metadata is loaded correctly\\\\n\\\",\\n+    \\\"    print(\\\\\\\"Debug: Metadata loaded successfully\\\\\\\")\\\\n\\\",\\n+    \\\"    print(metadata.get(\\\\\\\"id\\\\\\\", \\\\\\\"\\\\\\\"))  # Check if 'id' is being fetched\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # Check if the required fields are in the metadata\\\\n\\\",\\n+    \\\"    print(\\\\\\\"Debug: Extracting fields from metadata...\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    extracted_data = {\\\\n\\\",\\n+    \\\"        \\\\\\\"invenio_metadata\\\\\\\": {\\\\n\\\",\\n+    \\\"            \\\\\\\"id\\\\\\\": metadata.get(\\\\\\\"id\\\\\\\", \\\\\\\"\\\\\\\"),\\\\n\\\",\\n+    \\\"            \\\\\\\"title\\\\\\\": metadata.get(\\\\\\\"metadata\\\\\\\", {}).get(\\\\\\\"title\\\\\\\", \\\\\\\"\\\\\\\"),\\\\n\\\",\\n+    \\\"            \\\\\\\"creator\\\\\\\": \\\\\\\", \\\\\\\".join([creator[\\\\\\\"person_or_org\\\\\\\"].get(\\\\\\\"name\\\\\\\", \\\\\\\"\\\\\\\") for creator in metadata.get(\\\\\\\"metadata\\\\\\\", {}).get(\\\\\\\"creators\\\\\\\", [])]),\\\\n\\\",\\n+    \\\"            \\\\\\\"publication_date\\\\\\\": metadata.get(\\\\\\\"metadata\\\\\\\", {}).get(\\\\\\\"publication_date\\\\\\\", \\\\\\\"\\\\\\\"),\\\\n\\\",\\n+    \\\"            \\\\\\\"files\\\\\\\": [],  # Initialize 'files' as a list\\\\n\\\",\\n+    \\\"            \\\\\\\"pids\\\\\\\": metadata.get(\\\\\\\"pids\\\\\\\", {}),\\\\n\\\",\\n+    \\\"            \\\\\\\"version_info\\\\\\\": metadata.get(\\\\\\\"versions\\\\\\\", {}),\\\\n\\\",\\n+    \\\"            \\\\\\\"status\\\\\\\": metadata.get(\\\\\\\"status\\\\\\\", \\\\\\\"\\\\\\\"),\\\\n\\\",\\n+    \\\"            \\\\\\\"views\\\\\\\": metadata.get(\\\\\\\"stats\\\\\\\", {}).get(\\\\\\\"this_version\\\\\\\", {}).get(\\\\\\\"views\\\\\\\", 0),\\\\n\\\",\\n+    \\\"            \\\\\\\"downloads\\\\\\\": metadata.get(\\\\\\\"stats\\\\\\\", {}).get(\\\\\\\"this_version\\\\\\\", {}).get(\\\\\\\"downloads\\\\\\\", 0),\\\\n\\\",\\n+    \\\"        }\\\\n\\\",\\n+    \\\"    }\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # Extract file details from the metadata\\\\n\\\",\\n+    \\\"    for key, file_info in metadata.get(\\\\\\\"files\\\\\\\", {}).get(\\\\\\\"entries\\\\\\\", {}).items():\\\\n\\\",\\n+    \\\"        file_detail = {\\\\n\\\",\\n+    \\\"            \\\\\\\"key\\\\\\\": key,\\\\n\\\",\\n+    \\\"            \\\\\\\"url\\\\\\\": file_info[\\\\\\\"links\\\\\\\"].get(\\\\\\\"content\\\\\\\", \\\\\\\"\\\\\\\"),\\\\n\\\",\\n+    \\\"            \\\\\\\"size\\\\\\\": file_info.get(\\\\\\\"size\\\\\\\", 0),\\\\n\\\",\\n+    \\\"            \\\\\\\"mimetype\\\\\\\": file_info.get(\\\\\\\"mimetype\\\\\\\", \\\\\\\"\\\\\\\"),\\\\n\\\",\\n+    \\\"            \\\\\\\"checksum\\\\\\\": file_info.get(\\\\\\\"checksum\\\\\\\", \\\\\\\"\\\\\\\"),\\\\n\\\",\\n+    \\\"            \\\\\\\"metadata\\\\\\\": file_info.get(\\\\\\\"metadata\\\\\\\", {}),\\\\n\\\",\\n+    \\\"        }\\\\n\\\",\\n+    \\\"        extracted_data[\\\\\\\"invenio_metadata\\\\\\\"][\\\\\\\"files\\\\\\\"].append(file_detail)  # Append to the 'files' list\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    return extracted_data\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# Load the original metadata from the JSON file (replace with your actual file path)\\\\n\\\",\\n+    \\\"with open('metadata_p8a8y-1bn93.json', 'r') as f: \\\\n\\\",\\n+    \\\"    original_metadata = json.load(f)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# Debugging: print out the first part of the original metadata to verify its structure\\\\n\\\",\\n+    \\\"print(\\\\\\\"Debug: Original Metadata (start):\\\\\\\", json.dumps(original_metadata, indent=4)[:1000])  # Print only the start for review\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# Extract relevant details dynamically\\\\n\\\",\\n+    \\\"extracted_metadata = extract_metadata(original_metadata)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# Debugging: print the extracted metadata to verify it's correct\\\\n\\\",\\n+    \\\"print(\\\\\\\"Debug: Extracted Metadata:\\\\\\\", json.dumps(extracted_metadata, indent=4))\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# Load the existing JSON file (replace with your actual file path)\\\\n\\\",\\n+    \\\"with open('MODEL_PROVENANCE/RandomForest_Iris_v20250424_111946_run_summary.json', 'r') as f:\\\\n\\\",\\n+    \\\"    existing_metadata = json.load(f)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# Add the extracted metadata as a new node\\\\n\\\",\\n+    \\\"existing_metadata.update(extracted_metadata)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# Save the updated metadata back to the file\\\\n\\\",\\n+    \\\"with open('updated_metadata.json', 'w') as f:\\\\n\\\",\\n+    \\\"    json.dump(existing_metadata, f, indent=4)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"print(\\\\\\\"\\u2705 New dynamic metadata added successfully!\\\\\\\")\\\\n\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": null,\\n+   \\\"id\\\": \\\"38a807a7-6ecd-4ea7-93ac-78c0f853825c\\\",\\n+   \\\"metadata\\\": {\\n+    \\\"scrolled\\\": true\\n+   },\\n+   \\\"outputs\\\": [],\\n+   \\\"source\\\": [\\n+    \\\"# import mlflow\\\\n\\\",\\n+    \\\"# import mlflow.sklearn\\\\n\\\",\\n+    \\\"# from sklearn.datasets import load_iris\\\\n\\\",\\n+    \\\"# from sklearn.ensemble import RandomForestClassifier\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# X, y = load_iris(return_X_y=True)\\\\n\\\",\\n+    \\\"# mlflow.sklearn.autolog()\\\\n\\\",\\n+    \\\"# with mlflow.start_run() as run:\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"#     model = RandomForestClassifier(**hyperparams)\\\\n\\\",\\n+    \\\"#     model.fit(X_train, y_train)\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": null,\\n+   \\\"id\\\": \\\"570fa169-a5e2-47b3-b7f5-44f9577f22ad\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [],\\n+   \\\"source\\\": []\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": null,\\n+   \\\"id\\\": \\\"f67b7a46-a70d-44ea-976c-322a1a795311\\\",\\n+   \\\"metadata\\\": {\\n+    \\\"scrolled\\\": true\\n+   },\\n+   \\\"outputs\\\": [],\\n+   \\\"source\\\": []\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": null,\\n+   \\\"id\\\": \\\"4211bdef-5785-472d-8ea5-0bc24a3faf3c\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [],\\n+   \\\"source\\\": []\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": null,\\n+   \\\"id\\\": \\\"9d4d71f2-ef66-4e04-9d9b-c4b381d45590\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [],\\n+   \\\"source\\\": []\\n+  }\\n+ ],\\n+ \\\"metadata\\\": {\\n+  \\\"kernelspec\\\": {\\n+   \\\"display_name\\\": \\\"Python 3 (ipykernel)\\\",\\n+   \\\"language\\\": \\\"python\\\",\\n+   \\\"name\\\": \\\"python3\\\"\\n+  },\\n+  \\\"language_info\\\": {\\n+   \\\"codemirror_mode\\\": {\\n+    \\\"name\\\": \\\"ipython\\\",\\n+    \\\"version\\\": 3\\n+   },\\n+   \\\"file_extension\\\": \\\".py\\\",\\n+   \\\"mimetype\\\": \\\"text/x-python\\\",\\n+   \\\"name\\\": \\\"python\\\",\\n+   \\\"nbconvert_exporter\\\": \\\"python\\\",\\n+   \\\"pygments_lexer\\\": \\\"ipython3\\\",\\n+   \\\"version\\\": \\\"3.11.5\\\"\\n+  }\\n+ },\\n+ \\\"nbformat\\\": 4,\\n+ \\\"nbformat_minor\\\": 5\\n+}\\ndiff --git a/notebooks/RQ_notebooks/RQ1_updated_integretingsklearn_autolog.ipynb b/notebooks/RQ_notebooks/RQ1_updated_integretingsklearn_autolog.ipynb\\nnew file mode 100644\\nindex 0000000..dd9e22a\\n--- /dev/null\\n+++ b/notebooks/RQ_notebooks/RQ1_updated_integretingsklearn_autolog.ipynb\\n@@ -0,0 +1,3333 @@\\n+{\\n+ \\\"cells\\\": [\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 2,\\n+   \\\"id\\\": \\\"12fa6f59-927c-4003-964f-83e53793fd36\\\",\\n+   \\\"metadata\\\": {\\n+    \\\"scrolled\\\": true\\n+   },\\n+   \\\"outputs\\\": [],\\n+   \\\"source\\\": [\\n+    \\\"# TODO: atm the mlflow autolog isnt capturing metrics n params\\\\n\\\",\\n+    \\\"# and sklearn.autolog throws error( posted the issue on github)\\\\n\\\",\\n+    \\\"# Ideally, I should be able to fetch most of the imp detail via MLFLOW AUTOLOG. will check that later in time\\\\n\\\",\\n+    \\\"#============================\\\\n\\\",\\n+    \\\"# \\ud83e\\udde0 MLflow Autologging\\\\n\\\",\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# mlflow.autolog(log_input_examples=True, log_model_signatures=True)\\\\n\\\",\\n+    \\\"# mlflow.sklearn.autolog() \\\\n\\\",\\n+    \\\"# mlflow.sklearn.autolog(\\\\n\\\",\\n+    \\\"#     log_input_examples=True,\\\\n\\\",\\n+    \\\"#     log_model_signatures=True,\\\\n\\\",\\n+    \\\"#     log_post_training_metrics=True,        # calls model.score() \\u2192 accuracy\\\\n\\\",\\n+    \\\"#     disable_for_unsupported_versions=True,  # skips if versions still wonky\\\\n\\\",\\n+    \\\"#     exclusive=True                          # only patch the sklearn integration\\\\n\\\",\\n+    \\\"# )\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 3,\\n+   \\\"id\\\": \\\"1ce1a579-f08b-40bd-b4db-21b388aaea74\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [],\\n+   \\\"source\\\": [\\n+    \\\"\\\\n\\\",\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"# \\u2699\\ufe0f Install Dependencies (if needed )\\\\n\\\",\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"# !pip install mlflow scikit-learn pandas numpy matplotlib seaborn shap requests GitPython\\\\n\\\",\\n+    \\\"# !pip install --upgrade threadpoolctl\\\\n\\\",\\n+    \\\"# !pip install setuptools\\\\n\\\",\\n+    \\\"# !pip install ace_tools \\\\n\\\",\\n+    \\\"# !pip install rdflib\\\\n\\\",\\n+    \\\"# !pip install streamlit-option-menu\\\\n\\\",\\n+    \\\"# !pip install streamlit-agraph\\\\n\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"1ca4f0ae-39ee-4b22-b013-dfb1fa1b5694\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"LIBRARY IMPORTS:\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 4,\\n+   \\\"id\\\": \\\"8ca332e5-6501-4310-920b-2b769477b46e\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [],\\n+   \\\"source\\\": [\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"# \\ud83d\\udce6 Standard Library Imports\\\\n\\\",\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"import os\\\\n\\\",\\n+    \\\"import glob\\\\n\\\",\\n+    \\\"import io\\\\n\\\",\\n+    \\\"import json\\\\n\\\",\\n+    \\\"import time\\\\n\\\",\\n+    \\\"import ast\\\\n\\\",\\n+    \\\"import pickle\\\\n\\\",\\n+    \\\"import platform\\\\n\\\",\\n+    \\\"import subprocess\\\\n\\\",\\n+    \\\"from datetime import datetime, timezone\\\\n\\\",\\n+    \\\"from pprint import pprint\\\\n\\\",\\n+    \\\"from typing import List, Dict, Any\\\\n\\\",\\n+    \\\"import xml.etree.ElementTree as ET\\\\n\\\",\\n+    \\\"import urllib.parse\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"# \\ud83d\\udcca Data and Visualization\\\\n\\\",\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"import pandas as pd\\\\n\\\",\\n+    \\\"import numpy as np\\\\n\\\",\\n+    \\\"import seaborn as sns\\\\n\\\",\\n+    \\\"import matplotlib\\\\n\\\",\\n+    \\\"import matplotlib.pyplot as plt\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"# \\ud83e\\udd16 Machine Learning\\\\n\\\",\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"import sklearn\\\\n\\\",\\n+    \\\"from sklearn.datasets import load_iris\\\\n\\\",\\n+    \\\"from sklearn.ensemble import RandomForestClassifier\\\\n\\\",\\n+    \\\"from sklearn.model_selection import train_test_split\\\\n\\\",\\n+    \\\"from sklearn.preprocessing import LabelEncoder, label_binarize\\\\n\\\",\\n+    \\\"from sklearn.metrics import (\\\\n\\\",\\n+    \\\"    accuracy_score,\\\\n\\\",\\n+    \\\"    roc_auc_score,\\\\n\\\",\\n+    \\\"    confusion_matrix,\\\\n\\\",\\n+    \\\"    precision_score,\\\\n\\\",\\n+    \\\"    recall_score,\\\\n\\\",\\n+    \\\"    f1_score,\\\\n\\\",\\n+    \\\"    RocCurveDisplay,\\\\n\\\",\\n+    \\\"    PrecisionRecallDisplay\\\\n\\\",\\n+    \\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"# \\ud83d\\udd2c Experiment Tracking\\\\n\\\",\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"import mlflow\\\\n\\\",\\n+    \\\"import mlflow.sklearn\\\\n\\\",\\n+    \\\"from mlflow import MlflowClient\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"# \\ud83c\\udf10 Web / API / Networking\\\\n\\\",\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"import requests\\\\n\\\",\\n+    \\\"from dotenv import load_dotenv\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"# \\ud83e\\uddea Git & Version Control\\\\n\\\",\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"import git\\\\n\\\",\\n+    \\\"from git import Repo, GitCommandError\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"# \\ud83e\\udde0 SHAP for Explainability\\\\n\\\",\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"import shap\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"# \\ud83e\\uddec RDF & Provenance (rdflib)\\\\n\\\",\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"from rdflib import Graph, URIRef, Literal\\\\n\\\",\\n+    \\\"from rdflib.namespace import PROV, XSD\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"# \\u2699\\ufe0f System Monitoring\\\\n\\\",\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"import psutil\\\\n\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"61d4d6b8-34a9-47b5-974d-5927c0ee2256\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"DBREPO INTEGRETION\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 5,\\n+   \\\"id\\\": \\\"8e3570e2-9a60-45b4-8653-28060071e728\\\",\\n+   \\\"metadata\\\": {\\n+    \\\"scrolled\\\": true\\n+   },\\n+   \\\"outputs\\\": [\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"API Response: [{'id': '1', 'sepallengthcm': '5.100000000000000000', 'sepalwidthcm': '3.500000000000000000', 'petallengthcm': '1.400000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '2', 'sepallengthcm': '4.900000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '1.400000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '3', 'sepallengthcm': '4.700000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '1.300000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '4', 'sepallengthcm': '4.600000000000000000', 'sepalwidthcm': '3.100000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '5', 'sepallengthcm': '5.000000000000000000', 'sepalwidthcm': '3.600000000000000000', 'petallengthcm': '1.400000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '6', 'sepallengthcm': '5.400000000000000000', 'sepalwidthcm': '3.900000000000000000', 'petallengthcm': '1.700000000000000000', 'petalwidthcm': '0.400000000000000000', 'species': 'Iris-setosa'}, {'id': '7', 'sepallengthcm': '4.600000000000000000', 'sepalwidthcm': '3.400000000000000000', 'petallengthcm': '1.400000000000000000', 'petalwidthcm': '0.300000000000000000', 'species': 'Iris-setosa'}, {'id': '8', 'sepallengthcm': '5.000000000000000000', 'sepalwidthcm': '3.400000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '9', 'sepallengthcm': '4.400000000000000000', 'sepalwidthcm': '2.900000000000000000', 'petallengthcm': '1.400000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '10', 'sepallengthcm': '4.900000000000000000', 'sepalwidthcm': '3.100000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.100000000000000000', 'species': 'Iris-setosa'}, {'id': '11', 'sepallengthcm': '5.400000000000000000', 'sepalwidthcm': '3.700000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '12', 'sepallengthcm': '4.800000000000000000', 'sepalwidthcm': '3.400000000000000000', 'petallengthcm': '1.600000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '13', 'sepallengthcm': '4.800000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '1.400000000000000000', 'petalwidthcm': '0.100000000000000000', 'species': 'Iris-setosa'}, {'id': '14', 'sepallengthcm': '4.300000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '1.100000000000000000', 'petalwidthcm': '0.100000000000000000', 'species': 'Iris-setosa'}, {'id': '15', 'sepallengthcm': '5.800000000000000000', 'sepalwidthcm': '4.000000000000000000', 'petallengthcm': '1.200000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '16', 'sepallengthcm': '5.700000000000000000', 'sepalwidthcm': '4.400000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.400000000000000000', 'species': 'Iris-setosa'}, {'id': '17', 'sepallengthcm': '5.400000000000000000', 'sepalwidthcm': '3.900000000000000000', 'petallengthcm': '1.300000000000000000', 'petalwidthcm': '0.400000000000000000', 'species': 'Iris-setosa'}, {'id': '18', 'sepallengthcm': '5.100000000000000000', 'sepalwidthcm': '3.500000000000000000', 'petallengthcm': '1.400000000000000000', 'petalwidthcm': '0.300000000000000000', 'species': 'Iris-setosa'}, {'id': '19', 'sepallengthcm': '5.700000000000000000', 'sepalwidthcm': '3.800000000000000000', 'petallengthcm': '1.700000000000000000', 'petalwidthcm': '0.300000000000000000', 'species': 'Iris-setosa'}, {'id': '20', 'sepallengthcm': '5.100000000000000000', 'sepalwidthcm': '3.800000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.300000000000000000', 'species': 'Iris-setosa'}, {'id': '21', 'sepallengthcm': '5.400000000000000000', 'sepalwidthcm': '3.400000000000000000', 'petallengthcm': '1.700000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '22', 'sepallengthcm': '5.100000000000000000', 'sepalwidthcm': '3.700000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.400000000000000000', 'species': 'Iris-setosa'}, {'id': '23', 'sepallengthcm': '4.600000000000000000', 'sepalwidthcm': '3.600000000000000000', 'petallengthcm': '1.000000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '24', 'sepallengthcm': '5.100000000000000000', 'sepalwidthcm': '3.300000000000000000', 'petallengthcm': '1.700000000000000000', 'petalwidthcm': '0.500000000000000000', 'species': 'Iris-setosa'}, {'id': '25', 'sepallengthcm': '4.800000000000000000', 'sepalwidthcm': '3.400000000000000000', 'petallengthcm': '1.900000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '26', 'sepallengthcm': '5.000000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '1.600000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '27', 'sepallengthcm': '5.000000000000000000', 'sepalwidthcm': '3.400000000000000000', 'petallengthcm': '1.600000000000000000', 'petalwidthcm': '0.400000000000000000', 'species': 'Iris-setosa'}, {'id': '28', 'sepallengthcm': '5.200000000000000000', 'sepalwidthcm': '3.500000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '29', 'sepallengthcm': '5.200000000000000000', 'sepalwidthcm': '3.400000000000000000', 'petallengthcm': '1.400000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '30', 'sepallengthcm': '4.700000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '1.600000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '31', 'sepallengthcm': '4.800000000000000000', 'sepalwidthcm': '3.100000000000000000', 'petallengthcm': '1.600000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '32', 'sepallengthcm': '5.400000000000000000', 'sepalwidthcm': '3.400000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.400000000000000000', 'species': 'Iris-setosa'}, {'id': '33', 'sepallengthcm': '5.200000000000000000', 'sepalwidthcm': '4.100000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.100000000000000000', 'species': 'Iris-setosa'}, {'id': '34', 'sepallengthcm': '5.500000000000000000', 'sepalwidthcm': '4.200000000000000000', 'petallengthcm': '1.400000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '35', 'sepallengthcm': '4.900000000000000000', 'sepalwidthcm': '3.100000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.100000000000000000', 'species': 'Iris-setosa'}, {'id': '36', 'sepallengthcm': '5.000000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '1.200000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '37', 'sepallengthcm': '5.500000000000000000', 'sepalwidthcm': '3.500000000000000000', 'petallengthcm': '1.300000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '38', 'sepallengthcm': '4.900000000000000000', 'sepalwidthcm': '3.100000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.100000000000000000', 'species': 'Iris-setosa'}, {'id': '39', 'sepallengthcm': '4.400000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '1.300000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '40', 'sepallengthcm': '5.100000000000000000', 'sepalwidthcm': '3.400000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '41', 'sepallengthcm': '5.000000000000000000', 'sepalwidthcm': '3.500000000000000000', 'petallengthcm': '1.300000000000000000', 'petalwidthcm': '0.300000000000000000', 'species': 'Iris-setosa'}, {'id': '42', 'sepallengthcm': '4.500000000000000000', 'sepalwidthcm': '2.300000000000000000', 'petallengthcm': '1.300000000000000000', 'petalwidthcm': '0.300000000000000000', 'species': 'Iris-setosa'}, {'id': '43', 'sepallengthcm': '4.400000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '1.300000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '44', 'sepallengthcm': '5.000000000000000000', 'sepalwidthcm': '3.500000000000000000', 'petallengthcm': '1.600000000000000000', 'petalwidthcm': '0.600000000000000000', 'species': 'Iris-setosa'}, {'id': '45', 'sepallengthcm': '5.100000000000000000', 'sepalwidthcm': '3.800000000000000000', 'petallengthcm': '1.900000000000000000', 'petalwidthcm': '0.400000000000000000', 'species': 'Iris-setosa'}, {'id': '46', 'sepallengthcm': '4.800000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '1.400000000000000000', 'petalwidthcm': '0.300000000000000000', 'species': 'Iris-setosa'}, {'id': '47', 'sepallengthcm': '5.100000000000000000', 'sepalwidthcm': '3.800000000000000000', 'petallengthcm': '1.600000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '48', 'sepallengthcm': '4.600000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '1.400000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '49', 'sepallengthcm': '5.300000000000000000', 'sepalwidthcm': '3.700000000000000000', 'petallengthcm': '1.500000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '50', 'sepallengthcm': '5.000000000000000000', 'sepalwidthcm': '3.300000000000000000', 'petallengthcm': '1.400000000000000000', 'petalwidthcm': '0.200000000000000000', 'species': 'Iris-setosa'}, {'id': '51', 'sepallengthcm': '7.000000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '4.700000000000000000', 'petalwidthcm': '1.400000000000000000', 'species': 'Iris-versicolor'}, {'id': '52', 'sepallengthcm': '6.400000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '4.500000000000000000', 'petalwidthcm': '1.500000000000000000', 'species': 'Iris-versicolor'}, {'id': '53', 'sepallengthcm': '6.900000000000000000', 'sepalwidthcm': '3.100000000000000000', 'petallengthcm': '4.900000000000000000', 'petalwidthcm': '1.500000000000000000', 'species': 'Iris-versicolor'}, {'id': '54', 'sepallengthcm': '5.500000000000000000', 'sepalwidthcm': '2.300000000000000000', 'petallengthcm': '4.000000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '55', 'sepallengthcm': '6.500000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '4.600000000000000000', 'petalwidthcm': '1.500000000000000000', 'species': 'Iris-versicolor'}, {'id': '56', 'sepallengthcm': '5.700000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '4.500000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '57', 'sepallengthcm': '6.300000000000000000', 'sepalwidthcm': '3.300000000000000000', 'petallengthcm': '4.700000000000000000', 'petalwidthcm': '1.600000000000000000', 'species': 'Iris-versicolor'}, {'id': '58', 'sepallengthcm': '4.900000000000000000', 'sepalwidthcm': '2.400000000000000000', 'petallengthcm': '3.300000000000000000', 'petalwidthcm': '1.000000000000000000', 'species': 'Iris-versicolor'}, {'id': '59', 'sepallengthcm': '6.600000000000000000', 'sepalwidthcm': '2.900000000000000000', 'petallengthcm': '4.600000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '60', 'sepallengthcm': '5.200000000000000000', 'sepalwidthcm': '2.700000000000000000', 'petallengthcm': '3.900000000000000000', 'petalwidthcm': '1.400000000000000000', 'species': 'Iris-versicolor'}, {'id': '61', 'sepallengthcm': '5.000000000000000000', 'sepalwidthcm': '2.000000000000000000', 'petallengthcm': '3.500000000000000000', 'petalwidthcm': '1.000000000000000000', 'species': 'Iris-versicolor'}, {'id': '62', 'sepallengthcm': '5.900000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '4.200000000000000000', 'petalwidthcm': '1.500000000000000000', 'species': 'Iris-versicolor'}, {'id': '63', 'sepallengthcm': '6.000000000000000000', 'sepalwidthcm': '2.200000000000000000', 'petallengthcm': '4.000000000000000000', 'petalwidthcm': '1.000000000000000000', 'species': 'Iris-versicolor'}, {'id': '64', 'sepallengthcm': '6.100000000000000000', 'sepalwidthcm': '2.900000000000000000', 'petallengthcm': '4.700000000000000000', 'petalwidthcm': '1.400000000000000000', 'species': 'Iris-versicolor'}, {'id': '65', 'sepallengthcm': '5.600000000000000000', 'sepalwidthcm': '2.900000000000000000', 'petallengthcm': '3.600000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '66', 'sepallengthcm': '6.700000000000000000', 'sepalwidthcm': '3.100000000000000000', 'petallengthcm': '4.400000000000000000', 'petalwidthcm': '1.400000000000000000', 'species': 'Iris-versicolor'}, {'id': '67', 'sepallengthcm': '5.600000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '4.500000000000000000', 'petalwidthcm': '1.500000000000000000', 'species': 'Iris-versicolor'}, {'id': '68', 'sepallengthcm': '5.800000000000000000', 'sepalwidthcm': '2.700000000000000000', 'petallengthcm': '4.100000000000000000', 'petalwidthcm': '1.000000000000000000', 'species': 'Iris-versicolor'}, {'id': '69', 'sepallengthcm': '6.200000000000000000', 'sepalwidthcm': '2.200000000000000000', 'petallengthcm': '4.500000000000000000', 'petalwidthcm': '1.500000000000000000', 'species': 'Iris-versicolor'}, {'id': '70', 'sepallengthcm': '5.600000000000000000', 'sepalwidthcm': '2.500000000000000000', 'petallengthcm': '3.900000000000000000', 'petalwidthcm': '1.100000000000000000', 'species': 'Iris-versicolor'}, {'id': '71', 'sepallengthcm': '5.900000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '4.800000000000000000', 'petalwidthcm': '1.800000000000000000', 'species': 'Iris-versicolor'}, {'id': '72', 'sepallengthcm': '6.100000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '4.000000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '73', 'sepallengthcm': '6.300000000000000000', 'sepalwidthcm': '2.500000000000000000', 'petallengthcm': '4.900000000000000000', 'petalwidthcm': '1.500000000000000000', 'species': 'Iris-versicolor'}, {'id': '74', 'sepallengthcm': '6.100000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '4.700000000000000000', 'petalwidthcm': '1.200000000000000000', 'species': 'Iris-versicolor'}, {'id': '75', 'sepallengthcm': '6.400000000000000000', 'sepalwidthcm': '2.900000000000000000', 'petallengthcm': '4.300000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '76', 'sepallengthcm': '6.600000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '4.400000000000000000', 'petalwidthcm': '1.400000000000000000', 'species': 'Iris-versicolor'}, {'id': '77', 'sepallengthcm': '6.800000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '4.800000000000000000', 'petalwidthcm': '1.400000000000000000', 'species': 'Iris-versicolor'}, {'id': '78', 'sepallengthcm': '6.700000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '5.000000000000000000', 'petalwidthcm': '1.700000000000000000', 'species': 'Iris-versicolor'}, {'id': '79', 'sepallengthcm': '6.000000000000000000', 'sepalwidthcm': '2.900000000000000000', 'petallengthcm': '4.500000000000000000', 'petalwidthcm': '1.500000000000000000', 'species': 'Iris-versicolor'}, {'id': '80', 'sepallengthcm': '5.700000000000000000', 'sepalwidthcm': '2.600000000000000000', 'petallengthcm': '3.500000000000000000', 'petalwidthcm': '1.000000000000000000', 'species': 'Iris-versicolor'}, {'id': '81', 'sepallengthcm': '5.500000000000000000', 'sepalwidthcm': '2.400000000000000000', 'petallengthcm': '3.800000000000000000', 'petalwidthcm': '1.100000000000000000', 'species': 'Iris-versicolor'}, {'id': '82', 'sepallengthcm': '5.500000000000000000', 'sepalwidthcm': '2.400000000000000000', 'petallengthcm': '3.700000000000000000', 'petalwidthcm': '1.000000000000000000', 'species': 'Iris-versicolor'}, {'id': '83', 'sepallengthcm': '5.800000000000000000', 'sepalwidthcm': '2.700000000000000000', 'petallengthcm': '3.900000000000000000', 'petalwidthcm': '1.200000000000000000', 'species': 'Iris-versicolor'}, {'id': '84', 'sepallengthcm': '6.000000000000000000', 'sepalwidthcm': '2.700000000000000000', 'petallengthcm': '5.100000000000000000', 'petalwidthcm': '1.600000000000000000', 'species': 'Iris-versicolor'}, {'id': '85', 'sepallengthcm': '5.400000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '4.500000000000000000', 'petalwidthcm': '1.500000000000000000', 'species': 'Iris-versicolor'}, {'id': '86', 'sepallengthcm': '6.000000000000000000', 'sepalwidthcm': '3.400000000000000000', 'petallengthcm': '4.500000000000000000', 'petalwidthcm': '1.600000000000000000', 'species': 'Iris-versicolor'}, {'id': '87', 'sepallengthcm': '6.700000000000000000', 'sepalwidthcm': '3.100000000000000000', 'petallengthcm': '4.700000000000000000', 'petalwidthcm': '1.500000000000000000', 'species': 'Iris-versicolor'}, {'id': '88', 'sepallengthcm': '6.300000000000000000', 'sepalwidthcm': '2.300000000000000000', 'petallengthcm': '4.400000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '89', 'sepallengthcm': '5.600000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '4.100000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '90', 'sepallengthcm': '5.500000000000000000', 'sepalwidthcm': '2.500000000000000000', 'petallengthcm': '4.000000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '91', 'sepallengthcm': '5.500000000000000000', 'sepalwidthcm': '2.600000000000000000', 'petallengthcm': '4.400000000000000000', 'petalwidthcm': '1.200000000000000000', 'species': 'Iris-versicolor'}, {'id': '92', 'sepallengthcm': '6.100000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '4.600000000000000000', 'petalwidthcm': '1.400000000000000000', 'species': 'Iris-versicolor'}, {'id': '93', 'sepallengthcm': '5.800000000000000000', 'sepalwidthcm': '2.600000000000000000', 'petallengthcm': '4.000000000000000000', 'petalwidthcm': '1.200000000000000000', 'species': 'Iris-versicolor'}, {'id': '94', 'sepallengthcm': '5.000000000000000000', 'sepalwidthcm': '2.300000000000000000', 'petallengthcm': '3.300000000000000000', 'petalwidthcm': '1.000000000000000000', 'species': 'Iris-versicolor'}, {'id': '95', 'sepallengthcm': '5.600000000000000000', 'sepalwidthcm': '2.700000000000000000', 'petallengthcm': '4.200000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '96', 'sepallengthcm': '5.700000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '4.200000000000000000', 'petalwidthcm': '1.200000000000000000', 'species': 'Iris-versicolor'}, {'id': '97', 'sepallengthcm': '5.700000000000000000', 'sepalwidthcm': '2.900000000000000000', 'petallengthcm': '4.200000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '98', 'sepallengthcm': '6.200000000000000000', 'sepalwidthcm': '2.900000000000000000', 'petallengthcm': '4.300000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '99', 'sepallengthcm': '5.100000000000000000', 'sepalwidthcm': '2.500000000000000000', 'petallengthcm': '3.000000000000000000', 'petalwidthcm': '1.100000000000000000', 'species': 'Iris-versicolor'}, {'id': '100', 'sepallengthcm': '5.700000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '4.100000000000000000', 'petalwidthcm': '1.300000000000000000', 'species': 'Iris-versicolor'}, {'id': '101', 'sepallengthcm': '6.300000000000000000', 'sepalwidthcm': '3.300000000000000000', 'petallengthcm': '6.000000000000000000', 'petalwidthcm': '2.500000000000000000', 'species': 'Iris-virginica'}, {'id': '102', 'sepallengthcm': '5.800000000000000000', 'sepalwidthcm': '2.700000000000000000', 'petallengthcm': '5.100000000000000000', 'petalwidthcm': '1.900000000000000000', 'species': 'Iris-virginica'}, {'id': '103', 'sepallengthcm': '7.100000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '5.900000000000000000', 'petalwidthcm': '2.100000000000000000', 'species': 'Iris-virginica'}, {'id': '104', 'sepallengthcm': '6.300000000000000000', 'sepalwidthcm': '2.900000000000000000', 'petallengthcm': '5.600000000000000000', 'petalwidthcm': '1.800000000000000000', 'species': 'Iris-virginica'}, {'id': '105', 'sepallengthcm': '6.500000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '5.800000000000000000', 'petalwidthcm': '2.200000000000000000', 'species': 'Iris-virginica'}, {'id': '106', 'sepallengthcm': '7.600000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '6.600000000000000000', 'petalwidthcm': '2.100000000000000000', 'species': 'Iris-virginica'}, {'id': '107', 'sepallengthcm': '4.900000000000000000', 'sepalwidthcm': '2.500000000000000000', 'petallengthcm': '4.500000000000000000', 'petalwidthcm': '1.700000000000000000', 'species': 'Iris-virginica'}, {'id': '108', 'sepallengthcm': '7.300000000000000000', 'sepalwidthcm': '2.900000000000000000', 'petallengthcm': '6.300000000000000000', 'petalwidthcm': '1.800000000000000000', 'species': 'Iris-virginica'}, {'id': '109', 'sepallengthcm': '6.700000000000000000', 'sepalwidthcm': '2.500000000000000000', 'petallengthcm': '5.800000000000000000', 'petalwidthcm': '1.800000000000000000', 'species': 'Iris-virginica'}, {'id': '110', 'sepallengthcm': '7.200000000000000000', 'sepalwidthcm': '3.600000000000000000', 'petallengthcm': '6.100000000000000000', 'petalwidthcm': '2.500000000000000000', 'species': 'Iris-virginica'}, {'id': '111', 'sepallengthcm': '6.500000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '5.100000000000000000', 'petalwidthcm': '2.000000000000000000', 'species': 'Iris-virginica'}, {'id': '112', 'sepallengthcm': '6.400000000000000000', 'sepalwidthcm': '2.700000000000000000', 'petallengthcm': '5.300000000000000000', 'petalwidthcm': '1.900000000000000000', 'species': 'Iris-virginica'}, {'id': '113', 'sepallengthcm': '6.800000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '5.500000000000000000', 'petalwidthcm': '2.100000000000000000', 'species': 'Iris-virginica'}, {'id': '114', 'sepallengthcm': '5.700000000000000000', 'sepalwidthcm': '2.500000000000000000', 'petallengthcm': '5.000000000000000000', 'petalwidthcm': '2.000000000000000000', 'species': 'Iris-virginica'}, {'id': '115', 'sepallengthcm': '5.800000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '5.100000000000000000', 'petalwidthcm': '2.400000000000000000', 'species': 'Iris-virginica'}, {'id': '116', 'sepallengthcm': '6.400000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '5.300000000000000000', 'petalwidthcm': '2.300000000000000000', 'species': 'Iris-virginica'}, {'id': '117', 'sepallengthcm': '6.500000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '5.500000000000000000', 'petalwidthcm': '1.800000000000000000', 'species': 'Iris-virginica'}, {'id': '118', 'sepallengthcm': '7.700000000000000000', 'sepalwidthcm': '3.800000000000000000', 'petallengthcm': '6.700000000000000000', 'petalwidthcm': '2.200000000000000000', 'species': 'Iris-virginica'}, {'id': '119', 'sepallengthcm': '7.700000000000000000', 'sepalwidthcm': '2.600000000000000000', 'petallengthcm': '6.900000000000000000', 'petalwidthcm': '2.300000000000000000', 'species': 'Iris-virginica'}, {'id': '120', 'sepallengthcm': '6.000000000000000000', 'sepalwidthcm': '2.200000000000000000', 'petallengthcm': '5.000000000000000000', 'petalwidthcm': '1.500000000000000000', 'species': 'Iris-virginica'}, {'id': '121', 'sepallengthcm': '6.900000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '5.700000000000000000', 'petalwidthcm': '2.300000000000000000', 'species': 'Iris-virginica'}, {'id': '122', 'sepallengthcm': '5.600000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '4.900000000000000000', 'petalwidthcm': '2.000000000000000000', 'species': 'Iris-virginica'}, {'id': '123', 'sepallengthcm': '7.700000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '6.700000000000000000', 'petalwidthcm': '2.000000000000000000', 'species': 'Iris-virginica'}, {'id': '124', 'sepallengthcm': '6.300000000000000000', 'sepalwidthcm': '2.700000000000000000', 'petallengthcm': '4.900000000000000000', 'petalwidthcm': '1.800000000000000000', 'species': 'Iris-virginica'}, {'id': '125', 'sepallengthcm': '6.700000000000000000', 'sepalwidthcm': '3.300000000000000000', 'petallengthcm': '5.700000000000000000', 'petalwidthcm': '2.100000000000000000', 'species': 'Iris-virginica'}, {'id': '126', 'sepallengthcm': '7.200000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '6.000000000000000000', 'petalwidthcm': '1.800000000000000000', 'species': 'Iris-virginica'}, {'id': '127', 'sepallengthcm': '6.200000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '4.800000000000000000', 'petalwidthcm': '1.800000000000000000', 'species': 'Iris-virginica'}, {'id': '128', 'sepallengthcm': '6.100000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '4.900000000000000000', 'petalwidthcm': '1.800000000000000000', 'species': 'Iris-virginica'}, {'id': '129', 'sepallengthcm': '6.400000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '5.600000000000000000', 'petalwidthcm': '2.100000000000000000', 'species': 'Iris-virginica'}, {'id': '130', 'sepallengthcm': '7.200000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '5.800000000000000000', 'petalwidthcm': '1.600000000000000000', 'species': 'Iris-virginica'}, {'id': '131', 'sepallengthcm': '7.400000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '6.100000000000000000', 'petalwidthcm': '1.900000000000000000', 'species': 'Iris-virginica'}, {'id': '132', 'sepallengthcm': '7.900000000000000000', 'sepalwidthcm': '3.800000000000000000', 'petallengthcm': '6.400000000000000000', 'petalwidthcm': '2.000000000000000000', 'species': 'Iris-virginica'}, {'id': '133', 'sepallengthcm': '6.400000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '5.600000000000000000', 'petalwidthcm': '2.200000000000000000', 'species': 'Iris-virginica'}, {'id': '134', 'sepallengthcm': '6.300000000000000000', 'sepalwidthcm': '2.800000000000000000', 'petallengthcm': '5.100000000000000000', 'petalwidthcm': '1.500000000000000000', 'species': 'Iris-virginica'}, {'id': '135', 'sepallengthcm': '6.100000000000000000', 'sepalwidthcm': '2.600000000000000000', 'petallengthcm': '5.600000000000000000', 'petalwidthcm': '1.400000000000000000', 'species': 'Iris-virginica'}, {'id': '136', 'sepallengthcm': '7.700000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '6.100000000000000000', 'petalwidthcm': '2.300000000000000000', 'species': 'Iris-virginica'}, {'id': '137', 'sepallengthcm': '6.300000000000000000', 'sepalwidthcm': '3.400000000000000000', 'petallengthcm': '5.600000000000000000', 'petalwidthcm': '2.400000000000000000', 'species': 'Iris-virginica'}, {'id': '138', 'sepallengthcm': '6.400000000000000000', 'sepalwidthcm': '3.100000000000000000', 'petallengthcm': '5.500000000000000000', 'petalwidthcm': '1.800000000000000000', 'species': 'Iris-virginica'}, {'id': '139', 'sepallengthcm': '6.000000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '4.800000000000000000', 'petalwidthcm': '1.800000000000000000', 'species': 'Iris-virginica'}, {'id': '140', 'sepallengthcm': '6.900000000000000000', 'sepalwidthcm': '3.100000000000000000', 'petallengthcm': '5.400000000000000000', 'petalwidthcm': '2.100000000000000000', 'species': 'Iris-virginica'}, {'id': '141', 'sepallengthcm': '6.700000000000000000', 'sepalwidthcm': '3.100000000000000000', 'petallengthcm': '5.600000000000000000', 'petalwidthcm': '2.400000000000000000', 'species': 'Iris-virginica'}, {'id': '142', 'sepallengthcm': '6.900000000000000000', 'sepalwidthcm': '3.100000000000000000', 'petallengthcm': '5.100000000000000000', 'petalwidthcm': '2.300000000000000000', 'species': 'Iris-virginica'}, {'id': '143', 'sepallengthcm': '5.800000000000000000', 'sepalwidthcm': '2.700000000000000000', 'petallengthcm': '5.100000000000000000', 'petalwidthcm': '1.900000000000000000', 'species': 'Iris-virginica'}, {'id': '144', 'sepallengthcm': '6.800000000000000000', 'sepalwidthcm': '3.200000000000000000', 'petallengthcm': '5.900000000000000000', 'petalwidthcm': '2.300000000000000000', 'species': 'Iris-virginica'}, {'id': '145', 'sepallengthcm': '6.700000000000000000', 'sepalwidthcm': '3.300000000000000000', 'petallengthcm': '5.700000000000000000', 'petalwidthcm': '2.500000000000000000', 'species': 'Iris-virginica'}, {'id': '146', 'sepallengthcm': '6.700000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '5.200000000000000000', 'petalwidthcm': '2.300000000000000000', 'species': 'Iris-virginica'}, {'id': '147', 'sepallengthcm': '6.300000000000000000', 'sepalwidthcm': '2.500000000000000000', 'petallengthcm': '5.000000000000000000', 'petalwidthcm': '1.900000000000000000', 'species': 'Iris-virginica'}, {'id': '148', 'sepallengthcm': '6.500000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '5.200000000000000000', 'petalwidthcm': '2.000000000000000000', 'species': 'Iris-virginica'}, {'id': '149', 'sepallengthcm': '6.200000000000000000', 'sepalwidthcm': '3.400000000000000000', 'petallengthcm': '5.400000000000000000', 'petalwidthcm': '2.300000000000000000', 'species': 'Iris-virginica'}, {'id': '150', 'sepallengthcm': '5.900000000000000000', 'sepalwidthcm': '3.000000000000000000', 'petallengthcm': '5.100000000000000000', 'petalwidthcm': '1.800000000000000000', 'species': 'Iris-virginica'}]\\\\n\\\",\\n+      \\\"<built-in method count of list object at 0x0000022ADD5443C0>\\\\n\\\"\\n+     ]\\n+    }\\n+   ],\\n+   \\\"source\\\": [\\n+    \\\"# API endpoint URL\\\\n\\\",\\n+    \\\"API_URL = \\\\\\\"http://localhost/api/database/c3a42d17-42b7-43c9-a504-2363fb4c9c8d/table/5315e7da-64fb-4fdb-b493-95b4138c765f/data?size=100000&page=0\\\\\\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# Define the headers\\\\n\\\",\\n+    \\\"headers = {\\\\n\\\",\\n+    \\\"    \\\\\\\"Accept\\\\\\\": \\\\\\\"application/json\\\\\\\"  # Specify the expected response format\\\\n\\\",\\n+    \\\"}\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"try:\\\\n\\\",\\n+    \\\"    # Send a GET request to the API with the Accept header\\\\n\\\",\\n+    \\\"    response = requests.get(API_URL, headers=headers)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # Check if the request was successful\\\\n\\\",\\n+    \\\"    if response.status_code == 200:\\\\n\\\",\\n+    \\\"        # Parse the JSON response\\\\n\\\",\\n+    \\\"        dataset = response.json()\\\\n\\\",\\n+    \\\"        print(\\\\\\\"API Response:\\\\\\\", dataset)\\\\n\\\",\\n+    \\\"        print( dataset.count)\\\\n\\\",\\n+    \\\"    else:\\\\n\\\",\\n+    \\\"        print(f\\\\\\\"Error: Received status code {response.status_code}\\\\\\\")\\\\n\\\",\\n+    \\\"        print(\\\\\\\"Response content:\\\\\\\", response.text)\\\\n\\\",\\n+    \\\"       \\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"except requests.exceptions.RequestException as e:\\\\n\\\",\\n+    \\\"    print(f\\\\\\\"Request failed: {e}\\\\\\\")\\\\n\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"09557f94-325c-4bd6-882a-069a9e3c5ecd\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"replacing dynamic fetching of data When and if DBREPO isnt running \\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 6,\\n+   \\\"id\\\": \\\"ce6e020d-cb80-49ec-8bcc-687b1e08885c\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [],\\n+   \\\"source\\\": [\\n+    \\\"# 1. Read the JSON file id the API isnt available this data is saved locally but the data is from the API endpoint\\\\n\\\",\\n+    \\\"with open(\\\\\\\"iris_data.json\\\\\\\", \\\\\\\"r\\\\\\\") as f:\\\\n\\\",\\n+    \\\"    dataset = json.load(f)\\\\n\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"a6c6007a-2126-4b1a-90ee-3326eb39a362\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"Metadata fetching from db repo API CALLS\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"9165f478-a44e-4125-8929-a8d77fdcb4c5\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"METADATA ON DATABASE LEVEL\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 7,\\n+   \\\"id\\\": \\\"abe912e7-bf9b-4bbd-8e43-6046745ade3f\\\",\\n+   \\\"metadata\\\": {\\n+    \\\"scrolled\\\": true\\n+   },\\n+   \\\"outputs\\\": [],\\n+   \\\"source\\\": [\\n+    \\\"\\\\n\\\",\\n+    \\\"DB_API = \\\\\\\"http://localhost/api/database/{db_id}\\\\\\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"def fetch_db_metadata(db_id: str) -> dict:\\\\n\\\",\\n+    \\\"    url = DB_API.format(db_id=db_id)\\\\n\\\",\\n+    \\\"    try:\\\\n\\\",\\n+    \\\"        resp = requests.get(url)\\\\n\\\",\\n+    \\\"        resp.raise_for_status()\\\\n\\\",\\n+    \\\"        return resp.json()\\\\n\\\",\\n+    \\\"    except requests.exceptions.RequestException as e:\\\\n\\\",\\n+    \\\"        print(f\\\\\\\"[\\u26a0\\ufe0f Error] Failed to fetch DB metadata for {db_id}: {e}\\\\\\\")\\\\n\\\",\\n+    \\\"        return {}  # or return None, depending on what your app prefers\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"def log_db_metadata(db_meta: dict):\\\\n\\\",\\n+    \\\"    # 1) Core DB fields as params, defaulting to empty string if key is missing\\\\n\\\",\\n+    \\\"    mlflow.log_param(\\\\\\\"database.id\\\\\\\",          db_meta.get(\\\\\\\"id\\\\\\\", \\\\\\\"\\\\\\\"))\\\\n\\\",\\n+    \\\"    mlflow.log_param(\\\\\\\"database.name\\\\\\\",        db_meta.get(\\\\\\\"name\\\\\\\", \\\\\\\"\\\\\\\"))\\\\n\\\",\\n+    \\\"    mlflow.log_param(\\\\\\\"database.description\\\\\\\", db_meta.get(\\\\\\\"description\\\\\\\", \\\\\\\"\\\\\\\"))\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # 2) Handle nested keys safely for owner\\\\n\\\",\\n+    \\\"    try:\\\\n\\\",\\n+    \\\"        owner = db_meta.get(\\\\\\\"tables\\\\\\\", [{}])[0].get(\\\\\\\"owner\\\\\\\", {}).get(\\\\\\\"username\\\\\\\", \\\\\\\"\\\\\\\")\\\\n\\\",\\n+    \\\"    except Exception:\\\\n\\\",\\n+    \\\"        owner = \\\\\\\"\\\\\\\"\\\\n\\\",\\n+    \\\"    mlflow.log_param(\\\\\\\"database.owner\\\\\\\", owner)\\\\n\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"53cbd7eb-0d97-4326-9bfc-f6fcee14ef9c\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"MATADATA FROM: <ns0:OAI-PMH xmlns:ns0=\\\\\\\"http://www.openarchives.org/OAI/2.0/\\\\\\\" xmlns:xsi=\\\\\\\"http://www.w3.org/2001/XMLSchema-instance\\\\\\\" xsi:schemaLocation=\\\\\\\"http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd\\\\\\\">\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 8,\\n+   \\\"id\\\": \\\"296f307e-e01b-477a-9406-92cab9f2d7bf\\\",\\n+   \\\"metadata\\\": {\\n+    \\\"scrolled\\\": true\\n+   },\\n+   \\\"outputs\\\": [\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"<ns0:OAI-PMH xmlns:ns0=\\\\\\\"http://www.openarchives.org/OAI/2.0/\\\\\\\" xmlns:xsi=\\\\\\\"http://www.w3.org/2001/XMLSchema-instance\\\\\\\" xsi:schemaLocation=\\\\\\\"http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd\\\\\\\">\\\\n\\\",\\n+      \\\"    <ns0:responseDate>2025-04-25T11:13:30Z</ns0:responseDate>\\\\n\\\",\\n+      \\\"    <ns0:request verb=\\\\\\\"Identify\\\\\\\">https://localhost/api/oai</ns0:request>\\\\n\\\",\\n+      \\\"    <ns0:Identify>\\\\n\\\",\\n+      \\\"    <ns0:repositoryName>Database Repository</ns0:repositoryName>\\\\n\\\",\\n+      \\\"    <ns0:baseURL>http://localhost</ns0:baseURL>\\\\n\\\",\\n+      \\\"    <ns0:protocolVersion>2.0</ns0:protocolVersion>\\\\n\\\",\\n+      \\\"    <ns0:adminEmail>noreply@localhost</ns0:adminEmail>\\\\n\\\",\\n+      \\\"    <ns0:earliestDatestamp />\\\\n\\\",\\n+      \\\"    <ns0:deletedRecord>persistent</ns0:deletedRecord>\\\\n\\\",\\n+      \\\"    <ns0:granularity>YYYY-MM-DDThh:mm:ssZ</ns0:granularity>\\\\n\\\",\\n+      \\\"</ns0:Identify>\\\\n\\\",\\n+      \\\"</ns0:OAI-PMH>\\\\n\\\"\\n+     ]\\n+    }\\n+   ],\\n+   \\\"source\\\": [\\n+    \\\"# 1) Fetch your database metadata\\\\n\\\",\\n+    \\\"db_url = \\\\\\\"http://localhost/api/database/c3a42d17-42b7-43c9-a504-2363fb4c9c8d\\\\\\\"\\\\n\\\",\\n+    \\\"db_resp = requests.get(db_url)\\\\n\\\",\\n+    \\\"db_resp.raise_for_status()\\\\n\\\",\\n+    \\\"db_data = db_resp.json()\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"db_id  = db_data[\\\\\\\"id\\\\\\\"]\\\\n\\\",\\n+    \\\"tbl_id = db_data[\\\\\\\"tables\\\\\\\"][0][\\\\\\\"id\\\\\\\"]\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# 2) Build the OAI-PMH URL, URL-encoding the `set` param\\\\n\\\",\\n+    \\\"set_param   = f\\\\\\\"Databases/{db_id}/Tables/{tbl_id}\\\\\\\"\\\\n\\\",\\n+    \\\"encoded_set = urllib.parse.quote(set_param, safe=\\\\\\\"\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"oai_url = (\\\\n\\\",\\n+    \\\"    \\\\\\\"http://localhost/api/oai\\\\\\\"\\\\n\\\",\\n+    \\\"    f\\\\\\\"?metadataPrefix=oai_dc\\\\\\\"\\\\n\\\",\\n+    \\\"    f\\\\\\\"&from=2025-03-01\\\\\\\"\\\\n\\\",\\n+    \\\"    f\\\\\\\"&until=2025-03-07\\\\\\\"\\\\n\\\",\\n+    \\\"    f\\\\\\\"&set={encoded_set}\\\\\\\"\\\\n\\\",\\n+    \\\"    f\\\\\\\"&resumptionToken=string\\\\\\\"\\\\n\\\",\\n+    \\\"    f\\\\\\\"&fromDate=2025-03-07T19%3A35%3A51.476Z\\\\\\\"\\\\n\\\",\\n+    \\\"    f\\\\\\\"&untilDate=2025-03-07T19%3A35%3A51.476Z\\\\\\\"\\\\n\\\",\\n+    \\\"    f\\\\\\\"&parametersString=string\\\\\\\"\\\\n\\\",\\n+    \\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# 3) Call and parse\\\\n\\\",\\n+    \\\"try:\\\\n\\\",\\n+    \\\"    resp = requests.get(oai_url)\\\\n\\\",\\n+    \\\"    resp.raise_for_status()\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    if \\\\\\\"xml\\\\\\\" in resp.headers.get(\\\\\\\"Content-Type\\\\\\\", \\\\\\\"\\\\\\\"):\\\\n\\\",\\n+    \\\"        root = ET.fromstring(resp.text)\\\\n\\\",\\n+    \\\"        print(ET.tostring(root, encoding=\\\\\\\"utf-8\\\\\\\").decode())\\\\n\\\",\\n+    \\\"    else:\\\\n\\\",\\n+    \\\"        print(\\\\\\\"Non-XML response:\\\\\\\", resp.headers.get(\\\\\\\"Content-Type\\\\\\\"), resp.text)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"except requests.exceptions.RequestException as e:\\\\n\\\",\\n+    \\\"    print(\\\\\\\"Request failed:\\\\\\\", e)\\\\n\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 9,\\n+   \\\"id\\\": \\\"61cc99ab-4a5c-4142-8725-e7c940673ffd\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [],\\n+   \\\"source\\\": [\\n+    \\\"# \\u2026after you fetch & parse your XML into `root`\\u2026\\\\n\\\",\\n+    \\\"ns = {\\\\\\\"oai\\\\\\\": \\\\\\\"http://www.openarchives.org/OAI/2.0/\\\\\\\"}\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"repo_name   = root.findtext(\\\\\\\"oai:Identify/oai:repositoryName\\\\\\\", namespaces=ns) or \\\\\\\"N/A\\\\\\\"\\\\n\\\",\\n+    \\\"base_url    = root.findtext(\\\\\\\"oai:Identify/oai:baseURL\\\\\\\", namespaces=ns) or \\\\\\\"N/A\\\\\\\"\\\\n\\\",\\n+    \\\"protocol    = root.findtext(\\\\\\\"oai:Identify/oai:protocolVersion\\\\\\\", namespaces=ns) or \\\\\\\"N/A\\\\\\\"\\\\n\\\",\\n+    \\\"admin_email = root.findtext(\\\\\\\"oai:Identify/oai:adminEmail\\\\\\\", namespaces=ns) or \\\\\\\"N/A\\\\\\\"\\\\n\\\",\\n+    \\\"gran        = root.findtext(\\\\\\\"oai:Identify/oai:granularity\\\\\\\", namespaces=ns) or \\\\\\\"N/A\\\\\\\"\\\\n\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"74214aa7-c12f-414e-9feb-094a366b855b\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"METADATA ON History Logging\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 10,\\n+   \\\"id\\\": \\\"e9c74e9b-c9b0-4b4a-82eb-2a6e56456508\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"API Response: [{'timestamp': '2025-04-23T20:42:29.501Z', 'event': 'insert', 'total': 150}]\\\\n\\\"\\n+     ]\\n+    }\\n+   ],\\n+   \\\"source\\\": [\\n+    \\\"url = \\\\\\\"http://localhost/api/database/c3a42d17-42b7-43c9-a504-2363fb4c9c8d/table/5315e7da-64fb-4fdb-b493-95b4138c765f/history\\\\\\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"try:\\\\n\\\",\\n+    \\\"    # Send a GET request to the API\\\\n\\\",\\n+    \\\"    response = requests.get(url)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # Check if the request was successful\\\\n\\\",\\n+    \\\"    if response.status_code == 200:\\\\n\\\",\\n+    \\\"        # Parse the JSON response\\\\n\\\",\\n+    \\\"        data = response.json()\\\\n\\\",\\n+    \\\"        print(\\\\\\\"API Response:\\\\\\\", data)\\\\n\\\",\\n+    \\\"    else:\\\\n\\\",\\n+    \\\"        print(f\\\\\\\"Error: Received status code {response.status_code}\\\\\\\")\\\\n\\\",\\n+    \\\"        print(\\\\\\\"Response content:\\\\\\\", response.text)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"except requests.exceptions.RequestException as e:\\\\n\\\",\\n+    \\\"    print(f\\\\\\\"Request failed: {e}\\\\\\\")\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 11,\\n+   \\\"id\\\": \\\"3630c954-5ad2-4759-b9a0-fa6e20e184ef\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [],\\n+   \\\"source\\\": [\\n+    \\\"first   = data[0]\\\\n\\\",\\n+    \\\"last    = data[-1]\\\\n\\\",\\n+    \\\"count_0 = first[\\\\\\\"total\\\\\\\"]    # e.g. 149\\\\n\\\",\\n+    \\\"count_N = last[\\\\\\\"total\\\\\\\"]     # e.g. 149 again, or changed\\\\n\\\",\\n+    \\\"ts_last = last[\\\\\\\"timestamp\\\\\\\"]  # e.g. \\\\\\\"2025-03-28T17:42:38.058Z\\\\\\\"\\\\n\\\",\\n+    \\\"n_insert = sum(1 for ev in data if ev[\\\\\\\"event\\\\\\\"]==\\\\\\\"insert\\\\\\\")\\\\n\\\",\\n+    \\\"n_delete = sum(1 for ev in data if ev[\\\\\\\"event\\\\\\\"]==\\\\\\\"delete\\\\\\\")\\\\n\\\",\\n+    \\\"history = response.json()\\\\n\\\",\\n+    \\\"first, last = history[0], history[-1]\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# summary stats\\\\n\\\",\\n+    \\\"count_start = first[\\\\\\\"total\\\\\\\"]\\\\n\\\",\\n+    \\\"count_end   = last[\\\\\\\"total\\\\\\\"]\\\\n\\\",\\n+    \\\"ts_last     = last[\\\\\\\"timestamp\\\\\\\"]\\\\n\\\",\\n+    \\\"n_insert    = sum(1 for ev in history if ev[\\\\\\\"event\\\\\\\"]==\\\\\\\"insert\\\\\\\")\\\\n\\\",\\n+    \\\"n_delete    = sum(1 for ev in history if ev[\\\\\\\"event\\\\\\\"]==\\\\\\\"delete\\\\\\\")\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"1afd5dad-72d5-42e1-a0fa-b7bd3455937b\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"Dataset metadata fetching from ZONEDO or any public dataset repositories to gain more details\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 12,\\n+   \\\"id\\\": \\\"a7fa122a-c6e5-4b38-842a-dc81590a1f46\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [],\\n+   \\\"source\\\": [\\n+    \\\"\\\\n\\\",\\n+    \\\"def fetch_and_log_dataset_metadata_nested(doi_url: str):\\\\n\\\",\\n+    \\\"    # 1) fetch the CSL+JSON\\\\n\\\",\\n+    \\\"    headers = {\\\\\\\"Accept\\\\\\\": \\\\\\\"application/vnd.citationstyles.csl+json\\\\\\\"}\\\\n\\\",\\n+    \\\"    r = requests.get(doi_url, headers=headers); r.raise_for_status()\\\\n\\\",\\n+    \\\"    meta = r.json()\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # 2) pull out what you care about\\\\n\\\",\\n+    \\\"    authors = [f\\\\\\\"{a.get('family','')} {a.get('given','')}\\\\\\\".strip()\\\\n\\\",\\n+    \\\"               for a in meta.get(\\\\\\\"author\\\\\\\", [])]\\\\n\\\",\\n+    \\\"    pubdate = \\\\\\\"-\\\\\\\".join(str(x) for x in meta.get(\\\\\\\"issued\\\\\\\",{}).get(\\\\\\\"date-parts\\\\\\\",[[]])[0])\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # 3) assemble one nested dict\\\\n\\\",\\n+    \\\"    public_datasetRepository_metadata = {\\\\n\\\",\\n+    \\\"      \\\\\\\"zenodo\\\\\\\": {\\\\n\\\",\\n+    \\\"        \\\\\\\"title\\\\\\\":     meta.get(\\\\\\\"title\\\\\\\"),\\\\n\\\",\\n+    \\\"        \\\\\\\"doi\\\\\\\":       meta.get(\\\\\\\"DOI\\\\\\\"),\\\\n\\\",\\n+    \\\"        \\\\\\\"authors\\\\\\\":   authors,\\\\n\\\",\\n+    \\\"        \\\\\\\"published\\\\\\\": pubdate,\\\\n\\\",\\n+    \\\"        \\\\\\\"publisher\\\\\\\": meta.get(\\\\\\\"publisher\\\\\\\"),\\\\n\\\",\\n+    \\\"      },\\\\n\\\",\\n+    \\\"   \\\\n\\\",\\n+    \\\"    }\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"      # 4) log it as a single JSON artifact\\\\n\\\",\\n+    \\\"    mlflow.log_dict(public_datasetRepository_metadata,\\\\n\\\",\\n+    \\\"                \\\\\\\"public_datasetRepository_metadata.json\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # 2) Flatten and log the important bits as params:\\\\n\\\",\\n+    \\\"    z = public_datasetRepository_metadata[\\\\\\\"zenodo\\\\\\\"]\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    mlflow.log_param(\\\\\\\"dataset.title\\\\\\\",     z[\\\\\\\"title\\\\\\\"])\\\\n\\\",\\n+    \\\"    mlflow.log_param(\\\\\\\"dataset.doi\\\\\\\",       z[\\\\\\\"doi\\\\\\\"])\\\\n\\\",\\n+    \\\"    mlflow.log_param(\\\\\\\"dataset.authors\\\\\\\",   json.dumps(z[\\\\\\\"authors\\\\\\\"]))\\\\n\\\",\\n+    \\\"    mlflow.log_param(\\\\\\\"dataset.published\\\\\\\", z[\\\\\\\"published\\\\\\\"])\\\\n\\\",\\n+    \\\"    mlflow.log_param(\\\\\\\"dataset.publisher\\\\\\\", z[\\\\\\\"publisher\\\\\\\"])\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"   \\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"58c92e13-eb57-418d-b354-83777f88aa98\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"##################################################################\\\\n\\\",\\n+    \\\"# DATA PREPROCESSING STEPS\\\\n\\\",\\n+    \\\"###################################################################\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"9832d0df-af0a-4eee-90d0-fab926e03e85\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"STEP 1: LOAD DATASET\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 13,\\n+   \\\"id\\\": \\\"77402d80-22d1-4bed-9489-768958c3e9fa\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [],\\n+   \\\"source\\\": [\\n+    \\\"# \\u2500\\u2500 2) Load into a DataFrame \\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\\\n\\\",\\n+    \\\"df = pd.DataFrame(dataset)\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"6862e341-3ea1-43f6-a1ac-9a51188fe614\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"STEP2: seperate Dependent and Independent variables and drop unnecessary columns like ID\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 14,\\n+   \\\"id\\\": \\\"01309a7b-53d2-4df4-b334-0f0db8b03333\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"Shapes: (150, 4) (150,)\\\\n\\\"\\n+     ]\\n+    }\\n+   ],\\n+   \\\"source\\\": [\\n+    \\\"target_col = df.columns[-1]      # e.g. \\\\\\\"species\\\\\\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# 2) extract y as the Series of labels\\\\n\\\",\\n+    \\\"y = df[target_col]               # length == n_samples\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# 3) build X by dropping just that one column\\\\n\\\",\\n+    \\\"X = df.drop(columns=[target_col])\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# 4) drop any ID column (case-insensitive)\\\\n\\\",\\n+    \\\"id_cols = [c for c in X.columns if c.lower() == \\\\\\\"id\\\\\\\"]\\\\n\\\",\\n+    \\\"if id_cols:\\\\n\\\",\\n+    \\\"    X = X.drop(columns=id_cols)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# 5) coerce numeric where possible\\\\n\\\",\\n+    \\\"for c in X.columns:\\\\n\\\",\\n+    \\\"    try:\\\\n\\\",\\n+    \\\"        X[c] = pd.to_numeric(X[c])\\\\n\\\",\\n+    \\\"    except Exception:\\\\n\\\",\\n+    \\\"        pass\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"print(\\\\\\\"Shapes:\\\\\\\", X.shape, y.shape)\\\\n\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"367d6256-a30a-4f91-bc64-f20966d828ab\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"STEP3: Label Encoding as the target values are class names\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 15,\\n+   \\\"id\\\": \\\"11f5126d-6a03-48c6-9ecf-39ed0d43688c\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"Classes: ['Iris-setosa' 'Iris-versicolor' 'Iris-virginica']\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"data\\\": {\\n+      \\\"text/plain\\\": [\\n+       \\\"array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\\\\n\\\",\\n+       \\\"       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\\\\n\\\",\\n+       \\\"       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\\\\n\\\",\\n+       \\\"       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\\\\n\\\",\\n+       \\\"       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\\\\n\\\",\\n+       \\\"       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\\\\n\\\",\\n+       \\\"       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\\\"\\n+      ]\\n+     },\\n+     \\\"execution_count\\\": 15,\\n+     \\\"metadata\\\": {},\\n+     \\\"output_type\\\": \\\"execute_result\\\"\\n+    }\\n+   ],\\n+   \\\"source\\\": [\\n+    \\\"\\\\n\\\",\\n+    \\\"le = LabelEncoder()\\\\n\\\",\\n+    \\\"y = le.fit_transform(y)  \\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# now y_enc is a 1d numpy array of ints 0,1,2\\\\n\\\",\\n+    \\\"print(\\\\\\\"Classes:\\\\\\\", le.classes_)  \\\\n\\\",\\n+    \\\"y\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 16,\\n+   \\\"id\\\": \\\"68d0a924-c65f-4a44-a5cc-bbb32d17e96f\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [],\\n+   \\\"source\\\": [\\n+    \\\"# \\u2500\\u2500 4) Cast feature columns to numeric where possible \\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\\\n\\\",\\n+    \\\"for col in X.columns:\\\\n\\\",\\n+    \\\"    try:\\\\n\\\",\\n+    \\\"        X[col] = pd.to_numeric(X[col])   # no errors=\\\\\\\"ignore\\\\\\\"\\\\n\\\",\\n+    \\\"    except ValueError:\\\\n\\\",\\n+    \\\"        # if it can\\u2019t be cast, just leave it as-is\\\\n\\\",\\n+    \\\"        pass\\\\n\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 17,\\n+   \\\"id\\\": \\\"e17f39ce-3322-4626-83a6-079d304bbc04\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [],\\n+   \\\"source\\\": [\\n+    \\\"# \\u2500\\u2500 5) Drop any \\u201cid\\u201d column (case-insensitive) \\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\\\n\\\",\\n+    \\\"dropped = [c for c in X.columns if c.lower() == \\\\\\\"id\\\\\\\"]\\\\n\\\",\\n+    \\\"X = X.drop(columns=dropped, errors=\\\\\\\"ignore\\\\\\\")\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"6fcf2244-14dd-4e3d-b8cf-f7f3ba34f80f\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"# \\ud83d\\udcc2 Setup MLflow\\\\n\\\",\\n+    \\\"# ============================\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 30,\\n+   \\\"id\\\": \\\"cbe91ec0-6447-4586-b7cc-2c1f74d4218f\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [],\\n+   \\\"source\\\": [\\n+    \\\"\\\\n\\\",\\n+    \\\"project_dir = os.getcwd()\\\\n\\\",\\n+    \\\"mlflow.set_tracking_uri(\\\\\\\"mlrunlogs/mlflow.db\\\\\\\")\\\\n\\\",\\n+    \\\"mlflow.set_experiment(\\\\\\\"RandomForest-Iris-CSV\\\\\\\")\\\\n\\\",\\n+    \\\"mlflow.sklearn.autolog(log_input_examples=False, log_model_signatures=True)\\\\n\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"af2c2c5f-cc36-41a3-9643-83ef95b9f55e\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"# \\ud83d\\udd04 Git Commit Hash for previous commit for metadata\\\\n\\\",\\n+    \\\"# ============================\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 19,\\n+   \\\"id\\\": \\\"838dd233-25dc-4725-974d-4da89c257782\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [],\\n+   \\\"source\\\": [\\n+    \\\"\\\\n\\\",\\n+    \\\"repo_dir = \\\\\\\"C:/Users/reema/REPO\\\\\\\"\\\\n\\\",\\n+    \\\"previous_commit_repo = git.Repo(repo_dir)\\\\n\\\",\\n+    \\\"previous_commit_hash = previous_commit_repo.head.object.hexsha\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"430d15ef-3432-4e45-88fb-b7048a5b10a9\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"# Make threadpoolctl safe so MLflow\\u2019s autologger won\\u2019t crash \\u2500\\u2500\\u2500\\\\n\\\",\\n+    \\\"# ============================\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 20,\\n+   \\\"id\\\": \\\"9668451f-4352-4bdc-8b6b-bbe49074212a\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [\\n+    {\\n+     \\\"name\\\": \\\"stderr\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"2025/04/25 13:13:44 INFO mlflow.tracking.fluent: Autologging successfully enabled for statsmodels.\\\\n\\\"\\n+     ]\\n+    }\\n+   ],\\n+   \\\"source\\\": [\\n+    \\\"try:\\\\n\\\",\\n+    \\\"    import threadpoolctl\\\\n\\\",\\n+    \\\"    _orig = threadpoolctl.threadpool_info\\\\n\\\",\\n+    \\\"    def _safe_threadpool_info(*args, **kwargs):\\\\n\\\",\\n+    \\\"        try:\\\\n\\\",\\n+    \\\"            return _orig(*args, **kwargs)\\\\n\\\",\\n+    \\\"        except Exception:\\\\n\\\",\\n+    \\\"            return []\\\\n\\\",\\n+    \\\"    threadpoolctl.threadpool_info = _safe_threadpool_info\\\\n\\\",\\n+    \\\"except ImportError:\\\\n\\\",\\n+    \\\"    pass  # if threadpoolctl isn\\u2019t installed, autolog will skip unsupported versions\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# \\u2500\\u2500\\u2500 1) Enable generic autolog (will auto-patch sklearn under the hood) \\u2500\\u2500\\u2500\\\\n\\\",\\n+    \\\"import mlflow\\\\n\\\",\\n+    \\\"mlflow.autolog(\\\\n\\\",\\n+    \\\"    log_input_examples=True,\\\\n\\\",\\n+    \\\"    log_model_signatures=True\\\\n\\\",\\n+    \\\")\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"9058319a-adba-4a6b-93e9-d17080c0594d\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"# ============================\\\\n\\\",\\n+    \\\"# \\ud83d\\ude80 Start MLflow Run \\\\n\\\",\\n+    \\\"# ============================\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 21,\\n+   \\\"id\\\": \\\"14c62f08-a116-4060-9689-f69968e9f240\\\",\\n+   \\\"metadata\\\": {\\n+    \\\"scrolled\\\": true\\n+   },\\n+   \\\"outputs\\\": [\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\\\n\\\",\\n+      \\\"\\ud83d\\udcdd Justification for `n_estimators` (Hyperparameter configuration)\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdin\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\u2192 Why did you choose this value?  test\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\\\n\\\",\\n+      \\\"\\ud83d\\udcdd Justification for `criterion` (Hyperparameter configuration)\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdin\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\u2192 Why did you choose this value?  test\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\\\n\\\",\\n+      \\\"\\ud83d\\udcdd Justification for `max_depth` (Hyperparameter configuration)\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdin\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\u2192 Why did you choose this value?  test\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\\\n\\\",\\n+      \\\"\\ud83d\\udcdd Justification for `min_samples_split` (Hyperparameter configuration)\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdin\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\u2192 Why did you choose this value?  test\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\\\n\\\",\\n+      \\\"\\ud83d\\udcdd Justification for `min_samples_leaf` (Hyperparameter configuration)\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdin\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\u2192 Why did you choose this value?  test\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\\\n\\\",\\n+      \\\"\\ud83d\\udcdd Justification for `max_features` (Hyperparameter configuration)\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdin\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\u2192 Why did you choose this value?  test\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\\\n\\\",\\n+      \\\"\\ud83d\\udcdd Justification for `bootstrap` (Hyperparameter configuration)\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdin\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\u2192 Why did you choose this value?  test\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\\\n\\\",\\n+      \\\"\\ud83d\\udcdd Justification for `oob_score` (Hyperparameter configuration)\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdin\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\u2192 Why did you choose this value?  test\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\\\n\\\",\\n+      \\\"\\ud83d\\udcdd Justification for `class_weight` (Hyperparameter configuration)\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdin\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\u2192 Why did you choose this value?  test\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\\\n\\\",\\n+      \\\"\\ud83d\\udcdd Justification for `random_state` (Hyperparameter configuration)\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdin\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\u2192 Why did you choose this value?  test\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\\\n\\\",\\n+      \\\"\\ud83d\\udcdd Justification for `verbose` (Hyperparameter configuration)\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdin\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\u2192 Why did you choose this value?  test\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\\\n\\\",\\n+      \\\"\\ud83d\\udcdd Justification for `n_jobs` (Hyperparameter configuration)\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdin\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\u2192 Why did you choose this value?  test\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\\\n\\\",\\n+      \\\"\\ud83d\\udcdd Justification for `model_choice`\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdin\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\u2192 Why did you choose RandomForestClassifier for this task?  test\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\\\n\\\",\\n+      \\\"\\ud83d\\udcdd Justification for `target_variable`\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdin\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\u2192 Why did you choose this column as the prediction target?  test\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\\\n\\\",\\n+      \\\"\\ud83d\\udcdd Justification for `test_split`\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdin\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\u2192 Why this train/test ratio (e.g., 80/20)?  test\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\\\n\\\",\\n+      \\\"\\ud83d\\udcdd Justification for `metric_choice`\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdin\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\u2192 Why accuracy/f1/ROC-AUC as your evaluation metric?  test\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\\\n\\\",\\n+      \\\"\\ud83d\\udcdd Justification for `threshold_accuracy`\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdin\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\u2192 Why 0.95 as performance threshold?  test\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\\\n\\\",\\n+      \\\"\\ud83d\\udcdd Justification for `dataset_version`\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdin\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\u2192 Why use this specific dataset version?  test\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\\\n\\\",\\n+      \\\"\\ud83d\\udcdd Justification for `drop_column_X`\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdin\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\u2192 Why drop any specific columns from the dataset?  test\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\\\n\\\",\\n+      \\\"\\ud83d\\udcdd Justification for `experiment_name`\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdin\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\u2192 Any context behind this experiment name or setup?  test\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stderr\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.0s\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    0.2s\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    0.2s finished\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Done 200 out of 200 | elapsed:    0.0s finished\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Done 200 out of 200 | elapsed:    0.0s finished\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Done 200 out of 200 | elapsed:    0.0s finished\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Done 200 out of 200 | elapsed:    0.0s finished\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Done 200 out of 200 | elapsed:    0.0s finished\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Done 200 out of 200 | elapsed:    0.0s finished\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\\\\n\\\",\\n+      \\\"[Parallel(n_jobs=12)]: Done 200 out of 200 | elapsed:    0.0s finished\\\\n\\\",\\n+      \\\"C:\\\\\\\\Users\\\\\\\\reema\\\\\\\\anaconda3\\\\\\\\Lib\\\\\\\\site-packages\\\\\\\\shap\\\\\\\\plots\\\\\\\\_beeswarm.py:1153: UserWarning: The figure layout has changed to tight\\\\n\\\",\\n+      \\\"  pl.tight_layout()\\\\n\\\",\\n+      \\\"C:\\\\\\\\Users\\\\\\\\reema\\\\\\\\anaconda3\\\\\\\\Lib\\\\\\\\site-packages\\\\\\\\shap\\\\\\\\plots\\\\\\\\_beeswarm.py:761: UserWarning: The figure layout has changed to tight\\\\n\\\",\\n+      \\\"  pl.tight_layout(pad=0, w_pad=0, h_pad=0.0)\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\u2705 Commit successful.\\\\n\\\",\\n+      \\\"\\ud83d\\ude80 Push successful.\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"data\\\": {\\n+      \\\"text/plain\\\": [\\n+       \\\"<Figure size 600x600 with 0 Axes>\\\"\\n+      ]\\n+     },\\n+     \\\"metadata\\\": {},\\n+     \\\"output_type\\\": \\\"display_data\\\"\\n+    },\\n+    {\\n+     \\\"data\\\": {\\n+      \\\"image/png\\\": \\\"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\\\",\\n+      \\\"text/plain\\\": [\\n+       \\\"<Figure size 1150x660 with 1 Axes>\\\"\\n+      ]\\n+     },\\n+     \\\"metadata\\\": {},\\n+     \\\"output_type\\\": \\\"display_data\\\"\\n+    }\\n+   ],\\n+   \\\"source\\\": [\\n+    \\\"\\\\n\\\",\\n+    \\\"with mlflow.start_run() as run:\\\\n\\\",\\n+    \\\"    #################################################\\\\n\\\",\\n+    \\\"# Justification LOGGER\\\\n\\\",\\n+    \\\"################################################\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    def log_with_justification(log_func, key, value, context=\\\\\\\"\\\\\\\"):\\\\n\\\",\\n+    \\\"        \\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\",\\n+    \\\"        Log a parameter/metric/tag using `log_func` and ask for justification via console.\\\\n\\\",\\n+    \\\"        \\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\",\\n+    \\\"        log_func(key, value)\\\\n\\\",\\n+    \\\"        print(f\\\\\\\"\\\\\\\\n\\ud83d\\udcdd Justification for `{key}` ({context})\\\\\\\")\\\\n\\\",\\n+    \\\"        user_reason = input(\\\\\\\"\\u2192 Why did you choose this value? \\\\\\\")\\\\n\\\",\\n+    \\\"        mlflow.set_tag(f\\\\\\\"justification_{key}\\\\\\\", user_reason or \\\\\\\"No justification provided\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    def log_justification(key: str, question: str):\\\\n\\\",\\n+    \\\"        print(f\\\\\\\"\\\\\\\\n\\ud83d\\udcdd Justification for `{key}`\\\\\\\")\\\\n\\\",\\n+    \\\"        user_reason = input(f\\\\\\\"\\u2192 {question} \\\\\\\")\\\\n\\\",\\n+    \\\"        mlflow.set_tag(f\\\\\\\"justification_{key}\\\\\\\", user_reason or \\\\\\\"No justification provided\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    meta = fetch_and_log_dataset_metadata_nested(\\\\n\\\",\\n+    \\\"            \\\\\\\"https://doi.org/10.5281/zenodo.1404173\\\\\\\",\\\\n\\\",\\n+    \\\"           \\\\n\\\",\\n+    \\\"        )\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    #Datasbase info logging\\\\n\\\",\\n+    \\\"    db_id = \\\\\\\"c3a42d17-42b7-43c9-a504-2363fb4c9c8d\\\\\\\"\\\\n\\\",\\n+    \\\"    db_meta = fetch_db_metadata(db_id)\\\\n\\\",\\n+    \\\"    log_db_metadata(db_meta)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    #OAI metadata logging from api endpoint\\\\n\\\",\\n+    \\\"    # log as tags\\\\n\\\",\\n+    \\\"    mlflow.set_tag(\\\\\\\"dbrepo.repository_name\\\\\\\", repo_name)\\\\n\\\",\\n+    \\\"    mlflow.set_tag(\\\\\\\"dbrepo.base_url\\\\\\\",       base_url)\\\\n\\\",\\n+    \\\"    mlflow.set_tag(\\\\\\\"dbrepo.protocol_version\\\\\\\", protocol)\\\\n\\\",\\n+    \\\"    mlflow.set_tag(\\\\\\\"dbrepo.admin_email\\\\\\\",     admin_email)\\\\n\\\",\\n+    \\\"    mlflow.set_tag(\\\\\\\"dbrepo.granularity\\\\\\\",     gran)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    #From history API logging\\\\n\\\",\\n+    \\\"    # provenance tags\\\\n\\\",\\n+    \\\"    mlflow.set_tag(\\\\\\\"dbrepo.table_last_modified\\\\\\\", ts_last)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # row-count metrics\\\\n\\\",\\n+    \\\"    mlflow.log_metric(\\\\\\\"dbrepo.row_count_start\\\\\\\", count_start)\\\\n\\\",\\n+    \\\"    mlflow.log_metric(\\\\\\\"dbrepo.row_count_end\\\\\\\",   count_end)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # change-event metrics\\\\n\\\",\\n+    \\\"    mlflow.log_metric(\\\\\\\"dbrepo.num_inserts\\\\\\\", n_insert)\\\\n\\\",\\n+    \\\"    mlflow.log_metric(\\\\\\\"dbrepo.num_deletes\\\\\\\", n_delete)\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    # 2) Capture raw metadata\\\\n\\\",\\n+    \\\"    mlflow.set_tag(\\\\\\\"data_source\\\\\\\", API_URL)\\\\n\\\",\\n+    \\\"    mlflow.log_param(\\\\\\\"retrieval_time\\\\\\\", datetime.utcnow().isoformat())\\\\n\\\",\\n+    \\\"    mlflow.log_param(\\\\\\\"n_records\\\\\\\", len(df))\\\\n\\\",\\n+    \\\"    mlflow.log_param(\\\\\\\"columns_raw\\\\\\\", df.columns.tolist())\\\\n\\\",\\n+    \\\"    mlflow.log_param(\\\\\\\"dropped_columns\\\\\\\", id_cols)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # 4) Post\\u2010processing metadata\\\\n\\\",\\n+    \\\"    mlflow.log_param(\\\\\\\"n_features_final\\\\\\\", X.shape[1])\\\\n\\\",\\n+    \\\"    mlflow.log_param(\\\\\\\"feature_names\\\\\\\", X.columns.tolist())\\\\n\\\",\\n+    \\\"    mlflow.set_tag(\\\\\\\"target_name\\\\\\\", y)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"       # Label encoding\\\\n\\\",\\n+    \\\"    label_map = {int(idx): cls for idx, cls in enumerate(le.classes_)}\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    # Save to an in-memory file\\\\n\\\",\\n+    \\\"    buffer = io.StringIO()\\\\n\\\",\\n+    \\\"    json.dump(label_map, buffer, indent=2)\\\\n\\\",\\n+    \\\"    buffer.seek(0)\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    # Log it to MLflow\\\\n\\\",\\n+    \\\"    mlflow.log_text(buffer.getvalue(), artifact_file=\\\\\\\"label_mapping.json\\\\\\\")\\\\n\\\",\\n+    \\\"   \\\\n\\\",\\n+    \\\"    ts = datetime.now().strftime(\\\\\\\"%Y%m%d_%H%M%S\\\\\\\")\\\\n\\\",\\n+    \\\"    model_name = f\\\\\\\"RandomForest_Iris_v{ts}\\\\\\\"\\\\n\\\",\\n+    \\\"    mlflow.set_tag(\\\\\\\"model_name\\\\\\\",model_name)\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    train_start_ts = datetime.now().isoformat()\\\\n\\\",\\n+    \\\"    mlflow.set_tag(\\\\\\\"training_start_time\\\\\\\", train_start_ts)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    test_size    = 0.2\\\\n\\\",\\n+    \\\"    random_state = 42\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    # \\ud83d\\udcc8 Model Training\\\\n\\\",\\n+    \\\"    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    # \\u2500\\u2500 2) Log dataset split params \\u2500\\u2500\\\\n\\\",\\n+    \\\"    mlflow.log_param(\\\\\\\"test_size\\\\\\\", test_size)\\\\n\\\",\\n+    \\\"    mlflow.log_param(\\\\\\\"random_state\\\\\\\", random_state)\\\\n\\\",\\n+    \\\"    mlflow.log_param(\\\\\\\"n_train_samples\\\\\\\", X_train.shape[0])\\\\n\\\",\\n+    \\\"    mlflow.log_param(\\\\\\\"n_test_samples\\\\\\\",  X_test.shape[0])\\\\n\\\",\\n+    \\\"    mlflow.log_param(\\\\\\\"n_features\\\\\\\",      X_train.shape[1])\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"     # 1) Define a more complex hyperparameter dict\\\\n\\\",\\n+    \\\"    hyperparams = {\\\\n\\\",\\n+    \\\"        \\\\\\\"n_estimators\\\\\\\":       200,\\\\n\\\",\\n+    \\\"        \\\\\\\"criterion\\\\\\\":          \\\\\\\"entropy\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"max_depth\\\\\\\":          12,\\\\n\\\",\\n+    \\\"        \\\\\\\"min_samples_split\\\\\\\":  5,\\\\n\\\",\\n+    \\\"        \\\\\\\"min_samples_leaf\\\\\\\":   2,\\\\n\\\",\\n+    \\\"        \\\\\\\"max_features\\\\\\\":       \\\\\\\"sqrt\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"bootstrap\\\\\\\":          True,\\\\n\\\",\\n+    \\\"        \\\\\\\"oob_score\\\\\\\":          False,\\\\n\\\",\\n+    \\\"        \\\\\\\"class_weight\\\\\\\":       None,\\\\n\\\",\\n+    \\\"        \\\\\\\"random_state\\\\\\\":       42,\\\\n\\\",\\n+    \\\"        \\\\\\\"verbose\\\\\\\":            1,\\\\n\\\",\\n+    \\\"        \\\\\\\"n_jobs\\\\\\\":             -1\\\\n\\\",\\n+    \\\"    }\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    # 2) Log them ALL at once\\\\n\\\",\\n+    \\\"    # mlflow.log_params(hyperparams) #TEST\\\\n\\\",\\n+    \\\"    model = RandomForestClassifier(**hyperparams)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    for key, val in hyperparams.items():\\\\n\\\",\\n+    \\\"        log_with_justification(mlflow.log_param, key, val, context=\\\\\\\"Hyperparameter configuration\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # Prompt for and log justifications for high-level modeling decisions\\\\n\\\",\\n+    \\\"    log_justification(\\\\\\\"model_choice\\\\\\\", \\\\\\\"Why did you choose RandomForestClassifier for this task?\\\\\\\")\\\\n\\\",\\n+    \\\"    log_justification(\\\\\\\"target_variable\\\\\\\", \\\\\\\"Why did you choose this column as the prediction target?\\\\\\\")\\\\n\\\",\\n+    \\\"    log_justification(\\\\\\\"test_split\\\\\\\", \\\\\\\"Why this train/test ratio (e.g., 80/20)?\\\\\\\")\\\\n\\\",\\n+    \\\"    log_justification(\\\\\\\"metric_choice\\\\\\\", \\\\\\\"Why accuracy/f1/ROC-AUC as your evaluation metric?\\\\\\\")\\\\n\\\",\\n+    \\\"    log_justification(\\\\\\\"threshold_accuracy\\\\\\\", \\\\\\\"Why 0.95 as performance threshold?\\\\\\\")\\\\n\\\",\\n+    \\\"    log_justification(\\\\\\\"dataset_version\\\\\\\", \\\\\\\"Why use this specific dataset version?\\\\\\\")\\\\n\\\",\\n+    \\\"    log_justification(\\\\\\\"drop_column_X\\\\\\\", \\\\\\\"Why drop any specific columns from the dataset?\\\\\\\")\\\\n\\\",\\n+    \\\"    log_justification(\\\\\\\"experiment_name\\\\\\\", \\\\\\\"Any context behind this experiment name or setup?\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    model.fit(X_train, y_train)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    train_end_ts = datetime.now().isoformat()\\\\n\\\",\\n+    \\\"    mlflow.set_tag(\\\\\\\"training_end_time\\\\\\\", train_end_ts)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"     # \\u2500\\u2500 6) Predict & log metrics \\u2500\\u2500\\\\n\\\",\\n+    \\\"    y_pred = model.predict(X_test)\\\\n\\\",\\n+    \\\"    y_proba = model.predict_proba(X_test)\\\\n\\\",\\n+    \\\"    acc = accuracy_score(y_test, y_pred)\\\\n\\\",\\n+    \\\"    auc = roc_auc_score(y_test, y_proba, multi_class=\\\\\\\"ovr\\\\\\\")\\\\n\\\",\\n+    \\\"    prec = precision_score(y_test, y_pred, average=\\\\\\\"macro\\\\\\\")\\\\n\\\",\\n+    \\\"    rec  = recall_score(y_test,    y_pred, average=\\\\\\\"macro\\\\\\\")\\\\n\\\",\\n+    \\\"    f1   = f1_score(y_test,      y_pred, average=\\\\\\\"macro\\\\\\\")\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    # mlflow.log_metric(\\\\\\\"precision_macro\\\\\\\", prec) #TEST\\\\n\\\",\\n+    \\\"    # mlflow.log_metric(\\\\\\\"recall_macro\\\\\\\",    rec)#TEST\\\\n\\\",\\n+    \\\"    # mlflow.log_metric(\\\\\\\"f1_macro\\\\\\\",        f1)#TEST\\\\n\\\",\\n+    \\\"    # mlflow.log_metric(\\\\\\\"accuracy\\\\\\\", acc)#TEST\\\\n\\\",\\n+    \\\"    # mlflow.log_metric(\\\\\\\"roc_auc\\\\\\\",   auc)#TEST\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # \\u2705 Log Environment Automatically\\\\n\\\",\\n+    \\\"    # mlflow.log_params({\\\\n\\\",\\n+    \\\"    #     \\\\\\\"python_version\\\\\\\": platform.python_version(),\\\\n\\\",\\n+    \\\"    #     \\\\\\\"os_platform\\\\\\\": f\\\\\\\"{platform.system()} {platform.release()}\\\\\\\",\\\\n\\\",\\n+    \\\"    #     \\\\\\\"sklearn_version\\\\\\\": sklearn.__version__,\\\\n\\\",\\n+    \\\"    #     \\\\\\\"pandas_version\\\\\\\": pd.__version__,\\\\n\\\",\\n+    \\\"    #     \\\\\\\"numpy_version\\\\\\\": np.__version__,\\\\n\\\",\\n+    \\\"    #     \\\\\\\"matplotlib_version\\\\\\\": matplotlib.__version__,\\\\n\\\",\\n+    \\\"    #     \\\\\\\"seaborn_version\\\\\\\": sns.__version__,\\\\n\\\",\\n+    \\\"    #     \\\\\\\"shap_version\\\\\\\": shap.__version__,\\\\n\\\",\\n+    \\\"    # })#TEST\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # \\u2705 Git and Notebook Metadata\\\\n\\\",\\n+    \\\"    mlflow.set_tag(\\\\\\\"notebook_name\\\\\\\", \\\\\\\"RQ1.ipynb\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # \\u2705 Dataset Metadata Tags\\\\n\\\",\\n+    \\\"    mlflow.set_tag(\\\\\\\"dataset_name\\\\\\\", \\\\\\\"Iris\\\\\\\") #TODO\\\\n\\\",\\n+    \\\"    mlflow.set_tag(\\\\\\\"dataset_version\\\\\\\", \\\\\\\"1.0.0\\\\\\\") #TODO\\\\n\\\",\\n+    \\\"    mlflow.set_tag(\\\\\\\"dataset_id\\\\\\\", \\\\\\\"iris_local\\\\\\\") #TODO\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # \\u2500\\u2500\\u2500 2) Create a folder for this run\\u2019s plots \\u2500\\u2500\\u2500\\\\n\\\",\\n+    \\\"    plot_dir = os.path.join(\\\\\\\"plots\\\\\\\", model_name)\\\\n\\\",\\n+    \\\"    os.makedirs(plot_dir, exist_ok=True)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # 1) Feature Importance Bar Chart\\\\n\\\",\\n+    \\\"    importances = model.feature_importances_\\\\n\\\",\\n+    \\\"    try:\\\\n\\\",\\n+    \\\"        feature_names = X_train.columns\\\\n\\\",\\n+    \\\"    except AttributeError:\\\\n\\\",\\n+    \\\"        feature_names = [f\\\\\\\"f{i}\\\\\\\" for i in range(X_train.shape[1])]\\\\n\\\",\\n+    \\\"    fi_path = os.path.join(plot_dir, \\\\\\\"feature_importances.png\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    plt.figure(figsize=(8, 6))\\\\n\\\",\\n+    \\\"    sns.barplot(x=importances, y=feature_names)\\\\n\\\",\\n+    \\\"    plt.title(\\\\\\\"Feature Importances\\\\\\\")\\\\n\\\",\\n+    \\\"    plt.xlabel(\\\\\\\"Importance\\\\\\\")\\\\n\\\",\\n+    \\\"    plt.ylabel(\\\\\\\"Feature\\\\\\\")\\\\n\\\",\\n+    \\\"    plt.tight_layout()\\\\n\\\",\\n+    \\\"    plt.savefig(fi_path)\\\\n\\\",\\n+    \\\"    mlflow.log_artifact(fi_path)\\\\n\\\",\\n+    \\\"    plt.close()\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# 2) Multi-class ROC Curves\\\\n\\\",\\n+    \\\"# Binarize labels for one-vs-rest\\\\n\\\",\\n+    \\\"    classes = np.unique(y_test)\\\\n\\\",\\n+    \\\"    y_test_bin = label_binarize(y_test, classes=classes)\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    for idx, cls in enumerate(classes):\\\\n\\\",\\n+    \\\"        disp = RocCurveDisplay.from_predictions(\\\\n\\\",\\n+    \\\"            y_test_bin[:, idx], \\\\n\\\",\\n+    \\\"            y_proba[:, idx],\\\\n\\\",\\n+    \\\"            name=f\\\\\\\"ROC for class {cls}\\\\\\\"\\\\n\\\",\\n+    \\\"        )\\\\n\\\",\\n+    \\\"        roc_path = os.path.join(plot_dir, f\\\\\\\"roc_curve_cls_{cls}.png\\\\\\\")\\\\n\\\",\\n+    \\\"        disp.figure_.savefig(roc_path)\\\\n\\\",\\n+    \\\"        mlflow.log_artifact(roc_path)\\\\n\\\",\\n+    \\\"        plt.close(disp.figure_)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # 3) Multi-class Precision-Recall Curves\\\\n\\\",\\n+    \\\"    for idx, cls in enumerate(classes):\\\\n\\\",\\n+    \\\"        disp = PrecisionRecallDisplay.from_predictions(\\\\n\\\",\\n+    \\\"            y_test_bin[:, idx], \\\\n\\\",\\n+    \\\"            y_proba[:, idx],\\\\n\\\",\\n+    \\\"            name=f\\\\\\\"PR curve for class {cls}\\\\\\\"\\\\n\\\",\\n+    \\\"        )\\\\n\\\",\\n+    \\\"        pr_path = os.path.join(plot_dir, f\\\\\\\"pr_curve_cls_{cls}.png\\\\\\\")\\\\n\\\",\\n+    \\\"        disp.figure_.savefig(pr_path)\\\\n\\\",\\n+    \\\"        mlflow.log_artifact(pr_path)\\\\n\\\",\\n+    \\\"        plt.close(disp.figure_)\\\\n\\\",\\n+    \\\"        \\\\n\\\",\\n+    \\\"    # \\u2705 Confusion Matrix Plot\\\\n\\\",\\n+    \\\"    cm_path = os.path.join(plot_dir, \\\\\\\"confusion_matrix.png\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    cm = confusion_matrix(y_test, y_pred)\\\\n\\\",\\n+    \\\"    plt.figure(figsize=(6, 6))\\\\n\\\",\\n+    \\\"    sns.heatmap(cm, annot=True, fmt=\\\\\\\"d\\\\\\\", cmap=\\\\\\\"Blues\\\\\\\")\\\\n\\\",\\n+    \\\"    plt.title(\\\\\\\"Confusion Matrix\\\\\\\")\\\\n\\\",\\n+    \\\"    plt.xlabel(\\\\\\\"Predicted\\\\\\\")\\\\n\\\",\\n+    \\\"    plt.ylabel(\\\\\\\"Actual\\\\\\\")\\\\n\\\",\\n+    \\\"    plt.savefig(cm_path)\\\\n\\\",\\n+    \\\"    mlflow.log_artifact(cm_path)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # \\u2705 SHAP Summary\\\\n\\\",\\n+    \\\"    shap_path = os.path.join(plot_dir, \\\\\\\"shap_summary.png\\\\\\\")\\\\n\\\",\\n+    \\\"    explainer = shap.TreeExplainer(model)\\\\n\\\",\\n+    \\\"    shap_values = explainer.shap_values(X_test)\\\\n\\\",\\n+    \\\"    shap.summary_plot(shap_values, X_test, show=False)\\\\n\\\",\\n+    \\\"    plt.savefig(shap_path)\\\\n\\\",\\n+    \\\"    mlflow.log_artifact(shap_path)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    # \\u2500\\u2500\\u2500 1) Build a .pkl filename (you can include your model_name for clarity)\\\\n\\\",\\n+    \\\"    pkl_path = f\\\\\\\"Trained_models/{model_name}.pkl\\\\\\\"\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    # \\u2500\\u2500\\u2500 2) Serialize your trained model to disk\\\\n\\\",\\n+    \\\"    with open(pkl_path, \\\\\\\"wb\\\\\\\") as f:\\\\n\\\",\\n+    \\\"        pickle.dump(model, f)\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    # \\u2500\\u2500\\u2500 3) Log that pickle file as an MLflow artifact\\\\n\\\",\\n+    \\\"    #     It will appear under Artifacts \\u2192 models/RandomForest_Iris_vYYYYMMDD_HHMMSS.pkl\\\\n\\\",\\n+    \\\"    mlflow.log_artifact(pkl_path, artifact_path=model_name)\\\\n\\\",\\n+    \\\"        \\\\n\\\",\\n+    \\\"    def get_latest_commit_hash(repo_path=\\\\\\\".\\\\\\\"):\\\\n\\\",\\n+    \\\"        # returns the full SHA of HEAD\\\\n\\\",\\n+    \\\"        res = subprocess.run(\\\\n\\\",\\n+    \\\"            [\\\\\\\"git\\\\\\\", \\\\\\\"-C\\\\\\\", repo_path, \\\\\\\"rev-parse\\\\\\\", \\\\\\\"HEAD\\\\\\\"],\\\\n\\\",\\n+    \\\"            capture_output=True, text=True, check=True)\\\\n\\\",\\n+    \\\"        \\\\n\\\",\\n+    \\\"        return res.stdout.strip()\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    def get_remote_url(repo_path=\\\\\\\".\\\\\\\", remote=\\\\\\\"origin\\\\\\\"):\\\\n\\\",\\n+    \\\"        # returns something like git@github.com:user/repo.git or https://...\\\\n\\\",\\n+    \\\"        res = subprocess.run(\\\\n\\\",\\n+    \\\"            [\\\\\\\"git\\\\\\\", \\\\\\\"-C\\\\\\\", repo_path, \\\\\\\"config\\\\\\\", \\\\\\\"--get\\\\\\\", f\\\\\\\"remote.{remote}.url\\\\\\\"],\\\\n\\\",\\n+    \\\"            capture_output=True, text=True, check=True\\\\n\\\",\\n+    \\\"        )\\\\n\\\",\\n+    \\\"        return res.stdout.strip()\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    def make_commit_link(remote_url, commit_hash):\\\\n\\\",\\n+    \\\"        # handle GitHub/GitLab convention; strip \\u201c.git\\u201d if present\\\\n\\\",\\n+    \\\"        base = remote_url.rstrip(\\\\\\\".git\\\\\\\")\\\\n\\\",\\n+    \\\"        # if SSH form (git@github.com:owner/repo), convert to https\\\\n\\\",\\n+    \\\"        if base.startswith(\\\\\\\"git@\\\\\\\"):\\\\n\\\",\\n+    \\\"            base = base.replace(\\\\\\\":\\\\\\\", \\\\\\\"/\\\\\\\").replace(\\\\\\\"git@\\\\\\\", \\\\\\\"https://\\\\\\\")\\\\n\\\",\\n+    \\\"        return f\\\\\\\"{base}/commit/{commit_hash}\\\\\\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    def simple_commit_and_push_and_log(repo_path=\\\\\\\".\\\\\\\", message=\\\\\\\"Auto commit\\\\\\\", remote=\\\\\\\"origin\\\\\\\", branch=\\\\\\\"main\\\\\\\"):\\\\n\\\",\\n+    \\\"    # 1) Check for changes\\\\n\\\",\\n+    \\\"        status = subprocess.run(\\\\n\\\",\\n+    \\\"            [\\\\\\\"git\\\\\\\", \\\\\\\"-C\\\\\\\", repo_path, \\\\\\\"status\\\\\\\", \\\\\\\"--porcelain\\\\\\\"],\\\\n\\\",\\n+    \\\"            capture_output=True, text=True\\\\n\\\",\\n+    \\\"        )\\\\n\\\",\\n+    \\\"        if not status.stdout.strip():\\\\n\\\",\\n+    \\\"            print(\\\\\\\"\\ud83d\\udfe1 No changes to commit.\\\\\\\")\\\\n\\\",\\n+    \\\"            return None, None\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"        # 2) Stage everything\\\\n\\\",\\n+    \\\"        add = subprocess.run(\\\\n\\\",\\n+    \\\"            [\\\\\\\"git\\\\\\\", \\\\\\\"-C\\\\\\\", repo_path, \\\\\\\"add\\\\\\\", \\\\\\\"--all\\\\\\\"],\\\\n\\\",\\n+    \\\"            capture_output=True, text=True\\\\n\\\",\\n+    \\\"        )\\\\n\\\",\\n+    \\\"        if add.returncode:\\\\n\\\",\\n+    \\\"            print(\\\\\\\"\\u274c git add failed:\\\\\\\\n\\\\\\\", add.stderr)\\\\n\\\",\\n+    \\\"            return None, None\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"        # 3) Commit\\\\n\\\",\\n+    \\\"        commit = subprocess.run(\\\\n\\\",\\n+    \\\"            [\\\\\\\"git\\\\\\\", \\\\\\\"-C\\\\\\\", repo_path, \\\\\\\"commit\\\\\\\", \\\\\\\"-m\\\\\\\", message],\\\\n\\\",\\n+    \\\"            capture_output=True, text=True\\\\n\\\",\\n+    \\\"        )\\\\n\\\",\\n+    \\\"        if commit.returncode:\\\\n\\\",\\n+    \\\"            print(\\\\\\\"\\u274c git commit failed:\\\\\\\\n\\\\\\\", commit.stderr)\\\\n\\\",\\n+    \\\"            return None, None\\\\n\\\",\\n+    \\\"        print(\\\\\\\"\\u2705 Commit successful.\\\\\\\")\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"        # 4) Push\\\\n\\\",\\n+    \\\"        push = subprocess.run(\\\\n\\\",\\n+    \\\"            [\\\\\\\"git\\\\\\\", \\\\\\\"-C\\\\\\\", repo_path, \\\\\\\"push\\\\\\\", \\\\\\\"-u\\\\\\\", remote, branch],\\\\n\\\",\\n+    \\\"            capture_output=True, text=True\\\\n\\\",\\n+    \\\"        )\\\\n\\\",\\n+    \\\"        if push.returncode:\\\\n\\\",\\n+    \\\"            print(\\\\\\\"\\u274c git push failed:\\\\\\\\n\\\\\\\", push.stderr)\\\\n\\\",\\n+    \\\"        else:\\\\n\\\",\\n+    \\\"            print(\\\\\\\"\\ud83d\\ude80 Push successful.\\\\\\\")\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"        # 5) Retrieve hash & remote URL\\\\n\\\",\\n+    \\\"        sha = get_latest_commit_hash(repo_path)\\\\n\\\",\\n+    \\\"        url = get_remote_url(repo_path, remote)\\\\n\\\",\\n+    \\\"        link = make_commit_link(url, sha)\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"        return sha, link\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"      \\\\n\\\",\\n+    \\\"    sha, link = simple_commit_and_push_and_log(\\\\n\\\",\\n+    \\\"        repo_path=\\\\\\\".\\\\\\\",\\\\n\\\",\\n+    \\\"        message=\\\\\\\"Auto commit after successful training\\\\\\\"\\\\n\\\",\\n+    \\\"    )\\\\n\\\",\\n+    \\\"    if sha and link:\\\\n\\\",\\n+    \\\"        diff_text = subprocess.check_output(\\\\n\\\",\\n+    \\\"            [\\\\\\\"git\\\\\\\", \\\\\\\"-C\\\\\\\", \\\\\\\".\\\\\\\", \\\\\\\"diff\\\\\\\", previous_commit_hash, sha],\\\\n\\\",\\n+    \\\"            encoding=\\\\\\\"utf-8\\\\\\\",\\\\n\\\",\\n+    \\\"            errors=\\\\\\\"ignore\\\\\\\"    # or \\\\\\\"replace\\\\\\\"\\\\n\\\",\\n+    \\\"        )\\\\n\\\",\\n+    \\\"                \\\\n\\\",\\n+    \\\"        # 1) Get your repo\\u2019s remote URL and normalize to HTTPS\\\\n\\\",\\n+    \\\"        remote_url = subprocess.check_output(\\\\n\\\",\\n+    \\\"            [\\\\\\\"git\\\\\\\", \\\\\\\"config\\\\\\\", \\\\\\\"--get\\\\\\\", \\\\\\\"remote.origin.url\\\\\\\"],\\\\n\\\",\\n+    \\\"            text=True\\\\n\\\",\\n+    \\\"        ).strip().rstrip(\\\\\\\".git\\\\\\\")\\\\n\\\",\\n+    \\\"        if remote_url.startswith(\\\\\\\"git@\\\\\\\"):\\\\n\\\",\\n+    \\\"            # git@github.com:owner/repo.git \\u2192 https://github.com/owner/repo\\\\n\\\",\\n+    \\\"            remote_url = remote_url.replace(\\\\\\\":\\\\\\\", \\\\\\\"/\\\\\\\").replace(\\\\\\\"git@\\\\\\\", \\\\\\\"https://\\\\\\\")\\\\n\\\",\\n+    \\\"        \\\\n\\\",\\n+    \\\"        # 2) Build commit URLs\\\\n\\\",\\n+    \\\"        previous_commit_url  = f\\\\\\\"{remote_url}/commit/{previous_commit_hash}\\\\\\\"\\\\n\\\",\\n+    \\\"        current_commit_url = f\\\\\\\"{remote_url}/commit/{sha}\\\\\\\"\\\\n\\\",\\n+    \\\"        diff_data = {\\\\n\\\",\\n+    \\\"            \\\\\\\"previous_commit\\\\\\\":  previous_commit_hash,\\\\n\\\",\\n+    \\\"            \\\\\\\"previous_commit_url\\\\\\\":previous_commit_url,\\\\n\\\",\\n+    \\\"            \\\\\\\"current_commit_url\\\\\\\":current_commit_url,\\\\n\\\",\\n+    \\\"            \\\\\\\"current_commit\\\\\\\": sha,\\\\n\\\",\\n+    \\\"            \\\\\\\"diff\\\\\\\": diff_text\\\\n\\\",\\n+    \\\"        }\\\\n\\\",\\n+    \\\"        mlflow.log_dict(\\\\n\\\",\\n+    \\\"            diff_data,\\\\n\\\",\\n+    \\\"            artifact_file=\\\\\\\"commit_diff.json\\\\\\\"\\\\n\\\",\\n+    \\\"        )\\\\n\\\",\\n+    \\\"        mlflow.set_tag(\\\\\\\"git_previous_commit_hash\\\\\\\", previous_commit_hash)\\\\n\\\",\\n+    \\\"        mlflow.set_tag(\\\\\\\"git_current_commit_hash\\\\\\\", sha)\\\\n\\\",\\n+    \\\"        mlflow.set_tag(\\\\\\\"git__current_commit_url\\\\\\\", link) \\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    client   = MlflowClient()\\\\n\\\",\\n+    \\\"    run_id    = run.info.run_id\\\\n\\\",\\n+    \\\"    run_info  = client.get_run(run_id).info\\\\n\\\",\\n+    \\\"    run_data  = client.get_run(run_id).data\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    # 1) params, metrics, tags\\\\n\\\",\\n+    \\\"    params  = dict(run_data.params)\\\\n\\\",\\n+    \\\"    metrics = dict(run_data.metrics)\\\\n\\\",\\n+    \\\"    tags    = dict(run_data.tags)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # (4) List artifacts under a specific subfolder\\\\n\\\",\\n+    \\\"    run_meta     = client.get_run(run_id).info\\\\n\\\",\\n+    \\\"    artifact_uri = run_meta.artifact_uri  # base URI for all artifacts\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    artifact_meta = []\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    def _gather(path=\\\\\\\"\\\\\\\"):\\\\n\\\",\\n+    \\\"        for af in client.list_artifacts(run_id, path):\\\\n\\\",\\n+    \\\"            # If it\\u2019s a directory, recurse\\\\n\\\",\\n+    \\\"            if af.is_dir:\\\\n\\\",\\n+    \\\"                _gather(af.path)\\\\n\\\",\\n+    \\\"                continue\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"            rel_path = af.path\\\\n\\\",\\n+    \\\"            uri      = f\\\\\\\"{artifact_uri}/{rel_path}\\\\\\\"\\\\n\\\",\\n+    \\\"            lower    = rel_path.lower()\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"            # 1) Text files \\u2192 download & embed contents\\\\n\\\",\\n+    \\\"            if lower.endswith((\\\\\\\".json\\\\\\\", \\\\\\\".txt\\\\\\\", \\\\\\\".patch\\\\\\\")):\\\\n\\\",\\n+    \\\"                local = client.download_artifacts(run_id, rel_path)\\\\n\\\",\\n+    \\\"                with open(local, \\\\\\\"r\\\\\\\", encoding=\\\\\\\"utf-8\\\\\\\") as f:\\\\n\\\",\\n+    \\\"                    content = f.read()\\\\n\\\",\\n+    \\\"                artifact_meta.append({\\\\n\\\",\\n+    \\\"                    \\\\\\\"path\\\\\\\":    rel_path,\\\\n\\\",\\n+    \\\"                    \\\\\\\"type\\\\\\\":    \\\\\\\"text\\\\\\\",\\\\n\\\",\\n+    \\\"                    \\\\\\\"content\\\\\\\": content\\\\n\\\",\\n+    \\\"                })\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"            # 2) Images \\u2192 surface a clickable URI\\\\n\\\",\\n+    \\\"            elif lower.endswith((\\\\\\\".png\\\\\\\", \\\\\\\".jpg\\\\\\\", \\\\\\\".jpeg\\\\\\\", \\\\\\\".svg\\\\\\\")):\\\\n\\\",\\n+    \\\"                artifact_meta.append({\\\\n\\\",\\n+    \\\"                    \\\\\\\"path\\\\\\\": rel_path,\\\\n\\\",\\n+    \\\"                    \\\\\\\"type\\\\\\\": \\\\\\\"image\\\\\\\",\\\\n\\\",\\n+    \\\"                    \\\\\\\"uri\\\\\\\":  uri\\\\n\\\",\\n+    \\\"                })\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"            # 3) Everything else \\u2192 just link\\\\n\\\",\\n+    \\\"            else:\\\\n\\\",\\n+    \\\"                artifact_meta.append({\\\\n\\\",\\n+    \\\"                    \\\\\\\"path\\\\\\\": rel_path,\\\\n\\\",\\n+    \\\"                    \\\\\\\"type\\\\\\\": \\\\\\\"other\\\\\\\",\\\\n\\\",\\n+    \\\"                    \\\\\\\"uri\\\\\\\":  uri\\\\n\\\",\\n+    \\\"                })\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    # Run the gather\\\\n\\\",\\n+    \\\"    _gather()\\\\n\\\",\\n+    \\\"     \\\\n\\\",\\n+    \\\"    summary = {\\\\n\\\",\\n+    \\\"        \\\\\\\"run_id\\\\\\\":         run_id,\\\\n\\\",\\n+    \\\"        \\\\\\\"run_name\\\\\\\": run_info.run_name,\\\\n\\\",\\n+    \\\"        \\\\\\\"experiment_id\\\\\\\":  run_info.experiment_id,\\\\n\\\",\\n+    \\\"        \\\\\\\"start_time\\\\\\\":     run_info.start_time,\\\\n\\\",\\n+    \\\"        \\\\\\\"end_time\\\\\\\":       run_info.end_time,\\\\n\\\",\\n+    \\\"        \\\\\\\"params\\\\\\\":         params,\\\\n\\\",\\n+    \\\"        \\\\\\\"metrics\\\\\\\":        metrics,\\\\n\\\",\\n+    \\\"        \\\\\\\"tags\\\\\\\":           tags,\\\\n\\\",\\n+    \\\"        \\\\\\\"artifacts\\\\\\\":      artifact_meta\\\\n\\\",\\n+    \\\"    }\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # 1) Determine notebook directory (where your .ipynb lives)\\\\n\\\",\\n+    \\\"    notebook_dir = os.getcwd()\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    # \\u2705 Create a subdirectory inside MODEL_PROVENANCE for the model\\\\n\\\",\\n+    \\\"    summary_dir = os.path.join(os.getcwd(), \\\\\\\"MODEL_PROVENANCE\\\\\\\", model_name)\\\\n\\\",\\n+    \\\"    os.makedirs(summary_dir, exist_ok=True)\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"   # 2) Pick a filename based on your model_name\\\\n\\\",\\n+    \\\"    summary_filename   = f\\\\\\\"{model_name}_run_summary.json\\\\\\\"\\\\n\\\",\\n+    \\\"    summary_local_path = os.path.join(summary_dir, summary_filename)\\\\n\\\",\\n+    \\\"   # 3) Write the JSON locally\\\\n\\\",\\n+    \\\"    with open(summary_local_path, \\\\\\\"w\\\\\\\", encoding=\\\\\\\"utf-8\\\\\\\") as f:\\\\n\\\",\\n+    \\\"        json.dump(summary, f, indent=2)\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    # 4) (Optional) Mirror it into MLflow artifacts under a single folder\\\\n\\\",\\n+    \\\"    mlflow.log_artifact(summary_local_path, artifact_path=\\\\\\\"run_summaries\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    mlflow.end_run()\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"d0c4e1b2-9fa9-4606-8128-6ac66b5c6e78\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"what does it create: \\\\n\\\",\\n+    \\\"lable_mapping in the current dir\\\\n\\\",\\n+    \\\"provenence file :REPO/notebooks/RQ_notebooks/MODEL_PROVENANCE/RandomForest_Iris_v20250425_120045_run_summary.json\\\\n\\\",\\n+    \\\"plots based on run:REPO/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_120045/shap_summary.png\\\\n\\\",\\n+    \\\"mlrun:REPO/notebooks/RQ_notebooks/mlrunlogs/mlflow.db/615223710259862608/5d1fa0fc65af47128f3200628b1afaea\\\\n\\\",\\n+    \\\"trained model:REPO/notebooks/RQ_notebooks/Trained_models/RandomForest_Iris_v20250425_120852.pkl\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"7a5e3bbb-0288-47d0-9dc4-2855d7e4801a\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"1. Standards-compliant export (JSON-LD + Turtle)\\\\n\\\",\\n+    \\\"I already have your plain run_summary.json , wrap it in a JSON-LD context that maps your fields into PROV-O terms, then use rdflib to emit Turtle:\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": null,\\n+   \\\"id\\\": \\\"28ed1cfb-930a-4f17-a48f-30e4cffb7f3e\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [],\\n+   \\\"source\\\": [\\n+    \\\"import json\\\\n\\\",\\n+    \\\"import pandas as pd\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# Load the JSON file\\\\n\\\",\\n+    \\\"json_path = \\\\\\\"/mnt/data/REPO/notebooks/RQ_notebooks/MODEL_PROVENANCE/RandomForest_Iris_v20250425_125653/RandomForest_Iris_v20250425_125653_run_summary.json\\\\\\\"\\\\n\\\",\\n+    \\\"with open(json_path, \\\\\\\"r\\\\\\\", encoding=\\\\\\\"utf-8\\\\\\\") as file:\\\\n\\\",\\n+    \\\"    data = json.load(file)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# Extract justification tags\\\\n\\\",\\n+    \\\"justifications = {\\\\n\\\",\\n+    \\\"    k: v for k, v in data.get(\\\\\\\"tags\\\\\\\", {}).items()\\\\n\\\",\\n+    \\\"    if k.startswith(\\\\\\\"justification_\\\\\\\")\\\\n\\\",\\n+    \\\"}\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# Create a DataFrame\\\\n\\\",\\n+    \\\"justification_df = pd.DataFrame([\\\\n\\\",\\n+    \\\"    {\\\\\\\"Decision\\\\\\\": k.replace(\\\\\\\"justification_\\\\\\\", \\\\\\\"\\\\\\\"), \\\\\\\"Justification\\\\\\\": v}\\\\n\\\",\\n+    \\\"    for k, v in justifications.items()\\\\n\\\",\\n+    \\\"])\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"import ace_tools as tools; tools.display_dataframe_to_user(name=\\\\\\\"Researcher Justifications\\\\\\\", dataframe=justification_df)\\\\n\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 66,\\n+   \\\"id\\\": \\\"5cf88da4-69f8-4982-a594-28cf25e4f79a\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"Converted RandomForest_Iris_v20250425_121328_run_summary.json \\u2192 RandomForest_Iris_v20250425_121328.jsonld, RandomForest_Iris_v20250425_121328.ttl\\\\n\\\"\\n+     ]\\n+    }\\n+   ],\\n+   \\\"source\\\": [\\n+    \\\"\\\\n\\\",\\n+    \\\"def iso8601(ms):\\\\n\\\",\\n+    \\\"    \\\\\\\"\\\\\\\"\\\\\\\"Convert milliseconds since epoch to ISO8601 UTC.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\",\\n+    \\\"    return datetime.fromtimestamp(ms / 1000, tz=timezone.utc).isoformat()\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"for json_path in glob.glob(\\\\\\\"MODEL_PROVENANCE/*/*_run_summary.json\\\\\\\"):\\\\n\\\",\\n+    \\\"    basename   = os.path.basename(json_path)\\\\n\\\",\\n+    \\\"    model_name = basename.rsplit(\\\\\\\"_run_summary.json\\\\\\\", 1)[0]\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    with open(json_path, \\\\\\\"r\\\\\\\", encoding=\\\\\\\"utf-8\\\\\\\") as f:\\\\n\\\",\\n+    \\\"        summary = json.load(f)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    #\\u2013\\u2013 Minimal override context: keep all your flat fields as-is,\\\\n\\\",\\n+    \\\"    #\\u2013\\u2013 and only map the actual PROV terms to their IRIs.\\\\n\\\",\\n+    \\\"    ctx = {\\\\n\\\",\\n+    \\\"        # keep these flat\\\\n\\\",\\n+    \\\"        \\\\\\\"run_id\\\\\\\":       { \\\\\\\"@id\\\\\\\": \\\\\\\"run_id\\\\\\\" },\\\\n\\\",\\n+    \\\"        \\\\\\\"run_name\\\\\\\":     { \\\\\\\"@id\\\\\\\": \\\\\\\"run_name\\\\\\\" },\\\\n\\\",\\n+    \\\"        \\\\\\\"experiment_id\\\\\\\":{ \\\\\\\"@id\\\\\\\": \\\\\\\"experiment_id\\\\\\\" },\\\\n\\\",\\n+    \\\"        \\\\\\\"params\\\\\\\":       { \\\\\\\"@id\\\\\\\": \\\\\\\"params\\\\\\\" },\\\\n\\\",\\n+    \\\"        \\\\\\\"metrics\\\\\\\":      { \\\\\\\"@id\\\\\\\": \\\\\\\"metrics\\\\\\\" },\\\\n\\\",\\n+    \\\"        \\\\\\\"artifacts\\\\\\\":    { \\\\\\\"@id\\\\\\\": \\\\\\\"artifacts\\\\\\\" },\\\\n\\\",\\n+    \\\"        \\\\\\\"tags\\\\\\\":         { \\\\\\\"@id\\\\\\\": \\\\\\\"tags\\\\\\\" },\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"        # provenance namespace\\\\n\\\",\\n+    \\\"        \\\\\\\"prov\\\\\\\": \\\\\\\"http://www.w3.org/ns/prov#\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"xsd\\\\\\\":  \\\\\\\"http://www.w3.org/2001/XMLSchema#\\\\\\\",\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"        # map your timestamp fields into PROV\\\\n\\\",\\n+    \\\"        \\\\\\\"start_time\\\\\\\": { \\\\\\\"@id\\\\\\\": \\\\\\\"prov:startedAtTime\\\\\\\", \\\\\\\"@type\\\\\\\": \\\\\\\"xsd:dateTime\\\\\\\" },\\\\n\\\",\\n+    \\\"        \\\\\\\"end_time\\\\\\\":   { \\\\\\\"@id\\\\\\\": \\\\\\\"prov:endedAtTime\\\\\\\",   \\\\\\\"@type\\\\\\\": \\\\\\\"xsd:dateTime\\\\\\\" },\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"        # PROV-used/generated\\\\n\\\",\\n+    \\\"        \\\\\\\"used\\\\\\\":      { \\\\\\\"@id\\\\\\\": \\\\\\\"prov:used\\\\\\\",      \\\\\\\"@type\\\\\\\": \\\\\\\"@id\\\\\\\" },\\\\n\\\",\\n+    \\\"        \\\\\\\"generated\\\\\\\": { \\\\\\\"@id\\\\\\\": \\\\\\\"prov:generated\\\\\\\", \\\\\\\"@type\\\\\\\": \\\\\\\"@id\\\\\\\" },\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"        # JSON-LD boilerplate\\\\n\\\",\\n+    \\\"        \\\\\\\"@id\\\\\\\":   \\\\\\\"@id\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"@type\\\\\\\": \\\\\\\"@type\\\\\\\"\\\\n\\\",\\n+    \\\"    }\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    #\\u2013\\u2013 Build JSON-LD document, re-using your original keys verbatim\\\\n\\\",\\n+    \\\"    doc = {\\\\n\\\",\\n+    \\\"        \\\\\\\"@context\\\\\\\":      ctx,\\\\n\\\",\\n+    \\\"        \\\\\\\"run_id\\\\\\\":        summary[\\\\\\\"run_id\\\\\\\"],\\\\n\\\",\\n+    \\\"        \\\\\\\"run_name\\\\\\\":      summary.get(\\\\\\\"run_name\\\\\\\"),\\\\n\\\",\\n+    \\\"        \\\\\\\"experiment_id\\\\\\\": summary.get(\\\\\\\"experiment_id\\\\\\\"),\\\\n\\\",\\n+    \\\"        \\\\\\\"params\\\\\\\":        summary.get(\\\\\\\"params\\\\\\\", {}),\\\\n\\\",\\n+    \\\"        \\\\\\\"metrics\\\\\\\":       summary.get(\\\\\\\"metrics\\\\\\\", {}),\\\\n\\\",\\n+    \\\"        \\\\\\\"artifacts\\\\\\\":     summary.get(\\\\\\\"artifacts\\\\\\\", []),\\\\n\\\",\\n+    \\\"        \\\\\\\"tags\\\\\\\":          summary.get(\\\\\\\"tags\\\\\\\", {}),\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"        # PROV fields:\\\\n\\\",\\n+    \\\"        \\\\\\\"start_time\\\\\\\": iso8601(summary[\\\\\\\"start_time\\\\\\\"])\\\\n\\\",\\n+    \\\"    }\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    if summary.get(\\\\\\\"end_time\\\\\\\") is not None:\\\\n\\\",\\n+    \\\"        doc[\\\\\\\"end_time\\\\\\\"] = iso8601(summary[\\\\\\\"end_time\\\\\\\"])\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # for used/generated, just point at your dataset/model URIs\\\\n\\\",\\n+    \\\"    # (or blank-node them if you prefer richer structure)\\\\n\\\",\\n+    \\\"    doc[\\\\\\\"used\\\\\\\"] = summary.get(\\\\\\\"tags\\\\\\\", {}).get(\\\\\\\"dataset_uri\\\\\\\") or []\\\\n\\\",\\n+    \\\"    doc[\\\\\\\"generated\\\\\\\"] = [\\\\n\\\",\\n+    \\\"        art.get(\\\\\\\"uri\\\\\\\") or art.get(\\\\\\\"path\\\\\\\")\\\\n\\\",\\n+    \\\"        for art in summary.get(\\\\\\\"artifacts\\\\\\\", [])\\\\n\\\",\\n+    \\\"    ]\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    #\\u2013\\u2013 write JSON-LD\\\\n\\\",\\n+    \\\"    out_jsonld = os.path.join(\\\\\\\"MODEL_PROVENANCE\\\\\\\", model_name, f\\\\\\\"{model_name}.jsonld\\\\\\\")\\\\n\\\",\\n+    \\\"    with open(out_jsonld, \\\\\\\"w\\\\\\\", encoding=\\\\\\\"utf-8\\\\\\\") as f:\\\\n\\\",\\n+    \\\"        json.dump(doc, f, indent=2)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    #\\u2013\\u2013 parse & serialize to Turtle\\\\n\\\",\\n+    \\\"    g = Graph().parse(data=json.dumps(doc), format=\\\\\\\"json-ld\\\\\\\")\\\\n\\\",\\n+    \\\"    out_ttl = os.path.join(\\\\\\\"MODEL_PROVENANCE\\\\\\\", model_name, f\\\\\\\"{model_name}.ttl\\\\\\\")\\\\n\\\",\\n+    \\\"    g.serialize(destination=out_ttl, format=\\\\\\\"turtle\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    print(f\\\\\\\"Converted {basename} \\u2192 {os.path.basename(out_jsonld)}, {os.path.basename(out_ttl)}\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"83d6d524-01da-4f20-8131-0d4a3ac005e2\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"This code programatically, finds diff between generated Json file and created JsonLD and .TTL file to make it easier to understand if there is any discrepency\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 67,\\n+   \\\"id\\\": \\\"77a420c0-230d-41c0-9b63-f3dbbca1e670\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"== JSON-LD vs TTL ==\\\\n\\\",\\n+      \\\"Change summary:\\\\n\\\",\\n+      \\\"type\\\\n\\\",\\n+      \\\"changed    1 \\\\n\\\",\\n+      \\\"\\\\n\\\",\\n+      \\\"First 10 \\u2018changed\\u2019 entries:\\\\n\\\",\\n+      \\\"Top-level adds/removes:\\\\n\\\",\\n+      \\\"Empty DataFrame\\\\n\\\",\\n+      \\\"Columns: [path, type, a, b]\\\\n\\\",\\n+      \\\"Index: []\\\\n\\\",\\n+      \\\"\\\\n\\\",\\n+      \\\"== JSON vs JSON-LD ==\\\\n\\\",\\n+      \\\"Change summary:\\\\n\\\",\\n+      \\\"type\\\\n\\\",\\n+      \\\"added      3\\\\n\\\",\\n+      \\\"removed    1\\\\n\\\",\\n+      \\\"changed    1 \\\\n\\\",\\n+      \\\"\\\\n\\\",\\n+      \\\"First 10 \\u2018changed\\u2019 entries:\\\\n\\\",\\n+      \\\"Top-level adds/removes:\\\\n\\\",\\n+      \\\"Empty DataFrame\\\\n\\\",\\n+      \\\"Columns: [path, type, a, b]\\\\n\\\",\\n+      \\\"Index: []\\\\n\\\"\\n+     ]\\n+    }\\n+   ],\\n+   \\\"source\\\": [\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"def load_as_dict(path):\\\\n\\\",\\n+    \\\"    if path.endswith((\\\\\\\".ttl\\\\\\\", \\\\\\\".turtle\\\\\\\")):\\\\n\\\",\\n+    \\\"        g = Graph()\\\\n\\\",\\n+    \\\"        g.parse(path, format=\\\\\\\"turtle\\\\\\\")\\\\n\\\",\\n+    \\\"        # normalize to JSON-LD dict\\\\n\\\",\\n+    \\\"        return json.loads(g.serialize(format=\\\\\\\"json-ld\\\\\\\", indent=2))\\\\n\\\",\\n+    \\\"    else:\\\\n\\\",\\n+    \\\"        with open(path, encoding=\\\\\\\"utf-8\\\\\\\") as f:\\\\n\\\",\\n+    \\\"            return json.load(f)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"def compare_json(a, b, path=\\\\\\\"\\\\\\\"):\\\\n\\\",\\n+    \\\"    diffs = []\\\\n\\\",\\n+    \\\"    if isinstance(a, dict) and isinstance(b, dict):\\\\n\\\",\\n+    \\\"        all_keys = set(a) | set(b)\\\\n\\\",\\n+    \\\"        for k in all_keys:\\\\n\\\",\\n+    \\\"            new_path = f\\\\\\\"{path}/{k}\\\\\\\" if path else k\\\\n\\\",\\n+    \\\"            if k not in a:\\\\n\\\",\\n+    \\\"                diffs.append({\\\\\\\"path\\\\\\\": new_path, \\\\\\\"type\\\\\\\": \\\\\\\"added\\\\\\\",   \\\\\\\"a\\\\\\\": None,    \\\\\\\"b\\\\\\\": b[k]})\\\\n\\\",\\n+    \\\"            elif k not in b:\\\\n\\\",\\n+    \\\"                diffs.append({\\\\\\\"path\\\\\\\": new_path, \\\\\\\"type\\\\\\\": \\\\\\\"removed\\\\\\\", \\\\\\\"a\\\\\\\": a[k],   \\\\\\\"b\\\\\\\": None})\\\\n\\\",\\n+    \\\"            else:\\\\n\\\",\\n+    \\\"                diffs.extend(compare_json(a[k], b[k], new_path))\\\\n\\\",\\n+    \\\"    elif isinstance(a, list) and isinstance(b, list):\\\\n\\\",\\n+    \\\"        for i, (ia, ib) in enumerate(zip(a, b)):\\\\n\\\",\\n+    \\\"            diffs.extend(compare_json(ia, ib, f\\\\\\\"{path}[{i}]\\\\\\\"))\\\\n\\\",\\n+    \\\"        # handle length mismatches\\\\n\\\",\\n+    \\\"        if len(a) < len(b):\\\\n\\\",\\n+    \\\"            for i in range(len(a), len(b)):\\\\n\\\",\\n+    \\\"                diffs.append({\\\\\\\"path\\\\\\\": f\\\\\\\"{path}[{i}]\\\\\\\", \\\\\\\"type\\\\\\\": \\\\\\\"added\\\\\\\",   \\\\\\\"a\\\\\\\": None,  \\\\\\\"b\\\\\\\": b[i]})\\\\n\\\",\\n+    \\\"        elif len(a) > len(b):\\\\n\\\",\\n+    \\\"            for i in range(len(b), len(a)):\\\\n\\\",\\n+    \\\"                diffs.append({\\\\\\\"path\\\\\\\": f\\\\\\\"{path}[{i}]\\\\\\\", \\\\\\\"type\\\\\\\": \\\\\\\"removed\\\\\\\", \\\\\\\"a\\\\\\\": a[i],  \\\\\\\"b\\\\\\\": None})\\\\n\\\",\\n+    \\\"    else:\\\\n\\\",\\n+    \\\"        if a != b:\\\\n\\\",\\n+    \\\"            diffs.append({\\\\\\\"path\\\\\\\": path, \\\\\\\"type\\\\\\\": \\\\\\\"changed\\\\\\\", \\\\\\\"a\\\\\\\": a, \\\\\\\"b\\\\\\\": b})\\\\n\\\",\\n+    \\\"    return diffs\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# --- Usage example -----------------------------------------------\\\\n\\\",\\n+    \\\"# REPO/notebooks/RQ_notebooks/MODEL_PROVENANCE/RandomForest_Iris_v20250425_121328/RandomForest_Iris_v20250425_121328_run_summary.json\\\\n\\\",\\n+    \\\"# # Compare JSON-LD vs Turtle:\\\\n\\\",\\n+    \\\"# a = load_as_dict(\\\\\\\"MODEL_PROVENANCE/RandomForest_Iris_v20250423_230422_run_summary.json\\\\\\\")\\\\n\\\",\\n+    \\\"# b = load_as_dict(\\\\\\\"MODEL_PROVENANCE/RandomForest_Iris_v20250423_230422.ttl\\\\\\\")\\\\n\\\",\\n+    \\\"# diffs_jsonld_vs_ttl = compare_json(a, b)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# # Compare JSON vs JSON-LD:\\\\n\\\",\\n+    \\\"# c = load_as_dict(\\\\\\\"MODEL_PROVENANCE/RandomForest_Iris_v20250423_230422_run_summary.json\\\\\\\")\\\\n\\\",\\n+    \\\"# d = load_as_dict(\\\\\\\"MODEL_PROVENANCE/RandomForest_Iris_v20250423_230422.jsonld\\\\\\\")\\\\n\\\",\\n+    \\\"# diffs_json_vs_jsonld = compare_json(c, d)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# Define base directory\\\\n\\\",\\n+    \\\"base_dir = os.path.join(\\\\\\\"MODEL_PROVENANCE\\\\\\\", model_name)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# Build full paths for the files to compare\\\\n\\\",\\n+    \\\"summary_json    = os.path.join(base_dir, f\\\\\\\"{model_name}_run_summary.json\\\\\\\")\\\\n\\\",\\n+    \\\"turtle_file     = os.path.join(base_dir, f\\\\\\\"{model_name}.ttl\\\\\\\")\\\\n\\\",\\n+    \\\"jsonld_file     = os.path.join(base_dir, f\\\\\\\"{model_name}.jsonld\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# Load files\\\\n\\\",\\n+    \\\"a = load_as_dict(summary_json)\\\\n\\\",\\n+    \\\"b = load_as_dict(turtle_file)\\\\n\\\",\\n+    \\\"c = load_as_dict(summary_json)\\\\n\\\",\\n+    \\\"d = load_as_dict(jsonld_file)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# Perform comparisons\\\\n\\\",\\n+    \\\"diffs_jsonld_vs_ttl = compare_json(a, b)\\\\n\\\",\\n+    \\\"diffs_json_vs_jsonld = compare_json(c, d)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# Build DataFrames for interactive inspection\\\\n\\\",\\n+    \\\"df1 = pd.DataFrame(diffs_jsonld_vs_ttl)\\\\n\\\",\\n+    \\\"df2 = pd.DataFrame(diffs_json_vs_jsonld)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# --- Summaries & Filtering ---------------------------------------\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"def summarize_and_preview(df, preview_n=10):\\\\n\\\",\\n+    \\\"    print(\\\\\\\"Change summary:\\\\\\\")\\\\n\\\",\\n+    \\\"    print(df['type'].value_counts().to_string(), \\\\\\\"\\\\\\\\n\\\\\\\")\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    print(f\\\\\\\"First {preview_n} \\u2018changed\\u2019 entries:\\\\\\\")\\\\n\\\",\\n+    \\\"    # print(df[df['type']==\\\\\\\"changed\\\\\\\"].head(preview_n).to_string(index=False), \\\\\\\"\\\\\\\\n\\\\\\\")\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    # Top\\u2010level (one slash) adds/removes\\\\n\\\",\\n+    \\\"    top = df[df['path'].str.count(\\\\\\\"/\\\\\\\") == 1]\\\\n\\\",\\n+    \\\"    print(\\\\\\\"Top-level adds/removes:\\\\\\\")\\\\n\\\",\\n+    \\\"    print(top[top['type'].isin(['added','removed'])].to_string(index=False))\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"print(\\\\\\\"== JSON-LD vs TTL ==\\\\\\\")\\\\n\\\",\\n+    \\\"summarize_and_preview(df1)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"print(\\\\\\\"\\\\\\\\n== JSON vs JSON-LD ==\\\\\\\")\\\\n\\\",\\n+    \\\"summarize_and_preview(df2)\\\\n\\\",\\n+    \\\"\\\\n\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 68,\\n+   \\\"id\\\": \\\"41af9d6e-c683-45f9-bac1-296611b4d0b9\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"Removed in JSON-LD comparison:\\\\n\\\",\\n+      \\\"    path\\\\n\\\",\\n+      \\\"end_time\\\\n\\\",\\n+      \\\"\\\\n\\\",\\n+      \\\"Added in JSON-LD comparison:\\\\n\\\",\\n+      \\\"     path\\\\n\\\",\\n+      \\\" @context\\\\n\\\",\\n+      \\\"     used\\\\n\\\",\\n+      \\\"generated\\\\n\\\"\\n+     ]\\n+    }\\n+   ],\\n+   \\\"source\\\": [\\n+    \\\"# show all the removed paths (in JSON but not in JSON-LD)\\\\n\\\",\\n+    \\\"print(\\\\\\\"Removed in JSON-LD comparison:\\\\\\\")\\\\n\\\",\\n+    \\\"print(df2[df2['type']==\\\\\\\"removed\\\\\\\"][['path']].to_string(index=False))\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# show all the added paths (in JSON-LD but not in JSON)\\\\n\\\",\\n+    \\\"print(\\\\\\\"\\\\\\\\nAdded in JSON-LD comparison:\\\\\\\")\\\\n\\\",\\n+    \\\"print(df2[df2['type']==\\\\\\\"added\\\\\\\"][['path']].to_string(index=False))\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 69,\\n+   \\\"id\\\": \\\"f0d6f92a-5cd9-4c78-9c2a-0cd3247137c6\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"Removed in .ttl comparison:\\\\n\\\",\\n+      \\\"Empty DataFrame\\\\n\\\",\\n+      \\\"Columns: [path]\\\\n\\\",\\n+      \\\"Index: []\\\\n\\\",\\n+      \\\"\\\\n\\\",\\n+      \\\"Added in .ttl comparison:\\\\n\\\",\\n+      \\\"Empty DataFrame\\\\n\\\",\\n+      \\\"Columns: [path]\\\\n\\\",\\n+      \\\"Index: []\\\\n\\\"\\n+     ]\\n+    }\\n+   ],\\n+   \\\"source\\\": [\\n+    \\\"# show all the removed paths (in JSON but not in JSON-LD)\\\\n\\\",\\n+    \\\"print(\\\\\\\"Removed in .ttl comparison:\\\\\\\")\\\\n\\\",\\n+    \\\"print(df1[df1['type']==\\\\\\\"removed\\\\\\\"][['path']].to_string(index=False))\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# show all the added paths (in JSON-LD but not in JSON)\\\\n\\\",\\n+    \\\"print(\\\\\\\"\\\\\\\\nAdded in .ttl comparison:\\\\\\\")\\\\n\\\",\\n+    \\\"print(df1[df1['type']==\\\\\\\"added\\\\\\\"][['path']].to_string(index=False))\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"69efd0d0-9277-4efa-88cf-d2fd1b90d74c\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"Checks for completeness and mapping and time taken, needs work #TODO\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 70,\\n+   \\\"id\\\": \\\"165a13eb-7679-4f4c-b346-24f25da72cce\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\\\n\\\",\\n+      \\\"0/0 runs passed completeness checks (0.0%).\\\\n\\\",\\n+      \\\"\\\\n\\\",\\n+      \\\"Mapping integrity: 0/0 runs have zero diffs \\u2014 0.0%\\\\n\\\",\\n+      \\\"Overall quality score: 0.0%\\\\n\\\",\\n+      \\\"\\\\n\\\",\\n+      \\\"Benchmarking train_and_log() overhead:\\\\n\\\",\\n+      \\\"  \\u2022 No MLflow : 0.502s\\\\n\\\",\\n+      \\\"  \\u2022 With MLflow: 0.601s\\\\n\\\"\\n+     ]\\n+    }\\n+   ],\\n+   \\\"source\\\": [\\n+    \\\"\\\\n\\\",\\n+    \\\"# \\u2500\\u2500 User configuration \\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# Which keys must appear in every run_summary.json?\\\\n\\\",\\n+    \\\"REQUIRED_TOPLEVEL = {\\\\n\\\",\\n+    \\\"    \\\\\\\"run_id\\\\\\\", \\\\\\\"start_time\\\\\\\", \\\\\\\"end_time\\\\\\\",\\\\n\\\",\\n+    \\\"    \\\\\\\"params\\\\\\\", \\\\\\\"metrics\\\\\\\", \\\\\\\"tags\\\\\\\", \\\\\\\"artifacts\\\\\\\"\\\\n\\\",\\n+    \\\"}\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# A couple of sub-fields we also want to spot-check:\\\\n\\\",\\n+    \\\"REQUIRED_PARAMS  = {\\\\\\\"random_state\\\\\\\"}\\\\n\\\",\\n+    \\\"REQUIRED_METRICS = {\\\\\\\"accuracy\\\\\\\"}\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"JSON_SUMMARIES = glob.glob(\\\\\\\"MODEL_PROVENANCE/*_run_summary.json\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# \\u2500\\u2500 Helpers \\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"def iso8601(ms):\\\\n\\\",\\n+    \\\"    return datetime.fromtimestamp(ms/1000, tz=timezone.utc).isoformat()\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"def load_json(path):\\\\n\\\",\\n+    \\\"    with open(path, \\\\\\\"r\\\\\\\", encoding=\\\\\\\"utf-8\\\\\\\") as f:\\\\n\\\",\\n+    \\\"        return json.load(f)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"def write_json(path, obj):\\\\n\\\",\\n+    \\\"    with open(path, \\\\\\\"w\\\\\\\", encoding=\\\\\\\"utf-8\\\\\\\") as f:\\\\n\\\",\\n+    \\\"        json.dump(obj, f, indent=2)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"def convert_to_jsonld_and_ttl(summary, basename):\\\\n\\\",\\n+    \\\"    # build @context\\\\n\\\",\\n+    \\\"    ctx = {\\\\n\\\",\\n+    \\\"        \\\\\\\"prov\\\\\\\":    \\\\\\\"http://www.w3.org/ns/prov#\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"xsd\\\\\\\":     \\\\\\\"http://www.w3.org/2001/XMLSchema#\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"run\\\\\\\":     \\\\\\\"prov:Activity\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"start\\\\\\\":   \\\\\\\"prov:startedAtTime\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"end\\\\\\\":     \\\\\\\"prov:endedAtTime\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"used\\\\\\\":    \\\\\\\"prov:used\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"gen\\\\\\\":     \\\\\\\"prov:generated\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"param\\\\\\\":   \\\\\\\"prov:hadParameter\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"metric\\\\\\\":  \\\\\\\"prov:hadQuality\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"entity\\\\\\\":  \\\\\\\"prov:Entity\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"label\\\\\\\":   \\\\\\\"prov:label\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"value\\\\\\\":   \\\\\\\"prov:value\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"version\\\\\\\": \\\\\\\"prov:hadRevision\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"id\\\\\\\":      \\\\\\\"@id\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"type\\\\\\\":    \\\\\\\"@type\\\\\\\"\\\\n\\\",\\n+    \\\"    }\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    jsonld = {\\\\n\\\",\\n+    \\\"        \\\\\\\"@context\\\\\\\": ctx,\\\\n\\\",\\n+    \\\"        \\\\\\\"@id\\\\\\\":      f\\\\\\\"urn:run:{summary['run_id']}\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"@type\\\\\\\":    \\\\\\\"run\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"start\\\\\\\": {\\\\n\\\",\\n+    \\\"            \\\\\\\"@type\\\\\\\":  \\\\\\\"xsd:dateTime\\\\\\\",\\\\n\\\",\\n+    \\\"            \\\\\\\"@value\\\\\\\": iso8601(summary[\\\\\\\"start_time\\\\\\\"])\\\\n\\\",\\n+    \\\"        }\\\\n\\\",\\n+    \\\"    }\\\\n\\\",\\n+    \\\"    if summary.get(\\\\\\\"end_time\\\\\\\") is not None:\\\\n\\\",\\n+    \\\"        jsonld[\\\\\\\"end\\\\\\\"] = {\\\\n\\\",\\n+    \\\"            \\\\\\\"@type\\\\\\\":  \\\\\\\"xsd:dateTime\\\\\\\",\\\\n\\\",\\n+    \\\"            \\\\\\\"@value\\\\\\\": iso8601(summary[\\\\\\\"end_time\\\\\\\"])\\\\n\\\",\\n+    \\\"        }\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # params\\\\n\\\",\\n+    \\\"    jsonld[\\\\\\\"param\\\\\\\"] = [\\\\n\\\",\\n+    \\\"        {\\\\\\\"@type\\\\\\\":\\\\\\\"entity\\\\\\\",\\\\\\\"label\\\\\\\":k,\\\\\\\"value\\\\\\\":str(v)}\\\\n\\\",\\n+    \\\"        for k,v in summary.get(\\\\\\\"params\\\\\\\",{}).items()\\\\n\\\",\\n+    \\\"    ]\\\\n\\\",\\n+    \\\"    # metrics\\\\n\\\",\\n+    \\\"    jsonld[\\\\\\\"metric\\\\\\\"] = [\\\\n\\\",\\n+    \\\"        {\\\\\\\"@type\\\\\\\":\\\\\\\"entity\\\\\\\",\\\\\\\"label\\\\\\\":k,\\\\n\\\",\\n+    \\\"         \\\\\\\"value\\\\\\\":{\\\\\\\"@type\\\\\\\":\\\\\\\"xsd:decimal\\\\\\\",\\\\\\\"@value\\\\\\\":v}}\\\\n\\\",\\n+    \\\"        for k,v in summary.get(\\\\\\\"metrics\\\\\\\",{}).items()\\\\n\\\",\\n+    \\\"    ]\\\\n\\\",\\n+    \\\"    # artifacts\\\\n\\\",\\n+    \\\"    jsonld[\\\\\\\"gen\\\\\\\"] = [\\\\n\\\",\\n+    \\\"        {\\\\n\\\",\\n+    \\\"            \\\\\\\"@type\\\\\\\":\\\\\\\"entity\\\\\\\",\\\\n\\\",\\n+    \\\"            \\\\\\\"label\\\\\\\": art.get(\\\\\\\"path\\\\\\\") or art.get(\\\\\\\"label\\\\\\\"),\\\\n\\\",\\n+    \\\"            \\\\\\\"prov:location\\\\\\\": (\\\\n\\\",\\n+    \\\"                art.get(\\\\\\\"uri\\\\\\\")\\\\n\\\",\\n+    \\\"                or (art.get(\\\\\\\"content\\\\\\\",\\\\\\\"\\\\\\\")[:30]+\\\\\\\"\\u2026\\\\\\\")\\\\n\\\",\\n+    \\\"                if isinstance(art.get(\\\\\\\"content\\\\\\\"),str)\\\\n\\\",\\n+    \\\"                else \\\\\\\"\\\\\\\"\\\\n\\\",\\n+    \\\"            )\\\\n\\\",\\n+    \\\"        }\\\\n\\\",\\n+    \\\"        for art in summary.get(\\\\\\\"artifacts\\\\\\\",[])\\\\n\\\",\\n+    \\\"    ]\\\\n\\\",\\n+    \\\"    # dataset used\\\\n\\\",\\n+    \\\"    jsonld[\\\\\\\"used\\\\\\\"] = {\\\\n\\\",\\n+    \\\"        \\\\\\\"@type\\\\\\\":\\\\\\\"entity\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"label\\\\\\\": summary[\\\\\\\"tags\\\\\\\"].get(\\\\\\\"dataset_name\\\\\\\"),\\\\n\\\",\\n+    \\\"        \\\\\\\"version\\\\\\\": summary[\\\\\\\"tags\\\\\\\"].get(\\\\\\\"dataset_version\\\\\\\")\\\\n\\\",\\n+    \\\"    }\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # write JSON-LD\\\\n\\\",\\n+    \\\"    out_jsonld = f\\\\\\\"MODEL_PROVENANCE/{basename}.jsonld\\\\\\\"\\\\n\\\",\\n+    \\\"    write_json(out_jsonld, jsonld)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # serialize TTL\\\\n\\\",\\n+    \\\"    g = Graph().parse(data=json.dumps(jsonld), format=\\\\\\\"json-ld\\\\\\\")\\\\n\\\",\\n+    \\\"    out_ttl = f\\\\\\\"MODEL_PROVENANCE/{basename}.ttl\\\\\\\"\\\\n\\\",\\n+    \\\"    g.serialize(destination=out_ttl, format=\\\\\\\"turtle\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    return out_jsonld, out_ttl\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"def normalize_jsonld(js):\\\\n\\\",\\n+    \\\"    \\\\\\\"\\\\\\\"\\\\\\\"Simple deep-sort so compare_json doesn\\u2019t trip over ordering.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\",\\n+    \\\"    if isinstance(js, dict):\\\\n\\\",\\n+    \\\"        return {k: normalize_jsonld(js[k]) for k in sorted(js)}\\\\n\\\",\\n+    \\\"    if isinstance(js, list):\\\\n\\\",\\n+    \\\"        return sorted((normalize_jsonld(el) for el in js),\\\\n\\\",\\n+    \\\"                      key=lambda x: json.dumps(x, sort_keys=True))\\\\n\\\",\\n+    \\\"    return js\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"def diff_roundtrip(orig_json, jsonld_path, ttl_path):\\\\n\\\",\\n+    \\\"    orig = load_json(orig_json)\\\\n\\\",\\n+    \\\"    ld   = load_json(jsonld_path)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # parse TTL back to JSON-LD\\\\n\\\",\\n+    \\\"    g = Graph().parse(ttl_path, format=\\\\\\\"turtle\\\\\\\")\\\\n\\\",\\n+    \\\"    ttl_as_ld = json.loads(g.serialize(format=\\\\\\\"json-ld\\\\\\\"))\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # normalize\\\\n\\\",\\n+    \\\"    nl = normalize_jsonld(ld)\\\\n\\\",\\n+    \\\"    nt = normalize_jsonld(ttl_as_ld)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    return {\\\\n\\\",\\n+    \\\"        \\\\\\\"orig_vs_jsonld\\\\\\\":   compare_json(orig, ld),\\\\n\\\",\\n+    \\\"        \\\\\\\"jsonld_vs_ttl_ld\\\\\\\": compare_json(nl, nt)\\\\n\\\",\\n+    \\\"    }\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# \\u2500\\u2500 Main flow \\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"def main():\\\\n\\\",\\n+    \\\"    ok = 0\\\\n\\\",\\n+    \\\"    total = len(JSON_SUMMARIES)\\\\n\\\",\\n+    \\\"    missing_reports = []\\\\n\\\",\\n+    \\\"    cases = {}  # store diff results per run\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    for js_path in JSON_SUMMARIES:\\\\n\\\",\\n+    \\\"        summary = load_json(js_path)\\\\n\\\",\\n+    \\\"        base    = os.path.basename(js_path).split(\\\\\\\"_run_summary.json\\\\\\\")[0]\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"        # 1) completeness check\\\\n\\\",\\n+    \\\"        if not REQUIRED_TOPLEVEL.issubset(summary):\\\\n\\\",\\n+    \\\"            missing = REQUIRED_TOPLEVEL - set(summary)\\\\n\\\",\\n+    \\\"            missing_reports.append((js_path, f\\\\\\\"missing fields {missing}\\\\\\\"))\\\\n\\\",\\n+    \\\"            continue\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"        if not (REQUIRED_PARAMS <= summary[\\\\\\\"params\\\\\\\"].keys()):\\\\n\\\",\\n+    \\\"            missing_reports.append((js_path, f\\\\\\\"params missing {REQUIRED_PARAMS - summary['params'].keys()}\\\\\\\"))\\\\n\\\",\\n+    \\\"            continue\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"        if not (REQUIRED_METRICS <= summary[\\\\\\\"metrics\\\\\\\"].keys()):\\\\n\\\",\\n+    \\\"            missing_reports.append((js_path, f\\\\\\\"metrics missing {REQUIRED_METRICS - summary['metrics'].keys()}\\\\\\\"))\\\\n\\\",\\n+    \\\"            continue\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"        ok += 1\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"        # 2) convert\\\\n\\\",\\n+    \\\"        jsonld_path, ttl_path = convert_to_jsonld_and_ttl(summary, base)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"        # 3) diff\\\\n\\\",\\n+    \\\"        diffs = diff_roundtrip(js_path, jsonld_path, ttl_path)\\\\n\\\",\\n+    \\\"        cases[base] = diffs\\\\n\\\",\\n+    \\\"        print(f\\\\\\\"\\\\\\\\n\\u2500\\u2500 {base} diffs \\u2500\\u2500\\\\\\\")\\\\n\\\",\\n+    \\\"        print(\\\\\\\"  \\u2022 JSON \\u2192 JSON-LD:\\\\\\\", len(diffs[\\\\\\\"orig_vs_jsonld\\\\\\\"]), \\\\\\\"differences\\\\\\\")\\\\n\\\",\\n+    \\\"        print(\\\\\\\"  \\u2022 JSON-LD \\u2192 TTL \\u2192 JSON-LD:\\\\\\\", len(diffs[\\\\\\\"jsonld_vs_ttl_ld\\\\\\\"]), \\\\\\\"differences\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # 4) completeness summary\\\\n\\\",\\n+    \\\"    completeness_pct = (100 * ok / total) if total else 0\\\\n\\\",\\n+    \\\"    print(f\\\\\\\"\\\\\\\\n{ok}/{total} runs passed completeness checks ({completeness_pct:.1f}%).\\\\\\\")\\\\n\\\",\\n+    \\\"    if missing_reports:\\\\n\\\",\\n+    \\\"        print(\\\\\\\"\\\\\\\\nFailures:\\\\\\\")\\\\n\\\",\\n+    \\\"        for path, reason in missing_reports:\\\\n\\\",\\n+    \\\"            print(f\\\\\\\" \\u2022 {path}: {reason}\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # 5) integrity check\\\\n\\\",\\n+    \\\"    total_runs = len(cases)\\\\n\\\",\\n+    \\\"    zero_diff_runs = sum(\\\\n\\\",\\n+    \\\"        1\\\\n\\\",\\n+    \\\"        for diffs in cases.values()\\\\n\\\",\\n+    \\\"        if not diffs[\\\\\\\"orig_vs_jsonld\\\\\\\"] and not diffs[\\\\\\\"jsonld_vs_ttl_ld\\\\\\\"]\\\\n\\\",\\n+    \\\"    )\\\\n\\\",\\n+    \\\"    integrity_pct = (100 * zero_diff_runs / total_runs) if total_runs else 0\\\\n\\\",\\n+    \\\"    print(f\\\\\\\"\\\\\\\\nMapping integrity: {zero_diff_runs}/{total_runs} runs have zero diffs \\u2014 {integrity_pct:.1f}%\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # 6) overall quality score\\\\n\\\",\\n+    \\\"    overall_score = (completeness_pct + integrity_pct) / 2\\\\n\\\",\\n+    \\\"    print(f\\\\\\\"Overall quality score: {overall_score:.1f}%\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # 7) Benchmark your training fn\\\\n\\\",\\n+    \\\"    print(\\\\\\\"\\\\\\\\nBenchmarking train_and_log() overhead:\\\\\\\")\\\\n\\\",\\n+    \\\"    def train_and_log(use_mlflow=False):\\\\n\\\",\\n+    \\\"        # \\u2190 your real instrumentation + fit logic here\\\\n\\\",\\n+    \\\"        time.sleep(0.5 + (0.1 if use_mlflow else 0))  # stub\\\\n\\\",\\n+    \\\"        return\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    for flag in (False, True):\\\\n\\\",\\n+    \\\"        start = time.time()\\\\n\\\",\\n+    \\\"        train_and_log(use_mlflow=flag)\\\\n\\\",\\n+    \\\"        elapsed = time.time() - start\\\\n\\\",\\n+    \\\"        label = \\\\\\\"With MLflow\\\\\\\" if flag else \\\\\\\"No MLflow\\\\\\\"\\\\n\\\",\\n+    \\\"        print(f\\\\\\\"  \\u2022 {label:10s}: {elapsed:.3f}s\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"if __name__ == \\\\\\\"__main__\\\\\\\":\\\\n\\\",\\n+    \\\"    main()\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"5883f673-371e-415e-a73e-5c9c88b56fb1\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"RQ2  implementation\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 72,\\n+   \\\"id\\\": \\\"6d07ac1c-ea80-4787-bcb9-da047d12167d\\\",\\n+   \\\"metadata\\\": {\\n+    \\\"scrolled\\\": true\\n+   },\\n+   \\\"outputs\\\": [\\n+    {\\n+     \\\"data\\\": {\\n+      \\\"text/plain\\\": [\\n+       \\\"Index(['run_id', 'param_bootstrap', 'param_ccp_alpha', 'param_class_weight',\\\\n\\\",\\n+       \\\"       'param_columns_raw', 'param_criterion', 'param_database.description',\\\\n\\\",\\n+       \\\"       'param_database.id', 'param_database.name', 'param_database.owner',\\\\n\\\",\\n+       \\\"       'param_dataset.authors', 'param_dataset.doi', 'param_dataset.published',\\\\n\\\",\\n+       \\\"       'param_dataset.publisher', 'param_dataset.title',\\\\n\\\",\\n+       \\\"       'param_dropped_columns', 'param_feature_names',\\\\n\\\",\\n+       \\\"       'param_matplotlib_version', 'param_max_depth', 'param_max_features',\\\\n\\\",\\n+       \\\"       'param_max_leaf_nodes', 'param_max_samples',\\\\n\\\",\\n+       \\\"       'param_min_impurity_decrease', 'param_min_samples_leaf',\\\\n\\\",\\n+       \\\"       'param_min_samples_split', 'param_min_weight_fraction_leaf',\\\\n\\\",\\n+       \\\"       'param_numpy_version', 'param_n_estimators', 'param_n_features',\\\\n\\\",\\n+       \\\"       'param_n_features_final', 'param_n_jobs', 'param_n_records',\\\\n\\\",\\n+       \\\"       'param_n_test_samples', 'param_n_train_samples', 'param_oob_score',\\\\n\\\",\\n+       \\\"       'param_os_platform', 'param_pandas_version', 'param_python_version',\\\\n\\\",\\n+       \\\"       'param_random_state', 'param_retrieval_time', 'param_seaborn_version',\\\\n\\\",\\n+       \\\"       'param_shap_version', 'param_sklearn_version', 'param_test_size',\\\\n\\\",\\n+       \\\"       'param_verbose', 'param_warm_start', 'metric_accuracy',\\\\n\\\",\\n+       \\\"       'metric_accuracy_score_X_test', 'metric_dbrepo.num_deletes',\\\\n\\\",\\n+       \\\"       'metric_dbrepo.num_inserts', 'metric_dbrepo.row_count_end',\\\\n\\\",\\n+       \\\"       'metric_dbrepo.row_count_start', 'metric_f1_macro',\\\\n\\\",\\n+       \\\"       'metric_f1_score_X_test', 'metric_precision_macro',\\\\n\\\",\\n+       \\\"       'metric_precision_score_X_test', 'metric_recall_macro',\\\\n\\\",\\n+       \\\"       'metric_recall_score_X_test', 'metric_roc_auc',\\\\n\\\",\\n+       \\\"       'metric_roc_auc_score_X_test', 'metric_training_accuracy_score',\\\\n\\\",\\n+       \\\"       'metric_training_f1_score', 'metric_training_log_loss',\\\\n\\\",\\n+       \\\"       'metric_training_precision_score', 'metric_training_recall_score',\\\\n\\\",\\n+       \\\"       'metric_training_roc_auc', 'metric_training_score', 'tag_dataset_id',\\\\n\\\",\\n+       \\\"       'tag_dataset_name', 'tag_dataset_version', 'tag_data_source',\\\\n\\\",\\n+       \\\"       'tag_dbrepo.admin_email', 'tag_dbrepo.base_url',\\\\n\\\",\\n+       \\\"       'tag_dbrepo.granularity', 'tag_dbrepo.protocol_version',\\\\n\\\",\\n+       \\\"       'tag_dbrepo.repository_name', 'tag_dbrepo.table_last_modified',\\\\n\\\",\\n+       \\\"       'tag_estimator_class', 'tag_estimator_name',\\\\n\\\",\\n+       \\\"       'tag_git_current_commit_hash', 'tag_git_previous_commit_hash',\\\\n\\\",\\n+       \\\"       'tag_git__current_commit_url', 'tag_mlflow.log-model.history',\\\\n\\\",\\n+       \\\"       'tag_mlflow.runName', 'tag_mlflow.source.name',\\\\n\\\",\\n+       \\\"       'tag_mlflow.source.type', 'tag_mlflow.user', 'tag_model_name',\\\\n\\\",\\n+       \\\"       'tag_notebook_name', 'tag_target_name', 'tag_training_end_time',\\\\n\\\",\\n+       \\\"       'tag_training_start_time'],\\\\n\\\",\\n+       \\\"      dtype='object')\\\"\\n+      ]\\n+     },\\n+     \\\"execution_count\\\": 72,\\n+     \\\"metadata\\\": {},\\n+     \\\"output_type\\\": \\\"execute_result\\\"\\n+    }\\n+   ],\\n+   \\\"source\\\": [\\n+    \\\"\\\\n\\\",\\n+    \\\"# Load all run summary JSON files\\\\n\\\",\\n+    \\\"files = glob.glob(\\\\\\\"MODEL_PROVENANCE/*/*_run_summary.json\\\\\\\")\\\\n\\\",\\n+    \\\"rows = []\\\\n\\\",\\n+    \\\"for f in files:\\\\n\\\",\\n+    \\\"    with open(f) as fh:\\\\n\\\",\\n+    \\\"        summary = json.load(fh)\\\\n\\\",\\n+    \\\"    # Flatten parameters and metrics\\\\n\\\",\\n+    \\\"    row = {\\\\\\\"run_id\\\\\\\": summary[\\\\\\\"run_id\\\\\\\"]}\\\\n\\\",\\n+    \\\"    row.update({f\\\\\\\"param_{k}\\\\\\\": v for k, v in summary.get(\\\\\\\"params\\\\\\\", {}).items()})\\\\n\\\",\\n+    \\\"    row.update({f\\\\\\\"metric_{k}\\\\\\\": v for k, v in summary.get(\\\\\\\"metrics\\\\\\\", {}).items()})\\\\n\\\",\\n+    \\\"    row.update({f\\\\\\\"tag_{k}\\\\\\\": v for k, v in summary.get(\\\\\\\"tags\\\\\\\", {}).items()})\\\\n\\\",\\n+    \\\"    rows.append(row)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# Create DataFrame\\\\n\\\",\\n+    \\\"df = pd.DataFrame(rows)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# Display the DataFrame\\\\n\\\",\\n+    \\\"df.columns\\\\n\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"ba148da6-6ce5-45cf-a985-f164a53c969b\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"1) Tracing preprocessing steps\\\\n\\\",\\n+    \\\":\\\\n\\\",\\n+    \\\"Here are the top 4 Iris\\u2010focused preprocessing\\u2010tracing use cases I\\u2019d tackle first:\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"Reconstruct a run\\u2019s exact preprocessing\\\\n\\\",\\n+    \\\"Fetch a run\\u2019s run_id, columns_raw, dropped_columns, feature_names and test_size so you can replay the exact data pull & split.\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"Feature\\u2010drop impact analysis\\\\n\\\",\\n+    \\\"Identify runs where one or more measurements (e.g. petalwidthcm) were dropped and compare their test accuracies.\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"Best feature subset discovery\\\\n\\\",\\n+    \\\"Group runs by which features they used (sepals only vs petals only vs both) and rank them by test F1 or accuracy.\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"Common steps in high-accuracy runs\\\\n\\\",\\n+    \\\"Filter for runs with accuracy_score_X_test \\u2265 0.95 and list the shared preprocessing settings (dropped columns, test_size, etc.).\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 73,\\n+   \\\"id\\\": \\\"6e147555-afbf-4bba-b6da-7e90ff391920\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [\\n+    {\\n+     \\\"name\\\": \\\"stderr\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"2025/04/25 12:23:44 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'df84c36b36cc4ebd90a999db3ebc4ad4', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"[{'run_id': '28f01e38b7f04d2f948fe21f57f41d0c', 'param_dataset.title': 'Scikit-Learn Iris', 'param_columns_raw': \\\\\\\"['id', 'sepallengthcm', 'sepalwidthcm', 'petallengthcm', 'petalwidthcm', 'species']\\\\\\\", 'param_dropped_columns': \\\\\\\"['id']\\\\\\\", 'param_feature_names': \\\\\\\"['sepallengthcm', 'sepalwidthcm', 'petallengthcm', 'petalwidthcm']\\\\\\\", 'param_dataset.authors': '[\\\\\\\"Marshall Michael\\\\\\\"]', 'param_dataset.doi': '10.5281/ZENODO.1404173', 'param_dataset.published': '2018-8-27', 'param_test_size': '0.2', 'param_criterion': 'entropy', 'param_max_depth': '12', 'param_max_leaf_nodes': 'None', 'param_max_samples': 'None', 'metric_accuracy': 1.0, 'metric_f1_macro': 1.0, 'metric_roc_auc': 1.0}]\\\\n\\\",\\n+      \\\"[]\\\\n\\\",\\n+      \\\"[{'param_dropped_columns': \\\\\\\"['id']\\\\\\\", 'param_test_size': '0.2', 'param_feature_names': \\\\\\\"['sepallengthcm', 'sepalwidthcm', 'petallengthcm', 'petalwidthcm']\\\\\\\"}]\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"data\\\": {\\n+      \\\"application/vnd.jupyter.widget-view+json\\\": {\\n+       \\\"model_id\\\": \\\"d931b602947d4db8872f254d48e22027\\\",\\n+       \\\"version_major\\\": 2,\\n+       \\\"version_minor\\\": 0\\n+      },\\n+      \\\"text/plain\\\": [\\n+       \\\"Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]\\\"\\n+      ]\\n+     },\\n+     \\\"metadata\\\": {},\\n+     \\\"output_type\\\": \\\"display_data\\\"\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stderr\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"2025/04/25 12:23:52 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '41261519e1a643c5b1335701aee1bf95', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"{'features': ['sepallengthcm', 'sepalwidthcm'], 'accuracy': 0.7666666666666667}\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"data\\\": {\\n+      \\\"application/vnd.jupyter.widget-view+json\\\": {\\n+       \\\"model_id\\\": \\\"83ff1224205a4a8eb0c351a7f299dd93\\\",\\n+       \\\"version_major\\\": 2,\\n+       \\\"version_minor\\\": 0\\n+      },\\n+      \\\"text/plain\\\": [\\n+       \\\"Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]\\\"\\n+      ]\\n+     },\\n+     \\\"metadata\\\": {},\\n+     \\\"output_type\\\": \\\"display_data\\\"\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stderr\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"2025/04/25 12:23:58 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'e0955d231fa6488e9339086b5845064c', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"data\\\": {\\n+      \\\"application/vnd.jupyter.widget-view+json\\\": {\\n+       \\\"model_id\\\": \\\"1eaa6c141e064593b73b6c72ce0b00cf\\\",\\n+       \\\"version_major\\\": 2,\\n+       \\\"version_minor\\\": 0\\n+      },\\n+      \\\"text/plain\\\": [\\n+       \\\"Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]\\\"\\n+      ]\\n+     },\\n+     \\\"metadata\\\": {},\\n+     \\\"output_type\\\": \\\"display_data\\\"\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stderr\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"2025/04/25 12:24:04 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '21d299b426ac42a0ad799604e9e7ff88', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"{'dropped_feature': 'petallengthcm', 'baseline_acc': 1.0, 'dropped_acc': 0.9666666666666667, 'impact': 0.033333333333333326}\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"data\\\": {\\n+      \\\"application/vnd.jupyter.widget-view+json\\\": {\\n+       \\\"model_id\\\": \\\"4c04ce12f62f49a29f48509b1483f16b\\\",\\n+       \\\"version_major\\\": 2,\\n+       \\\"version_minor\\\": 0\\n+      },\\n+      \\\"text/plain\\\": [\\n+       \\\"Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]\\\"\\n+      ]\\n+     },\\n+     \\\"metadata\\\": {},\\n+     \\\"output_type\\\": \\\"display_data\\\"\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stderr\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"2025/04/25 12:24:10 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '8ca4591a1b53402f854187104d1e7ee0', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"data\\\": {\\n+      \\\"application/vnd.jupyter.widget-view+json\\\": {\\n+       \\\"model_id\\\": \\\"66bf06c45648410daa144c12f85658c6\\\",\\n+       \\\"version_major\\\": 2,\\n+       \\\"version_minor\\\": 0\\n+      },\\n+      \\\"text/plain\\\": [\\n+       \\\"Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]\\\"\\n+      ]\\n+     },\\n+     \\\"metadata\\\": {},\\n+     \\\"output_type\\\": \\\"display_data\\\"\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stderr\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"2025/04/25 12:24:16 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '0c8a66e5e4b244f9a6a8e9fa02d26828', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"data\\\": {\\n+      \\\"application/vnd.jupyter.widget-view+json\\\": {\\n+       \\\"model_id\\\": \\\"0d71b6d9b58d4e5a9db241baeaa79d53\\\",\\n+       \\\"version_major\\\": 2,\\n+       \\\"version_minor\\\": 0\\n+      },\\n+      \\\"text/plain\\\": [\\n+       \\\"Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]\\\"\\n+      ]\\n+     },\\n+     \\\"metadata\\\": {},\\n+     \\\"output_type\\\": \\\"display_data\\\"\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stderr\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"2025/04/25 12:24:22 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '53994143a51e481abd23e988be2466b1', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"data\\\": {\\n+      \\\"application/vnd.jupyter.widget-view+json\\\": {\\n+       \\\"model_id\\\": \\\"3fa13db4a66940d59cf37a30cb7a3cbc\\\",\\n+       \\\"version_major\\\": 2,\\n+       \\\"version_minor\\\": 0\\n+      },\\n+      \\\"text/plain\\\": [\\n+       \\\"Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]\\\"\\n+      ]\\n+     },\\n+     \\\"metadata\\\": {},\\n+     \\\"output_type\\\": \\\"display_data\\\"\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stderr\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"2025/04/25 12:24:28 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '35588f1cd8c34ce28770848de714d3c4', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"data\\\": {\\n+      \\\"application/vnd.jupyter.widget-view+json\\\": {\\n+       \\\"model_id\\\": \\\"273c026f2e0b464f98090472792b3a87\\\",\\n+       \\\"version_major\\\": 2,\\n+       \\\"version_minor\\\": 0\\n+      },\\n+      \\\"text/plain\\\": [\\n+       \\\"Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]\\\"\\n+      ]\\n+     },\\n+     \\\"metadata\\\": {},\\n+     \\\"output_type\\\": \\\"display_data\\\"\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"[{'dropped_feature': 'sepallengthcm', 'baseline_acc': 1.0, 'dropped_acc': 1.0, 'impact': 0.0}, {'dropped_feature': 'sepalwidthcm', 'baseline_acc': 1.0, 'dropped_acc': 1.0, 'impact': 0.0}, {'dropped_feature': 'petallengthcm', 'baseline_acc': 1.0, 'dropped_acc': 0.9666666666666667, 'impact': 0.0333}, {'dropped_feature': 'petalwidthcm', 'baseline_acc': 1.0, 'dropped_acc': 0.9666666666666667, 'impact': 0.0333}]\\\\n\\\"\\n+     ]\\n+    }\\n+   ],\\n+   \\\"source\\\": [\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# Helper to get the \\u201cofficial\\u201d feature_names from your summary DF\\\\n\\\",\\n+    \\\"def _get_all_features(df):\\\\n\\\",\\n+    \\\"    # assumes every row has the same param_feature_names\\\\n\\\",\\n+    \\\"    raw = df.loc[0, 'param_feature_names']\\\\n\\\",\\n+    \\\"    return ast.literal_eval(raw)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# Train & eval RF on just these columns of Iris\\\\n\\\",\\n+    \\\"def evaluate_subset(features, test_size=0.2, random_state=42, n_estimators=200):\\\\n\\\",\\n+    \\\"    iris = load_iris()\\\\n\\\",\\n+    \\\"    X = pd.DataFrame(iris.data, columns=iris.feature_names)\\\\n\\\",\\n+    \\\"    # map sklearn\\u2019s names to your param names, e.g. \\\\\\\"sepal length (cm)\\\\\\\" \\u2192 \\\\\\\"sepallengthcm\\\\\\\"\\\\n\\\",\\n+    \\\"    canon = _get_all_features(df)\\\\n\\\",\\n+    \\\"    mapping = dict(zip(iris.feature_names, canon))\\\\n\\\",\\n+    \\\"    X = X.rename(columns=mapping)\\\\n\\\",\\n+    \\\"    X_sub = X[features]\\\\n\\\",\\n+    \\\"    y = iris.target\\\\n\\\",\\n+    \\\"    Xtr, Xte, ytr, yte = train_test_split(X_sub, y, test_size=test_size, random_state=random_state)\\\\n\\\",\\n+    \\\"    m = RandomForestClassifier(n_estimators=n_estimators, random_state=random_state)\\\\n\\\",\\n+    \\\"    m.fit(Xtr, ytr)\\\\n\\\",\\n+    \\\"    return accuracy_score(yte, m.predict(Xte))\\\\n\\\",\\n+    \\\"def trace_preprocessing(df, run_id=None):\\\\n\\\",\\n+    \\\"    cols = ['run_id',\\\\n\\\",\\n+    \\\"            'param_dataset.title',\\\\n\\\",\\n+    \\\"            'param_columns_raw',\\\\n\\\",\\n+    \\\"            'param_dropped_columns',\\\\n\\\",\\n+    \\\"            'param_feature_names',\\\\n\\\",\\n+    \\\"            'param_dataset.authors', 'param_dataset.doi', 'param_dataset.published',\\\\n\\\",\\n+    \\\"            'param_test_size',\\\\n\\\",\\n+    \\\"            'param_criterion',\\\\n\\\",\\n+    \\\"            'param_max_depth','param_max_leaf_nodes', 'param_max_samples',\\\\n\\\",\\n+    \\\"           'metric_accuracy','metric_f1_macro','metric_roc_auc']\\\\n\\\",\\n+    \\\"    if run_id is None:\\\\n\\\",\\n+    \\\"        subset = df.loc[:, cols]\\\\n\\\",\\n+    \\\"    else:\\\\n\\\",\\n+    \\\"        subset = df.loc[df['run_id'] == run_id, cols]\\\\n\\\",\\n+    \\\"    return subset.to_dict(orient='records')\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"def drop_impact(df, feature, **_):\\\\n\\\",\\n+    \\\"    all_feats = _get_all_features(df)\\\\n\\\",\\n+    \\\"    baseline = evaluate_subset(all_feats)\\\\n\\\",\\n+    \\\"    without = [f for f in all_feats if f!=feature]\\\\n\\\",\\n+    \\\"    dropped = evaluate_subset(without)\\\\n\\\",\\n+    \\\"    return {\\\\n\\\",\\n+    \\\"      'dropped_feature': feature,\\\\n\\\",\\n+    \\\"      'baseline_acc': baseline,\\\\n\\\",\\n+    \\\"      'dropped_acc': dropped,\\\\n\\\",\\n+    \\\"      'impact': baseline - dropped\\\\n\\\",\\n+    \\\"    }\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"def drop_impact_all(df: pd.DataFrame) -> List[Dict[str, Any]]:\\\\n\\\",\\n+    \\\"    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\",\\n+    \\\"    Compute drop-impact for every feature in the dataset.\\\\n\\\",\\n+    \\\"    Returns list of dicts with dropped_feature, baseline_acc, dropped_acc, impact.\\\\n\\\",\\n+    \\\"    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\",\\n+    \\\"    feats = _get_all_features(df)\\\\n\\\",\\n+    \\\"    baseline = evaluate_subset(feats)\\\\n\\\",\\n+    \\\"    summary = []\\\\n\\\",\\n+    \\\"    for feat in feats:\\\\n\\\",\\n+    \\\"        without = [f for f in feats if f != feat]\\\\n\\\",\\n+    \\\"        acc = evaluate_subset(without)\\\\n\\\",\\n+    \\\"        summary.append({\\\\n\\\",\\n+    \\\"            'dropped_feature': feat,\\\\n\\\",\\n+    \\\"            'baseline_acc': baseline,\\\\n\\\",\\n+    \\\"            'dropped_acc': acc,\\\\n\\\",\\n+    \\\"            'impact': round(baseline - acc, 4)\\\\n\\\",\\n+    \\\"        })\\\\n\\\",\\n+    \\\"    return summary\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"def best_feature_subset(df, features, **_):\\\\n\\\",\\n+    \\\"    acc = evaluate_subset(features)\\\\n\\\",\\n+    \\\"    return {'features': features, 'accuracy': acc}\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"def common_high_accuracy(df: pd.DataFrame, threshold: float = 0.95) -> List[Dict[str, Any]]:\\\\n\\\",\\n+    \\\"    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\",\\n+    \\\"    Filter runs with test accuracy >= threshold and list unique shared preprocessing settings.\\\\n\\\",\\n+    \\\"    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\",\\n+    \\\"    high = df[df['metric_accuracy_score_X_test'] >= threshold]\\\\n\\\",\\n+    \\\"    cols = ['param_dropped_columns', 'param_test_size', 'param_feature_names']\\\\n\\\",\\n+    \\\"    return high[cols].drop_duplicates().to_dict(orient='records')\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# --------------------------------------------\\\\n\\\",\\n+    \\\"# Use Case Registry with parameter order for minimal input\\\\n\\\",\\n+    \\\"# --------------------------------------------\\\\n\\\",\\n+    \\\"USE_CASES = {\\\\n\\\",\\n+    \\\"    'trace_preprocessing': {\\\\n\\\",\\n+    \\\"        'func': trace_preprocessing,\\\\n\\\",\\n+    \\\"        'required_params': [],            # none strictly required\\\\n\\\",\\n+    \\\"        'optional_params': ['run_id'],    # run_id can be supplied or not\\\\n\\\",\\n+    \\\"    },\\\\n\\\",\\n+    \\\"    'drop_impact': {\\\\n\\\",\\n+    \\\"        'func': drop_impact,\\\\n\\\",\\n+    \\\"        'required_params': ['feature'],\\\\n\\\",\\n+    \\\"        'optional_params': [],\\\\n\\\",\\n+    \\\"    },\\\\n\\\",\\n+    \\\"     'drop_impact_all': {\\\\n\\\",\\n+    \\\"        'func': drop_impact_all,\\\\n\\\",\\n+    \\\"        'required_params': [],\\\\n\\\",\\n+    \\\"        'optional_params': [],\\\\n\\\",\\n+    \\\"    },\\\\n\\\",\\n+    \\\"    'best_feature_subset': {\\\\n\\\",\\n+    \\\"        'func': best_feature_subset,\\\\n\\\",\\n+    \\\"        'required_params': ['features'],\\\\n\\\",\\n+    \\\"        'optional_params': [],\\\\n\\\",\\n+    \\\"    },\\\\n\\\",\\n+    \\\"    'common_high_accuracy': {\\\\n\\\",\\n+    \\\"        'func': common_high_accuracy,\\\\n\\\",\\n+    \\\"        'required_params': ['threshold'],\\\\n\\\",\\n+    \\\"        'optional_params': [],\\\\n\\\",\\n+    \\\"    },\\\\n\\\",\\n+    \\\"}\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"def call_use_case(df, use_case_name, **kwargs):\\\\n\\\",\\n+    \\\"    if use_case_name not in USE_CASES:\\\\n\\\",\\n+    \\\"        raise ValueError(f\\\\\\\"Unknown use case: {use_case_name}\\\\\\\")\\\\n\\\",\\n+    \\\"    case = USE_CASES[use_case_name]\\\\n\\\",\\n+    \\\"    func = case['func']\\\\n\\\",\\n+    \\\"    # check required\\\\n\\\",\\n+    \\\"    missing = [p for p in case['required_params'] if p not in kwargs]\\\\n\\\",\\n+    \\\"    if missing:\\\\n\\\",\\n+    \\\"        raise ValueError(f\\\\\\\"{use_case_name} missing required params: {missing}\\\\\\\")\\\\n\\\",\\n+    \\\"    # build args\\\\n\\\",\\n+    \\\"    args = {p: kwargs[p] for p in case['required_params']}\\\\n\\\",\\n+    \\\"    for p in case['optional_params']:\\\\n\\\",\\n+    \\\"        args[p] = kwargs.get(p)\\\\n\\\",\\n+    \\\"    return func(df, **args)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# --------------------------------------------\\\\n\\\",\\n+    \\\"# Example Usage\\\\n\\\",\\n+    \\\"# --------------------------------------------\\\\n\\\",\\n+    \\\"if __name__ == '__main__':\\\\n\\\",\\n+    \\\"   # # 1) trace_preprocessing for all runs\\\\n\\\",\\n+    \\\"    print(call_use_case(df, 'trace_preprocessing'))\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    # 2) trace_preprocessing for a single run_id\\\\n\\\",\\n+    \\\"    print(call_use_case(df, 'trace_preprocessing', run_id='361daa12f99f4129a06cd20b78dd6fa7'))\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # 5) common_high_accuracy\\\\n\\\",\\n+    \\\"    print(call_use_case(df, 'common_high_accuracy', threshold=0.99))\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # 4) Best\\u2010subset on just sepals:\\\\n\\\",\\n+    \\\"    print(call_use_case(df, 'best_feature_subset', features=['sepallengthcm','sepalwidthcm']))\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # 3) Drop\\u2010impact for \\u201cpetallengthcm\\u201d:\\\\n\\\",\\n+    \\\"    print(call_use_case(df, 'drop_impact', feature='petallengthcm'))\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    print(call_use_case(df, 'drop_impact_all'))  # summary for all features\\\\n\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"96f912d6-0e84-4155-858a-9668bef63f6e\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\" \\u2022 Detecting models trained with deprecated code versions\\\\n\\\",\\n+    \\\" \\u2022 Mapping models to specific datasets used during training\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 74,\\n+   \\\"id\\\": \\\"34a02c9a-5459-478f-a3c5-7f7a58ff22b0\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"[{'param_dataset.doi': '10.5281/ZENODO.1404173',\\\\n\\\",\\n+      \\\"  'param_dataset.published': '2018-8-27',\\\\n\\\",\\n+      \\\"  'param_dataset.publisher': 'Zenodo',\\\\n\\\",\\n+      \\\"  'param_dataset.title': 'Scikit-Learn Iris',\\\\n\\\",\\n+      \\\"  'run_id': '28f01e38b7f04d2f948fe21f57f41d0c',\\\\n\\\",\\n+      \\\"  'tag_model_name': 'RandomForest_Iris_v20250425_121328'}]\\\\n\\\"\\n+     ]\\n+    }\\n+   ],\\n+   \\\"source\\\": [\\n+    \\\"\\\\n\\\",\\n+    \\\"def detect_deprecated_code(df: pd.DataFrame, deprecated_commits: List[str], **_) -> List[Dict[str, Any]]:\\\\n\\\",\\n+    \\\"    # we know the column is called tag_git_current_commit_hash\\\\n\\\",\\n+    \\\"    commit_col = 'tag_git_current_commit_hash'\\\\n\\\",\\n+    \\\"    if commit_col not in df.columns:\\\\n\\\",\\n+    \\\"        raise KeyError(f\\\\\\\"Missing {commit_col} in DataFrame\\\\\\\")\\\\n\\\",\\n+    \\\"    out = df[df[commit_col].isin(deprecated_commits)]\\\\n\\\",\\n+    \\\"    # include run_id and notebook/runName for context\\\\n\\\",\\n+    \\\"    cols = ['run_id', commit_col, 'tag_notebook_name', 'tag_mlflow.runName']\\\\n\\\",\\n+    \\\"    # drop any that don\\u2019t exist\\\\n\\\",\\n+    \\\"    cols = [c for c in cols if c in df.columns]\\\\n\\\",\\n+    \\\"    return out[cols].to_dict(orient='records')\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"def map_model_dataset(df: pd.DataFrame, **_) -> List[Dict[str, Any]]:\\\\n\\\",\\n+    \\\"    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\",\\n+    \\\"    For each run, return its model name (or run_id) alongside the dataset\\\\n\\\",\\n+    \\\"    title, DOI, published date and publisher.\\\\n\\\",\\n+    \\\"    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\",\\n+    \\\"    # pick whichever model-name column you have\\\\n\\\",\\n+    \\\"    model_col = 'tag_model_name' if 'tag_model_name' in df.columns else 'param_model_name'\\\\n\\\",\\n+    \\\"    cols = [\\\\n\\\",\\n+    \\\"        'run_id',\\\\n\\\",\\n+    \\\"        model_col,\\\\n\\\",\\n+    \\\"        'param_dataset.title',\\\\n\\\",\\n+    \\\"        'param_dataset.doi',\\\\n\\\",\\n+    \\\"        'param_dataset.published',\\\\n\\\",\\n+    \\\"        'param_dataset.publisher'\\\\n\\\",\\n+    \\\"    ]\\\\n\\\",\\n+    \\\"    # filter out any columns that don\\u2019t actually exist\\\\n\\\",\\n+    \\\"    cols = [c for c in cols if c in df.columns]\\\\n\\\",\\n+    \\\"    return df[cols].to_dict(orient='records')\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# --------------------------------------------\\\\n\\\",\\n+    \\\"# Extend Use-Case Registry\\\\n\\\",\\n+    \\\"# --------------------------------------------\\\\n\\\",\\n+    \\\"USE_CASES.update({\\\\n\\\",\\n+    \\\"    'detect_deprecated_code': {\\\\n\\\",\\n+    \\\"        'func': detect_deprecated_code,\\\\n\\\",\\n+    \\\"        'required_params': ['deprecated_commits'],\\\\n\\\",\\n+    \\\"        'optional_params': []\\\\n\\\",\\n+    \\\"    },\\\\n\\\",\\n+    \\\"    'map_model_dataset': {\\\\n\\\",\\n+    \\\"        'func': map_model_dataset,\\\\n\\\",\\n+    \\\"        'required_params': [],\\\\n\\\",\\n+    \\\"        'optional_params': []\\\\n\\\",\\n+    \\\"    },\\\\n\\\",\\n+    \\\"})\\\\n\\\",\\n+    \\\"# 1) Detect runs on deprecated commits:\\\\n\\\",\\n+    \\\"deprecated = [\\\\n\\\",\\n+    \\\"    \\\\\\\"a07434af4f547af2daab044d6873eb7081162293\\\\\\\",\\\\n\\\",\\n+    \\\"    \\\\\\\"d329c92495e196ec0f39fbb19dfdd367131a77d9\\\\\\\"\\\\n\\\",\\n+    \\\"]\\\\n\\\",\\n+    \\\"# print(call_use_case(df, \\\\\\\"detect_deprecated_code\\\\\\\", deprecated_commits=deprecated))\\\\n\\\",\\n+    \\\"pprint(call_use_case(df, 'map_model_dataset'))\\\\n\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"c52607ad-5849-4a2d-97ef-e8fc1ca16dc7\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"Goal: Notify collaborators who have forked the GitHub repo if their fork is outdated (i.e., behind the current commit used to train a model).\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"f29c8ad9-00bb-4c1e-ac3b-ee6861991acd\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"\\ud83e\\udde0 What We Need\\\\n\\\",\\n+    \\\"Current training run\\u2019s Git commit hash\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"GitHub API to fetch all forks of your repo\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"Compare each fork\\u2019s main or master branch head commit\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"Create an issue on their fork or on your repo tagging them if they\\u2019re behind\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"c72bed50-fb56-442d-a21e-bb7991892d07\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\": Notify via issues on your own repo\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 75,\\n+   \\\"id\\\": \\\"852f147c-9d0a-4d7f-a4ab-545d1e2375fb\\\",\\n+   \\\"metadata\\\": {\\n+    \\\"scrolled\\\": true\\n+   },\\n+   \\\"outputs\\\": [\\n+    {\\n+     \\\"name\\\": \\\"stdin\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"Do you want to notify collaborators whose forks are behind? (y/N):  N\\\\n\\\"\\n+     ]\\n+    },\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"No action taken.\\\\n\\\"\\n+     ]\\n+    }\\n+   ],\\n+   \\\"source\\\": [\\n+    \\\"def notify_outdated_forks():\\\\n\\\",\\n+    \\\"    load_dotenv()\\\\n\\\",\\n+    \\\"    token     = os.getenv(\\\\\\\"THESIS_TOKEN\\\\\\\")\\\\n\\\",\\n+    \\\"    owner     = \\\\\\\"reema-dass26\\\\\\\"\\\\n\\\",\\n+    \\\"    repo      = \\\\\\\"REPO\\\\\\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    if not token:\\\\n\\\",\\n+    \\\"        print(\\\\\\\"\\u26a0\\ufe0f GITHUB_TOKEN not set.\\\\\\\")\\\\n\\\",\\n+    \\\"        return\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    headers = {\\\\n\\\",\\n+    \\\"        \\\\\\\"Authorization\\\\\\\": f\\\\\\\"token {token}\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"Accept\\\\\\\":        \\\\\\\"application/vnd.github.v3+json\\\\\\\"\\\\n\\\",\\n+    \\\"    }\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # 1) Get latest upstream commit\\\\n\\\",\\n+    \\\"    main_commits = requests.get(\\\\n\\\",\\n+    \\\"        f\\\\\\\"https://api.github.com/repos/{owner}/{repo}/commits\\\\\\\",\\\\n\\\",\\n+    \\\"        headers=headers,\\\\n\\\",\\n+    \\\"        params={\\\\\\\"per_page\\\\\\\": 1}\\\\n\\\",\\n+    \\\"    )\\\\n\\\",\\n+    \\\"    main_commits.raise_for_status()\\\\n\\\",\\n+    \\\"    new_commit_hash = main_commits.json()[0][\\\\\\\"sha\\\\\\\"]\\\\n\\\",\\n+    \\\"    print(f\\\\\\\"Latest upstream commit: {new_commit_hash}\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # 2) List forks\\\\n\\\",\\n+    \\\"    forks_resp = requests.get(f\\\\\\\"https://api.github.com/repos/{owner}/{repo}/forks\\\\\\\", headers=headers)\\\\n\\\",\\n+    \\\"    forks_resp.raise_for_status()\\\\n\\\",\\n+    \\\"    forks = forks_resp.json()\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # 3) Compare each fork\\\\n\\\",\\n+    \\\"    outdated = []\\\\n\\\",\\n+    \\\"    for fork in forks:\\\\n\\\",\\n+    \\\"        fork_owner = fork[\\\\\\\"owner\\\\\\\"][\\\\\\\"login\\\\\\\"]\\\\n\\\",\\n+    \\\"        fork_comm = requests.get(\\\\n\\\",\\n+    \\\"            fork[\\\\\\\"url\\\\\\\"] + \\\\\\\"/commits\\\\\\\",\\\\n\\\",\\n+    \\\"            headers=headers,\\\\n\\\",\\n+    \\\"            params={\\\\\\\"per_page\\\\\\\": 1}\\\\n\\\",\\n+    \\\"        )\\\\n\\\",\\n+    \\\"        if fork_comm.status_code != 200:\\\\n\\\",\\n+    \\\"            print(f\\\\\\\"\\u00a0\\u00a0\\u2013 could not fetch commits for {fork_owner}, skipping.\\\\\\\")\\\\n\\\",\\n+    \\\"            continue\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"        fork_sha = fork_comm.json()[0][\\\\\\\"sha\\\\\\\"]\\\\n\\\",\\n+    \\\"        if fork_sha != new_commit_hash:\\\\n\\\",\\n+    \\\"            outdated.append(f\\\\\\\"@{fork_owner}\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # 4) Open an issue if any are behind\\\\n\\\",\\n+    \\\"    if outdated:\\\\n\\\",\\n+    \\\"        title = \\\\\\\"\\ud83d\\udd14 Notification: Your fork is behind the latest commit\\\\\\\"\\\\n\\\",\\n+    \\\"        body  = (\\\\n\\\",\\n+    \\\"            f\\\\\\\"Hi {' '.join(outdated)},\\\\\\\\n\\\\\\\\n\\\\\\\"\\\\n\\\",\\n+    \\\"            f\\\\\\\"The main repository has been updated to commit `{new_commit_hash}`.\\\\\\\\n\\\\\\\"\\\\n\\\",\\n+    \\\"            \\\\\\\"Please consider pulling the latest changes to stay in sync.\\\\\\\\n\\\\\\\\n\\\\\\\"\\\\n\\\",\\n+    \\\"            \\\\\\\"Thanks!\\\\\\\"\\\\n\\\",\\n+    \\\"        )\\\\n\\\",\\n+    \\\"        issues_url = f\\\\\\\"https://api.github.com/repos/{owner}/{repo}/issues\\\\\\\"\\\\n\\\",\\n+    \\\"        resp = requests.post(\\\\n\\\",\\n+    \\\"        issues_url,\\\\n\\\",\\n+    \\\"        headers=headers,\\\\n\\\",\\n+    \\\"        json={\\\\\\\"title\\\\\\\": title, \\\\\\\"body\\\\\\\": body}\\\\n\\\",\\n+    \\\"    )\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # DEBUGGING OUTPUT\\\\n\\\",\\n+    \\\"    print(f\\\\\\\"\\u2192 POST {issues_url}\\\\\\\")\\\\n\\\",\\n+    \\\"    print(\\\\\\\"\\u2192 Status code:\\\\\\\", resp.status_code)\\\\n\\\",\\n+    \\\"    print(\\\\\\\"\\u2192 Response headers:\\\\\\\", resp.headers)\\\\n\\\",\\n+    \\\"    try:\\\\n\\\",\\n+    \\\"        data = resp.json()\\\\n\\\",\\n+    \\\"        print(\\\\\\\"\\u2192 Response JSON:\\\\\\\", data)\\\\n\\\",\\n+    \\\"        print(\\\\\\\"\\u2192 html_url field:\\\\\\\", data.get(\\\\\\\"html_url\\\\\\\"))\\\\n\\\",\\n+    \\\"    except ValueError:\\\\n\\\",\\n+    \\\"        print(\\\\\\\"\\u2192 No JSON response body; raw text:\\\\\\\", resp.text)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"if __name__ == \\\\\\\"__main__\\\\\\\":\\\\n\\\",\\n+    \\\"    answer = input(\\\\\\\"Do you want to notify collaborators whose forks are behind? (y/N): \\\\\\\").strip().lower()\\\\n\\\",\\n+    \\\"    if answer in (\\\\\\\"y\\\\\\\", \\\\\\\"yes\\\\\\\"):\\\\n\\\",\\n+    \\\"        notify_outdated_forks()\\\\n\\\",\\n+    \\\"    else:\\\\n\\\",\\n+    \\\"        print(\\\\\\\"No action taken.\\\\\\\")\\\\n\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"cda31f16-fbe9-40ce-ac1b-9ebc898c8820\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"INVENIO INTEGRETION to upload the necessary files and publish\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": null,\\n+   \\\"id\\\": \\\"c2e5a7fc-3b03-45c8-bc90-817ea5ba7352\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [],\\n+   \\\"source\\\": [\\n+    \\\"############################################################################################\\\\n\\\",\\n+    \\\"# TEST CODE FOR INVENIO INTEGRETION\\\\n\\\",\\n+    \\\"#############################################################################################\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# API_BASE = \\\\\\\"https://127.0.0.1:5000\\\\\\\"\\\\n\\\",\\n+    \\\"# TOKEN    = \\\\\\\"8LnqJuz3TsBHffnDJ3isPLHYHtRbWrC0M667Nb5haEbnXpWqGbFRyfDApymr\\\\\\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# # 1) Test read\\u2010scope by listing records (no size param or size=1)\\\\n\\\",\\n+    \\\"# resp = requests.get(\\\\n\\\",\\n+    \\\"#     f\\\\\\\"{API_BASE}/api/records\\\\\\\",\\\\n\\\",\\n+    \\\"#     headers={\\\\\\\"Authorization\\\\\\\": f\\\\\\\"Bearer {TOKEN}\\\\\\\"},\\\\n\\\",\\n+    \\\"#     verify=False\\\\n\\\",\\n+    \\\"# )\\\\n\\\",\\n+    \\\"# print(resp.status_code)\\\\n\\\",\\n+    \\\"# # should be 200 and a JSON page of records\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# # or explicitly:\\\\n\\\",\\n+    \\\"# resp = requests.get(\\\\n\\\",\\n+    \\\"#     f\\\\\\\"{API_BASE}/api/records?size=1\\\\\\\",\\\\n\\\",\\n+    \\\"#     headers={\\\\\\\"Authorization\\\\\\\": f\\\\\\\"Bearer {TOKEN}\\\\\\\"},\\\\n\\\",\\n+    \\\"#     verify=False\\\\n\\\",\\n+    \\\"# )\\\\n\\\",\\n+    \\\"# print(resp.status_code, resp.json())\\\\n\\\",\\n+    \\\"# #################################################################################################\\\\n\\\",\\n+    \\\"# API_BASE = \\\\\\\"https://127.0.0.1:5000\\\\\\\"\\\\n\\\",\\n+    \\\"# TOKEN    = \\\\\\\"8LnqJuz3TsBHffnDJ3isPLHYHtRbWrC0M667Nb5haEbnXpWqGbFRyfDApymr\\\\\\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# resp = requests.options(\\\\n\\\",\\n+    \\\"#     f\\\\\\\"{API_BASE}/api/records\\\\\\\",\\\\n\\\",\\n+    \\\"#     headers={\\\\\\\"Authorization\\\\\\\": f\\\\\\\"Bearer {TOKEN}\\\\\\\"},\\\\n\\\",\\n+    \\\"#     verify=False\\\\n\\\",\\n+    \\\"# )\\\\n\\\",\\n+    \\\"# print(\\\\\\\"Allowed methods:\\\\\\\", resp.headers.get(\\\\\\\"Allow\\\\\\\"))\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": null,\\n+   \\\"id\\\": \\\"7e5b2cc5-ecf3-4e13-8cac-47f57f12cbdd\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [],\\n+   \\\"source\\\": [\\n+    \\\"\\\\n\\\",\\n+    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n+    \\\"# Configuration\\\\n\\\",\\n+    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n+    \\\"API_BASE   = \\\\\\\"https://127.0.0.1:5000\\\\\\\"\\\\n\\\",\\n+    \\\"TOKEN      = \\\\\\\"8LnqJuz3TsBHffnDJ3isPLHYHtRbWrC0M667Nb5haEbnXpWqGbFRyfDApymr\\\\\\\"\\\\n\\\",\\n+    \\\"VERIFY_SSL = False  # only for self\\u2010signed dev\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"HEADERS_JSON = {\\\\n\\\",\\n+    \\\"    \\\\\\\"Accept\\\\\\\":        \\\\\\\"application/json\\\\\\\",\\\\n\\\",\\n+    \\\"    \\\\\\\"Content-Type\\\\\\\":  \\\\\\\"application/json\\\\\\\",\\\\n\\\",\\n+    \\\"    \\\\\\\"Authorization\\\\\\\": f\\\\\\\"Bearer {TOKEN}\\\\\\\",\\\\n\\\",\\n+    \\\"}\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"HEADERS_OCTET = {\\\\n\\\",\\n+    \\\"    \\\\\\\"Content-Type\\\\\\\":  \\\\\\\"application/octet-stream\\\\\\\",\\\\n\\\",\\n+    \\\"    \\\\\\\"Authorization\\\\\\\": f\\\\\\\"Bearer {TOKEN}\\\\\\\",\\\\n\\\",\\n+    \\\"}\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# The folders you want to walk & upload:\\\\n\\\",\\n+    \\\"TO_UPLOAD = [\\\\\\\"Trained_models\\\\\\\", \\\\\\\"plots\\\\\\\", \\\\\\\"MODEL_PROVENANCE\\\\\\\"]\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n+    \\\"# 1) Create draft with ALL required metadata\\\\n\\\",\\n+    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n+    \\\"def create_draft():\\\\n\\\",\\n+    \\\"    payload = {\\\\n\\\",\\n+    \\\"  \\\\\\\"metadata\\\\\\\": {\\\\n\\\",\\n+    \\\"    \\\\\\\"title\\\\\\\":            \\\\\\\"RandomForest Iris Model Artifacts\\\\\\\",\\\\n\\\",\\n+    \\\"    \\\\\\\"creators\\\\\\\": [ {\\\\n\\\",\\n+    \\\"      \\\\\\\"person_or_org\\\\\\\": {\\\\n\\\",\\n+    \\\"        \\\\\\\"type\\\\\\\":        \\\\\\\"personal\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"given_name\\\\\\\":  \\\\\\\"Reema\\\\\\\",\\\\n\\\",\\n+    \\\"        \\\\\\\"family_name\\\\\\\": \\\\\\\"Dass\\\\\\\"\\\\n\\\",\\n+    \\\"      }\\\\n\\\",\\n+    \\\"    } ],\\\\n\\\",\\n+    \\\"    \\\\\\\"publication_date\\\\\\\": \\\\\\\"2025-04-24\\\\\\\",\\\\n\\\",\\n+    \\\"    \\\\\\\"resource_type\\\\\\\":    { \\\\\\\"id\\\\\\\": \\\\\\\"software\\\\\\\" },\\\\n\\\",\\n+    \\\"    \\\\\\\"access\\\\\\\": {\\\\n\\\",\\n+    \\\"      \\\\\\\"record\\\\\\\": \\\\\\\"public\\\\\\\",\\\\n\\\",\\n+    \\\"      \\\\\\\"files\\\\\\\":  \\\\\\\"public\\\\\\\"\\\\n\\\",\\n+    \\\"    }\\\\n\\\",\\n+    \\\"  }\\\\n\\\",\\n+    \\\"}\\\\n\\\",\\n+    \\\"    r = requests.post(f\\\\\\\"{API_BASE}/api/records\\\\\\\",\\\\n\\\",\\n+    \\\"                      headers=HEADERS_JSON,\\\\n\\\",\\n+    \\\"                      json=payload,\\\\n\\\",\\n+    \\\"                      verify=VERIFY_SSL)\\\\n\\\",\\n+    \\\"    r.raise_for_status()\\\\n\\\",\\n+    \\\"    draft = r.json()\\\\n\\\",\\n+    \\\"    print(\\\\\\\"\\u2705 Draft created:\\\\\\\", draft[\\\\\\\"id\\\\\\\"])\\\\n\\\",\\n+    \\\"    return draft[\\\\\\\"id\\\\\\\"], draft[\\\\\\\"links\\\\\\\"]\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n+    \\\"# 2) Register, upload and commit a single file\\\\n\\\",\\n+    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n+    \\\"def upload_and_commit(links, key, path):\\\\n\\\",\\n+    \\\"    # 2a) register the filename in the draft\\\\n\\\",\\n+    \\\"    r1 = requests.post(links[\\\\\\\"files\\\\\\\"],\\\\n\\\",\\n+    \\\"                       headers=HEADERS_JSON,\\\\n\\\",\\n+    \\\"                       json=[{\\\\\\\"key\\\\\\\": key}],\\\\n\\\",\\n+    \\\"                       verify=VERIFY_SSL)\\\\n\\\",\\n+    \\\"    r1.raise_for_status()\\\\n\\\",\\n+    \\\"    entry = next(e for e in r1.json()[\\\\\\\"entries\\\\\\\"] if e[\\\\\\\"key\\\\\\\"] == key)\\\\n\\\",\\n+    \\\"    file_links = entry[\\\\\\\"links\\\\\\\"]\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # 2b) upload the bytes\\\\n\\\",\\n+    \\\"    with open(path, \\\\\\\"rb\\\\\\\") as fp:\\\\n\\\",\\n+    \\\"        r2 = requests.put(file_links[\\\\\\\"content\\\\\\\"],\\\\n\\\",\\n+    \\\"                          headers=HEADERS_OCTET,\\\\n\\\",\\n+    \\\"                          data=fp,\\\\n\\\",\\n+    \\\"                          verify=VERIFY_SSL)\\\\n\\\",\\n+    \\\"    r2.raise_for_status()\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # 2c) commit the upload\\\\n\\\",\\n+    \\\"    r3 = requests.post(file_links[\\\\\\\"commit\\\\\\\"],\\\\n\\\",\\n+    \\\"                       headers=HEADERS_JSON,\\\\n\\\",\\n+    \\\"                       verify=VERIFY_SSL)\\\\n\\\",\\n+    \\\"    r3.raise_for_status()\\\\n\\\",\\n+    \\\"    print(f\\\\\\\"  \\u2022 Uploaded {key}\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n+    \\\"# 3) Walk each folder and upload every file\\\\n\\\",\\n+    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n+    \\\"def upload_folder(links):\\\\n\\\",\\n+    \\\"    for folder in TO_UPLOAD:\\\\n\\\",\\n+    \\\"        if not os.path.isdir(folder):\\\\n\\\",\\n+    \\\"            print(f\\\\\\\"\\u26a0\\ufe0f Skipping missing folder {folder}\\\\\\\")\\\\n\\\",\\n+    \\\"            continue\\\\n\\\",\\n+    \\\"        base = os.path.dirname(folder) or folder\\\\n\\\",\\n+    \\\"        for root, _, files in os.walk(folder):\\\\n\\\",\\n+    \\\"            for fn in files:\\\\n\\\",\\n+    \\\"                local = os.path.join(root, fn)\\\\n\\\",\\n+    \\\"                # create a POSIX\\u2010style key preserving subfolders\\\\n\\\",\\n+    \\\"                key = os.path.relpath(local, start=base).replace(os.sep, \\\\\\\"/\\\\\\\")\\\\n\\\",\\n+    \\\"                upload_and_commit(links, key, local)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n+    \\\"# 4) Publish the draft\\\\n\\\",\\n+    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n+    \\\"def publish(links):\\\\n\\\",\\n+    \\\"    r = requests.post(links[\\\\\\\"publish\\\\\\\"],\\\\n\\\",\\n+    \\\"                      headers=HEADERS_JSON,\\\\n\\\",\\n+    \\\"                      verify=VERIFY_SSL)\\\\n\\\",\\n+    \\\"    if not r.ok:\\\\n\\\",\\n+    \\\"        print(\\\\\\\"\\u274c Publish failed:\\\\\\\", r.status_code, r.text)\\\\n\\\",\\n+    \\\"        try: print(r.json())\\\\n\\\",\\n+    \\\"        except: pass\\\\n\\\",\\n+    \\\"        r.raise_for_status()\\\\n\\\",\\n+    \\\"    print(\\\\\\\"\\u2705 Published:\\\\\\\", r.json()[\\\\\\\"id\\\\\\\"])\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n+    \\\"# 5) Fetch metadata and save to a file\\\\n\\\",\\n+    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n+    \\\"def fetch_metadata(record_id):\\\\n\\\",\\n+    \\\"    r = requests.get(f\\\\\\\"{API_BASE}/api/records/{record_id}\\\\\\\",\\\\n\\\",\\n+    \\\"                     headers=HEADERS_JSON,\\\\n\\\",\\n+    \\\"                     verify=VERIFY_SSL)\\\\n\\\",\\n+    \\\"    r.raise_for_status()\\\\n\\\",\\n+    \\\"    metadata = r.json()\\\\n\\\",\\n+    \\\"    print(\\\\\\\"\\u2705 Metadata fetched successfully\\\\\\\")\\\\n\\\",\\n+    \\\"    \\\\n\\\",\\n+    \\\"    # Save the metadata to a file\\\\n\\\",\\n+    \\\"    with open(f\\\\\\\"metadata_{record_id}.json\\\\\\\", \\\\\\\"w\\\\\\\") as f:\\\\n\\\",\\n+    \\\"        json.dump(metadata, f, indent=4)\\\\n\\\",\\n+    \\\"    print(f\\\\\\\"\\u2705 Metadata saved as metadata_{record_id}.json\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n+    \\\"# Main\\\\n\\\",\\n+    \\\"# -----------------------------------------------------------------------------\\\\n\\\",\\n+    \\\"if __name__ == \\\\\\\"__main__\\\\\\\":\\\\n\\\",\\n+    \\\"    recid, links = create_draft()\\\\n\\\",\\n+    \\\"    upload_folder(links)\\\\n\\\",\\n+    \\\"    publish(links)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # Fetch and save metadata after publishing\\\\n\\\",\\n+    \\\"    print(fetch_metadata(recid))\\\\n\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"markdown\\\",\\n+   \\\"id\\\": \\\"2f7423f2-0ff3-4104-913e-50eeb32d9d0f\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"source\\\": [\\n+    \\\"METADATA EXTRACTION FROM INVENIO:\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": null,\\n+   \\\"id\\\": \\\"0013878b-37da-4a22-9586-3773531bfd01\\\",\\n+   \\\"metadata\\\": {\\n+    \\\"scrolled\\\": true\\n+   },\\n+   \\\"outputs\\\": [],\\n+   \\\"source\\\": [\\n+    \\\"\\\\n\\\",\\n+    \\\"# Function to dynamically extract and structure metadata from the original JSON\\\\n\\\",\\n+    \\\"def extract_metadata(metadata):\\\\n\\\",\\n+    \\\"    # Debug: Check if metadata is loaded correctly\\\\n\\\",\\n+    \\\"    print(\\\\\\\"Debug: Metadata loaded successfully\\\\\\\")\\\\n\\\",\\n+    \\\"    print(metadata.get(\\\\\\\"id\\\\\\\", \\\\\\\"\\\\\\\"))  # Check if 'id' is being fetched\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # Check if the required fields are in the metadata\\\\n\\\",\\n+    \\\"    print(\\\\\\\"Debug: Extracting fields from metadata...\\\\\\\")\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    extracted_data = {\\\\n\\\",\\n+    \\\"        \\\\\\\"invenio_metadata\\\\\\\": {\\\\n\\\",\\n+    \\\"            \\\\\\\"id\\\\\\\": metadata.get(\\\\\\\"id\\\\\\\", \\\\\\\"\\\\\\\"),\\\\n\\\",\\n+    \\\"            \\\\\\\"title\\\\\\\": metadata.get(\\\\\\\"metadata\\\\\\\", {}).get(\\\\\\\"title\\\\\\\", \\\\\\\"\\\\\\\"),\\\\n\\\",\\n+    \\\"            \\\\\\\"creator\\\\\\\": \\\\\\\", \\\\\\\".join([creator[\\\\\\\"person_or_org\\\\\\\"].get(\\\\\\\"name\\\\\\\", \\\\\\\"\\\\\\\") for creator in metadata.get(\\\\\\\"metadata\\\\\\\", {}).get(\\\\\\\"creators\\\\\\\", [])]),\\\\n\\\",\\n+    \\\"            \\\\\\\"publication_date\\\\\\\": metadata.get(\\\\\\\"metadata\\\\\\\", {}).get(\\\\\\\"publication_date\\\\\\\", \\\\\\\"\\\\\\\"),\\\\n\\\",\\n+    \\\"            \\\\\\\"files\\\\\\\": [],  # Initialize 'files' as a list\\\\n\\\",\\n+    \\\"            \\\\\\\"pids\\\\\\\": metadata.get(\\\\\\\"pids\\\\\\\", {}),\\\\n\\\",\\n+    \\\"            \\\\\\\"version_info\\\\\\\": metadata.get(\\\\\\\"versions\\\\\\\", {}),\\\\n\\\",\\n+    \\\"            \\\\\\\"status\\\\\\\": metadata.get(\\\\\\\"status\\\\\\\", \\\\\\\"\\\\\\\"),\\\\n\\\",\\n+    \\\"            \\\\\\\"views\\\\\\\": metadata.get(\\\\\\\"stats\\\\\\\", {}).get(\\\\\\\"this_version\\\\\\\", {}).get(\\\\\\\"views\\\\\\\", 0),\\\\n\\\",\\n+    \\\"            \\\\\\\"downloads\\\\\\\": metadata.get(\\\\\\\"stats\\\\\\\", {}).get(\\\\\\\"this_version\\\\\\\", {}).get(\\\\\\\"downloads\\\\\\\", 0),\\\\n\\\",\\n+    \\\"        }\\\\n\\\",\\n+    \\\"    }\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    # Extract file details from the metadata\\\\n\\\",\\n+    \\\"    for key, file_info in metadata.get(\\\\\\\"files\\\\\\\", {}).get(\\\\\\\"entries\\\\\\\", {}).items():\\\\n\\\",\\n+    \\\"        file_detail = {\\\\n\\\",\\n+    \\\"            \\\\\\\"key\\\\\\\": key,\\\\n\\\",\\n+    \\\"            \\\\\\\"url\\\\\\\": file_info[\\\\\\\"links\\\\\\\"].get(\\\\\\\"content\\\\\\\", \\\\\\\"\\\\\\\"),\\\\n\\\",\\n+    \\\"            \\\\\\\"size\\\\\\\": file_info.get(\\\\\\\"size\\\\\\\", 0),\\\\n\\\",\\n+    \\\"            \\\\\\\"mimetype\\\\\\\": file_info.get(\\\\\\\"mimetype\\\\\\\", \\\\\\\"\\\\\\\"),\\\\n\\\",\\n+    \\\"            \\\\\\\"checksum\\\\\\\": file_info.get(\\\\\\\"checksum\\\\\\\", \\\\\\\"\\\\\\\"),\\\\n\\\",\\n+    \\\"            \\\\\\\"metadata\\\\\\\": file_info.get(\\\\\\\"metadata\\\\\\\", {}),\\\\n\\\",\\n+    \\\"        }\\\\n\\\",\\n+    \\\"        extracted_data[\\\\\\\"invenio_metadata\\\\\\\"][\\\\\\\"files\\\\\\\"].append(file_detail)  # Append to the 'files' list\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"    return extracted_data\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# Load the original metadata from the JSON file (replace with your actual file path)\\\\n\\\",\\n+    \\\"with open('metadata_p8a8y-1bn93.json', 'r') as f: \\\\n\\\",\\n+    \\\"    original_metadata = json.load(f)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# Debugging: print out the first part of the original metadata to verify its structure\\\\n\\\",\\n+    \\\"print(\\\\\\\"Debug: Original Metadata (start):\\\\\\\", json.dumps(original_metadata, indent=4)[:1000])  # Print only the start for review\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# Extract relevant details dynamically\\\\n\\\",\\n+    \\\"extracted_metadata = extract_metadata(original_metadata)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# Debugging: print the extracted metadata to verify it's correct\\\\n\\\",\\n+    \\\"print(\\\\\\\"Debug: Extracted Metadata:\\\\\\\", json.dumps(extracted_metadata, indent=4))\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# Load the existing JSON file (replace with your actual file path)\\\\n\\\",\\n+    \\\"with open('MODEL_PROVENANCE/RandomForest_Iris_v20250424_111946_run_summary.json', 'r') as f:\\\\n\\\",\\n+    \\\"    existing_metadata = json.load(f)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# Add the extracted metadata as a new node\\\\n\\\",\\n+    \\\"existing_metadata.update(extracted_metadata)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# Save the updated metadata back to the file\\\\n\\\",\\n+    \\\"with open('updated_metadata.json', 'w') as f:\\\\n\\\",\\n+    \\\"    json.dump(existing_metadata, f, indent=4)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"print(\\\\\\\"\\u2705 New dynamic metadata added successfully!\\\\\\\")\\\\n\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": null,\\n+   \\\"id\\\": \\\"38a807a7-6ecd-4ea7-93ac-78c0f853825c\\\",\\n+   \\\"metadata\\\": {\\n+    \\\"scrolled\\\": true\\n+   },\\n+   \\\"outputs\\\": [],\\n+   \\\"source\\\": [\\n+    \\\"# import mlflow\\\\n\\\",\\n+    \\\"# import mlflow.sklearn\\\\n\\\",\\n+    \\\"# from sklearn.datasets import load_iris\\\\n\\\",\\n+    \\\"# from sklearn.ensemble import RandomForestClassifier\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"# X, y = load_iris(return_X_y=True)\\\\n\\\",\\n+    \\\"# mlflow.sklearn.autolog()\\\\n\\\",\\n+    \\\"# with mlflow.start_run() as run:\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"#     model = RandomForestClassifier(**hyperparams)\\\\n\\\",\\n+    \\\"#     model.fit(X_train, y_train)\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": null,\\n+   \\\"id\\\": \\\"570fa169-a5e2-47b3-b7f5-44f9577f22ad\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [],\\n+   \\\"source\\\": []\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 22,\\n+   \\\"id\\\": \\\"f67b7a46-a70d-44ea-976c-322a1a795311\\\",\\n+   \\\"metadata\\\": {\\n+    \\\"scrolled\\\": true\\n+   },\\n+   \\\"outputs\\\": [],\\n+   \\\"source\\\": [\\n+    \\\"import json\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"with open(\\\\\\\"MODEL_PROVENANCE/RandomForest_Iris_v20250425_131407/RandomForest_Iris_v20250425_131407_run_summary.json\\\\\\\", \\\\\\\"r\\\\\\\") as f1:\\\\n\\\",\\n+    \\\"    json1_with_sklearn = json.load(f1)\\\\n\\\",\\n+    \\\"\\\\n\\\",\\n+    \\\"with open(\\\\\\\"MODEL_PROVENANCE/RandomForest_Iris_v20250425_125653/RandomForest_Iris_v20250425_125653_run_summary.json\\\\\\\", \\\\\\\"r\\\\\\\") as f2:\\\\n\\\",\\n+    \\\"    json2 = json.load(f2)\\\\n\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 24,\\n+   \\\"id\\\": \\\"4211bdef-5785-472d-8ea5-0bc24a3faf3c\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [],\\n+   \\\"source\\\": [\\n+    \\\"keys1 = set(json1_with_sklearn.keys())\\\\n\\\",\\n+    \\\"keys2 = set(json2.keys())\\\\n\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 25,\\n+   \\\"id\\\": \\\"9d4d71f2-ef66-4e04-9d9b-c4b381d45590\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [],\\n+   \\\"source\\\": [\\n+    \\\"only_in_file1 = keys1 - keys2\\\\n\\\",\\n+    \\\"only_in_file2 = keys2 - keys1\\\\n\\\",\\n+    \\\"common_keys   = keys1 & keys2\\\\n\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 26,\\n+   \\\"id\\\": \\\"a51fb61b-d0f6-407e-8563-8a24060e06c2\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\u2705 Common Keys: {'end_time', 'start_time', 'experiment_id', 'run_name', 'artifacts', 'run_id', 'params', 'tags', 'metrics'}\\\\n\\\",\\n+      \\\"\\ud83d\\udd34 Keys only in file1: set()\\\\n\\\",\\n+      \\\"\\ud83d\\udd35 Keys only in file2: set()\\\\n\\\"\\n+     ]\\n+    }\\n+   ],\\n+   \\\"source\\\": [\\n+    \\\"print(\\\\\\\"\\u2705 Common Keys:\\\\\\\", common_keys)\\\\n\\\",\\n+    \\\"print(\\\\\\\"\\ud83d\\udd34 Keys only in file1:\\\\\\\", only_in_file1)\\\\n\\\",\\n+    \\\"print(\\\\\\\"\\ud83d\\udd35 Keys only in file2:\\\\\\\", only_in_file2)\\\\n\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 27,\\n+   \\\"id\\\": \\\"39c248fd-10d1-4229-b60f-4373b4b3214f\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [],\\n+   \\\"source\\\": [\\n+    \\\"def get_all_keys(d, prefix=''):\\\\n\\\",\\n+    \\\"    keys = set()\\\\n\\\",\\n+    \\\"    for k, v in d.items():\\\\n\\\",\\n+    \\\"        full_key = f\\\\\\\"{prefix}.{k}\\\\\\\" if prefix else k\\\\n\\\",\\n+    \\\"        keys.add(full_key)\\\\n\\\",\\n+    \\\"        if isinstance(v, dict):\\\\n\\\",\\n+    \\\"            keys.update(get_all_keys(v, full_key))\\\\n\\\",\\n+    \\\"    return keys\\\\n\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 28,\\n+   \\\"id\\\": \\\"83618982-c802-4ffa-b7e5-c018d36fe517\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [],\\n+   \\\"source\\\": [\\n+    \\\"keys1 = get_all_keys(json1_with_sklearn)\\\\n\\\",\\n+    \\\"keys2 = get_all_keys(json2)\\\\n\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": 29,\\n+   \\\"id\\\": \\\"549ce528-5a49-476c-9546-a8bbc7fa466d\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [\\n+    {\\n+     \\\"name\\\": \\\"stdout\\\",\\n+     \\\"output_type\\\": \\\"stream\\\",\\n+     \\\"text\\\": [\\n+      \\\"\\u2705 Common Keys: {'tags.justification_n_jobs', 'params.sklearn_version', 'metrics.roc_auc', 'params.min_samples_split', 'run_name', 'tags.justification_dataset_version', 'tags.estimator_name', 'tags.justification_random_state', 'params.n_estimators', 'metrics.training_log_loss', 'params.max_features', 'params.max_leaf_nodes', 'tags.justification_verbose', 'tags.target_name', 'tags.estimator_class', 'tags.justification_test_split', 'params.python_version', 'params.database.description', 'metrics.training_roc_auc', 'tags.justification_metric_choice', 'params.dropped_columns', 'tags.dataset_name', 'experiment_id', 'tags.mlflow.source.name', 'tags', 'metrics.dbrepo.row_count_end', 'params.max_depth', 'params.database.id', 'params.n_test_samples', 'params.random_state', 'tags.justification_threshold_accuracy', 'tags.justification_max_features', 'params.verbose', 'tags.mlflow.log-model.history', 'params.shap_version', 'tags.notebook_name', 'tags.justification_oob_score', 'params.n_train_samples', 'params.feature_names', 'params.numpy_version', 'tags.training_end_time', 'tags.justification_max_depth', 'params.ccp_alpha', 'tags.dataset_id', 'metrics.training_score', 'params.test_size', 'params.seaborn_version', 'params.retrieval_time', 'params.dataset.title', 'tags.dbrepo.repository_name', 'params.bootstrap', 'tags.git_previous_commit_hash', 'params.min_impurity_decrease', 'params.min_weight_fraction_leaf', 'tags.dbrepo.granularity', 'params.max_samples', 'params.matplotlib_version', 'metrics.accuracy', 'tags.model_name', 'params.n_features_final', 'params.oob_score', 'metrics.f1_macro', 'params.database.name', 'params.pandas_version', 'metrics.dbrepo.num_inserts', 'tags.mlflow.user', 'params.dataset.authors', 'params.class_weight', 'tags.justification_min_samples_split', 'artifacts', 'metrics', 'tags.justification_model_choice', 'tags.justification_criterion', 'tags.training_start_time', 'tags.justification_n_estimators', 'tags.justification_drop_column_X', 'metrics.dbrepo.num_deletes', 'tags.git__current_commit_url', 'params.dataset.publisher', 'tags.justification_class_weight', 'metrics.training_accuracy_score', 'metrics.recall_macro', 'tags.dataset_version', 'params.columns_raw', 'tags.dbrepo.table_last_modified', 'tags.dbrepo.base_url', 'params.n_features', 'tags.dbrepo.protocol_version', 'params.database.owner', 'end_time', 'start_time', 'tags.justification_experiment_name', 'params.os_platform', 'metrics.training_f1_score', 'metrics.precision_macro', 'params', 'metrics.dbrepo.row_count_start', 'params.n_jobs', 'tags.dbrepo.admin_email', 'tags.justification_target_variable', 'params.criterion', 'tags.data_source', 'params.n_records', 'run_id', 'metrics.training_precision_score', 'params.dataset.doi', 'params.min_samples_leaf', 'tags.justification_bootstrap', 'tags.git_current_commit_hash', 'tags.mlflow.runName', 'metrics.training_recall_score', 'tags.justification_min_samples_leaf', 'params.dataset.published', 'tags.mlflow.source.type', 'params.warm_start'}\\\\n\\\",\\n+      \\\"\\ud83d\\udd34 Keys only in file1: set()\\\\n\\\",\\n+      \\\"\\ud83d\\udd35 Keys only in file2: {'metrics.f1_score_X_test', 'metrics.roc_auc_score_X_test', 'metrics.recall_score_X_test', 'metrics.precision_score_X_test', 'metrics.accuracy_score_X_test'}\\\\n\\\"\\n+     ]\\n+    }\\n+   ],\\n+   \\\"source\\\": [\\n+    \\\"only_in_file1 = keys1 - keys2\\\\n\\\",\\n+    \\\"only_in_file2 = keys2 - keys1\\\\n\\\",\\n+    \\\"common_keys   = keys1 & keys2\\\\n\\\",\\n+    \\\"print(\\\\\\\"\\u2705 Common Keys:\\\\\\\", common_keys)\\\\n\\\",\\n+    \\\"print(\\\\\\\"\\ud83d\\udd34 Keys only in file1:\\\\\\\", only_in_file1)\\\\n\\\",\\n+    \\\"print(\\\\\\\"\\ud83d\\udd35 Keys only in file2:\\\\\\\", only_in_file2)\\\\n\\\"\\n+   ]\\n+  },\\n+  {\\n+   \\\"cell_type\\\": \\\"code\\\",\\n+   \\\"execution_count\\\": null,\\n+   \\\"id\\\": \\\"c7e158ee-7016-43dc-9570-dc522f07d3c2\\\",\\n+   \\\"metadata\\\": {},\\n+   \\\"outputs\\\": [],\\n+   \\\"source\\\": []\\n+  }\\n+ ],\\n+ \\\"metadata\\\": {\\n+  \\\"kernelspec\\\": {\\n+   \\\"display_name\\\": \\\"Python 3 (ipykernel)\\\",\\n+   \\\"language\\\": \\\"python\\\",\\n+   \\\"name\\\": \\\"python3\\\"\\n+  },\\n+  \\\"language_info\\\": {\\n+   \\\"codemirror_mode\\\": {\\n+    \\\"name\\\": \\\"ipython\\\",\\n+    \\\"version\\\": 3\\n+   },\\n+   \\\"file_extension\\\": \\\".py\\\",\\n+   \\\"mimetype\\\": \\\"text/x-python\\\",\\n+   \\\"name\\\": \\\"python\\\",\\n+   \\\"nbconvert_exporter\\\": \\\"python\\\",\\n+   \\\"pygments_lexer\\\": \\\"ipython3\\\",\\n+   \\\"version\\\": \\\"3.11.5\\\"\\n+  }\\n+ },\\n+ \\\"nbformat\\\": 4,\\n+ \\\"nbformat_minor\\\": 5\\n+}\\ndiff --git a/notebooks/RQ_notebooks/RQ3.ipynb b/notebooks/RQ_notebooks/RQ3_draft.ipynb\\nsimilarity index 100%\\nrename from notebooks/RQ_notebooks/RQ3.ipynb\\nrename to notebooks/RQ_notebooks/RQ3_draft.ipynb\\ndiff --git a/notebooks/RQ_notebooks/Trained_models/RandomForest_Iris_v20250425_131407.pkl b/notebooks/RQ_notebooks/Trained_models/RandomForest_Iris_v20250425_131407.pkl\\nnew file mode 100644\\nindex 0000000..648e779\\nBinary files /dev/null and b/notebooks/RQ_notebooks/Trained_models/RandomForest_Iris_v20250425_131407.pkl differ\\ndiff --git a/notebooks/RQ_notebooks/Trained_models/RandomForest_Iris_v20250425_132526.pkl b/notebooks/RQ_notebooks/Trained_models/RandomForest_Iris_v20250425_132526.pkl\\nnew file mode 100644\\nindex 0000000..c675f79\\nBinary files /dev/null and b/notebooks/RQ_notebooks/Trained_models/RandomForest_Iris_v20250425_132526.pkl differ\\ndiff --git a/notebooks/RQ_notebooks/all_runs_provenance.csv b/notebooks/RQ_notebooks/all_runs_provenance.csv\\ndeleted file mode 100644\\nindex 2784e45..0000000\\n--- a/notebooks/RQ_notebooks/all_runs_provenance.csv\\n+++ /dev/null\\n@@ -1,6 +0,0 @@\\n-run_id,run_name,experiment_id,start_time,end_time,n_artifacts,params__bootstrap,params__ccp_alpha,params__class_weight,params__columns_raw,params__criterion,params__database.description,params__database.id,params__database.name,params__database.owner,params__dataset.authors,params__dataset.doi,params__dataset.published,params__dataset.publisher,params__dataset.title,params__dropped_columns,params__feature_names,params__matplotlib_version,params__max_depth,params__max_features,params__max_leaf_nodes,params__max_samples,params__min_impurity_decrease,params__min_samples_leaf,params__min_samples_split,params__min_weight_fraction_leaf,params__numpy_version,params__n_estimators,params__n_features,params__n_features_final,params__n_jobs,params__n_records,params__n_test_samples,params__n_train_samples,params__oob_score,params__os_platform,params__pandas_version,params__python_version,params__random_state,params__retrieval_time,params__seaborn_version,params__shap_version,params__sklearn_version,params__test_size,params__verbose,params__warm_start,metrics__accuracy,metrics__accuracy_score_X_test,metrics__dbrepo.num_deletes,metrics__dbrepo.num_inserts,metrics__dbrepo.row_count_end,metrics__dbrepo.row_count_start,metrics__f1_macro,metrics__f1_score_X_test,metrics__precision_macro,metrics__precision_score_X_test,metrics__recall_macro,metrics__recall_score_X_test,metrics__roc_auc,metrics__roc_auc_score_X_test,metrics__training_accuracy_score,metrics__training_f1_score,metrics__training_log_loss,metrics__training_precision_score,metrics__training_recall_score,metrics__training_roc_auc,metrics__training_score,tags__dataset_id,tags__dataset_name,tags__dataset_version,tags__data_source,tags__dbrepo.admin_email,tags__dbrepo.base_url,tags__dbrepo.granularity,tags__dbrepo.protocol_version,tags__dbrepo.repository_name,tags__dbrepo.table_last_modified,tags__estimator_class,tags__estimator_name,tags__git_current_commit_hash,tags__git_previous_commit_hash,tags__git__current_commit_url,tags__mlflow.log-model.history,tags__mlflow.runName,tags__mlflow.source.name,tags__mlflow.source.type,tags__mlflow.user,tags__model_name,tags__notebook_name,tags__target_name,tags__training_end_time,tags__training_start_time\\n-361daa12f99f4129a06cd20b78dd6fa7,flawless-kit-371,615223710259862608,2025-04-23 21:04:21.262000+00:00,,23,True,0.0,None,\\\"['id', 'sepallengthcm', 'sepalwidthcm', 'petallengthcm', 'petalwidthcm', 'species']\\\",entropy,None,c3a42d17-42b7-43c9-a504-2363fb4c9c8d,Iris,reema,\\\"[\\\"\\\"Marshall Michael\\\"\\\"]\\\",10.5281/ZENODO.1404173,2018-8-27,Zenodo,Scikit-Learn Iris,[],\\\"['sepallengthcm', 'sepalwidthcm', 'petallengthcm', 'petalwidthcm']\\\",3.7.2,12,sqrt,None,None,0.0,2,5,0.0,1.24.4,200,4,4,-1,150,30,120,False,Windows 10,2.2.3,3.11.5,42,2025-04-23T21:04:22.410093,0.12.2,0.47.1,1.3.0,0.2,1,False,1.0,1.0,0.0,1.0,150.0,150.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9666666666666667,0.9666666666666667,0.0653522301195834,0.9674588284344383,0.9666666666666667,0.9987492182614135,0.9666666666666667,iris_local,Iris,1.0.0,http://localhost/api/database/c3a42d17-42b7-43c9-a504-2363fb4c9c8d/table/5315e7da-64fb-4fdb-b493-95b4138c765f/data?size=100000&page=0,noreply@localhost,http://localhost,YYYY-MM-DDThh:mm:ssZ,2.0,Database Repository,2025-04-23T20:42:29.501Z,sklearn.ensemble._forest.RandomForestClassifier,RandomForestClassifier,d329c92495e196ec0f39fbb19dfdd367131a77d9,a07434af4f547af2daab044d6873eb7081162293,https://github.com/reema-dass26/REPO/commit/d329c92495e196ec0f39fbb19dfdd367131a77d9,\\\"[{\\\"\\\"run_id\\\"\\\": \\\"\\\"361daa12f99f4129a06cd20b78dd6fa7\\\"\\\", \\\"\\\"artifact_path\\\"\\\": \\\"\\\"model\\\"\\\", \\\"\\\"utc_time_created\\\"\\\": \\\"\\\"2025-04-23 21:04:23.264719\\\"\\\", \\\"\\\"model_uuid\\\"\\\": \\\"\\\"5788ebda55b2492fb25d01738dae4022\\\"\\\", \\\"\\\"flavors\\\"\\\": {\\\"\\\"python_function\\\"\\\": {\\\"\\\"model_path\\\"\\\": \\\"\\\"model.pkl\\\"\\\", \\\"\\\"predict_fn\\\"\\\": \\\"\\\"predict\\\"\\\", \\\"\\\"loader_module\\\"\\\": \\\"\\\"mlflow.sklearn\\\"\\\", \\\"\\\"python_version\\\"\\\": \\\"\\\"3.11.5\\\"\\\", \\\"\\\"env\\\"\\\": {\\\"\\\"conda\\\"\\\": \\\"\\\"conda.yaml\\\"\\\", \\\"\\\"virtualenv\\\"\\\": \\\"\\\"python_env.yaml\\\"\\\"}}, \\\"\\\"sklearn\\\"\\\": {\\\"\\\"pickled_model\\\"\\\": \\\"\\\"model.pkl\\\"\\\", \\\"\\\"sklearn_version\\\"\\\": \\\"\\\"1.3.0\\\"\\\", \\\"\\\"serialization_format\\\"\\\": \\\"\\\"cloudpickle\\\"\\\", \\\"\\\"code\\\"\\\": null}}}]\\\",flawless-kit-371,C:\\\\Users\\\\reema\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\site-packages\\\\ipykernel_launcher.py,LOCAL,reema,RandomForest_Iris_v20250423_230422,RQ1.ipynb,\\\"[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n- 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\\n- 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\\n- 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\\n- 2 2]\\\",2025-04-23T23:04:30.472556,2025-04-23T23:04:22.449390\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_131407/confusion_matrix.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_131407/confusion_matrix.png\\nnew file mode 100644\\nindex 0000000..5bf98dd\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_131407/confusion_matrix.png differ\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_131407/feature_importances.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_131407/feature_importances.png\\nnew file mode 100644\\nindex 0000000..65481a2\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_131407/feature_importances.png differ\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_131407/pr_curve_cls_0.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_131407/pr_curve_cls_0.png\\nnew file mode 100644\\nindex 0000000..a8d230a\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_131407/pr_curve_cls_0.png differ\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_131407/pr_curve_cls_1.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_131407/pr_curve_cls_1.png\\nnew file mode 100644\\nindex 0000000..b36796e\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_131407/pr_curve_cls_1.png differ\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_131407/pr_curve_cls_2.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_131407/pr_curve_cls_2.png\\nnew file mode 100644\\nindex 0000000..86bc90f\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_131407/pr_curve_cls_2.png differ\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_131407/roc_curve_cls_0.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_131407/roc_curve_cls_0.png\\nnew file mode 100644\\nindex 0000000..5ae6a09\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_131407/roc_curve_cls_0.png differ\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_131407/roc_curve_cls_1.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_131407/roc_curve_cls_1.png\\nnew file mode 100644\\nindex 0000000..7d3f039\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_131407/roc_curve_cls_1.png differ\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_131407/roc_curve_cls_2.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_131407/roc_curve_cls_2.png\\nnew file mode 100644\\nindex 0000000..24b4468\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_131407/roc_curve_cls_2.png differ\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_131407/shap_summary.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_131407/shap_summary.png\\nnew file mode 100644\\nindex 0000000..4ed1b76\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_131407/shap_summary.png differ\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_132526/confusion_matrix.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_132526/confusion_matrix.png\\nnew file mode 100644\\nindex 0000000..5bf98dd\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_132526/confusion_matrix.png differ\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_132526/feature_importances.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_132526/feature_importances.png\\nnew file mode 100644\\nindex 0000000..65481a2\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_132526/feature_importances.png differ\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_132526/pr_curve_cls_0.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_132526/pr_curve_cls_0.png\\nnew file mode 100644\\nindex 0000000..a8d230a\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_132526/pr_curve_cls_0.png differ\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_132526/pr_curve_cls_1.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_132526/pr_curve_cls_1.png\\nnew file mode 100644\\nindex 0000000..b36796e\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_132526/pr_curve_cls_1.png differ\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_132526/pr_curve_cls_2.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_132526/pr_curve_cls_2.png\\nnew file mode 100644\\nindex 0000000..86bc90f\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_132526/pr_curve_cls_2.png differ\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_132526/roc_curve_cls_0.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_132526/roc_curve_cls_0.png\\nnew file mode 100644\\nindex 0000000..5ae6a09\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_132526/roc_curve_cls_0.png differ\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_132526/roc_curve_cls_1.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_132526/roc_curve_cls_1.png\\nnew file mode 100644\\nindex 0000000..7d3f039\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_132526/roc_curve_cls_1.png differ\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_132526/roc_curve_cls_2.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_132526/roc_curve_cls_2.png\\nnew file mode 100644\\nindex 0000000..24b4468\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_132526/roc_curve_cls_2.png differ\\ndiff --git a/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_132526/shap_summary.png b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_132526/shap_summary.png\\nnew file mode 100644\\nindex 0000000..86c9184\\nBinary files /dev/null and b/notebooks/RQ_notebooks/plots/RandomForest_Iris_v20250425_132526/shap_summary.png differ\\ndiff --git a/notebooks/RQ_notebooks/vizualization.py b/notebooks/RQ_notebooks/vizualization.py\\nindex a858d33..358973f 100644\\n--- a/notebooks/RQ_notebooks/vizualization.py\\n+++ b/notebooks/RQ_notebooks/vizualization.py\\n@@ -19,7 +19,8 @@ import streamlit.components.v1 as components\\n import networkx as nx\\n from streamlit_agraph import agraph, Node, Edge, Config\\n import time\\n-\\n+from datetime import datetime\\n+import re\\n \\n st.set_page_config(\\n     page_title=\\\"Building Bridges in Research: Integrating Provenance and Data Management in Virtual Research Environments\\\",\\n@@ -213,7 +214,42 @@ USE_CASES = {\\n         'optional_params': [],\\n     },\\n }\\n-\\n+# \\u2014\\u2014 Find latest run summary with justification data \\u2014\\u2014\\n+\\n+def get_latest_justification_summary(base_dir=\\\"MODEL_PROVENANCE\\\"):\\n+    folders = [d for d in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, d))]\\n+    timestamped_folders = []\\n+    for folder in folders:\\n+        match = re.search(r'_(v\\\\d{8}_\\\\d{6})', folder)\\n+        if match:\\n+            try:\\n+                timestamp = datetime.strptime(match.group(1), \\\"v%Y%m%d_%H%M%S\\\")\\n+                timestamped_folders.append((timestamp, folder))\\n+            except ValueError:\\n+                continue\\n+\\n+    if not timestamped_folders:\\n+        raise FileNotFoundError(\\\"No timestamped folders found in MODEL_PROVENANCE\\\")\\n+\\n+    latest_folder = max(timestamped_folders)[1]\\n+    file_path = os.path.join(base_dir, latest_folder, f\\\"{latest_folder}_run_summary.json\\\")\\n+    return file_path\\n+\\n+# \\u2014\\u2014 Load justifications and return as DataFrame \\u2014\\u2014\\n+\\n+def load_justification_table(path):\\n+    with open(path, \\\"r\\\") as f:\\n+        js = json.load(f)\\n+\\n+    justifications = {\\n+        k: v for k, v in js.get(\\\"tags\\\", {}).items()\\n+        if k.startswith(\\\"justification_\\\")\\n+    }\\n+    rows = [\\n+        {\\\"Decision\\\": k.replace(\\\"justification_\\\", \\\"\\\"), \\\"Justification\\\": v}\\n+        for k, v in justifications.items()\\n+    ]\\n+    return pd.DataFrame(rows)\\n # -------- Load the metadata (flattened like before) ----------\\n @st.cache_data\\n def load_data():\\n@@ -278,7 +314,8 @@ with st.sidebar:\\n             \\\"\\ud83d\\udef0\\ufe0f Provenance Trace\\\",\\n             \\\"\\u26a0\\ufe0f Deprecated Code Check\\\",\\n             \\\"\\ud83e\\udded Model-Dataset Mapping\\\",\\n-            \\\"\\ud83d\\udce3 Notify Outdated Forks\\\"\\n+            \\\"\\ud83d\\udce3 Notify Outdated Forks\\\",\\n+            \\\"\\ud83d\\udcd8 Researcher Justifications\\\"\\n         ],\\n         icons=[\\n             \\\"house\\\", \\\"database\\\", \\\"gear\\\", \\\"bar-chart\\\", \\\"globe\\\", \\\"link\\\", \\\"exclamation-triangle\\\",\\\"map\\\", \\\"megaphone\\\" \\n@@ -874,3 +911,21 @@ Detect whether collaborators' forks of your GitHub repository are out-of-date wi\\n \\n                 except Exception as e:\\n                     st.error(f\\\"An error occurred: {e}\\\")\\n+elif selected == \\\"\\ud83d\\udcd8 Researcher Justifications\\\":\\n+    st.title(\\\"\\ud83d\\udcd8 Researcher Justifications\\\")\\n+    st.markdown(\\\"\\\"\\\"\\n+    This section displays all recorded **justifications** provided by the researcher \\n+    for specific modeling decisions, such as hyperparameter choices, dataset version, and evaluation criteria.\\n+    \\n+    \\ud83e\\udde0 These justifications help ensure **transparency**, **explainability**, and support for reproducibility.\\n+    \\\"\\\"\\\")\\n+\\n+    try:\\n+        latest_path = get_latest_justification_summary()\\n+        st.success(f\\\"Loaded: `{latest_path}`\\\")\\n+\\n+        df_just = load_justification_table(latest_path)\\n+        st.write(\\\"### Justification Table\\\")\\n+        st.dataframe(df_just, use_container_width=True)\\n+    except Exception as e:\\n+        st.error(f\\\"Failed to load justification data: {e}\\\")\\n\"\n}"
    },
    {
      "path": "confusion_matrix.png",
      "type": "image",
      "uri": "file:///C:/Users/reema/REPO/notebooks/RQ_notebooks/mlrunlogs/mlflow.db/615223710259862608/78e6e34ac94a460a893791a3e02f6da7/artifacts/confusion_matrix.png"
    },
    {
      "path": "estimator.html",
      "type": "other",
      "uri": "file:///C:/Users/reema/REPO/notebooks/RQ_notebooks/mlrunlogs/mlflow.db/615223710259862608/78e6e34ac94a460a893791a3e02f6da7/artifacts/estimator.html"
    },
    {
      "path": "feature_importances.png",
      "type": "image",
      "uri": "file:///C:/Users/reema/REPO/notebooks/RQ_notebooks/mlrunlogs/mlflow.db/615223710259862608/78e6e34ac94a460a893791a3e02f6da7/artifacts/feature_importances.png"
    },
    {
      "path": "label_mapping.json",
      "type": "text",
      "content": "{\n  \"0\": \"Iris-setosa\",\n  \"1\": \"Iris-versicolor\",\n  \"2\": \"Iris-virginica\"\n}"
    },
    {
      "path": "model/MLmodel",
      "type": "other",
      "uri": "file:///C:/Users/reema/REPO/notebooks/RQ_notebooks/mlrunlogs/mlflow.db/615223710259862608/78e6e34ac94a460a893791a3e02f6da7/artifacts/model/MLmodel"
    },
    {
      "path": "model/conda.yaml",
      "type": "other",
      "uri": "file:///C:/Users/reema/REPO/notebooks/RQ_notebooks/mlrunlogs/mlflow.db/615223710259862608/78e6e34ac94a460a893791a3e02f6da7/artifacts/model/conda.yaml"
    },
    {
      "path": "model/model.pkl",
      "type": "other",
      "uri": "file:///C:/Users/reema/REPO/notebooks/RQ_notebooks/mlrunlogs/mlflow.db/615223710259862608/78e6e34ac94a460a893791a3e02f6da7/artifacts/model/model.pkl"
    },
    {
      "path": "model/python_env.yaml",
      "type": "other",
      "uri": "file:///C:/Users/reema/REPO/notebooks/RQ_notebooks/mlrunlogs/mlflow.db/615223710259862608/78e6e34ac94a460a893791a3e02f6da7/artifacts/model/python_env.yaml"
    },
    {
      "path": "model/requirements.txt",
      "type": "text",
      "content": "mlflow==2.21.2\nbackports-functools-lru-cache==1.6.4\nbackports-tempfile==1.0\ncloudpickle==2.2.1\njaraco-classes==3.2.1\njaraco-collections==5.1.0\nlz4==4.3.2\nnumpy==1.24.4\npathlib==1.0.1\npsutil==5.9.5\nscikit-learn==1.3.0\nscipy==1.11.1"
    },
    {
      "path": "pr_curve_cls_0.png",
      "type": "image",
      "uri": "file:///C:/Users/reema/REPO/notebooks/RQ_notebooks/mlrunlogs/mlflow.db/615223710259862608/78e6e34ac94a460a893791a3e02f6da7/artifacts/pr_curve_cls_0.png"
    },
    {
      "path": "pr_curve_cls_1.png",
      "type": "image",
      "uri": "file:///C:/Users/reema/REPO/notebooks/RQ_notebooks/mlrunlogs/mlflow.db/615223710259862608/78e6e34ac94a460a893791a3e02f6da7/artifacts/pr_curve_cls_1.png"
    },
    {
      "path": "pr_curve_cls_2.png",
      "type": "image",
      "uri": "file:///C:/Users/reema/REPO/notebooks/RQ_notebooks/mlrunlogs/mlflow.db/615223710259862608/78e6e34ac94a460a893791a3e02f6da7/artifacts/pr_curve_cls_2.png"
    },
    {
      "path": "public_datasetRepository_metadata.json",
      "type": "text",
      "content": "{\n  \"zenodo\": {\n    \"title\": \"Scikit-Learn Iris\",\n    \"doi\": \"10.5281/ZENODO.1404173\",\n    \"authors\": [\n      \"Marshall Michael\"\n    ],\n    \"published\": \"2018-8-27\",\n    \"publisher\": \"Zenodo\"\n  }\n}"
    },
    {
      "path": "roc_curve_cls_0.png",
      "type": "image",
      "uri": "file:///C:/Users/reema/REPO/notebooks/RQ_notebooks/mlrunlogs/mlflow.db/615223710259862608/78e6e34ac94a460a893791a3e02f6da7/artifacts/roc_curve_cls_0.png"
    },
    {
      "path": "roc_curve_cls_1.png",
      "type": "image",
      "uri": "file:///C:/Users/reema/REPO/notebooks/RQ_notebooks/mlrunlogs/mlflow.db/615223710259862608/78e6e34ac94a460a893791a3e02f6da7/artifacts/roc_curve_cls_1.png"
    },
    {
      "path": "roc_curve_cls_2.png",
      "type": "image",
      "uri": "file:///C:/Users/reema/REPO/notebooks/RQ_notebooks/mlrunlogs/mlflow.db/615223710259862608/78e6e34ac94a460a893791a3e02f6da7/artifacts/roc_curve_cls_2.png"
    },
    {
      "path": "shap_summary.png",
      "type": "image",
      "uri": "file:///C:/Users/reema/REPO/notebooks/RQ_notebooks/mlrunlogs/mlflow.db/615223710259862608/78e6e34ac94a460a893791a3e02f6da7/artifacts/shap_summary.png"
    },
    {
      "path": "training_confusion_matrix.png",
      "type": "image",
      "uri": "file:///C:/Users/reema/REPO/notebooks/RQ_notebooks/mlrunlogs/mlflow.db/615223710259862608/78e6e34ac94a460a893791a3e02f6da7/artifacts/training_confusion_matrix.png"
    }
  ]
}