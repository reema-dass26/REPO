{
  "FAIR": {
    "dcterms:identifier": "0a16d4fd-8567-46b8-8f0c-223bfe29f4a1",
    "dc:title": "Iris",
    "dc:description": "https://archive.ics.uci.edu/dataset/53",
    "dc:creator": "R. A. Fisher",
    "dc:license": "info not available",
    "dcterms:hasVersion": "v0",
    "dcterms:created": "2023-03-16 12:57:44",
    "dcterms:modified": "2025-04-18 08:55:20",
    "dcat:landingPage": "https://archive.ics.uci.edu/dataset/53",
    "dc:publisher": "UCI Machine Learning Repository",
    "dcterms:issued": "1936",
    "dc:language": "unknown",
    "dcat:citationCount": "23",
    "dc:subject": "info not available",
    "dcat:relatedResource": "\"[]\"",
    "dcat:schemaVersion": "http://datacite.org/schema/kernel-4",
    "dcat:registered": "2023-03-16 12:57:45",
    "dcat:citationsOverTime": "\"[{\\\"year\\\": \\\"2023\\\", \\\"total\\\": 5}, {\\\"year\\\": \\\"2024\\\", \\\"total\\\": 11}, {\\\"year\\\": \\\"2025\\\", \\\"total\\\": 7}]\""
  },
  "FAIR4ML": {
    "fair4ml:experimentID": "None_specified",
    "fair4ml:runID": "b68723e6719c4ca282f7064ef5daace1",
    "fair4ml:sessionID": "e07eb931-d725-4a64-a4f9-5c89dcc0bd10",
    "fair4ml:modelID": "model_randomforest_iris_v20250626_171359_20250626_171359",
    "fair4ml:datasetID": "722083fe-167c-43a4-8745-c4688d2af383",
    "fair4ml:trainedOn": "Iris",
    "fair4ml:modelType": "Classifier",
    "dcterms:source": "10.24432/C56C76",
    "fair4ml:trainingStartTime": "2025-06-26T17:13:59.922204",
    "fair4ml:trainingEndTime": "2025-06-26T17:14:29.026176",
    "fair4ml:targetVariable": "species",
    "fair4ml:trainingScriptVersion": "b90e74fa2eb66e90619c525eb9829f72ed65de62",
    "fair4ml:runEnvironment": "Windows 10 | Python 3.11.5"
  },
  "MLSEA": {
    "mlsea:accuracy": "1.000000000000000000",
    "mlsea:f1_score": "1.000000000000000000",
    "mlsea:num_deleted_rows": "0E-18",
    "mlsea:num_inserted_rows": "0E-18",
    "mlsea:precision": "1.000000000000000000",
    "mlsea:recall": "1.000000000000000000",
    "mlsea:roc_auc": "1.000000000000000000",
    "mlsea:row_count_end": "150.000000000000000000",
    "mlsea:row_count_start": "150.000000000000000000",
    "mlsea:training_accuracy_score": "1.000000000000000000",
    "mlsea:training_f1_score": "1.000000000000000000",
    "mlsea:training_log_loss": "0.041644324039124790",
    "mlsea:training_precision_score": "1.000000000000000000",
    "mlsea:training_recall_score": "1.000000000000000000",
    "mlsea:training_roc_auc": "1.000000000000000000",
    "mlsea:training_score": "1.000000000000000000",
    "justification_bootstrap": "No justification provided",
    "justification_class_weight": "No justification provided",
    "justification_criterion": "No justification provided",
    "justification_dataset_version": "No justification provided",
    "justification_drop_column_x": "No justification provided",
    "justification_ethical_considerations": "No justification provided",
    "justification_experiment_name": "No justification provided",
    "justification_intended_use": "No justification provided",
    "justification_max_depth": "No justification provided",
    "justification_max_features": "No justification provided",
    "justification_metric_choice": "No justification provided",
    "justification_min_samples_leaf": "No justification provided",
    "justification_min_samples_split": "No justification provided",
    "justification_model_choice": "No justification provided",
    "justification_model_limitations": "No justification provided",
    "justification_not_intended_for": "No justification provided",
    "justification_n_estimators": "No justification provided",
    "justification_n_jobs": "No justification provided",
    "justification_oob_score": "No justification provided",
    "justification_target_variable": "No justification provided",
    "justification_test_split": "No justification provided",
    "justification_threshold_accuracy": "No justification provided",
    "justification_verbose": "No justification provided",
    "mlsea:trainSplit": "0.800000000000000000",
    "mlsea:testSplit": "0.200000000000000000",
    "mlsea:featureSelection": "id,sepallengthcm,sepalwidthcm,petallengthcm,petalwidthcm",
    "mlsea:labelMap": "{\"0\": \"Iris-setosa\", \"1\": \"Iris-versicolor\", \"2\": \"Iris-virginica\"}",
    "mlsea:imbalanceRatio": "1.000000000000000000"
  },
  "Croissant": {
    "mls:modelID": "model_randomforest_iris_v20250626_171359_20250626_171359",
    "mls:modelName": "RandomForest_Iris_v20250626_171359",
    "mls:learningAlgorithm": "RandomForestClassifier",
    "mls:modelArchitecture": "RandomForestClassifier",
    "mls:featureList": "['sepallengthcm', 'sepalwidthcm', 'petallengthcm', 'petalwidthcm']",
    "mls:targetVariable": "species",
    "mls:labelEncoding": "species",
    "mls:modelPath": "RandomForest_Iris_v20250626_171359.pkl",
    "mls:serializationFormat": "pickle",
    "mls:modelVersion": "vtest",
    "mls:hyperparameters": "{\"n_estimators\": 100, \"criterion\": \"entropy\", \"max_depth\": 10, \"min_samples_split\": 3, \"min_samples_leaf\": 1, \"max_features\": \"sqrt\", \"bootstrap\": true, \"oob_score\": true, \"class_weight\": null, \"verbose\": 1, \"n_jobs\": -1}",
    "mls:preprocessingSteps": "{\"dropped_columns\": [\"id\"], \"numeric_columns\": [\"sepallengthcm\", \"sepalwidthcm\", \"petallengthcm\", \"petalwidthcm\"], \"target_column\": \"species\", \"stratified\": false, \"coercion_strategy\": \"Numeric cast (auto)\", \"feature_engineering\": \"None\", \"missing_value_strategy\": \"None\", \"outlier_detection\": \"None\", \"encoding_strategy\": \"LabelEncoder (target only)\", \"scaling\": \"None\", \"sampling\": \"None\", \"feature_selection\": \"None\", \"train_test_split\": {\"test_size\": 0.2, \"random_state\": 42}, \"imbalance_ratio\": \"{0: 50, 1: 50, 2: 50}\", \"preprocessing_timestamp\": \"2025-06-26T17:14:40.371803\"}",
    "mls:hasInput": "Iris",
    "mls:hasOutput": "categorical"
  },
  "PROV-O": {
    "prov:Entity": "0a16d4fd-8567-46b8-8f0c-223bfe29f4a1",
    "prov:Activity": "b68723e6719c4ca282f7064ef5daace1",
    "prov:Agent": "reema",
    "prov:wasGeneratedBy": "b68723e6719c4ca282f7064ef5daace1",
    "prov:wasAssociatedWith": "default_project",
    "prov:startedAtTime": "2025-06-26T17:13:59.922204",
    "prov:endedAtTime": "2025-06-26T17:14:29.026176",
    "prov:used": "C:\\Users\\reema\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel_launcher.py",
    "fair4ml:usedNotebook": "RQ1_2.ipynb",
    "prov:sessionID": "e07eb931-d725-4a64-a4f9-5c89dcc0bd10",
    "prov:location": "Purplish",
    "prov:platform": "Windows",
    "prov:pythonVersion": "3.11.5",
    "prov:osPlatform": "Windows 10",
    "prov:role": "d",
    "prov:scriptName": "None_specified",
    "prov:commit": "b90e74fa2eb66e90619c525eb9829f72ed65de62",
    "prov:commitTime": "2025-06-26T15:13:55.245566",
    "prov:commitAuthor": "Reema George",
    "prov:commitEmail": "106236154+reema-dass26@users.noreply.github.com",
    "prov:branch": "main",
    "prov:repository": "https://archive.ics.uci.edu/dataset/53"
  },
  "Uncategorized": {
    "run_name": "charming-boar-698",
    "origin_url": "None_specified"
  }
}