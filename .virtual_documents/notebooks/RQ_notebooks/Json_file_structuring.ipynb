import requests
import json

# Constants
DB_ID = "ae259a21-2211-4fe4-9060-ce382e154705"
HEADERS = {"Accept": "application/json"}
TABLES = {
    "session_metadata": "56abc9be-baa4-4c37-8b47-70abb0babb59",
    "experiment_metadata": "82e295c3-bb70-48df-aecc-dcc6ce03a49c",
    "git_metadata": "99cdf248-7601-48fb-bf04-b16d60d2da99",
    "dataset_metadata": "8a165d25-c88c-4797-84a4-5c6023c1b294",
    "model_metadata": "8e1b546c-71c7-4270-be59-397ec564ec50",
    "metrics_justification": "c0ae72c8-97a3-4ff9-864a-ecf7c40853f8"
}

# Replace this with your actual run ID
run_id = run_id

# Dictionary to store results
table_objects = {}

# Step 1: Fetch experiment_metadata first
try:
    url = f"http://localhost/api/database/{DB_ID}/table/{TABLES['experiment_metadata']}/data?size=100000&page=0"
    r = requests.get(url, headers=HEADERS)
    r.raise_for_status()
    records = r.json()
    experiment = next((x for x in records if x.get("runid") == run_id), None)
    table_objects["experiment_metadata"] = experiment or "❌ No match for experiment_metadata"
except Exception as e:
    experiment = None
    table_objects["experiment_metadata"] = f"⚠️ Request failed: {e}"

# Step 2: Extract related identifiers
sid = experiment.get("sessionid") if experiment else None
mid = experiment.get("modelid") if experiment else None
did = experiment.get("datasetid") if experiment else None
ghash = experiment.get("git_commit") if experiment else None

# Step 3: Fetch the rest of the metadata tables
for table, table_id in TABLES.items():
    if table == "experiment_metadata":
        continue  # already handled

    url = f"http://localhost/api/database/{DB_ID}/table/{table_id}/data?size=100000&page=0"
    try:
        r = requests.get(url, headers=HEADERS)
        r.raise_for_status()
        records = r.json()

        if table == "metrics_justification":
            match = next((x for x in records if x.get("run_id") == run_id), None)
        elif table == "model_metadata":
            match = next((x for x in records if x.get("model_id") == mid), None)
        elif table == "dataset_metadata":
            match = next((x for x in records if x.get("dataset_guid") == did), None)
        elif table == "session_metadata":
            if not sid:
                match = None
            else:
               sid = str(sid).strip()
            match = next((x for x in records if str(x.get("session_id", "")).strip() == sid), None)


        elif table == "git_metadata":
            match = next((x for x in records if x.get("commit_hash") == ghash), None)
        else:
            match = None

        table_objects[table] = match or f"❌ No match for {table}"

    except Exception as e:
        table_objects[table] = f"⚠️ Request failed: {e}"

# Step 4: Save the results to a file
output_path = f"run_metadata_trace_{run_id}.json"
with open(output_path, "w", encoding="utf-8") as f:
    json.dump(table_objects, f, indent=2, ensure_ascii=False)

print(f"✅ Metadata trace saved to: {output_path}")



import json
from pathlib import Path

# Load the uploaded file
input_path = Path("run_metadata_trace_eadb7132644b4d5bba45bdf5a2104b09.json")
with open(input_path, "r", encoding="utf-8") as f:
    data = json.load(f)

# Initialize structured output
structured = {
    "FAIR": {},
    "FAIR4ML": {},
    "MLSEA": {},
    "Croissant": {},
    "Uncategorized": {}
}

# Populate FAIR
if "dataset_metadata" in data:
    ds = data["dataset_metadata"]
    structured["FAIR"].update({
        "identifier": ds.get("dataset_id"),
        "title": ds.get("title"),
        "description": ds.get("description"),
        "creator": ds.get("creator"),
        "license": ds.get("license"),
        "version": ds.get("version"),
        "created": ds.get("created"),
        "updated": ds.get("updated"),
        "url": ds.get("source_url")
    })

# Populate FAIR4ML
if "experiment_metadata" in data:
    exp = data["experiment_metadata"]
    structured["FAIR4ML"].update({
        "experiment_id": exp.get("experiment_id"),
        "run_id": exp.get("runid"),
        "session_id": exp.get("sessionid"),
        "model_id": exp.get("modelid"),
        "dataset_id": exp.get("datasetid"),
        "timestamp": exp.get("timestamp"),
        "training_start_time": exp.get("training_start_time"),
        "training_end_time": exp.get("training_end_time"),
        "source_file": exp.get("source_file"),
        "source_notebook": exp.get("source_notebook"),
        "invenio_id": exp.get("invenioid")
    })

# Populate MLSEA
if "metrics_justification" in data:
    metrics = data["metrics_justification"]
    structured["MLSEA"].update({
        k: v for k, v in metrics.items()
        if any(key in k for key in ["score", "accuracy", "f1", "roc", "precision", "recall", "log_loss", "justification_"])
    })

# Populate Croissant
if "model_metadata" in data:
    model = data["model_metadata"]
    structured["Croissant"].update({
        "model_id": model.get("model_id"),
        "name": model.get("name"),
        "algorithm": model.get("algo"),
        "architecture": model.get("architecture"),
        "features": model.get("features"),
        "target_variable": model.get("target_var"),
        "label_encoding": model.get("label_snap"),
        "model_path": model.get("model_path"),
        "serialization_format": model.get("serialization_format"),
        "model_version": model.get("version"),
        "hyperparameters": model.get("hyperparameters"),
        "preprocessing_info": model.get("preprocessing_info")
    })

# Add session + git + other remaining fields to Uncategorized
structured["Uncategorized"]["session_metadata"] = data.get("session_metadata", {})
structured["Uncategorized"]["git_metadata"] = data.get("git_metadata", {})

# Save to output
output_path = "structured_metadata_full.json"
with open(output_path, "w", encoding="utf-8") as f:
    json.dump(structured, f, indent=2, ensure_ascii=False)

output_path



import json
from pathlib import Path

# Load the structured metadata
input_path = Path("structured_metadata_full.json")
with open(input_path, "r", encoding="utf-8") as f:
    structured = json.load(f)

# Define field renaming per strategy
rename_map = {
    "FAIR": {
        "title": "dc:title",
        "description": "dc:description",
        "creator": "dc:creator",
        "license": "dc:license",
        "version": "dcterms:hasVersion",
        "created": "dcterms:created",
        "updated": "dcterms:modified",
        "identifier": "dcterms:identifier",
        "url": "dcat:landingPage"
    },
    "FAIR4ML": {
        "experiment_id": "fair4ml:experimentID",
        "run_id": "fair4ml:runID",
        "session_id": "fair4ml:sessionID",
        "model_id": "fair4ml:modelID",
        "dataset_id": "fair4ml:datasetID",
        "git_commit": "prov:wasDerivedFrom",
        "timestamp": "prov:startedAtTime",
        "training_start_time": "fair4ml:trainingStartTime",
        "training_end_time": "fair4ml:trainingEndTime",
        "source_file": "prov:usedFile",
        "source_notebook": "fair4ml:usedNotebook"
    },
    "MLSEA": {
        "run_id": "mlsea:run_id",
        "accuracy": "mlsea:accuracy",
        "f1_macro": "mlsea:f1_macro",
        "num_deleted_rows": "mlsea:num_deleted_rows",
        "num_inserted_rows": "mlsea:num_inserted_rows",
        "precision_macro": "mlsea:precision_macro",
        "recall_macro": "mlsea:recall_macro",
        "roc_auc": "mlsea:roc_auc",
        "row_count_end": "mlsea:row_count_end",
        "row_count_start": "mlsea:row_count_start",
        "training_accuracy_score": "mlsea:training_accuracy_score",
        "training_f1_score": "mlsea:training_f1_score",
        "training_log_loss": "mlsea:training_log_loss",
        "training_precision_score": "mlsea:training_precision_score",
        "training_recall_score": "mlsea:training_recall_score",
        "training_roc_auc": "mlsea:training_roc_auc",
        "training_score": "mlsea:training_score"
    },
    "Croissant": {
        "model_id": "mls:model_id",
        "name": "mls:modelName",
        "algo": "mls:learningAlgorithm",
        "architecture": "mls:modelArchitecture",
        "features": "mls:featureList",
        "target_variable": "mls:targetVariable",
        "label_encoding": "mls:labelEncoding",
        "model_path": "mls:modelPath",
        "serialization_format": "mls:serializationFormat",
        "model_version": "mls:modelVersion"
    }
}

# Rename fields according to the mapping
renamed_structured = {}
for category, content in structured.items():
    new_fields = {}
    if category in rename_map:
        for k, v in content.items():
            new_key = rename_map[category].get(k, k)
            new_fields[new_key] = v
    else:
        new_fields = content  # Keep uncategorized untouched
    renamed_structured[category] = new_fields

# Save renamed output
output_path = "structured_metadata_renamed.json"
with open(output_path, "w", encoding="utf-8") as f:
    json.dump(renamed_structured, f, indent=2, ensure_ascii=False)

output_path




